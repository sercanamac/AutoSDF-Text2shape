{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ddad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ./launchers/train_new_bert.sh: Permission denied\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_new_bert.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9b0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autosdf.yaml\t\t      filelists\t\t      README.md\r\n",
      "Compare.ipynb\t\t      info-shapenet.json      results\r\n",
      "configs\t\t\t      launchers\t\t      shape_set_paths.json\r\n",
      "datasets\t\t      logs\t\t      Test-Reproduce.ipynb\r\n",
      "demo_data\t\t      logs2\t\t      test_samples_paper.txt\r\n",
      "demo-lang-conditional.ipynb   models\t\t      text2ShapePP.json\r\n",
      "demo_shape_comp.ipynb\t      New-Bert-Sandbox.ipynb  train.py\r\n",
      "demo_single_view_recon.ipynb  NewBetTrain.ipynb       utils\r\n",
      "extract_code.py\t\t      options\r\n",
      "file.json\t\t      preprocess\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03f6cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 32\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: text2shape-seq\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: ./logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 100000000000\n",
      "model: bert2vqsc_v4\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "ndf: 64\n",
      "nepochs: 20\n",
      "nepochs_decay: 5\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: Text2Shape\n",
      "[*] # training images = 140707\n",
      "[*] # testing images = 16000\n",
      "---------- Networks initialized -------------\n",
      "-----------------------------------------------\n",
      "[*] Model has been created: BERT2VQSC-Model\n",
      "[*] \"bert2vqsc_v4\" initialized.\n",
      "[*] create image directory:\n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3/images...\n",
      "[*] saving model and dataset files: /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py, /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/datasets/text2shape.py\n",
      "140707 Length train dataset\n",
      "16000 Length test dataset\n",
      "4397 Length train_dl\n",
      "500 Length test_dl\n",
      "[*] Start training. name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.030) nll: 4.995050 \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3199/4397 [16:10<05:09,  3.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.030) nll: 4.894806 \n",
      "(GPU: 0, epoch: 0, iters: 800, time: 0.008) nll: 1.562692 \n",
      "(GPU: 0, epoch: 0, iters: 1600, time: 0.008) nll: 1.293296 \n",
      "(GPU: 0, epoch: 0, iters: 2400, time: 0.003) nll: 1.102239 \n",
      "(GPU: 0, epoch: 0, iters: 3200, time: 0.008) nll: 1.119818 \n",
      "(GPU: 0, epoch: 0, iters: 4000, time: 0.008) nll: 0.888545 \n",
      "(GPU: 0, epoch: 0, iters: 4800, time: 0.008) nll: 0.750814 \n",
      "(GPU: 0, epoch: 0, iters: 5600, time: 0.008) nll: 0.626922 \n",
      "(GPU: 0, epoch: 0, iters: 6400, time: 0.008) nll: 0.913535 \n",
      "(GPU: 0, epoch: 0, iters: 7200, time: 0.008) nll: 0.804176 \n",
      "(GPU: 0, epoch: 0, iters: 8000, time: 0.008) nll: 0.787771 \n",
      "(GPU: 0, epoch: 0, iters: 8800, time: 0.008) nll: 0.823192 \n",
      "(GPU: 0, epoch: 0, iters: 9600, time: 0.008) nll: 1.146183 \n",
      "(GPU: 0, epoch: 0, iters: 10400, time: 0.008) nll: 0.842355 \n",
      "(GPU: 0, epoch: 0, iters: 11200, time: 0.008) nll: 0.668579 \n",
      "(GPU: 0, epoch: 0, iters: 12000, time: 0.007) nll: 0.646945 \n",
      "(GPU: 0, epoch: 0, iters: 12800, time: 0.008) nll: 0.885720 \n",
      "(GPU: 0, epoch: 0, iters: 13600, time: 0.008) nll: 0.882439 \n",
      "(GPU: 0, epoch: 0, iters: 14400, time: 0.008) nll: 0.626609 \n",
      "(GPU: 0, epoch: 0, iters: 15200, time: 0.008) nll: 0.831820 \n",
      "(GPU: 0, epoch: 0, iters: 16000, time: 0.008) nll: 1.067544 \n",
      "(GPU: 0, epoch: 0, iters: 16800, time: 0.008) nll: 0.750834 \n",
      "(GPU: 0, epoch: 0, iters: 17600, time: 0.008) nll: 0.739008 \n",
      "(GPU: 0, epoch: 0, iters: 18400, time: 0.008) nll: 1.116472 \n",
      "(GPU: 0, epoch: 0, iters: 19200, time: 0.008) nll: 1.263572 \n",
      "(GPU: 0, epoch: 0, iters: 20000, time: 0.008) nll: 0.644133 \n",
      "saving the latest model (epoch 0, total_steps 20000)\n",
      "(GPU: 0, epoch: 0, iters: 20800, time: 0.008) nll: 0.666576 \n",
      "(GPU: 0, epoch: 0, iters: 21600, time: 0.008) nll: 0.887895 \n",
      "(GPU: 0, epoch: 0, iters: 22400, time: 0.008) nll: 0.747720 \n",
      "(GPU: 0, epoch: 0, iters: 23200, time: 0.008) nll: 0.738577 \n",
      "(GPU: 0, epoch: 0, iters: 24000, time: 0.008) nll: 0.709614 \n",
      "(GPU: 0, epoch: 0, iters: 24800, time: 0.008) nll: 0.991513 \n",
      "(GPU: 0, epoch: 0, iters: 25600, time: 0.008) nll: 0.679304 \n",
      "(GPU: 0, epoch: 0, iters: 26400, time: 0.008) nll: 0.633564 \n",
      "(GPU: 0, epoch: 0, iters: 27200, time: 0.008) nll: 0.929073 \n",
      "(GPU: 0, epoch: 0, iters: 28000, time: 0.008) nll: 0.674822 \n",
      "(GPU: 0, epoch: 0, iters: 28800, time: 0.008) nll: 0.969199 \n",
      "(GPU: 0, epoch: 0, iters: 29600, time: 0.008) nll: 0.836343 \n",
      "(GPU: 0, epoch: 0, iters: 30400, time: 0.008) nll: 0.901406 \n",
      "(GPU: 0, epoch: 0, iters: 31200, time: 0.008) nll: 0.570663 \n",
      "(GPU: 0, epoch: 0, iters: 32000, time: 0.008) nll: 0.649749 \n",
      "(GPU: 0, epoch: 0, iters: 32800, time: 0.008) nll: 0.722726 \n",
      "(GPU: 0, epoch: 0, iters: 33600, time: 0.008) nll: 0.696332 \n",
      "(GPU: 0, epoch: 0, iters: 34400, time: 0.008) nll: 0.794590 \n",
      "(GPU: 0, epoch: 0, iters: 35200, time: 0.008) nll: 0.509807 \n",
      "(GPU: 0, epoch: 0, iters: 36000, time: 0.008) nll: 0.913422 \n",
      "(GPU: 0, epoch: 0, iters: 36800, time: 0.008) nll: 0.789697 \n",
      "(GPU: 0, epoch: 0, iters: 37600, time: 0.008) nll: 0.768525 \n",
      "(GPU: 0, epoch: 0, iters: 38400, time: 0.008) nll: 1.148917 \n",
      "(GPU: 0, epoch: 0, iters: 39200, time: 0.007) nll: 1.410529 \n",
      "(GPU: 0, epoch: 0, iters: 40000, time: 0.008) nll: 0.879906 \n",
      "saving the latest model (epoch 0, total_steps 40000)\n",
      "(GPU: 0, epoch: 0, iters: 40800, time: 0.008) nll: 0.934113 \n",
      "(GPU: 0, epoch: 0, iters: 41600, time: 0.008) nll: 0.616262 \n",
      "(GPU: 0, epoch: 0, iters: 42400, time: 0.008) nll: 0.905188 \n",
      "(GPU: 0, epoch: 0, iters: 43200, time: 0.008) nll: 0.598318 \n",
      "(GPU: 0, epoch: 0, iters: 44000, time: 0.008) nll: 1.235860 \n",
      "(GPU: 0, epoch: 0, iters: 44800, time: 0.008) nll: 0.894215 \n",
      "(GPU: 0, epoch: 0, iters: 45600, time: 0.008) nll: 0.781687 \n",
      "(GPU: 0, epoch: 0, iters: 46400, time: 0.008) nll: 0.554424 \n",
      "(GPU: 0, epoch: 0, iters: 47200, time: 0.008) nll: 0.727532 \n",
      "(GPU: 0, epoch: 0, iters: 48000, time: 0.008) nll: 0.818647 \n",
      "(GPU: 0, epoch: 0, iters: 48800, time: 0.008) nll: 0.762346 \n",
      "(GPU: 0, epoch: 0, iters: 49600, time: 0.008) nll: 0.770468 \n",
      "(GPU: 0, epoch: 0, iters: 50400, time: 0.008) nll: 0.494052 \n",
      "(GPU: 0, epoch: 0, iters: 51200, time: 0.008) nll: 0.674369 \n",
      "(GPU: 0, epoch: 0, iters: 52000, time: 0.008) nll: 0.906319 \n",
      "(GPU: 0, epoch: 0, iters: 52800, time: 0.008) nll: 0.856027 \n",
      "(GPU: 0, epoch: 0, iters: 53600, time: 0.008) nll: 0.507948 \n",
      "(GPU: 0, epoch: 0, iters: 54400, time: 0.008) nll: 0.721479 \n",
      "(GPU: 0, epoch: 0, iters: 55200, time: 0.008) nll: 0.569283 \n",
      "(GPU: 0, epoch: 0, iters: 56000, time: 0.008) nll: 0.832862 \n",
      "(GPU: 0, epoch: 0, iters: 56800, time: 0.007) nll: 0.815603 \n",
      "(GPU: 0, epoch: 0, iters: 57600, time: 0.008) nll: 0.951487 \n",
      "(GPU: 0, epoch: 0, iters: 58400, time: 0.008) nll: 0.655602 \n",
      "(GPU: 0, epoch: 0, iters: 59200, time: 0.008) nll: 0.792914 \n",
      "(GPU: 0, epoch: 0, iters: 60000, time: 0.008) nll: 0.581965 \n",
      "saving the latest model (epoch 0, total_steps 60000)\n",
      "(GPU: 0, epoch: 0, iters: 60800, time: 0.008) nll: 1.140707 \n",
      "(GPU: 0, epoch: 0, iters: 61600, time: 0.008) nll: 0.908312 \n",
      "(GPU: 0, epoch: 0, iters: 62400, time: 0.008) nll: 0.706808 \n",
      "(GPU: 0, epoch: 0, iters: 63200, time: 0.008) nll: 1.003334 \n",
      "(GPU: 0, epoch: 0, iters: 64000, time: 0.008) nll: 0.822358 \n",
      "(GPU: 0, epoch: 0, iters: 64800, time: 0.008) nll: 0.601500 \n",
      "(GPU: 0, epoch: 0, iters: 65600, time: 0.008) nll: 0.718726 \n",
      "(GPU: 0, epoch: 0, iters: 66400, time: 0.008) nll: 0.808151 \n",
      "(GPU: 0, epoch: 0, iters: 67200, time: 0.008) nll: 0.656591 \n",
      "(GPU: 0, epoch: 0, iters: 68000, time: 0.008) nll: 1.218851 \n",
      "(GPU: 0, epoch: 0, iters: 68800, time: 0.008) nll: 0.738442 \n",
      "(GPU: 0, epoch: 0, iters: 69600, time: 0.008) nll: 0.811900 \n",
      "(GPU: 0, epoch: 0, iters: 70400, time: 0.008) nll: 0.554798 \n",
      "(GPU: 0, epoch: 0, iters: 71200, time: 0.008) nll: 0.757984 \n",
      "(GPU: 0, epoch: 0, iters: 72000, time: 0.008) nll: 0.585331 \n",
      "(GPU: 0, epoch: 0, iters: 72800, time: 0.008) nll: 0.523719 \n",
      "(GPU: 0, epoch: 0, iters: 73600, time: 0.008) nll: 0.564519 \n",
      "(GPU: 0, epoch: 0, iters: 74400, time: 0.008) nll: 1.023432 \n",
      "(GPU: 0, epoch: 0, iters: 75200, time: 0.008) nll: 0.701574 \n",
      "(GPU: 0, epoch: 0, iters: 76000, time: 0.008) nll: 0.672820 \n",
      "(GPU: 0, epoch: 0, iters: 76800, time: 0.008) nll: 0.715341 \n",
      "(GPU: 0, epoch: 0, iters: 77600, time: 0.008) nll: 0.779302 \n",
      "(GPU: 0, epoch: 0, iters: 78400, time: 0.008) nll: 0.476576 \n",
      "(GPU: 0, epoch: 0, iters: 79200, time: 0.008) nll: 0.825883 \n",
      "(GPU: 0, epoch: 0, iters: 80000, time: 0.008) nll: 0.534431 \n",
      "saving the latest model (epoch 0, total_steps 80000)\n",
      "(GPU: 0, epoch: 0, iters: 80800, time: 0.008) nll: 0.868109 \n",
      "(GPU: 0, epoch: 0, iters: 81600, time: 0.008) nll: 0.518722 \n",
      "(GPU: 0, epoch: 0, iters: 82400, time: 0.008) nll: 0.754122 \n",
      "(GPU: 0, epoch: 0, iters: 83200, time: 0.008) nll: 0.831546 \n",
      "(GPU: 0, epoch: 0, iters: 84000, time: 0.008) nll: 0.665887 \n",
      "(GPU: 0, epoch: 0, iters: 84800, time: 0.008) nll: 0.784717 \n",
      "(GPU: 0, epoch: 0, iters: 85600, time: 0.008) nll: 0.743814 \n",
      "(GPU: 0, epoch: 0, iters: 86400, time: 0.008) nll: 0.820217 \n",
      "(GPU: 0, epoch: 0, iters: 87200, time: 0.008) nll: 0.719722 \n",
      "(GPU: 0, epoch: 0, iters: 88000, time: 0.008) nll: 0.941098 \n",
      "(GPU: 0, epoch: 0, iters: 88800, time: 0.008) nll: 1.160777 \n",
      "(GPU: 0, epoch: 0, iters: 89600, time: 0.008) nll: 0.655990 \n",
      "(GPU: 0, epoch: 0, iters: 90400, time: 0.008) nll: 0.552194 \n",
      "(GPU: 0, epoch: 0, iters: 91200, time: 0.008) nll: 0.961340 \n",
      "(GPU: 0, epoch: 0, iters: 92000, time: 0.008) nll: 0.916050 \n",
      "(GPU: 0, epoch: 0, iters: 92800, time: 0.008) nll: 0.707473 \n",
      "(GPU: 0, epoch: 0, iters: 93600, time: 0.008) nll: 0.573712 \n",
      "(GPU: 0, epoch: 0, iters: 94400, time: 0.008) nll: 0.749211 \n",
      "(GPU: 0, epoch: 0, iters: 95200, time: 0.008) nll: 0.810713 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.008) nll: 0.711049 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.013) nll: 0.688846 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.013) nll: 0.720591 \n",
      "(GPU: 0, epoch: 0, iters: 96800, time: 0.008) nll: 0.799393 \n",
      "(GPU: 0, epoch: 0, iters: 97600, time: 0.008) nll: 0.575768 \n",
      "(GPU: 0, epoch: 0, iters: 98400, time: 0.008) nll: 0.590663 \n",
      "(GPU: 0, epoch: 0, iters: 99200, time: 0.008) nll: 1.018325 \n",
      "(GPU: 0, epoch: 0, iters: 100000, time: 0.008) nll: 1.287839 \n",
      "saving the latest model (epoch 0, total_steps 100000)\n",
      "(GPU: 0, epoch: 0, iters: 100800, time: 0.008) nll: 0.848179 \n",
      "(GPU: 0, epoch: 0, iters: 101600, time: 0.008) nll: 0.870916 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [21:50<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 102400, time: 0.008) nll: 0.900561 \n",
      "(GPU: 0, epoch: 0, iters: 103200, time: 0.007) nll: 0.435055 \n",
      "(GPU: 0, epoch: 0, iters: 104000, time: 0.008) nll: 0.773573 \n",
      "(GPU: 0, epoch: 0, iters: 104800, time: 0.008) nll: 0.569316 \n",
      "(GPU: 0, epoch: 0, iters: 105600, time: 0.008) nll: 0.901372 \n",
      "(GPU: 0, epoch: 0, iters: 106400, time: 0.008) nll: 1.154306 \n",
      "(GPU: 0, epoch: 0, iters: 107200, time: 0.008) nll: 0.872681 \n",
      "(GPU: 0, epoch: 0, iters: 108000, time: 0.008) nll: 0.500670 \n",
      "(GPU: 0, epoch: 0, iters: 108800, time: 0.008) nll: 0.573528 \n",
      "(GPU: 0, epoch: 0, iters: 109600, time: 0.008) nll: 0.872204 \n",
      "(GPU: 0, epoch: 0, iters: 110400, time: 0.008) nll: 0.828815 \n",
      "(GPU: 0, epoch: 0, iters: 111200, time: 0.008) nll: 0.846723 \n",
      "(GPU: 0, epoch: 0, iters: 112000, time: 0.008) nll: 0.838311 \n",
      "(GPU: 0, epoch: 0, iters: 112800, time: 0.008) nll: 0.647624 \n",
      "(GPU: 0, epoch: 0, iters: 113600, time: 0.008) nll: 0.682238 \n",
      "(GPU: 0, epoch: 0, iters: 114400, time: 0.008) nll: 0.459970 \n",
      "(GPU: 0, epoch: 0, iters: 115200, time: 0.008) nll: 0.789516 \n",
      "(GPU: 0, epoch: 0, iters: 116000, time: 0.008) nll: 0.690815 \n",
      "(GPU: 0, epoch: 0, iters: 116800, time: 0.008) nll: 0.519668 \n",
      "(GPU: 0, epoch: 0, iters: 117600, time: 0.008) nll: 0.623156 \n",
      "(GPU: 0, epoch: 0, iters: 118400, time: 0.008) nll: 0.681970 \n",
      "(GPU: 0, epoch: 0, iters: 119200, time: 0.008) nll: 0.843949 \n",
      "(GPU: 0, epoch: 0, iters: 120000, time: 0.008) nll: 0.602227 \n",
      "saving the latest model (epoch 0, total_steps 120000)\n",
      "(GPU: 0, epoch: 0, iters: 120800, time: 0.008) nll: 0.626814 \n",
      "(GPU: 0, epoch: 0, iters: 121600, time: 0.008) nll: 0.735942 \n",
      "(GPU: 0, epoch: 0, iters: 122400, time: 0.008) nll: 0.793765 \n",
      "(GPU: 0, epoch: 0, iters: 123200, time: 0.008) nll: 0.794400 \n",
      "(GPU: 0, epoch: 0, iters: 124000, time: 0.008) nll: 0.828750 \n",
      "(GPU: 0, epoch: 0, iters: 124800, time: 0.008) nll: 0.797351 \n",
      "(GPU: 0, epoch: 0, iters: 125600, time: 0.008) nll: 0.641447 \n",
      "(GPU: 0, epoch: 0, iters: 126400, time: 0.008) nll: 0.814469 \n",
      "(GPU: 0, epoch: 0, iters: 127200, time: 0.008) nll: 0.633113 \n",
      "(GPU: 0, epoch: 0, iters: 128000, time: 0.008) nll: 0.794828 \n",
      "(GPU: 0, epoch: 0, iters: 128800, time: 0.008) nll: 0.689504 \n",
      "(GPU: 0, epoch: 0, iters: 129600, time: 0.008) nll: 0.679961 \n",
      "(GPU: 0, epoch: 0, iters: 130400, time: 0.008) nll: 0.840294 \n",
      "(GPU: 0, epoch: 0, iters: 131200, time: 0.008) nll: 0.644621 \n",
      "(GPU: 0, epoch: 0, iters: 132000, time: 0.008) nll: 0.731470 \n",
      "(GPU: 0, epoch: 0, iters: 132800, time: 0.008) nll: 0.719579 \n",
      "(GPU: 0, epoch: 0, iters: 133600, time: 0.008) nll: 0.780847 \n",
      "(GPU: 0, epoch: 0, iters: 134400, time: 0.008) nll: 0.388835 \n",
      "(GPU: 0, epoch: 0, iters: 135200, time: 0.008) nll: 0.798588 \n",
      "(GPU: 0, epoch: 0, iters: 136000, time: 0.008) nll: 0.857682 \n",
      "(GPU: 0, epoch: 0, iters: 136800, time: 0.008) nll: 0.696523 \n",
      "(GPU: 0, epoch: 0, iters: 137600, time: 0.008) nll: 0.688672 \n",
      "(GPU: 0, epoch: 0, iters: 138400, time: 0.008) nll: 0.558402 \n",
      "(GPU: 0, epoch: 0, iters: 139200, time: 0.008) nll: 0.526230 \n",
      "(GPU: 0, epoch: 0, iters: 140000, time: 0.007) nll: 0.620263 \n",
      "saving the latest model (epoch 0, total_steps 140000)\n",
      "saving the model at the end of epoch 0, iters 140704\n",
      "([test] GPU: 0, epoch: 0) \n",
      "OrderedDict()\n",
      "[*] End of epoch 0 / 25 \t Time Taken: 1339 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000100\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3152/4397 [14:45<05:19,  3.90it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 32, time: 0.004) nll: 0.660433 \n",
      "(GPU: 0, epoch: 1, iters: 32, time: 0.004) nll: 0.899621 \n",
      "(GPU: 0, epoch: 1, iters: 96, time: 0.008) nll: 0.633818 \n",
      "(GPU: 0, epoch: 1, iters: 896, time: 0.008) nll: 0.989110 \n",
      "(GPU: 0, epoch: 1, iters: 1696, time: 0.008) nll: 0.776940 \n",
      "(GPU: 0, epoch: 1, iters: 2496, time: 0.008) nll: 0.667468 \n",
      "(GPU: 0, epoch: 1, iters: 3296, time: 0.008) nll: 0.599464 \n",
      "(GPU: 0, epoch: 1, iters: 4096, time: 0.008) nll: 0.593261 \n",
      "(GPU: 0, epoch: 1, iters: 4896, time: 0.008) nll: 0.803813 \n",
      "(GPU: 0, epoch: 1, iters: 5696, time: 0.008) nll: 1.300577 \n",
      "(GPU: 0, epoch: 1, iters: 6496, time: 0.007) nll: 0.793440 \n",
      "(GPU: 0, epoch: 1, iters: 7296, time: 0.008) nll: 0.724397 \n",
      "(GPU: 0, epoch: 1, iters: 8096, time: 0.008) nll: 1.158463 \n",
      "(GPU: 0, epoch: 1, iters: 8896, time: 0.008) nll: 0.386979 \n",
      "(GPU: 0, epoch: 1, iters: 9696, time: 0.008) nll: 0.787808 \n",
      "(GPU: 0, epoch: 1, iters: 10496, time: 0.008) nll: 0.631377 \n",
      "(GPU: 0, epoch: 1, iters: 11296, time: 0.008) nll: 0.813564 \n",
      "(GPU: 0, epoch: 1, iters: 12096, time: 0.008) nll: 0.761652 \n",
      "(GPU: 0, epoch: 1, iters: 12896, time: 0.008) nll: 0.721769 \n",
      "(GPU: 0, epoch: 1, iters: 13696, time: 0.008) nll: 0.579139 \n",
      "(GPU: 0, epoch: 1, iters: 14496, time: 0.008) nll: 0.707670 \n",
      "(GPU: 0, epoch: 1, iters: 15296, time: 0.008) nll: 0.753521 \n",
      "(GPU: 0, epoch: 1, iters: 16096, time: 0.008) nll: 0.699658 \n",
      "(GPU: 0, epoch: 1, iters: 16896, time: 0.008) nll: 0.840896 \n",
      "(GPU: 0, epoch: 1, iters: 17696, time: 0.008) nll: 0.717496 \n",
      "(GPU: 0, epoch: 1, iters: 18496, time: 0.008) nll: 0.570583 \n",
      "(GPU: 0, epoch: 1, iters: 19296, time: 0.008) nll: 0.787456 \n",
      "saving the latest model (epoch 1, total_steps 160000)\n",
      "(GPU: 0, epoch: 1, iters: 20096, time: 0.008) nll: 0.609948 \n",
      "(GPU: 0, epoch: 1, iters: 20896, time: 0.008) nll: 0.642235 \n",
      "(GPU: 0, epoch: 1, iters: 21696, time: 0.008) nll: 0.488164 \n",
      "(GPU: 0, epoch: 1, iters: 22496, time: 0.008) nll: 0.895524 \n",
      "(GPU: 0, epoch: 1, iters: 23296, time: 0.008) nll: 0.558862 \n",
      "(GPU: 0, epoch: 1, iters: 24096, time: 0.008) nll: 0.526350 \n",
      "(GPU: 0, epoch: 1, iters: 24896, time: 0.008) nll: 0.849816 \n",
      "(GPU: 0, epoch: 1, iters: 25696, time: 0.008) nll: 0.705427 \n",
      "(GPU: 0, epoch: 1, iters: 26496, time: 0.008) nll: 0.628635 \n",
      "(GPU: 0, epoch: 1, iters: 27296, time: 0.008) nll: 0.953024 \n",
      "(GPU: 0, epoch: 1, iters: 28096, time: 0.008) nll: 0.867117 \n",
      "(GPU: 0, epoch: 1, iters: 28896, time: 0.008) nll: 0.669179 \n",
      "(GPU: 0, epoch: 1, iters: 29696, time: 0.008) nll: 0.682034 \n",
      "(GPU: 0, epoch: 1, iters: 30496, time: 0.008) nll: 0.872534 \n",
      "(GPU: 0, epoch: 1, iters: 31296, time: 0.008) nll: 0.844415 \n",
      "(GPU: 0, epoch: 1, iters: 32096, time: 0.008) nll: 0.655942 \n",
      "(GPU: 0, epoch: 1, iters: 32896, time: 0.008) nll: 0.647264 \n",
      "(GPU: 0, epoch: 1, iters: 33696, time: 0.008) nll: 0.678173 \n",
      "(GPU: 0, epoch: 1, iters: 34496, time: 0.008) nll: 0.896478 \n",
      "(GPU: 0, epoch: 1, iters: 35296, time: 0.008) nll: 0.455145 \n",
      "(GPU: 0, epoch: 1, iters: 36096, time: 0.008) nll: 0.569909 \n",
      "(GPU: 0, epoch: 1, iters: 36896, time: 0.008) nll: 1.029369 \n",
      "(GPU: 0, epoch: 1, iters: 37696, time: 0.008) nll: 0.642658 \n",
      "(GPU: 0, epoch: 1, iters: 38496, time: 0.008) nll: 0.764892 \n",
      "(GPU: 0, epoch: 1, iters: 39296, time: 0.008) nll: 0.730744 \n",
      "saving the latest model (epoch 1, total_steps 180000)\n",
      "(GPU: 0, epoch: 1, iters: 40096, time: 0.008) nll: 0.711014 \n",
      "(GPU: 0, epoch: 1, iters: 40896, time: 0.008) nll: 0.766105 \n",
      "(GPU: 0, epoch: 1, iters: 41696, time: 0.008) nll: 0.603384 \n",
      "(GPU: 0, epoch: 1, iters: 42496, time: 0.008) nll: 0.956922 \n",
      "(GPU: 0, epoch: 1, iters: 43296, time: 0.008) nll: 0.774488 \n",
      "(GPU: 0, epoch: 1, iters: 44096, time: 0.008) nll: 0.530673 \n",
      "(GPU: 0, epoch: 1, iters: 44896, time: 0.008) nll: 0.559676 \n",
      "(GPU: 0, epoch: 1, iters: 45696, time: 0.008) nll: 0.780900 \n",
      "(GPU: 0, epoch: 1, iters: 46496, time: 0.008) nll: 0.572705 \n",
      "(GPU: 0, epoch: 1, iters: 47296, time: 0.008) nll: 0.676045 \n",
      "(GPU: 0, epoch: 1, iters: 48096, time: 0.007) nll: 0.650697 \n",
      "(GPU: 0, epoch: 1, iters: 48896, time: 0.008) nll: 0.579223 \n",
      "(GPU: 0, epoch: 1, iters: 49696, time: 0.008) nll: 0.839883 \n",
      "(GPU: 0, epoch: 1, iters: 50496, time: 0.008) nll: 0.773065 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.008) nll: 0.418500 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.013) nll: 0.413249 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.013) nll: 0.603404 \n",
      "(GPU: 0, epoch: 1, iters: 52096, time: 0.008) nll: 0.714602 \n",
      "(GPU: 0, epoch: 1, iters: 52896, time: 0.007) nll: 0.828540 \n",
      "(GPU: 0, epoch: 1, iters: 53696, time: 0.008) nll: 0.705552 \n",
      "(GPU: 0, epoch: 1, iters: 54496, time: 0.008) nll: 1.038273 \n",
      "(GPU: 0, epoch: 1, iters: 55296, time: 0.008) nll: 0.849668 \n",
      "(GPU: 0, epoch: 1, iters: 56096, time: 0.007) nll: 0.818987 \n",
      "(GPU: 0, epoch: 1, iters: 56896, time: 0.008) nll: 0.773489 \n",
      "(GPU: 0, epoch: 1, iters: 57696, time: 0.008) nll: 0.587731 \n",
      "(GPU: 0, epoch: 1, iters: 58496, time: 0.008) nll: 0.745638 \n",
      "(GPU: 0, epoch: 1, iters: 59296, time: 0.008) nll: 0.590173 \n",
      "saving the latest model (epoch 1, total_steps 200000)\n",
      "(GPU: 0, epoch: 1, iters: 60096, time: 0.008) nll: 0.443191 \n",
      "(GPU: 0, epoch: 1, iters: 60896, time: 0.008) nll: 0.725151 \n",
      "(GPU: 0, epoch: 1, iters: 61696, time: 0.008) nll: 0.736644 \n",
      "(GPU: 0, epoch: 1, iters: 62496, time: 0.008) nll: 0.613967 \n",
      "(GPU: 0, epoch: 1, iters: 63296, time: 0.008) nll: 0.855836 \n",
      "(GPU: 0, epoch: 1, iters: 64096, time: 0.008) nll: 0.741625 \n",
      "(GPU: 0, epoch: 1, iters: 64896, time: 0.008) nll: 0.651979 \n",
      "(GPU: 0, epoch: 1, iters: 65696, time: 0.008) nll: 0.580027 \n",
      "(GPU: 0, epoch: 1, iters: 66496, time: 0.008) nll: 0.568352 \n",
      "(GPU: 0, epoch: 1, iters: 67296, time: 0.008) nll: 0.771695 \n",
      "(GPU: 0, epoch: 1, iters: 68096, time: 0.008) nll: 0.911462 \n",
      "(GPU: 0, epoch: 1, iters: 68896, time: 0.007) nll: 0.511412 \n",
      "(GPU: 0, epoch: 1, iters: 69696, time: 0.008) nll: 1.349692 \n",
      "(GPU: 0, epoch: 1, iters: 70496, time: 0.008) nll: 0.828760 \n",
      "(GPU: 0, epoch: 1, iters: 71296, time: 0.008) nll: 0.721974 \n",
      "(GPU: 0, epoch: 1, iters: 72096, time: 0.007) nll: 0.703349 \n",
      "(GPU: 0, epoch: 1, iters: 72896, time: 0.008) nll: 0.833586 \n",
      "(GPU: 0, epoch: 1, iters: 73696, time: 0.008) nll: 0.876889 \n",
      "(GPU: 0, epoch: 1, iters: 74496, time: 0.008) nll: 0.747811 \n",
      "(GPU: 0, epoch: 1, iters: 75296, time: 0.008) nll: 0.573947 \n",
      "(GPU: 0, epoch: 1, iters: 76096, time: 0.008) nll: 0.680950 \n",
      "(GPU: 0, epoch: 1, iters: 76896, time: 0.008) nll: 0.536583 \n",
      "(GPU: 0, epoch: 1, iters: 77696, time: 0.008) nll: 0.564977 \n",
      "(GPU: 0, epoch: 1, iters: 78496, time: 0.008) nll: 0.719526 \n",
      "(GPU: 0, epoch: 1, iters: 79296, time: 0.008) nll: 0.579936 \n",
      "saving the latest model (epoch 1, total_steps 220000)\n",
      "(GPU: 0, epoch: 1, iters: 80096, time: 0.008) nll: 0.635604 \n",
      "(GPU: 0, epoch: 1, iters: 80896, time: 0.008) nll: 0.583521 \n",
      "(GPU: 0, epoch: 1, iters: 81696, time: 0.008) nll: 0.827134 \n",
      "(GPU: 0, epoch: 1, iters: 82496, time: 0.008) nll: 0.981392 \n",
      "(GPU: 0, epoch: 1, iters: 83296, time: 0.008) nll: 0.478685 \n",
      "(GPU: 0, epoch: 1, iters: 84096, time: 0.008) nll: 0.806586 \n",
      "(GPU: 0, epoch: 1, iters: 84896, time: 0.008) nll: 0.541876 \n",
      "(GPU: 0, epoch: 1, iters: 85696, time: 0.008) nll: 0.912285 \n",
      "(GPU: 0, epoch: 1, iters: 86496, time: 0.008) nll: 0.914906 \n",
      "(GPU: 0, epoch: 1, iters: 87296, time: 0.008) nll: 0.545568 \n",
      "(GPU: 0, epoch: 1, iters: 88096, time: 0.007) nll: 0.752530 \n",
      "(GPU: 0, epoch: 1, iters: 88896, time: 0.008) nll: 0.680586 \n",
      "(GPU: 0, epoch: 1, iters: 89696, time: 0.008) nll: 0.777462 \n",
      "(GPU: 0, epoch: 1, iters: 90496, time: 0.008) nll: 0.579866 \n",
      "(GPU: 0, epoch: 1, iters: 91296, time: 0.008) nll: 0.648492 \n",
      "(GPU: 0, epoch: 1, iters: 92096, time: 0.008) nll: 0.648574 \n",
      "(GPU: 0, epoch: 1, iters: 92896, time: 0.008) nll: 0.713803 \n",
      "(GPU: 0, epoch: 1, iters: 93696, time: 0.008) nll: 0.691256 \n",
      "(GPU: 0, epoch: 1, iters: 94496, time: 0.008) nll: 0.844629 \n",
      "(GPU: 0, epoch: 1, iters: 95296, time: 0.008) nll: 1.146238 \n",
      "(GPU: 0, epoch: 1, iters: 96096, time: 0.008) nll: 0.660897 \n",
      "(GPU: 0, epoch: 1, iters: 96896, time: 0.008) nll: 0.776608 \n",
      "(GPU: 0, epoch: 1, iters: 97696, time: 0.008) nll: 0.642122 \n",
      "(GPU: 0, epoch: 1, iters: 98496, time: 0.008) nll: 0.768895 \n",
      "(GPU: 0, epoch: 1, iters: 99296, time: 0.008) nll: 0.699961 \n",
      "saving the latest model (epoch 1, total_steps 240000)\n",
      "(GPU: 0, epoch: 1, iters: 100096, time: 0.008) nll: 0.492260 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:34<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 100896, time: 0.008) nll: 0.595046 \n",
      "(GPU: 0, epoch: 1, iters: 101696, time: 0.008) nll: 0.721410 \n",
      "(GPU: 0, epoch: 1, iters: 102496, time: 0.008) nll: 0.544176 \n",
      "(GPU: 0, epoch: 1, iters: 103296, time: 0.008) nll: 0.798497 \n",
      "(GPU: 0, epoch: 1, iters: 104096, time: 0.008) nll: 0.612179 \n",
      "(GPU: 0, epoch: 1, iters: 104896, time: 0.008) nll: 0.684085 \n",
      "(GPU: 0, epoch: 1, iters: 105696, time: 0.008) nll: 0.780857 \n",
      "(GPU: 0, epoch: 1, iters: 106496, time: 0.008) nll: 0.728421 \n",
      "(GPU: 0, epoch: 1, iters: 107296, time: 0.008) nll: 0.665451 \n",
      "(GPU: 0, epoch: 1, iters: 108096, time: 0.008) nll: 0.874688 \n",
      "(GPU: 0, epoch: 1, iters: 108896, time: 0.008) nll: 0.723691 \n",
      "(GPU: 0, epoch: 1, iters: 109696, time: 0.008) nll: 0.843818 \n",
      "(GPU: 0, epoch: 1, iters: 110496, time: 0.008) nll: 0.698562 \n",
      "(GPU: 0, epoch: 1, iters: 111296, time: 0.008) nll: 0.635748 \n",
      "(GPU: 0, epoch: 1, iters: 112096, time: 0.008) nll: 1.000165 \n",
      "(GPU: 0, epoch: 1, iters: 112896, time: 0.008) nll: 0.881316 \n",
      "(GPU: 0, epoch: 1, iters: 113696, time: 0.007) nll: 0.507869 \n",
      "(GPU: 0, epoch: 1, iters: 114496, time: 0.008) nll: 0.921722 \n",
      "(GPU: 0, epoch: 1, iters: 115296, time: 0.008) nll: 0.763298 \n",
      "(GPU: 0, epoch: 1, iters: 116096, time: 0.008) nll: 0.611927 \n",
      "(GPU: 0, epoch: 1, iters: 116896, time: 0.008) nll: 0.597851 \n",
      "(GPU: 0, epoch: 1, iters: 117696, time: 0.008) nll: 0.787677 \n",
      "(GPU: 0, epoch: 1, iters: 118496, time: 0.008) nll: 0.865576 \n",
      "(GPU: 0, epoch: 1, iters: 119296, time: 0.008) nll: 0.865164 \n",
      "saving the latest model (epoch 1, total_steps 260000)\n",
      "(GPU: 0, epoch: 1, iters: 120096, time: 0.008) nll: 0.975556 \n",
      "(GPU: 0, epoch: 1, iters: 120896, time: 0.008) nll: 0.660336 \n",
      "(GPU: 0, epoch: 1, iters: 121696, time: 0.008) nll: 0.804057 \n",
      "(GPU: 0, epoch: 1, iters: 122496, time: 0.008) nll: 1.170410 \n",
      "(GPU: 0, epoch: 1, iters: 123296, time: 0.008) nll: 0.653134 \n",
      "(GPU: 0, epoch: 1, iters: 124096, time: 0.008) nll: 0.628145 \n",
      "(GPU: 0, epoch: 1, iters: 124896, time: 0.008) nll: 0.777883 \n",
      "(GPU: 0, epoch: 1, iters: 125696, time: 0.008) nll: 0.743746 \n",
      "(GPU: 0, epoch: 1, iters: 126496, time: 0.007) nll: 0.656347 \n",
      "(GPU: 0, epoch: 1, iters: 127296, time: 0.008) nll: 0.676624 \n",
      "(GPU: 0, epoch: 1, iters: 128096, time: 0.008) nll: 0.650803 \n",
      "(GPU: 0, epoch: 1, iters: 128896, time: 0.008) nll: 0.722396 \n",
      "(GPU: 0, epoch: 1, iters: 129696, time: 0.008) nll: 0.716478 \n",
      "(GPU: 0, epoch: 1, iters: 130496, time: 0.008) nll: 0.577361 \n",
      "(GPU: 0, epoch: 1, iters: 131296, time: 0.008) nll: 0.642229 \n",
      "(GPU: 0, epoch: 1, iters: 132096, time: 0.008) nll: 0.847462 \n",
      "(GPU: 0, epoch: 1, iters: 132896, time: 0.008) nll: 0.505245 \n",
      "(GPU: 0, epoch: 1, iters: 133696, time: 0.008) nll: 0.896436 \n",
      "(GPU: 0, epoch: 1, iters: 134496, time: 0.008) nll: 0.818955 \n",
      "(GPU: 0, epoch: 1, iters: 135296, time: 0.008) nll: 0.775045 \n",
      "(GPU: 0, epoch: 1, iters: 136096, time: 0.008) nll: 0.552480 \n",
      "(GPU: 0, epoch: 1, iters: 136896, time: 0.008) nll: 1.171083 \n",
      "(GPU: 0, epoch: 1, iters: 137696, time: 0.008) nll: 0.672793 \n",
      "(GPU: 0, epoch: 1, iters: 138496, time: 0.008) nll: 0.837458 \n",
      "(GPU: 0, epoch: 1, iters: 139296, time: 0.007) nll: 0.785251 \n",
      "saving the latest model (epoch 1, total_steps 280000)\n",
      "(GPU: 0, epoch: 1, iters: 140096, time: 0.008) nll: 0.530782 \n",
      "[*] End of epoch 1 / 25 \t Time Taken: 1235 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000200\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3155/4397 [14:44<05:20,  3.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 32, time: 0.004) nll: 0.875341 \n",
      "(GPU: 0, epoch: 2, iters: 32, time: 0.004) nll: 0.425455 \n",
      "(GPU: 0, epoch: 2, iters: 192, time: 0.008) nll: 0.679939 \n",
      "(GPU: 0, epoch: 2, iters: 992, time: 0.008) nll: 0.880174 \n",
      "(GPU: 0, epoch: 2, iters: 1792, time: 0.008) nll: 0.699727 \n",
      "(GPU: 0, epoch: 2, iters: 2592, time: 0.008) nll: 0.658737 \n",
      "(GPU: 0, epoch: 2, iters: 3392, time: 0.008) nll: 0.582349 \n",
      "(GPU: 0, epoch: 2, iters: 4192, time: 0.008) nll: 0.636671 \n",
      "(GPU: 0, epoch: 2, iters: 4992, time: 0.008) nll: 0.627380 \n",
      "(GPU: 0, epoch: 2, iters: 5792, time: 0.008) nll: 0.569408 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.008) nll: 0.909176 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.013) nll: 0.896104 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.013) nll: 0.554434 \n",
      "(GPU: 0, epoch: 2, iters: 7392, time: 0.008) nll: 0.671156 \n",
      "(GPU: 0, epoch: 2, iters: 8192, time: 0.008) nll: 0.935899 \n",
      "(GPU: 0, epoch: 2, iters: 8992, time: 0.008) nll: 0.832479 \n",
      "(GPU: 0, epoch: 2, iters: 9792, time: 0.008) nll: 0.634479 \n",
      "(GPU: 0, epoch: 2, iters: 10592, time: 0.008) nll: 0.796278 \n",
      "(GPU: 0, epoch: 2, iters: 11392, time: 0.008) nll: 0.892645 \n",
      "(GPU: 0, epoch: 2, iters: 12192, time: 0.008) nll: 0.799255 \n",
      "(GPU: 0, epoch: 2, iters: 12992, time: 0.008) nll: 0.887463 \n",
      "(GPU: 0, epoch: 2, iters: 13792, time: 0.008) nll: 0.754973 \n",
      "(GPU: 0, epoch: 2, iters: 14592, time: 0.008) nll: 0.668190 \n",
      "(GPU: 0, epoch: 2, iters: 15392, time: 0.008) nll: 0.976240 \n",
      "(GPU: 0, epoch: 2, iters: 16192, time: 0.008) nll: 0.743506 \n",
      "(GPU: 0, epoch: 2, iters: 16992, time: 0.008) nll: 1.326392 \n",
      "(GPU: 0, epoch: 2, iters: 17792, time: 0.008) nll: 0.753847 \n",
      "(GPU: 0, epoch: 2, iters: 18592, time: 0.008) nll: 0.722408 \n",
      "saving the latest model (epoch 2, total_steps 300000)\n",
      "(GPU: 0, epoch: 2, iters: 19392, time: 0.008) nll: 0.871248 \n",
      "(GPU: 0, epoch: 2, iters: 20192, time: 0.008) nll: 0.710027 \n",
      "(GPU: 0, epoch: 2, iters: 20992, time: 0.008) nll: 0.554345 \n",
      "(GPU: 0, epoch: 2, iters: 21792, time: 0.008) nll: 0.581861 \n",
      "(GPU: 0, epoch: 2, iters: 22592, time: 0.008) nll: 0.713217 \n",
      "(GPU: 0, epoch: 2, iters: 23392, time: 0.008) nll: 0.528518 \n",
      "(GPU: 0, epoch: 2, iters: 24192, time: 0.008) nll: 0.834397 \n",
      "(GPU: 0, epoch: 2, iters: 24992, time: 0.008) nll: 0.739673 \n",
      "(GPU: 0, epoch: 2, iters: 25792, time: 0.008) nll: 0.899780 \n",
      "(GPU: 0, epoch: 2, iters: 26592, time: 0.008) nll: 0.766410 \n",
      "(GPU: 0, epoch: 2, iters: 27392, time: 0.008) nll: 0.591562 \n",
      "(GPU: 0, epoch: 2, iters: 28192, time: 0.007) nll: 0.742663 \n",
      "(GPU: 0, epoch: 2, iters: 28992, time: 0.008) nll: 0.656572 \n",
      "(GPU: 0, epoch: 2, iters: 29792, time: 0.007) nll: 0.773843 \n",
      "(GPU: 0, epoch: 2, iters: 30592, time: 0.008) nll: 0.780561 \n",
      "(GPU: 0, epoch: 2, iters: 31392, time: 0.008) nll: 0.689249 \n",
      "(GPU: 0, epoch: 2, iters: 32192, time: 0.008) nll: 0.612995 \n",
      "(GPU: 0, epoch: 2, iters: 32992, time: 0.008) nll: 0.892603 \n",
      "(GPU: 0, epoch: 2, iters: 33792, time: 0.008) nll: 0.814291 \n",
      "(GPU: 0, epoch: 2, iters: 34592, time: 0.008) nll: 0.705736 \n",
      "(GPU: 0, epoch: 2, iters: 35392, time: 0.008) nll: 0.727293 \n",
      "(GPU: 0, epoch: 2, iters: 36192, time: 0.008) nll: 0.862854 \n",
      "(GPU: 0, epoch: 2, iters: 36992, time: 0.008) nll: 0.996286 \n",
      "(GPU: 0, epoch: 2, iters: 37792, time: 0.008) nll: 0.540764 \n",
      "(GPU: 0, epoch: 2, iters: 38592, time: 0.008) nll: 0.596693 \n",
      "saving the latest model (epoch 2, total_steps 320000)\n",
      "(GPU: 0, epoch: 2, iters: 39392, time: 0.008) nll: 0.897547 \n",
      "(GPU: 0, epoch: 2, iters: 40192, time: 0.008) nll: 0.324646 \n",
      "(GPU: 0, epoch: 2, iters: 40992, time: 0.008) nll: 0.624820 \n",
      "(GPU: 0, epoch: 2, iters: 41792, time: 0.008) nll: 0.996414 \n",
      "(GPU: 0, epoch: 2, iters: 42592, time: 0.008) nll: 0.823284 \n",
      "(GPU: 0, epoch: 2, iters: 43392, time: 0.008) nll: 0.848031 \n",
      "(GPU: 0, epoch: 2, iters: 44192, time: 0.008) nll: 0.800666 \n",
      "(GPU: 0, epoch: 2, iters: 44992, time: 0.008) nll: 0.854433 \n",
      "(GPU: 0, epoch: 2, iters: 45792, time: 0.008) nll: 0.678155 \n",
      "(GPU: 0, epoch: 2, iters: 46592, time: 0.008) nll: 0.679821 \n",
      "(GPU: 0, epoch: 2, iters: 47392, time: 0.008) nll: 0.718639 \n",
      "(GPU: 0, epoch: 2, iters: 48192, time: 0.008) nll: 0.567793 \n",
      "(GPU: 0, epoch: 2, iters: 48992, time: 0.008) nll: 0.754319 \n",
      "(GPU: 0, epoch: 2, iters: 49792, time: 0.008) nll: 0.698400 \n",
      "(GPU: 0, epoch: 2, iters: 50592, time: 0.008) nll: 0.708588 \n",
      "(GPU: 0, epoch: 2, iters: 51392, time: 0.008) nll: 0.699316 \n",
      "(GPU: 0, epoch: 2, iters: 52192, time: 0.008) nll: 0.968449 \n",
      "(GPU: 0, epoch: 2, iters: 52992, time: 0.008) nll: 1.183921 \n",
      "(GPU: 0, epoch: 2, iters: 53792, time: 0.008) nll: 1.020541 \n",
      "(GPU: 0, epoch: 2, iters: 54592, time: 0.008) nll: 0.674938 \n",
      "(GPU: 0, epoch: 2, iters: 55392, time: 0.008) nll: 0.777396 \n",
      "(GPU: 0, epoch: 2, iters: 56192, time: 0.008) nll: 0.767846 \n",
      "(GPU: 0, epoch: 2, iters: 56992, time: 0.008) nll: 0.840750 \n",
      "(GPU: 0, epoch: 2, iters: 57792, time: 0.008) nll: 0.769656 \n",
      "(GPU: 0, epoch: 2, iters: 58592, time: 0.008) nll: 0.535405 \n",
      "saving the latest model (epoch 2, total_steps 340000)\n",
      "(GPU: 0, epoch: 2, iters: 59392, time: 0.008) nll: 0.793501 \n",
      "(GPU: 0, epoch: 2, iters: 60192, time: 0.008) nll: 0.640081 \n",
      "(GPU: 0, epoch: 2, iters: 60992, time: 0.008) nll: 0.807489 \n",
      "(GPU: 0, epoch: 2, iters: 61792, time: 0.008) nll: 0.879508 \n",
      "(GPU: 0, epoch: 2, iters: 62592, time: 0.008) nll: 0.955226 \n",
      "(GPU: 0, epoch: 2, iters: 63392, time: 0.007) nll: 0.841122 \n",
      "(GPU: 0, epoch: 2, iters: 64192, time: 0.008) nll: 1.627097 \n",
      "(GPU: 0, epoch: 2, iters: 64992, time: 0.008) nll: 0.753411 \n",
      "(GPU: 0, epoch: 2, iters: 65792, time: 0.008) nll: 0.538888 \n",
      "(GPU: 0, epoch: 2, iters: 66592, time: 0.008) nll: 1.174385 \n",
      "(GPU: 0, epoch: 2, iters: 67392, time: 0.008) nll: 0.953912 \n",
      "(GPU: 0, epoch: 2, iters: 68192, time: 0.008) nll: 0.755864 \n",
      "(GPU: 0, epoch: 2, iters: 68992, time: 0.008) nll: 0.580077 \n",
      "(GPU: 0, epoch: 2, iters: 69792, time: 0.007) nll: 0.764456 \n",
      "(GPU: 0, epoch: 2, iters: 70592, time: 0.008) nll: 0.784755 \n",
      "(GPU: 0, epoch: 2, iters: 71392, time: 0.008) nll: 0.575778 \n",
      "(GPU: 0, epoch: 2, iters: 72192, time: 0.008) nll: 0.710791 \n",
      "(GPU: 0, epoch: 2, iters: 72992, time: 0.008) nll: 0.702985 \n",
      "(GPU: 0, epoch: 2, iters: 73792, time: 0.008) nll: 0.768208 \n",
      "(GPU: 0, epoch: 2, iters: 74592, time: 0.008) nll: 0.527792 \n",
      "(GPU: 0, epoch: 2, iters: 75392, time: 0.008) nll: 0.997537 \n",
      "(GPU: 0, epoch: 2, iters: 76192, time: 0.008) nll: 1.035252 \n",
      "(GPU: 0, epoch: 2, iters: 76992, time: 0.008) nll: 0.908172 \n",
      "(GPU: 0, epoch: 2, iters: 77792, time: 0.008) nll: 0.548674 \n",
      "(GPU: 0, epoch: 2, iters: 78592, time: 0.008) nll: 0.930707 \n",
      "saving the latest model (epoch 2, total_steps 360000)\n",
      "(GPU: 0, epoch: 2, iters: 79392, time: 0.008) nll: 0.685361 \n",
      "(GPU: 0, epoch: 2, iters: 80192, time: 0.008) nll: 1.115454 \n",
      "(GPU: 0, epoch: 2, iters: 80992, time: 0.008) nll: 0.883323 \n",
      "(GPU: 0, epoch: 2, iters: 81792, time: 0.008) nll: 0.702570 \n",
      "(GPU: 0, epoch: 2, iters: 82592, time: 0.007) nll: 0.801025 \n",
      "(GPU: 0, epoch: 2, iters: 83392, time: 0.008) nll: 0.861204 \n",
      "(GPU: 0, epoch: 2, iters: 84192, time: 0.008) nll: 0.629125 \n",
      "(GPU: 0, epoch: 2, iters: 84992, time: 0.008) nll: 0.801717 \n",
      "(GPU: 0, epoch: 2, iters: 85792, time: 0.008) nll: 0.678676 \n",
      "(GPU: 0, epoch: 2, iters: 86592, time: 0.008) nll: 0.870004 \n",
      "(GPU: 0, epoch: 2, iters: 87392, time: 0.008) nll: 0.704096 \n",
      "(GPU: 0, epoch: 2, iters: 88192, time: 0.008) nll: 0.636744 \n",
      "(GPU: 0, epoch: 2, iters: 88992, time: 0.007) nll: 0.868071 \n",
      "(GPU: 0, epoch: 2, iters: 89792, time: 0.008) nll: 0.965004 \n",
      "(GPU: 0, epoch: 2, iters: 90592, time: 0.008) nll: 1.111594 \n",
      "(GPU: 0, epoch: 2, iters: 91392, time: 0.008) nll: 0.582328 \n",
      "(GPU: 0, epoch: 2, iters: 92192, time: 0.008) nll: 0.811056 \n",
      "(GPU: 0, epoch: 2, iters: 92992, time: 0.008) nll: 0.845757 \n",
      "(GPU: 0, epoch: 2, iters: 93792, time: 0.008) nll: 1.164090 \n",
      "(GPU: 0, epoch: 2, iters: 94592, time: 0.008) nll: 0.772234 \n",
      "(GPU: 0, epoch: 2, iters: 95392, time: 0.008) nll: 0.698865 \n",
      "(GPU: 0, epoch: 2, iters: 96192, time: 0.008) nll: 0.961122 \n",
      "(GPU: 0, epoch: 2, iters: 96992, time: 0.008) nll: 0.918189 \n",
      "(GPU: 0, epoch: 2, iters: 97792, time: 0.008) nll: 0.655781 \n",
      "(GPU: 0, epoch: 2, iters: 98592, time: 0.008) nll: 0.593148 \n",
      "saving the latest model (epoch 2, total_steps 380000)\n",
      "(GPU: 0, epoch: 2, iters: 99392, time: 0.008) nll: 0.676977 \n",
      "(GPU: 0, epoch: 2, iters: 100192, time: 0.008) nll: 0.739717 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:34<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 100992, time: 0.008) nll: 0.649216 \n",
      "(GPU: 0, epoch: 2, iters: 101792, time: 0.008) nll: 0.984156 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.008) nll: 0.722086 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.013) nll: 0.708048 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.013) nll: 0.873698 \n",
      "(GPU: 0, epoch: 2, iters: 103392, time: 0.007) nll: 0.465082 \n",
      "(GPU: 0, epoch: 2, iters: 104192, time: 0.008) nll: 0.550825 \n",
      "(GPU: 0, epoch: 2, iters: 104992, time: 0.007) nll: 0.617999 \n",
      "(GPU: 0, epoch: 2, iters: 105792, time: 0.008) nll: 0.685347 \n",
      "(GPU: 0, epoch: 2, iters: 106592, time: 0.008) nll: 0.741765 \n",
      "(GPU: 0, epoch: 2, iters: 107392, time: 0.008) nll: 0.783962 \n",
      "(GPU: 0, epoch: 2, iters: 108192, time: 0.008) nll: 0.982885 \n",
      "(GPU: 0, epoch: 2, iters: 108992, time: 0.008) nll: 0.692541 \n",
      "(GPU: 0, epoch: 2, iters: 109792, time: 0.008) nll: 0.678842 \n",
      "(GPU: 0, epoch: 2, iters: 110592, time: 0.008) nll: 0.620581 \n",
      "(GPU: 0, epoch: 2, iters: 111392, time: 0.008) nll: 0.924701 \n",
      "(GPU: 0, epoch: 2, iters: 112192, time: 0.008) nll: 0.757474 \n",
      "(GPU: 0, epoch: 2, iters: 112992, time: 0.008) nll: 0.765136 \n",
      "(GPU: 0, epoch: 2, iters: 113792, time: 0.008) nll: 0.557356 \n",
      "(GPU: 0, epoch: 2, iters: 114592, time: 0.008) nll: 0.936891 \n",
      "(GPU: 0, epoch: 2, iters: 115392, time: 0.008) nll: 0.861528 \n",
      "(GPU: 0, epoch: 2, iters: 116192, time: 0.008) nll: 0.712841 \n",
      "(GPU: 0, epoch: 2, iters: 116992, time: 0.008) nll: 0.826252 \n",
      "(GPU: 0, epoch: 2, iters: 117792, time: 0.008) nll: 0.747142 \n",
      "(GPU: 0, epoch: 2, iters: 118592, time: 0.008) nll: 0.604654 \n",
      "saving the latest model (epoch 2, total_steps 400000)\n",
      "(GPU: 0, epoch: 2, iters: 119392, time: 0.008) nll: 0.593294 \n",
      "(GPU: 0, epoch: 2, iters: 120192, time: 0.008) nll: 0.624950 \n",
      "(GPU: 0, epoch: 2, iters: 120992, time: 0.008) nll: 0.621383 \n",
      "(GPU: 0, epoch: 2, iters: 121792, time: 0.008) nll: 1.113512 \n",
      "(GPU: 0, epoch: 2, iters: 122592, time: 0.008) nll: 0.521249 \n",
      "(GPU: 0, epoch: 2, iters: 123392, time: 0.008) nll: 0.826058 \n",
      "(GPU: 0, epoch: 2, iters: 124192, time: 0.008) nll: 0.842023 \n",
      "(GPU: 0, epoch: 2, iters: 124992, time: 0.008) nll: 0.757781 \n",
      "(GPU: 0, epoch: 2, iters: 125792, time: 0.008) nll: 0.652823 \n",
      "(GPU: 0, epoch: 2, iters: 126592, time: 0.008) nll: 0.631849 \n",
      "(GPU: 0, epoch: 2, iters: 127392, time: 0.008) nll: 0.707827 \n",
      "(GPU: 0, epoch: 2, iters: 128192, time: 0.008) nll: 0.637368 \n",
      "(GPU: 0, epoch: 2, iters: 128992, time: 0.008) nll: 0.977374 \n",
      "(GPU: 0, epoch: 2, iters: 129792, time: 0.008) nll: 0.658934 \n",
      "(GPU: 0, epoch: 2, iters: 130592, time: 0.008) nll: 1.180033 \n",
      "(GPU: 0, epoch: 2, iters: 131392, time: 0.008) nll: 0.556543 \n",
      "(GPU: 0, epoch: 2, iters: 132192, time: 0.008) nll: 0.923710 \n",
      "(GPU: 0, epoch: 2, iters: 132992, time: 0.008) nll: 0.709581 \n",
      "(GPU: 0, epoch: 2, iters: 133792, time: 0.008) nll: 0.949640 \n",
      "(GPU: 0, epoch: 2, iters: 134592, time: 0.008) nll: 0.716081 \n",
      "(GPU: 0, epoch: 2, iters: 135392, time: 0.008) nll: 0.730107 \n",
      "(GPU: 0, epoch: 2, iters: 136192, time: 0.008) nll: 1.227020 \n",
      "(GPU: 0, epoch: 2, iters: 136992, time: 0.008) nll: 1.316679 \n",
      "(GPU: 0, epoch: 2, iters: 137792, time: 0.008) nll: 0.959576 \n",
      "(GPU: 0, epoch: 2, iters: 138592, time: 0.008) nll: 0.581589 \n",
      "saving the latest model (epoch 2, total_steps 420000)\n",
      "(GPU: 0, epoch: 2, iters: 139392, time: 0.008) nll: 0.635067 \n",
      "(GPU: 0, epoch: 2, iters: 140192, time: 0.007) nll: 0.615375 \n",
      "[*] End of epoch 2 / 25 \t Time Taken: 1234 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000300\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3158/4397 [14:44<05:20,  3.86it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.922420 \n",
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.855287 \n",
      "(GPU: 0, epoch: 3, iters: 288, time: 0.008) nll: 0.737809 \n",
      "(GPU: 0, epoch: 3, iters: 1088, time: 0.008) nll: 0.920969 \n",
      "(GPU: 0, epoch: 3, iters: 1888, time: 0.008) nll: 0.746377 \n",
      "(GPU: 0, epoch: 3, iters: 2688, time: 0.008) nll: 0.868511 \n",
      "(GPU: 0, epoch: 3, iters: 3488, time: 0.008) nll: 0.733817 \n",
      "(GPU: 0, epoch: 3, iters: 4288, time: 0.008) nll: 0.803371 \n",
      "(GPU: 0, epoch: 3, iters: 5088, time: 0.007) nll: 0.768541 \n",
      "(GPU: 0, epoch: 3, iters: 5888, time: 0.008) nll: 0.492574 \n",
      "(GPU: 0, epoch: 3, iters: 6688, time: 0.008) nll: 0.720900 \n",
      "(GPU: 0, epoch: 3, iters: 7488, time: 0.008) nll: 0.651275 \n",
      "(GPU: 0, epoch: 3, iters: 8288, time: 0.008) nll: 0.565681 \n",
      "(GPU: 0, epoch: 3, iters: 9088, time: 0.008) nll: 0.841745 \n",
      "(GPU: 0, epoch: 3, iters: 9888, time: 0.008) nll: 0.537172 \n",
      "(GPU: 0, epoch: 3, iters: 10688, time: 0.008) nll: 0.717121 \n",
      "(GPU: 0, epoch: 3, iters: 11488, time: 0.008) nll: 0.882126 \n",
      "(GPU: 0, epoch: 3, iters: 12288, time: 0.008) nll: 0.538999 \n",
      "(GPU: 0, epoch: 3, iters: 13088, time: 0.008) nll: 0.501616 \n",
      "(GPU: 0, epoch: 3, iters: 13888, time: 0.008) nll: 0.727719 \n",
      "(GPU: 0, epoch: 3, iters: 14688, time: 0.008) nll: 0.663450 \n",
      "(GPU: 0, epoch: 3, iters: 15488, time: 0.008) nll: 0.563309 \n",
      "(GPU: 0, epoch: 3, iters: 16288, time: 0.008) nll: 0.951342 \n",
      "(GPU: 0, epoch: 3, iters: 17088, time: 0.008) nll: 0.796336 \n",
      "(GPU: 0, epoch: 3, iters: 17888, time: 0.008) nll: 0.596596 \n",
      "saving the latest model (epoch 3, total_steps 440000)\n",
      "(GPU: 0, epoch: 3, iters: 18688, time: 0.008) nll: 0.713743 \n",
      "(GPU: 0, epoch: 3, iters: 19488, time: 0.008) nll: 0.847673 \n",
      "(GPU: 0, epoch: 3, iters: 20288, time: 0.008) nll: 0.688244 \n",
      "(GPU: 0, epoch: 3, iters: 21088, time: 0.007) nll: 0.582201 \n",
      "(GPU: 0, epoch: 3, iters: 21888, time: 0.008) nll: 0.812805 \n",
      "(GPU: 0, epoch: 3, iters: 22688, time: 0.008) nll: 0.728555 \n",
      "(GPU: 0, epoch: 3, iters: 23488, time: 0.008) nll: 0.715571 \n",
      "(GPU: 0, epoch: 3, iters: 24288, time: 0.008) nll: 0.595167 \n",
      "(GPU: 0, epoch: 3, iters: 25088, time: 0.008) nll: 0.565975 \n",
      "(GPU: 0, epoch: 3, iters: 25888, time: 0.007) nll: 0.953683 \n",
      "(GPU: 0, epoch: 3, iters: 26688, time: 0.008) nll: 1.074577 \n",
      "(GPU: 0, epoch: 3, iters: 27488, time: 0.008) nll: 0.717036 \n",
      "(GPU: 0, epoch: 3, iters: 28288, time: 0.008) nll: 0.675419 \n",
      "(GPU: 0, epoch: 3, iters: 29088, time: 0.008) nll: 0.794296 \n",
      "(GPU: 0, epoch: 3, iters: 29888, time: 0.008) nll: 0.708076 \n",
      "(GPU: 0, epoch: 3, iters: 30688, time: 0.008) nll: 0.518938 \n",
      "(GPU: 0, epoch: 3, iters: 31488, time: 0.008) nll: 0.595948 \n",
      "(GPU: 0, epoch: 3, iters: 32288, time: 0.008) nll: 0.956772 \n",
      "(GPU: 0, epoch: 3, iters: 33088, time: 0.008) nll: 0.862229 \n",
      "(GPU: 0, epoch: 3, iters: 33888, time: 0.008) nll: 0.716581 \n",
      "(GPU: 0, epoch: 3, iters: 34688, time: 0.008) nll: 0.572863 \n",
      "(GPU: 0, epoch: 3, iters: 35488, time: 0.008) nll: 1.175064 \n",
      "(GPU: 0, epoch: 3, iters: 36288, time: 0.008) nll: 0.719211 \n",
      "(GPU: 0, epoch: 3, iters: 37088, time: 0.008) nll: 0.598224 \n",
      "(GPU: 0, epoch: 3, iters: 37888, time: 0.008) nll: 0.662441 \n",
      "saving the latest model (epoch 3, total_steps 460000)\n",
      "(GPU: 0, epoch: 3, iters: 38688, time: 0.008) nll: 0.679005 \n",
      "(GPU: 0, epoch: 3, iters: 39488, time: 0.008) nll: 0.798076 \n",
      "(GPU: 0, epoch: 3, iters: 40288, time: 0.007) nll: 0.824331 \n",
      "(GPU: 0, epoch: 3, iters: 41088, time: 0.008) nll: 0.852147 \n",
      "(GPU: 0, epoch: 3, iters: 41888, time: 0.007) nll: 0.759304 \n",
      "(GPU: 0, epoch: 3, iters: 42688, time: 0.008) nll: 0.807208 \n",
      "(GPU: 0, epoch: 3, iters: 43488, time: 0.008) nll: 0.631178 \n",
      "(GPU: 0, epoch: 3, iters: 44288, time: 0.008) nll: 0.783104 \n",
      "(GPU: 0, epoch: 3, iters: 45088, time: 0.008) nll: 0.625935 \n",
      "(GPU: 0, epoch: 3, iters: 45888, time: 0.008) nll: 0.821288 \n",
      "(GPU: 0, epoch: 3, iters: 46688, time: 0.008) nll: 1.001470 \n",
      "(GPU: 0, epoch: 3, iters: 47488, time: 0.008) nll: 0.678169 \n",
      "(GPU: 0, epoch: 3, iters: 48288, time: 0.008) nll: 0.831376 \n",
      "(GPU: 0, epoch: 3, iters: 49088, time: 0.008) nll: 1.025394 \n",
      "(GPU: 0, epoch: 3, iters: 49888, time: 0.008) nll: 0.836720 \n",
      "(GPU: 0, epoch: 3, iters: 50688, time: 0.008) nll: 0.781309 \n",
      "(GPU: 0, epoch: 3, iters: 51488, time: 0.008) nll: 0.876437 \n",
      "(GPU: 0, epoch: 3, iters: 52288, time: 0.008) nll: 0.620688 \n",
      "(GPU: 0, epoch: 3, iters: 53088, time: 0.008) nll: 0.673669 \n",
      "(GPU: 0, epoch: 3, iters: 53888, time: 0.008) nll: 0.736783 \n",
      "(GPU: 0, epoch: 3, iters: 54688, time: 0.008) nll: 0.506580 \n",
      "(GPU: 0, epoch: 3, iters: 55488, time: 0.008) nll: 0.624496 \n",
      "(GPU: 0, epoch: 3, iters: 56288, time: 0.008) nll: 0.866777 \n",
      "(GPU: 0, epoch: 3, iters: 57088, time: 0.008) nll: 0.704650 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.008) nll: 0.883704 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.013) nll: 0.859232 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.013) nll: 0.767686 \n",
      "saving the latest model (epoch 3, total_steps 480000)\n",
      "(GPU: 0, epoch: 3, iters: 58688, time: 0.008) nll: 0.670673 \n",
      "(GPU: 0, epoch: 3, iters: 59488, time: 0.008) nll: 0.721678 \n",
      "(GPU: 0, epoch: 3, iters: 60288, time: 0.008) nll: 0.671880 \n",
      "(GPU: 0, epoch: 3, iters: 61088, time: 0.008) nll: 1.021257 \n",
      "(GPU: 0, epoch: 3, iters: 61888, time: 0.008) nll: 0.607910 \n",
      "(GPU: 0, epoch: 3, iters: 62688, time: 0.008) nll: 0.707353 \n",
      "(GPU: 0, epoch: 3, iters: 63488, time: 0.008) nll: 0.735645 \n",
      "(GPU: 0, epoch: 3, iters: 64288, time: 0.008) nll: 0.693761 \n",
      "(GPU: 0, epoch: 3, iters: 65088, time: 0.008) nll: 0.780830 \n",
      "(GPU: 0, epoch: 3, iters: 65888, time: 0.008) nll: 0.660207 \n",
      "(GPU: 0, epoch: 3, iters: 66688, time: 0.008) nll: 0.611736 \n",
      "(GPU: 0, epoch: 3, iters: 67488, time: 0.008) nll: 0.667478 \n",
      "(GPU: 0, epoch: 3, iters: 68288, time: 0.008) nll: 1.017108 \n",
      "(GPU: 0, epoch: 3, iters: 69088, time: 0.008) nll: 0.576712 \n",
      "(GPU: 0, epoch: 3, iters: 69888, time: 0.008) nll: 0.916437 \n",
      "(GPU: 0, epoch: 3, iters: 70688, time: 0.007) nll: 0.515147 \n",
      "(GPU: 0, epoch: 3, iters: 71488, time: 0.008) nll: 0.917254 \n",
      "(GPU: 0, epoch: 3, iters: 72288, time: 0.007) nll: 0.658514 \n",
      "(GPU: 0, epoch: 3, iters: 73088, time: 0.008) nll: 1.124398 \n",
      "(GPU: 0, epoch: 3, iters: 73888, time: 0.008) nll: 0.632724 \n",
      "(GPU: 0, epoch: 3, iters: 74688, time: 0.008) nll: 0.770445 \n",
      "(GPU: 0, epoch: 3, iters: 75488, time: 0.008) nll: 0.863902 \n",
      "(GPU: 0, epoch: 3, iters: 76288, time: 0.008) nll: 0.672456 \n",
      "(GPU: 0, epoch: 3, iters: 77088, time: 0.008) nll: 0.695932 \n",
      "(GPU: 0, epoch: 3, iters: 77888, time: 0.008) nll: 0.829492 \n",
      "saving the latest model (epoch 3, total_steps 500000)\n",
      "(GPU: 0, epoch: 3, iters: 78688, time: 0.007) nll: 0.621581 \n",
      "(GPU: 0, epoch: 3, iters: 79488, time: 0.008) nll: 0.729590 \n",
      "(GPU: 0, epoch: 3, iters: 80288, time: 0.008) nll: 0.608036 \n",
      "(GPU: 0, epoch: 3, iters: 81088, time: 0.008) nll: 0.647867 \n",
      "(GPU: 0, epoch: 3, iters: 81888, time: 0.008) nll: 0.499769 \n",
      "(GPU: 0, epoch: 3, iters: 82688, time: 0.008) nll: 0.780755 \n",
      "(GPU: 0, epoch: 3, iters: 83488, time: 0.008) nll: 1.432939 \n",
      "(GPU: 0, epoch: 3, iters: 84288, time: 0.008) nll: 0.761919 \n",
      "(GPU: 0, epoch: 3, iters: 85088, time: 0.008) nll: 0.570949 \n",
      "(GPU: 0, epoch: 3, iters: 85888, time: 0.008) nll: 0.742901 \n",
      "(GPU: 0, epoch: 3, iters: 86688, time: 0.008) nll: 0.710412 \n",
      "(GPU: 0, epoch: 3, iters: 87488, time: 0.008) nll: 0.907687 \n",
      "(GPU: 0, epoch: 3, iters: 88288, time: 0.008) nll: 0.559462 \n",
      "(GPU: 0, epoch: 3, iters: 89088, time: 0.008) nll: 0.634166 \n",
      "(GPU: 0, epoch: 3, iters: 89888, time: 0.008) nll: 0.800514 \n",
      "(GPU: 0, epoch: 3, iters: 90688, time: 0.008) nll: 0.755560 \n",
      "(GPU: 0, epoch: 3, iters: 91488, time: 0.008) nll: 0.795377 \n",
      "(GPU: 0, epoch: 3, iters: 92288, time: 0.008) nll: 0.753578 \n",
      "(GPU: 0, epoch: 3, iters: 93088, time: 0.008) nll: 0.895153 \n",
      "(GPU: 0, epoch: 3, iters: 93888, time: 0.008) nll: 0.844891 \n",
      "(GPU: 0, epoch: 3, iters: 94688, time: 0.008) nll: 1.149585 \n",
      "(GPU: 0, epoch: 3, iters: 95488, time: 0.008) nll: 0.623379 \n",
      "(GPU: 0, epoch: 3, iters: 96288, time: 0.008) nll: 0.726173 \n",
      "(GPU: 0, epoch: 3, iters: 97088, time: 0.008) nll: 0.530966 \n",
      "(GPU: 0, epoch: 3, iters: 97888, time: 0.008) nll: 0.760994 \n",
      "saving the latest model (epoch 3, total_steps 520000)\n",
      "(GPU: 0, epoch: 3, iters: 98688, time: 0.008) nll: 0.612500 \n",
      "(GPU: 0, epoch: 3, iters: 99488, time: 0.008) nll: 0.695985 \n",
      "(GPU: 0, epoch: 3, iters: 100288, time: 0.008) nll: 0.615882 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:32<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 101088, time: 0.008) nll: 0.687121 \n",
      "(GPU: 0, epoch: 3, iters: 101888, time: 0.008) nll: 0.656563 \n",
      "(GPU: 0, epoch: 3, iters: 102688, time: 0.008) nll: 0.555905 \n",
      "(GPU: 0, epoch: 3, iters: 103488, time: 0.008) nll: 0.764351 \n",
      "(GPU: 0, epoch: 3, iters: 104288, time: 0.008) nll: 0.816673 \n",
      "(GPU: 0, epoch: 3, iters: 105088, time: 0.008) nll: 0.769837 \n",
      "(GPU: 0, epoch: 3, iters: 105888, time: 0.008) nll: 0.666965 \n",
      "(GPU: 0, epoch: 3, iters: 106688, time: 0.008) nll: 0.527851 \n",
      "(GPU: 0, epoch: 3, iters: 107488, time: 0.008) nll: 0.692489 \n",
      "(GPU: 0, epoch: 3, iters: 108288, time: 0.008) nll: 0.557505 \n",
      "(GPU: 0, epoch: 3, iters: 109088, time: 0.008) nll: 0.611497 \n",
      "(GPU: 0, epoch: 3, iters: 109888, time: 0.008) nll: 0.748804 \n",
      "(GPU: 0, epoch: 3, iters: 110688, time: 0.007) nll: 0.797281 \n",
      "(GPU: 0, epoch: 3, iters: 111488, time: 0.008) nll: 0.627541 \n",
      "(GPU: 0, epoch: 3, iters: 112288, time: 0.008) nll: 0.672839 \n",
      "(GPU: 0, epoch: 3, iters: 113088, time: 0.008) nll: 0.657590 \n",
      "(GPU: 0, epoch: 3, iters: 113888, time: 0.008) nll: 0.700712 \n",
      "(GPU: 0, epoch: 3, iters: 114688, time: 0.008) nll: 0.688161 \n",
      "(GPU: 0, epoch: 3, iters: 115488, time: 0.008) nll: 0.640233 \n",
      "(GPU: 0, epoch: 3, iters: 116288, time: 0.008) nll: 0.706467 \n",
      "(GPU: 0, epoch: 3, iters: 117088, time: 0.008) nll: 0.820457 \n",
      "(GPU: 0, epoch: 3, iters: 117888, time: 0.008) nll: 0.588101 \n",
      "saving the latest model (epoch 3, total_steps 540000)\n",
      "(GPU: 0, epoch: 3, iters: 118688, time: 0.008) nll: 1.147412 \n",
      "(GPU: 0, epoch: 3, iters: 119488, time: 0.008) nll: 0.656903 \n",
      "(GPU: 0, epoch: 3, iters: 120288, time: 0.008) nll: 0.684877 \n",
      "(GPU: 0, epoch: 3, iters: 121088, time: 0.008) nll: 0.845287 \n",
      "(GPU: 0, epoch: 3, iters: 121888, time: 0.008) nll: 0.792680 \n",
      "(GPU: 0, epoch: 3, iters: 122688, time: 0.008) nll: 0.719738 \n",
      "(GPU: 0, epoch: 3, iters: 123488, time: 0.008) nll: 0.649929 \n",
      "(GPU: 0, epoch: 3, iters: 124288, time: 0.008) nll: 0.549708 \n",
      "(GPU: 0, epoch: 3, iters: 125088, time: 0.008) nll: 0.905017 \n",
      "(GPU: 0, epoch: 3, iters: 125888, time: 0.008) nll: 0.748514 \n",
      "(GPU: 0, epoch: 3, iters: 126688, time: 0.008) nll: 1.108221 \n",
      "(GPU: 0, epoch: 3, iters: 127488, time: 0.008) nll: 0.642426 \n",
      "(GPU: 0, epoch: 3, iters: 128288, time: 0.008) nll: 0.635849 \n",
      "(GPU: 0, epoch: 3, iters: 129088, time: 0.008) nll: 0.707541 \n",
      "(GPU: 0, epoch: 3, iters: 129888, time: 0.008) nll: 0.644075 \n",
      "(GPU: 0, epoch: 3, iters: 130688, time: 0.008) nll: 0.912315 \n",
      "(GPU: 0, epoch: 3, iters: 131488, time: 0.008) nll: 0.604174 \n",
      "(GPU: 0, epoch: 3, iters: 132288, time: 0.008) nll: 0.618602 \n",
      "(GPU: 0, epoch: 3, iters: 133088, time: 0.008) nll: 0.844752 \n",
      "(GPU: 0, epoch: 3, iters: 133888, time: 0.008) nll: 1.047891 \n",
      "(GPU: 0, epoch: 3, iters: 134688, time: 0.008) nll: 0.820240 \n",
      "(GPU: 0, epoch: 3, iters: 135488, time: 0.008) nll: 1.068480 \n",
      "(GPU: 0, epoch: 3, iters: 136288, time: 0.008) nll: 0.716080 \n",
      "(GPU: 0, epoch: 3, iters: 137088, time: 0.008) nll: 0.904423 \n",
      "(GPU: 0, epoch: 3, iters: 137888, time: 0.008) nll: 0.778234 \n",
      "saving the latest model (epoch 3, total_steps 560000)\n",
      "(GPU: 0, epoch: 3, iters: 138688, time: 0.008) nll: 0.494226 \n",
      "(GPU: 0, epoch: 3, iters: 139488, time: 0.008) nll: 0.519769 \n",
      "(GPU: 0, epoch: 3, iters: 140288, time: 0.008) nll: 0.578469 \n",
      "saving the model at the end of epoch 3, iters 562816\n",
      "([test] GPU: 0, epoch: 3) \n",
      "OrderedDict()\n",
      "[*] End of epoch 3 / 25 \t Time Taken: 1261 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000400\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3161/4397 [14:46<05:18,  3.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 32, time: 0.004) nll: 0.725273 \n",
      "(GPU: 0, epoch: 4, iters: 32, time: 0.004) nll: 0.801261 \n",
      "(GPU: 0, epoch: 4, iters: 384, time: 0.008) nll: 0.822078 \n",
      "(GPU: 0, epoch: 4, iters: 1184, time: 0.008) nll: 0.965487 \n",
      "(GPU: 0, epoch: 4, iters: 1984, time: 0.008) nll: 1.101455 \n",
      "(GPU: 0, epoch: 4, iters: 2784, time: 0.008) nll: 0.657130 \n",
      "(GPU: 0, epoch: 4, iters: 3584, time: 0.008) nll: 0.770746 \n",
      "(GPU: 0, epoch: 4, iters: 4384, time: 0.008) nll: 0.659538 \n",
      "(GPU: 0, epoch: 4, iters: 5184, time: 0.008) nll: 0.589365 \n",
      "(GPU: 0, epoch: 4, iters: 5984, time: 0.008) nll: 0.797895 \n",
      "(GPU: 0, epoch: 4, iters: 6784, time: 0.008) nll: 0.929624 \n",
      "(GPU: 0, epoch: 4, iters: 7584, time: 0.007) nll: 0.615821 \n",
      "(GPU: 0, epoch: 4, iters: 8384, time: 0.008) nll: 0.699475 \n",
      "(GPU: 0, epoch: 4, iters: 9184, time: 0.008) nll: 0.669269 \n",
      "(GPU: 0, epoch: 4, iters: 9984, time: 0.008) nll: 0.667991 \n",
      "(GPU: 0, epoch: 4, iters: 10784, time: 0.008) nll: 0.693130 \n",
      "(GPU: 0, epoch: 4, iters: 11584, time: 0.008) nll: 0.601066 \n",
      "(GPU: 0, epoch: 4, iters: 12384, time: 0.008) nll: 0.890431 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.008) nll: 0.483724 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.013) nll: 0.483154 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.013) nll: 0.527848 \n",
      "(GPU: 0, epoch: 4, iters: 13984, time: 0.008) nll: 0.943581 \n",
      "(GPU: 0, epoch: 4, iters: 14784, time: 0.008) nll: 0.824718 \n",
      "(GPU: 0, epoch: 4, iters: 15584, time: 0.008) nll: 0.680424 \n",
      "(GPU: 0, epoch: 4, iters: 16384, time: 0.008) nll: 0.729047 \n",
      "(GPU: 0, epoch: 4, iters: 17184, time: 0.007) nll: 1.011994 \n",
      "saving the latest model (epoch 4, total_steps 580000)\n",
      "(GPU: 0, epoch: 4, iters: 17984, time: 0.008) nll: 0.708633 \n",
      "(GPU: 0, epoch: 4, iters: 18784, time: 0.008) nll: 1.191550 \n",
      "(GPU: 0, epoch: 4, iters: 19584, time: 0.008) nll: 0.975155 \n",
      "(GPU: 0, epoch: 4, iters: 20384, time: 0.008) nll: 0.664338 \n",
      "(GPU: 0, epoch: 4, iters: 21184, time: 0.008) nll: 0.830644 \n",
      "(GPU: 0, epoch: 4, iters: 21984, time: 0.007) nll: 0.573761 \n",
      "(GPU: 0, epoch: 4, iters: 22784, time: 0.008) nll: 0.729729 \n",
      "(GPU: 0, epoch: 4, iters: 23584, time: 0.008) nll: 0.731740 \n",
      "(GPU: 0, epoch: 4, iters: 24384, time: 0.008) nll: 0.657021 \n",
      "(GPU: 0, epoch: 4, iters: 25184, time: 0.008) nll: 0.583201 \n",
      "(GPU: 0, epoch: 4, iters: 25984, time: 0.008) nll: 0.555382 \n",
      "(GPU: 0, epoch: 4, iters: 26784, time: 0.008) nll: 0.633204 \n",
      "(GPU: 0, epoch: 4, iters: 27584, time: 0.008) nll: 0.423288 \n",
      "(GPU: 0, epoch: 4, iters: 28384, time: 0.008) nll: 0.589997 \n",
      "(GPU: 0, epoch: 4, iters: 29184, time: 0.008) nll: 0.735874 \n",
      "(GPU: 0, epoch: 4, iters: 29984, time: 0.008) nll: 0.778071 \n",
      "(GPU: 0, epoch: 4, iters: 30784, time: 0.008) nll: 0.618830 \n",
      "(GPU: 0, epoch: 4, iters: 31584, time: 0.008) nll: 0.734703 \n",
      "(GPU: 0, epoch: 4, iters: 32384, time: 0.008) nll: 0.882344 \n",
      "(GPU: 0, epoch: 4, iters: 33184, time: 0.008) nll: 1.072262 \n",
      "(GPU: 0, epoch: 4, iters: 33984, time: 0.008) nll: 0.935465 \n",
      "(GPU: 0, epoch: 4, iters: 34784, time: 0.008) nll: 0.676081 \n",
      "(GPU: 0, epoch: 4, iters: 35584, time: 0.008) nll: 0.576419 \n",
      "(GPU: 0, epoch: 4, iters: 36384, time: 0.008) nll: 0.768211 \n",
      "(GPU: 0, epoch: 4, iters: 37184, time: 0.008) nll: 0.685093 \n",
      "saving the latest model (epoch 4, total_steps 600000)\n",
      "(GPU: 0, epoch: 4, iters: 37984, time: 0.008) nll: 0.856670 \n",
      "(GPU: 0, epoch: 4, iters: 38784, time: 0.008) nll: 0.638504 \n",
      "(GPU: 0, epoch: 4, iters: 39584, time: 0.008) nll: 0.854261 \n",
      "(GPU: 0, epoch: 4, iters: 40384, time: 0.008) nll: 0.560997 \n",
      "(GPU: 0, epoch: 4, iters: 41184, time: 0.008) nll: 0.540109 \n",
      "(GPU: 0, epoch: 4, iters: 41984, time: 0.008) nll: 0.934108 \n",
      "(GPU: 0, epoch: 4, iters: 42784, time: 0.008) nll: 0.571318 \n",
      "(GPU: 0, epoch: 4, iters: 43584, time: 0.008) nll: 0.557991 \n",
      "(GPU: 0, epoch: 4, iters: 44384, time: 0.007) nll: 0.732854 \n",
      "(GPU: 0, epoch: 4, iters: 45184, time: 0.008) nll: 0.692923 \n",
      "(GPU: 0, epoch: 4, iters: 45984, time: 0.008) nll: 0.906606 \n",
      "(GPU: 0, epoch: 4, iters: 46784, time: 0.008) nll: 0.696566 \n",
      "(GPU: 0, epoch: 4, iters: 47584, time: 0.008) nll: 0.595767 \n",
      "(GPU: 0, epoch: 4, iters: 48384, time: 0.008) nll: 0.684892 \n",
      "(GPU: 0, epoch: 4, iters: 49184, time: 0.008) nll: 0.729299 \n",
      "(GPU: 0, epoch: 4, iters: 49984, time: 0.008) nll: 0.892633 \n",
      "(GPU: 0, epoch: 4, iters: 50784, time: 0.008) nll: 0.650048 \n",
      "(GPU: 0, epoch: 4, iters: 51584, time: 0.008) nll: 0.677863 \n",
      "(GPU: 0, epoch: 4, iters: 52384, time: 0.007) nll: 0.843562 \n",
      "(GPU: 0, epoch: 4, iters: 53184, time: 0.008) nll: 0.636903 \n",
      "(GPU: 0, epoch: 4, iters: 53984, time: 0.008) nll: 0.801706 \n",
      "(GPU: 0, epoch: 4, iters: 54784, time: 0.008) nll: 0.524376 \n",
      "(GPU: 0, epoch: 4, iters: 55584, time: 0.008) nll: 0.739251 \n",
      "(GPU: 0, epoch: 4, iters: 56384, time: 0.008) nll: 0.623525 \n",
      "(GPU: 0, epoch: 4, iters: 57184, time: 0.008) nll: 0.886067 \n",
      "saving the latest model (epoch 4, total_steps 620000)\n",
      "(GPU: 0, epoch: 4, iters: 57984, time: 0.008) nll: 0.817972 \n",
      "(GPU: 0, epoch: 4, iters: 58784, time: 0.008) nll: 0.888765 \n",
      "(GPU: 0, epoch: 4, iters: 59584, time: 0.008) nll: 0.649497 \n",
      "(GPU: 0, epoch: 4, iters: 60384, time: 0.008) nll: 0.753890 \n",
      "(GPU: 0, epoch: 4, iters: 61184, time: 0.008) nll: 0.553435 \n",
      "(GPU: 0, epoch: 4, iters: 61984, time: 0.008) nll: 0.577174 \n",
      "(GPU: 0, epoch: 4, iters: 62784, time: 0.008) nll: 0.733825 \n",
      "(GPU: 0, epoch: 4, iters: 63584, time: 0.008) nll: 0.943067 \n",
      "(GPU: 0, epoch: 4, iters: 64384, time: 0.008) nll: 0.676381 \n",
      "(GPU: 0, epoch: 4, iters: 65184, time: 0.008) nll: 1.060344 \n",
      "(GPU: 0, epoch: 4, iters: 65984, time: 0.008) nll: 0.814262 \n",
      "(GPU: 0, epoch: 4, iters: 66784, time: 0.008) nll: 0.554457 \n",
      "(GPU: 0, epoch: 4, iters: 67584, time: 0.008) nll: 0.637196 \n",
      "(GPU: 0, epoch: 4, iters: 68384, time: 0.008) nll: 0.610594 \n",
      "(GPU: 0, epoch: 4, iters: 69184, time: 0.008) nll: 0.517823 \n",
      "(GPU: 0, epoch: 4, iters: 69984, time: 0.008) nll: 0.882828 \n",
      "(GPU: 0, epoch: 4, iters: 70784, time: 0.008) nll: 0.794471 \n",
      "(GPU: 0, epoch: 4, iters: 71584, time: 0.008) nll: 0.729507 \n",
      "(GPU: 0, epoch: 4, iters: 72384, time: 0.008) nll: 0.813299 \n",
      "(GPU: 0, epoch: 4, iters: 73184, time: 0.008) nll: 0.723278 \n",
      "(GPU: 0, epoch: 4, iters: 73984, time: 0.008) nll: 0.582856 \n",
      "(GPU: 0, epoch: 4, iters: 74784, time: 0.008) nll: 0.698948 \n",
      "(GPU: 0, epoch: 4, iters: 75584, time: 0.008) nll: 0.964625 \n",
      "(GPU: 0, epoch: 4, iters: 76384, time: 0.008) nll: 0.672751 \n",
      "(GPU: 0, epoch: 4, iters: 77184, time: 0.008) nll: 0.631579 \n",
      "saving the latest model (epoch 4, total_steps 640000)\n",
      "(GPU: 0, epoch: 4, iters: 77984, time: 0.008) nll: 0.906796 \n",
      "(GPU: 0, epoch: 4, iters: 78784, time: 0.008) nll: 0.664337 \n",
      "(GPU: 0, epoch: 4, iters: 79584, time: 0.008) nll: 0.677809 \n",
      "(GPU: 0, epoch: 4, iters: 80384, time: 0.008) nll: 0.816623 \n",
      "(GPU: 0, epoch: 4, iters: 81184, time: 0.008) nll: 0.917088 \n",
      "(GPU: 0, epoch: 4, iters: 81984, time: 0.008) nll: 0.964611 \n",
      "(GPU: 0, epoch: 4, iters: 82784, time: 0.008) nll: 0.674579 \n",
      "(GPU: 0, epoch: 4, iters: 83584, time: 0.008) nll: 0.734572 \n",
      "(GPU: 0, epoch: 4, iters: 84384, time: 0.008) nll: 0.724015 \n",
      "(GPU: 0, epoch: 4, iters: 85184, time: 0.008) nll: 0.609097 \n",
      "(GPU: 0, epoch: 4, iters: 85984, time: 0.008) nll: 0.704587 \n",
      "(GPU: 0, epoch: 4, iters: 86784, time: 0.008) nll: 0.681381 \n",
      "(GPU: 0, epoch: 4, iters: 87584, time: 0.008) nll: 0.771720 \n",
      "(GPU: 0, epoch: 4, iters: 88384, time: 0.008) nll: 0.749355 \n",
      "(GPU: 0, epoch: 4, iters: 89184, time: 0.008) nll: 0.753901 \n",
      "(GPU: 0, epoch: 4, iters: 89984, time: 0.008) nll: 0.769188 \n",
      "(GPU: 0, epoch: 4, iters: 90784, time: 0.008) nll: 0.652660 \n",
      "(GPU: 0, epoch: 4, iters: 91584, time: 0.008) nll: 0.939631 \n",
      "(GPU: 0, epoch: 4, iters: 92384, time: 0.008) nll: 0.838920 \n",
      "(GPU: 0, epoch: 4, iters: 93184, time: 0.008) nll: 0.605754 \n",
      "(GPU: 0, epoch: 4, iters: 93984, time: 0.008) nll: 0.817342 \n",
      "(GPU: 0, epoch: 4, iters: 94784, time: 0.008) nll: 0.594408 \n",
      "(GPU: 0, epoch: 4, iters: 95584, time: 0.008) nll: 0.773884 \n",
      "(GPU: 0, epoch: 4, iters: 96384, time: 0.008) nll: 0.661960 \n",
      "(GPU: 0, epoch: 4, iters: 97184, time: 0.008) nll: 0.532105 \n",
      "saving the latest model (epoch 4, total_steps 660000)\n",
      "(GPU: 0, epoch: 4, iters: 97984, time: 0.008) nll: 0.710250 \n",
      "(GPU: 0, epoch: 4, iters: 98784, time: 0.007) nll: 0.660403 \n",
      "(GPU: 0, epoch: 4, iters: 99584, time: 0.008) nll: 0.633468 \n",
      "(GPU: 0, epoch: 4, iters: 100384, time: 0.008) nll: 0.796963 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:33<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 101184, time: 0.008) nll: 0.757060 \n",
      "(GPU: 0, epoch: 4, iters: 101984, time: 0.007) nll: 0.824753 \n",
      "(GPU: 0, epoch: 4, iters: 102784, time: 0.008) nll: 0.549509 \n",
      "(GPU: 0, epoch: 4, iters: 103584, time: 0.008) nll: 0.719467 \n",
      "(GPU: 0, epoch: 4, iters: 104384, time: 0.008) nll: 0.756779 \n",
      "(GPU: 0, epoch: 4, iters: 105184, time: 0.008) nll: 0.817822 \n",
      "(GPU: 0, epoch: 4, iters: 105984, time: 0.008) nll: 0.486521 \n",
      "(GPU: 0, epoch: 4, iters: 106784, time: 0.008) nll: 0.561244 \n",
      "(GPU: 0, epoch: 4, iters: 107584, time: 0.008) nll: 0.730680 \n",
      "(GPU: 0, epoch: 4, iters: 108384, time: 0.008) nll: 0.620910 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.008) nll: 0.636540 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.013) nll: 0.629625 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.013) nll: 0.678538 \n",
      "(GPU: 0, epoch: 4, iters: 109984, time: 0.008) nll: 0.716829 \n",
      "(GPU: 0, epoch: 4, iters: 110784, time: 0.008) nll: 1.007861 \n",
      "(GPU: 0, epoch: 4, iters: 111584, time: 0.008) nll: 0.622766 \n",
      "(GPU: 0, epoch: 4, iters: 112384, time: 0.008) nll: 0.616813 \n",
      "(GPU: 0, epoch: 4, iters: 113184, time: 0.008) nll: 0.863363 \n",
      "(GPU: 0, epoch: 4, iters: 113984, time: 0.008) nll: 0.612402 \n",
      "(GPU: 0, epoch: 4, iters: 114784, time: 0.008) nll: 0.625105 \n",
      "(GPU: 0, epoch: 4, iters: 115584, time: 0.008) nll: 0.553826 \n",
      "(GPU: 0, epoch: 4, iters: 116384, time: 0.008) nll: 0.795350 \n",
      "(GPU: 0, epoch: 4, iters: 117184, time: 0.008) nll: 0.737366 \n",
      "saving the latest model (epoch 4, total_steps 680000)\n",
      "(GPU: 0, epoch: 4, iters: 117984, time: 0.008) nll: 0.720210 \n",
      "(GPU: 0, epoch: 4, iters: 118784, time: 0.008) nll: 1.291939 \n",
      "(GPU: 0, epoch: 4, iters: 119584, time: 0.008) nll: 0.660660 \n",
      "(GPU: 0, epoch: 4, iters: 120384, time: 0.008) nll: 0.740607 \n",
      "(GPU: 0, epoch: 4, iters: 121184, time: 0.008) nll: 1.087071 \n",
      "(GPU: 0, epoch: 4, iters: 121984, time: 0.008) nll: 0.648769 \n",
      "(GPU: 0, epoch: 4, iters: 122784, time: 0.007) nll: 0.788350 \n",
      "(GPU: 0, epoch: 4, iters: 123584, time: 0.008) nll: 0.470593 \n",
      "(GPU: 0, epoch: 4, iters: 124384, time: 0.008) nll: 0.577023 \n",
      "(GPU: 0, epoch: 4, iters: 125184, time: 0.008) nll: 0.649100 \n",
      "(GPU: 0, epoch: 4, iters: 125984, time: 0.008) nll: 0.636973 \n",
      "(GPU: 0, epoch: 4, iters: 126784, time: 0.008) nll: 0.630722 \n",
      "(GPU: 0, epoch: 4, iters: 127584, time: 0.008) nll: 0.676495 \n",
      "(GPU: 0, epoch: 4, iters: 128384, time: 0.008) nll: 0.823584 \n",
      "(GPU: 0, epoch: 4, iters: 129184, time: 0.007) nll: 0.696846 \n",
      "(GPU: 0, epoch: 4, iters: 129984, time: 0.008) nll: 0.658626 \n",
      "(GPU: 0, epoch: 4, iters: 130784, time: 0.008) nll: 0.634623 \n",
      "(GPU: 0, epoch: 4, iters: 131584, time: 0.008) nll: 0.548030 \n",
      "(GPU: 0, epoch: 4, iters: 132384, time: 0.008) nll: 0.842805 \n",
      "(GPU: 0, epoch: 4, iters: 133184, time: 0.008) nll: 1.122221 \n",
      "(GPU: 0, epoch: 4, iters: 133984, time: 0.008) nll: 0.667381 \n",
      "(GPU: 0, epoch: 4, iters: 134784, time: 0.008) nll: 0.657860 \n",
      "(GPU: 0, epoch: 4, iters: 135584, time: 0.008) nll: 0.639668 \n",
      "(GPU: 0, epoch: 4, iters: 136384, time: 0.008) nll: 1.213565 \n",
      "(GPU: 0, epoch: 4, iters: 137184, time: 0.008) nll: 0.799098 \n",
      "saving the latest model (epoch 4, total_steps 700000)\n",
      "(GPU: 0, epoch: 4, iters: 137984, time: 0.008) nll: 0.788909 \n",
      "(GPU: 0, epoch: 4, iters: 138784, time: 0.008) nll: 0.717571 \n",
      "(GPU: 0, epoch: 4, iters: 139584, time: 0.008) nll: 0.575384 \n",
      "(GPU: 0, epoch: 4, iters: 140384, time: 0.008) nll: 0.879135 \n",
      "[*] End of epoch 4 / 25 \t Time Taken: 1234 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000500\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3164/4397 [14:47<05:18,  3.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 32, time: 0.003) nll: 0.575256 \n",
      "(GPU: 0, epoch: 5, iters: 32, time: 0.003) nll: 0.611030 \n",
      "(GPU: 0, epoch: 5, iters: 480, time: 0.008) nll: 0.362123 \n",
      "(GPU: 0, epoch: 5, iters: 1280, time: 0.008) nll: 0.818944 \n",
      "(GPU: 0, epoch: 5, iters: 2080, time: 0.008) nll: 0.641922 \n",
      "(GPU: 0, epoch: 5, iters: 2880, time: 0.008) nll: 0.583754 \n",
      "(GPU: 0, epoch: 5, iters: 3680, time: 0.008) nll: 0.595151 \n",
      "(GPU: 0, epoch: 5, iters: 4480, time: 0.008) nll: 0.793617 \n",
      "(GPU: 0, epoch: 5, iters: 5280, time: 0.008) nll: 0.836948 \n",
      "(GPU: 0, epoch: 5, iters: 6080, time: 0.008) nll: 0.569977 \n",
      "(GPU: 0, epoch: 5, iters: 6880, time: 0.008) nll: 0.697690 \n",
      "(GPU: 0, epoch: 5, iters: 7680, time: 0.009) nll: 0.501770 \n",
      "(GPU: 0, epoch: 5, iters: 8480, time: 0.008) nll: 0.505453 \n",
      "(GPU: 0, epoch: 5, iters: 9280, time: 0.008) nll: 0.829095 \n",
      "(GPU: 0, epoch: 5, iters: 10080, time: 0.008) nll: 0.826114 \n",
      "(GPU: 0, epoch: 5, iters: 10880, time: 0.008) nll: 0.443501 \n",
      "(GPU: 0, epoch: 5, iters: 11680, time: 0.008) nll: 0.722549 \n",
      "(GPU: 0, epoch: 5, iters: 12480, time: 0.008) nll: 0.837334 \n",
      "(GPU: 0, epoch: 5, iters: 13280, time: 0.008) nll: 0.583876 \n",
      "(GPU: 0, epoch: 5, iters: 14080, time: 0.008) nll: 0.838779 \n",
      "(GPU: 0, epoch: 5, iters: 14880, time: 0.008) nll: 0.703075 \n",
      "(GPU: 0, epoch: 5, iters: 15680, time: 0.008) nll: 0.593639 \n",
      "(GPU: 0, epoch: 5, iters: 16480, time: 0.008) nll: 0.599683 \n",
      "saving the latest model (epoch 5, total_steps 720000)\n",
      "(GPU: 0, epoch: 5, iters: 17280, time: 0.008) nll: 0.782706 \n",
      "(GPU: 0, epoch: 5, iters: 18080, time: 0.008) nll: 0.596962 \n",
      "(GPU: 0, epoch: 5, iters: 18880, time: 0.008) nll: 0.863756 \n",
      "(GPU: 0, epoch: 5, iters: 19680, time: 0.008) nll: 0.688049 \n",
      "(GPU: 0, epoch: 5, iters: 20480, time: 0.008) nll: 0.864509 \n",
      "(GPU: 0, epoch: 5, iters: 21280, time: 0.008) nll: 1.341077 \n",
      "(GPU: 0, epoch: 5, iters: 22080, time: 0.008) nll: 0.659448 \n",
      "(GPU: 0, epoch: 5, iters: 22880, time: 0.008) nll: 0.792733 \n",
      "(GPU: 0, epoch: 5, iters: 23680, time: 0.008) nll: 0.753165 \n",
      "(GPU: 0, epoch: 5, iters: 24480, time: 0.008) nll: 0.551083 \n",
      "(GPU: 0, epoch: 5, iters: 25280, time: 0.008) nll: 0.701599 \n",
      "(GPU: 0, epoch: 5, iters: 26080, time: 0.008) nll: 0.677960 \n",
      "(GPU: 0, epoch: 5, iters: 26880, time: 0.008) nll: 0.596058 \n",
      "(GPU: 0, epoch: 5, iters: 27680, time: 0.007) nll: 0.702310 \n",
      "(GPU: 0, epoch: 5, iters: 28480, time: 0.008) nll: 0.648925 \n",
      "(GPU: 0, epoch: 5, iters: 29280, time: 0.008) nll: 1.151615 \n",
      "(GPU: 0, epoch: 5, iters: 30080, time: 0.008) nll: 0.617655 \n",
      "(GPU: 0, epoch: 5, iters: 30880, time: 0.007) nll: 0.593531 \n",
      "(GPU: 0, epoch: 5, iters: 31680, time: 0.008) nll: 1.325307 \n",
      "(GPU: 0, epoch: 5, iters: 32480, time: 0.008) nll: 0.396188 \n",
      "(GPU: 0, epoch: 5, iters: 33280, time: 0.008) nll: 0.546348 \n",
      "(GPU: 0, epoch: 5, iters: 34080, time: 0.008) nll: 0.930298 \n",
      "(GPU: 0, epoch: 5, iters: 34880, time: 0.008) nll: 0.823421 \n",
      "(GPU: 0, epoch: 5, iters: 35680, time: 0.008) nll: 0.896067 \n",
      "(GPU: 0, epoch: 5, iters: 36480, time: 0.008) nll: 0.894002 \n",
      "saving the latest model (epoch 5, total_steps 740000)\n",
      "(GPU: 0, epoch: 5, iters: 37280, time: 0.008) nll: 0.624468 \n",
      "(GPU: 0, epoch: 5, iters: 38080, time: 0.008) nll: 0.788365 \n",
      "(GPU: 0, epoch: 5, iters: 38880, time: 0.008) nll: 0.585062 \n",
      "(GPU: 0, epoch: 5, iters: 39680, time: 0.008) nll: 0.711386 \n",
      "(GPU: 0, epoch: 5, iters: 40480, time: 0.008) nll: 0.599844 \n",
      "(GPU: 0, epoch: 5, iters: 41280, time: 0.008) nll: 0.702914 \n",
      "(GPU: 0, epoch: 5, iters: 42080, time: 0.008) nll: 0.772800 \n",
      "(GPU: 0, epoch: 5, iters: 42880, time: 0.008) nll: 0.917849 \n",
      "(GPU: 0, epoch: 5, iters: 43680, time: 0.008) nll: 0.771688 \n",
      "(GPU: 0, epoch: 5, iters: 44480, time: 0.008) nll: 0.865789 \n",
      "(GPU: 0, epoch: 5, iters: 45280, time: 0.008) nll: 0.483427 \n",
      "(GPU: 0, epoch: 5, iters: 46080, time: 0.008) nll: 0.764087 \n",
      "(GPU: 0, epoch: 5, iters: 46880, time: 0.008) nll: 0.550219 \n",
      "(GPU: 0, epoch: 5, iters: 47680, time: 0.008) nll: 0.702973 \n",
      "(GPU: 0, epoch: 5, iters: 48480, time: 0.008) nll: 0.541380 \n",
      "(GPU: 0, epoch: 5, iters: 49280, time: 0.008) nll: 0.954656 \n",
      "(GPU: 0, epoch: 5, iters: 50080, time: 0.008) nll: 1.007309 \n",
      "(GPU: 0, epoch: 5, iters: 50880, time: 0.008) nll: 0.694892 \n",
      "(GPU: 0, epoch: 5, iters: 51680, time: 0.008) nll: 0.587788 \n",
      "(GPU: 0, epoch: 5, iters: 52480, time: 0.008) nll: 0.674587 \n",
      "(GPU: 0, epoch: 5, iters: 53280, time: 0.008) nll: 0.521848 \n",
      "(GPU: 0, epoch: 5, iters: 54080, time: 0.008) nll: 1.095738 \n",
      "(GPU: 0, epoch: 5, iters: 54880, time: 0.008) nll: 0.856273 \n",
      "(GPU: 0, epoch: 5, iters: 55680, time: 0.008) nll: 0.981683 \n",
      "(GPU: 0, epoch: 5, iters: 56480, time: 0.008) nll: 0.832511 \n",
      "saving the latest model (epoch 5, total_steps 760000)\n",
      "(GPU: 0, epoch: 5, iters: 57280, time: 0.008) nll: 0.706956 \n",
      "(GPU: 0, epoch: 5, iters: 58080, time: 0.008) nll: 0.736007 \n",
      "(GPU: 0, epoch: 5, iters: 58880, time: 0.008) nll: 0.799310 \n",
      "(GPU: 0, epoch: 5, iters: 59680, time: 0.008) nll: 0.679465 \n",
      "(GPU: 0, epoch: 5, iters: 60480, time: 0.008) nll: 0.434259 \n",
      "(GPU: 0, epoch: 5, iters: 61280, time: 0.008) nll: 0.625160 \n",
      "(GPU: 0, epoch: 5, iters: 62080, time: 0.008) nll: 0.641690 \n",
      "(GPU: 0, epoch: 5, iters: 62880, time: 0.008) nll: 0.788646 \n",
      "(GPU: 0, epoch: 5, iters: 63680, time: 0.008) nll: 0.547343 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.008) nll: 0.667901 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.013) nll: 0.661466 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.013) nll: 0.722572 \n",
      "(GPU: 0, epoch: 5, iters: 65280, time: 0.008) nll: 0.902505 \n",
      "(GPU: 0, epoch: 5, iters: 66080, time: 0.008) nll: 0.633510 \n",
      "(GPU: 0, epoch: 5, iters: 66880, time: 0.008) nll: 0.782709 \n",
      "(GPU: 0, epoch: 5, iters: 67680, time: 0.008) nll: 0.817284 \n",
      "(GPU: 0, epoch: 5, iters: 68480, time: 0.008) nll: 0.672340 \n",
      "(GPU: 0, epoch: 5, iters: 69280, time: 0.008) nll: 1.150712 \n",
      "(GPU: 0, epoch: 5, iters: 70080, time: 0.008) nll: 0.614807 \n",
      "(GPU: 0, epoch: 5, iters: 70880, time: 0.008) nll: 0.756607 \n",
      "(GPU: 0, epoch: 5, iters: 71680, time: 0.008) nll: 0.817396 \n",
      "(GPU: 0, epoch: 5, iters: 72480, time: 0.008) nll: 0.715415 \n",
      "(GPU: 0, epoch: 5, iters: 73280, time: 0.008) nll: 0.684423 \n",
      "(GPU: 0, epoch: 5, iters: 74080, time: 0.008) nll: 1.017408 \n",
      "(GPU: 0, epoch: 5, iters: 74880, time: 0.008) nll: 0.648199 \n",
      "(GPU: 0, epoch: 5, iters: 75680, time: 0.008) nll: 0.802231 \n",
      "(GPU: 0, epoch: 5, iters: 76480, time: 0.008) nll: 0.756001 \n",
      "saving the latest model (epoch 5, total_steps 780000)\n",
      "(GPU: 0, epoch: 5, iters: 77280, time: 0.008) nll: 0.792146 \n",
      "(GPU: 0, epoch: 5, iters: 78080, time: 0.008) nll: 0.581733 \n",
      "(GPU: 0, epoch: 5, iters: 78880, time: 0.007) nll: 0.800433 \n",
      "(GPU: 0, epoch: 5, iters: 79680, time: 0.008) nll: 0.604820 \n",
      "(GPU: 0, epoch: 5, iters: 80480, time: 0.008) nll: 0.612463 \n",
      "(GPU: 0, epoch: 5, iters: 81280, time: 0.008) nll: 0.813931 \n",
      "(GPU: 0, epoch: 5, iters: 82080, time: 0.008) nll: 0.533808 \n",
      "(GPU: 0, epoch: 5, iters: 82880, time: 0.008) nll: 0.659031 \n",
      "(GPU: 0, epoch: 5, iters: 83680, time: 0.008) nll: 0.749747 \n",
      "(GPU: 0, epoch: 5, iters: 84480, time: 0.008) nll: 0.557503 \n",
      "(GPU: 0, epoch: 5, iters: 85280, time: 0.008) nll: 0.772122 \n",
      "(GPU: 0, epoch: 5, iters: 86080, time: 0.008) nll: 0.738105 \n",
      "(GPU: 0, epoch: 5, iters: 86880, time: 0.008) nll: 0.448152 \n",
      "(GPU: 0, epoch: 5, iters: 87680, time: 0.008) nll: 0.434694 \n",
      "(GPU: 0, epoch: 5, iters: 88480, time: 0.008) nll: 0.824225 \n",
      "(GPU: 0, epoch: 5, iters: 89280, time: 0.008) nll: 0.689442 \n",
      "(GPU: 0, epoch: 5, iters: 90080, time: 0.007) nll: 0.708707 \n",
      "(GPU: 0, epoch: 5, iters: 90880, time: 0.008) nll: 0.689972 \n",
      "(GPU: 0, epoch: 5, iters: 91680, time: 0.008) nll: 0.555676 \n",
      "(GPU: 0, epoch: 5, iters: 92480, time: 0.008) nll: 0.658864 \n",
      "(GPU: 0, epoch: 5, iters: 93280, time: 0.008) nll: 0.792801 \n",
      "(GPU: 0, epoch: 5, iters: 94080, time: 0.008) nll: 0.690651 \n",
      "(GPU: 0, epoch: 5, iters: 94880, time: 0.008) nll: 1.112456 \n",
      "(GPU: 0, epoch: 5, iters: 95680, time: 0.008) nll: 0.675630 \n",
      "(GPU: 0, epoch: 5, iters: 96480, time: 0.008) nll: 0.616306 \n",
      "saving the latest model (epoch 5, total_steps 800000)\n",
      "(GPU: 0, epoch: 5, iters: 97280, time: 0.008) nll: 0.735031 \n",
      "(GPU: 0, epoch: 5, iters: 98080, time: 0.008) nll: 0.738472 \n",
      "(GPU: 0, epoch: 5, iters: 98880, time: 0.008) nll: 0.866424 \n",
      "(GPU: 0, epoch: 5, iters: 99680, time: 0.007) nll: 0.476587 \n",
      "(GPU: 0, epoch: 5, iters: 100480, time: 0.008) nll: 0.863925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:34<00:00,  3.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 101280, time: 0.008) nll: 0.574786 \n",
      "(GPU: 0, epoch: 5, iters: 102080, time: 0.008) nll: 0.766454 \n",
      "(GPU: 0, epoch: 5, iters: 102880, time: 0.008) nll: 1.056221 \n",
      "(GPU: 0, epoch: 5, iters: 103680, time: 0.008) nll: 0.552433 \n",
      "(GPU: 0, epoch: 5, iters: 104480, time: 0.008) nll: 0.806872 \n",
      "(GPU: 0, epoch: 5, iters: 105280, time: 0.008) nll: 0.810759 \n",
      "(GPU: 0, epoch: 5, iters: 106080, time: 0.008) nll: 0.378844 \n",
      "(GPU: 0, epoch: 5, iters: 106880, time: 0.008) nll: 0.649977 \n",
      "(GPU: 0, epoch: 5, iters: 107680, time: 0.008) nll: 0.658640 \n",
      "(GPU: 0, epoch: 5, iters: 108480, time: 0.008) nll: 0.981098 \n",
      "(GPU: 0, epoch: 5, iters: 109280, time: 0.008) nll: 0.745400 \n",
      "(GPU: 0, epoch: 5, iters: 110080, time: 0.008) nll: 0.880345 \n",
      "(GPU: 0, epoch: 5, iters: 110880, time: 0.008) nll: 0.768045 \n",
      "(GPU: 0, epoch: 5, iters: 111680, time: 0.008) nll: 0.624436 \n",
      "(GPU: 0, epoch: 5, iters: 112480, time: 0.008) nll: 0.622618 \n",
      "(GPU: 0, epoch: 5, iters: 113280, time: 0.008) nll: 0.570520 \n",
      "(GPU: 0, epoch: 5, iters: 114080, time: 0.008) nll: 0.880805 \n",
      "(GPU: 0, epoch: 5, iters: 114880, time: 0.008) nll: 0.860693 \n",
      "(GPU: 0, epoch: 5, iters: 115680, time: 0.008) nll: 0.581161 \n",
      "(GPU: 0, epoch: 5, iters: 116480, time: 0.008) nll: 0.871618 \n",
      "saving the latest model (epoch 5, total_steps 820000)\n",
      "(GPU: 0, epoch: 5, iters: 117280, time: 0.008) nll: 0.635523 \n",
      "(GPU: 0, epoch: 5, iters: 118080, time: 0.008) nll: 0.684555 \n",
      "(GPU: 0, epoch: 5, iters: 118880, time: 0.008) nll: 0.718119 \n",
      "(GPU: 0, epoch: 5, iters: 119680, time: 0.008) nll: 0.900506 \n",
      "(GPU: 0, epoch: 5, iters: 120480, time: 0.008) nll: 1.145093 \n",
      "(GPU: 0, epoch: 5, iters: 121280, time: 0.008) nll: 0.990319 \n",
      "(GPU: 0, epoch: 5, iters: 122080, time: 0.008) nll: 0.490979 \n",
      "(GPU: 0, epoch: 5, iters: 122880, time: 0.008) nll: 0.751697 \n",
      "(GPU: 0, epoch: 5, iters: 123680, time: 0.008) nll: 0.982811 \n",
      "(GPU: 0, epoch: 5, iters: 124480, time: 0.008) nll: 0.819041 \n",
      "(GPU: 0, epoch: 5, iters: 125280, time: 0.008) nll: 0.757599 \n",
      "(GPU: 0, epoch: 5, iters: 126080, time: 0.008) nll: 0.600105 \n",
      "(GPU: 0, epoch: 5, iters: 126880, time: 0.008) nll: 0.510355 \n",
      "(GPU: 0, epoch: 5, iters: 127680, time: 0.008) nll: 0.798037 \n",
      "(GPU: 0, epoch: 5, iters: 128480, time: 0.008) nll: 1.060083 \n",
      "(GPU: 0, epoch: 5, iters: 129280, time: 0.008) nll: 0.521862 \n",
      "(GPU: 0, epoch: 5, iters: 130080, time: 0.008) nll: 0.738875 \n",
      "(GPU: 0, epoch: 5, iters: 130880, time: 0.008) nll: 0.807502 \n",
      "(GPU: 0, epoch: 5, iters: 131680, time: 0.008) nll: 0.560054 \n",
      "(GPU: 0, epoch: 5, iters: 132480, time: 0.008) nll: 0.734074 \n",
      "(GPU: 0, epoch: 5, iters: 133280, time: 0.008) nll: 0.767290 \n",
      "(GPU: 0, epoch: 5, iters: 134080, time: 0.008) nll: 0.789845 \n",
      "(GPU: 0, epoch: 5, iters: 134880, time: 0.008) nll: 0.683706 \n",
      "(GPU: 0, epoch: 5, iters: 135680, time: 0.008) nll: 0.919922 \n",
      "(GPU: 0, epoch: 5, iters: 136480, time: 0.008) nll: 0.750622 \n",
      "saving the latest model (epoch 5, total_steps 840000)\n",
      "(GPU: 0, epoch: 5, iters: 137280, time: 0.008) nll: 0.429593 \n",
      "(GPU: 0, epoch: 5, iters: 138080, time: 0.008) nll: 0.864847 \n",
      "(GPU: 0, epoch: 5, iters: 138880, time: 0.008) nll: 1.097597 \n",
      "(GPU: 0, epoch: 5, iters: 139680, time: 0.008) nll: 0.486934 \n",
      "(GPU: 0, epoch: 5, iters: 140480, time: 0.008) nll: 0.829381 \n",
      "[*] End of epoch 5 / 25 \t Time Taken: 1235 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000600\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3167/4397 [14:51<05:19,  3.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 32, time: 0.004) nll: 0.620199 \n",
      "(GPU: 0, epoch: 6, iters: 32, time: 0.004) nll: 0.637655 \n",
      "(GPU: 0, epoch: 6, iters: 576, time: 0.008) nll: 0.646427 \n",
      "(GPU: 0, epoch: 6, iters: 1376, time: 0.008) nll: 0.702397 \n",
      "(GPU: 0, epoch: 6, iters: 2176, time: 0.008) nll: 0.647105 \n",
      "(GPU: 0, epoch: 6, iters: 2976, time: 0.008) nll: 0.619027 \n",
      "(GPU: 0, epoch: 6, iters: 3776, time: 0.008) nll: 0.953490 \n",
      "(GPU: 0, epoch: 6, iters: 4576, time: 0.008) nll: 0.709872 \n",
      "(GPU: 0, epoch: 6, iters: 5376, time: 0.008) nll: 0.756253 \n",
      "(GPU: 0, epoch: 6, iters: 6176, time: 0.008) nll: 0.832920 \n",
      "(GPU: 0, epoch: 6, iters: 6976, time: 0.008) nll: 0.671568 \n",
      "(GPU: 0, epoch: 6, iters: 7776, time: 0.008) nll: 0.643318 \n",
      "(GPU: 0, epoch: 6, iters: 8576, time: 0.008) nll: 0.833790 \n",
      "(GPU: 0, epoch: 6, iters: 9376, time: 0.008) nll: 0.570955 \n",
      "(GPU: 0, epoch: 6, iters: 10176, time: 0.008) nll: 0.790576 \n",
      "(GPU: 0, epoch: 6, iters: 10976, time: 0.008) nll: 0.630793 \n",
      "(GPU: 0, epoch: 6, iters: 11776, time: 0.008) nll: 0.696425 \n",
      "(GPU: 0, epoch: 6, iters: 12576, time: 0.008) nll: 0.611811 \n",
      "(GPU: 0, epoch: 6, iters: 13376, time: 0.008) nll: 0.759326 \n",
      "(GPU: 0, epoch: 6, iters: 14176, time: 0.008) nll: 0.688074 \n",
      "(GPU: 0, epoch: 6, iters: 14976, time: 0.008) nll: 0.856091 \n",
      "(GPU: 0, epoch: 6, iters: 15776, time: 0.008) nll: 0.652661 \n",
      "saving the latest model (epoch 6, total_steps 860000)\n",
      "(GPU: 0, epoch: 6, iters: 16576, time: 0.008) nll: 0.737907 \n",
      "(GPU: 0, epoch: 6, iters: 17376, time: 0.008) nll: 0.788400 \n",
      "(GPU: 0, epoch: 6, iters: 18176, time: 0.008) nll: 0.821404 \n",
      "(GPU: 0, epoch: 6, iters: 18976, time: 0.008) nll: 0.604961 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.008) nll: 0.691465 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.013) nll: 0.690155 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.013) nll: 0.734212 \n",
      "(GPU: 0, epoch: 6, iters: 20576, time: 0.008) nll: 0.722613 \n",
      "(GPU: 0, epoch: 6, iters: 21376, time: 0.008) nll: 0.838408 \n",
      "(GPU: 0, epoch: 6, iters: 22176, time: 0.008) nll: 1.288442 \n",
      "(GPU: 0, epoch: 6, iters: 22976, time: 0.008) nll: 0.663234 \n",
      "(GPU: 0, epoch: 6, iters: 23776, time: 0.008) nll: 0.796810 \n",
      "(GPU: 0, epoch: 6, iters: 24576, time: 0.008) nll: 0.821402 \n",
      "(GPU: 0, epoch: 6, iters: 25376, time: 0.008) nll: 0.858358 \n",
      "(GPU: 0, epoch: 6, iters: 26176, time: 0.008) nll: 0.569219 \n",
      "(GPU: 0, epoch: 6, iters: 26976, time: 0.008) nll: 0.792585 \n",
      "(GPU: 0, epoch: 6, iters: 27776, time: 0.008) nll: 0.558937 \n",
      "(GPU: 0, epoch: 6, iters: 28576, time: 0.008) nll: 1.132279 \n",
      "(GPU: 0, epoch: 6, iters: 29376, time: 0.008) nll: 0.773278 \n",
      "(GPU: 0, epoch: 6, iters: 30176, time: 0.008) nll: 0.771405 \n",
      "(GPU: 0, epoch: 6, iters: 30976, time: 0.008) nll: 0.652764 \n",
      "(GPU: 0, epoch: 6, iters: 31776, time: 0.008) nll: 0.545132 \n",
      "(GPU: 0, epoch: 6, iters: 32576, time: 0.008) nll: 0.617864 \n",
      "(GPU: 0, epoch: 6, iters: 33376, time: 0.008) nll: 0.909760 \n",
      "(GPU: 0, epoch: 6, iters: 34176, time: 0.008) nll: 0.641359 \n",
      "(GPU: 0, epoch: 6, iters: 34976, time: 0.008) nll: 0.953918 \n",
      "(GPU: 0, epoch: 6, iters: 35776, time: 0.008) nll: 0.717482 \n",
      "saving the latest model (epoch 6, total_steps 880000)\n",
      "(GPU: 0, epoch: 6, iters: 36576, time: 0.008) nll: 0.795357 \n",
      "(GPU: 0, epoch: 6, iters: 37376, time: 0.008) nll: 0.580227 \n",
      "(GPU: 0, epoch: 6, iters: 38176, time: 0.008) nll: 0.666584 \n",
      "(GPU: 0, epoch: 6, iters: 38976, time: 0.008) nll: 0.740383 \n",
      "(GPU: 0, epoch: 6, iters: 39776, time: 0.008) nll: 0.819761 \n",
      "(GPU: 0, epoch: 6, iters: 40576, time: 0.008) nll: 0.708920 \n",
      "(GPU: 0, epoch: 6, iters: 41376, time: 0.008) nll: 0.716775 \n",
      "(GPU: 0, epoch: 6, iters: 42176, time: 0.008) nll: 0.638867 \n",
      "(GPU: 0, epoch: 6, iters: 42976, time: 0.008) nll: 0.671060 \n",
      "(GPU: 0, epoch: 6, iters: 43776, time: 0.008) nll: 0.635805 \n",
      "(GPU: 0, epoch: 6, iters: 44576, time: 0.008) nll: 1.017078 \n",
      "(GPU: 0, epoch: 6, iters: 45376, time: 0.008) nll: 0.755011 \n",
      "(GPU: 0, epoch: 6, iters: 46176, time: 0.008) nll: 0.811219 \n",
      "(GPU: 0, epoch: 6, iters: 46976, time: 0.008) nll: 0.588275 \n",
      "(GPU: 0, epoch: 6, iters: 47776, time: 0.008) nll: 0.677417 \n",
      "(GPU: 0, epoch: 6, iters: 48576, time: 0.008) nll: 0.825553 \n",
      "(GPU: 0, epoch: 6, iters: 49376, time: 0.008) nll: 0.579618 \n",
      "(GPU: 0, epoch: 6, iters: 50176, time: 0.008) nll: 0.750408 \n",
      "(GPU: 0, epoch: 6, iters: 50976, time: 0.008) nll: 0.835426 \n",
      "(GPU: 0, epoch: 6, iters: 51776, time: 0.008) nll: 0.704043 \n",
      "(GPU: 0, epoch: 6, iters: 52576, time: 0.008) nll: 0.707778 \n",
      "(GPU: 0, epoch: 6, iters: 53376, time: 0.008) nll: 0.854719 \n",
      "(GPU: 0, epoch: 6, iters: 54176, time: 0.008) nll: 0.783561 \n",
      "(GPU: 0, epoch: 6, iters: 54976, time: 0.008) nll: 0.684945 \n",
      "(GPU: 0, epoch: 6, iters: 55776, time: 0.008) nll: 0.558431 \n",
      "saving the latest model (epoch 6, total_steps 900000)\n",
      "(GPU: 0, epoch: 6, iters: 56576, time: 0.008) nll: 0.539967 \n",
      "(GPU: 0, epoch: 6, iters: 57376, time: 0.008) nll: 0.768314 \n",
      "(GPU: 0, epoch: 6, iters: 58176, time: 0.008) nll: 0.583756 \n",
      "(GPU: 0, epoch: 6, iters: 58976, time: 0.008) nll: 0.703575 \n",
      "(GPU: 0, epoch: 6, iters: 59776, time: 0.008) nll: 0.577736 \n",
      "(GPU: 0, epoch: 6, iters: 60576, time: 0.008) nll: 0.755573 \n",
      "(GPU: 0, epoch: 6, iters: 61376, time: 0.008) nll: 0.666260 \n",
      "(GPU: 0, epoch: 6, iters: 62176, time: 0.008) nll: 0.941770 \n",
      "(GPU: 0, epoch: 6, iters: 62976, time: 0.008) nll: 1.049637 \n",
      "(GPU: 0, epoch: 6, iters: 63776, time: 0.008) nll: 0.589316 \n",
      "(GPU: 0, epoch: 6, iters: 64576, time: 0.008) nll: 1.180773 \n",
      "(GPU: 0, epoch: 6, iters: 65376, time: 0.008) nll: 0.605116 \n",
      "(GPU: 0, epoch: 6, iters: 66176, time: 0.008) nll: 0.663002 \n",
      "(GPU: 0, epoch: 6, iters: 66976, time: 0.008) nll: 0.642580 \n",
      "(GPU: 0, epoch: 6, iters: 67776, time: 0.008) nll: 0.910499 \n",
      "(GPU: 0, epoch: 6, iters: 68576, time: 0.008) nll: 0.817660 \n",
      "(GPU: 0, epoch: 6, iters: 69376, time: 0.008) nll: 0.676496 \n",
      "(GPU: 0, epoch: 6, iters: 70176, time: 0.008) nll: 0.800111 \n",
      "(GPU: 0, epoch: 6, iters: 70976, time: 0.008) nll: 0.788980 \n",
      "(GPU: 0, epoch: 6, iters: 71776, time: 0.008) nll: 0.704789 \n",
      "(GPU: 0, epoch: 6, iters: 72576, time: 0.008) nll: 1.185810 \n",
      "(GPU: 0, epoch: 6, iters: 73376, time: 0.008) nll: 0.571860 \n",
      "(GPU: 0, epoch: 6, iters: 74176, time: 0.008) nll: 0.475067 \n",
      "(GPU: 0, epoch: 6, iters: 74976, time: 0.008) nll: 0.794823 \n",
      "(GPU: 0, epoch: 6, iters: 75776, time: 0.008) nll: 0.697520 \n",
      "saving the latest model (epoch 6, total_steps 920000)\n",
      "(GPU: 0, epoch: 6, iters: 76576, time: 0.008) nll: 0.676201 \n",
      "(GPU: 0, epoch: 6, iters: 77376, time: 0.008) nll: 0.832166 \n",
      "(GPU: 0, epoch: 6, iters: 78176, time: 0.007) nll: 0.670988 \n",
      "(GPU: 0, epoch: 6, iters: 78976, time: 0.008) nll: 0.673974 \n",
      "(GPU: 0, epoch: 6, iters: 79776, time: 0.008) nll: 0.788352 \n",
      "(GPU: 0, epoch: 6, iters: 80576, time: 0.008) nll: 0.717774 \n",
      "(GPU: 0, epoch: 6, iters: 81376, time: 0.008) nll: 0.819135 \n",
      "(GPU: 0, epoch: 6, iters: 82176, time: 0.008) nll: 0.684228 \n",
      "(GPU: 0, epoch: 6, iters: 82976, time: 0.008) nll: 0.465836 \n",
      "(GPU: 0, epoch: 6, iters: 83776, time: 0.008) nll: 0.738498 \n",
      "(GPU: 0, epoch: 6, iters: 84576, time: 0.008) nll: 0.501938 \n",
      "(GPU: 0, epoch: 6, iters: 85376, time: 0.008) nll: 0.657037 \n",
      "(GPU: 0, epoch: 6, iters: 86176, time: 0.007) nll: 0.567786 \n",
      "(GPU: 0, epoch: 6, iters: 86976, time: 0.008) nll: 0.767915 \n",
      "(GPU: 0, epoch: 6, iters: 87776, time: 0.008) nll: 0.820615 \n",
      "(GPU: 0, epoch: 6, iters: 88576, time: 0.008) nll: 0.726400 \n",
      "(GPU: 0, epoch: 6, iters: 89376, time: 0.008) nll: 0.624038 \n",
      "(GPU: 0, epoch: 6, iters: 90176, time: 0.008) nll: 0.720367 \n",
      "(GPU: 0, epoch: 6, iters: 90976, time: 0.008) nll: 0.906844 \n",
      "(GPU: 0, epoch: 6, iters: 91776, time: 0.008) nll: 0.691623 \n",
      "(GPU: 0, epoch: 6, iters: 92576, time: 0.008) nll: 0.491952 \n",
      "(GPU: 0, epoch: 6, iters: 93376, time: 0.008) nll: 0.772318 \n",
      "(GPU: 0, epoch: 6, iters: 94176, time: 0.008) nll: 0.950153 \n",
      "(GPU: 0, epoch: 6, iters: 94976, time: 0.008) nll: 0.468413 \n",
      "(GPU: 0, epoch: 6, iters: 95776, time: 0.008) nll: 0.900828 \n",
      "saving the latest model (epoch 6, total_steps 940000)\n",
      "(GPU: 0, epoch: 6, iters: 96576, time: 0.008) nll: 0.576101 \n",
      "(GPU: 0, epoch: 6, iters: 97376, time: 0.008) nll: 0.779494 \n",
      "(GPU: 0, epoch: 6, iters: 98176, time: 0.008) nll: 0.833392 \n",
      "(GPU: 0, epoch: 6, iters: 98976, time: 0.008) nll: 0.788481 \n",
      "(GPU: 0, epoch: 6, iters: 99776, time: 0.008) nll: 0.571724 \n",
      "(GPU: 0, epoch: 6, iters: 100576, time: 0.008) nll: 0.981331 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:38<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 101376, time: 0.008) nll: 0.643168 \n",
      "(GPU: 0, epoch: 6, iters: 102176, time: 0.008) nll: 0.597040 \n",
      "(GPU: 0, epoch: 6, iters: 102976, time: 0.008) nll: 0.905669 \n",
      "(GPU: 0, epoch: 6, iters: 103776, time: 0.008) nll: 0.580466 \n",
      "(GPU: 0, epoch: 6, iters: 104576, time: 0.008) nll: 0.891511 \n",
      "(GPU: 0, epoch: 6, iters: 105376, time: 0.008) nll: 0.604224 \n",
      "(GPU: 0, epoch: 6, iters: 106176, time: 0.008) nll: 0.677202 \n",
      "(GPU: 0, epoch: 6, iters: 106976, time: 0.008) nll: 0.608599 \n",
      "(GPU: 0, epoch: 6, iters: 107776, time: 0.008) nll: 0.647249 \n",
      "(GPU: 0, epoch: 6, iters: 108576, time: 0.007) nll: 0.709425 \n",
      "(GPU: 0, epoch: 6, iters: 109376, time: 0.008) nll: 0.836459 \n",
      "(GPU: 0, epoch: 6, iters: 110176, time: 0.008) nll: 0.601772 \n",
      "(GPU: 0, epoch: 6, iters: 110976, time: 0.008) nll: 0.593207 \n",
      "(GPU: 0, epoch: 6, iters: 111776, time: 0.008) nll: 0.774805 \n",
      "(GPU: 0, epoch: 6, iters: 112576, time: 0.008) nll: 0.785792 \n",
      "(GPU: 0, epoch: 6, iters: 113376, time: 0.007) nll: 0.380378 \n",
      "(GPU: 0, epoch: 6, iters: 114176, time: 0.008) nll: 0.810878 \n",
      "(GPU: 0, epoch: 6, iters: 114976, time: 0.008) nll: 0.844097 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.008) nll: 1.064829 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.013) nll: 1.039303 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.013) nll: 0.605007 \n",
      "saving the latest model (epoch 6, total_steps 960000)\n",
      "(GPU: 0, epoch: 6, iters: 116576, time: 0.008) nll: 0.574780 \n",
      "(GPU: 0, epoch: 6, iters: 117376, time: 0.008) nll: 1.166736 \n",
      "(GPU: 0, epoch: 6, iters: 118176, time: 0.008) nll: 0.701111 \n",
      "(GPU: 0, epoch: 6, iters: 118976, time: 0.008) nll: 0.878449 \n",
      "(GPU: 0, epoch: 6, iters: 119776, time: 0.008) nll: 0.765241 \n",
      "(GPU: 0, epoch: 6, iters: 120576, time: 0.008) nll: 0.779908 \n",
      "(GPU: 0, epoch: 6, iters: 121376, time: 0.008) nll: 0.617299 \n",
      "(GPU: 0, epoch: 6, iters: 122176, time: 0.008) nll: 0.873565 \n",
      "(GPU: 0, epoch: 6, iters: 122976, time: 0.008) nll: 0.769088 \n",
      "(GPU: 0, epoch: 6, iters: 123776, time: 0.008) nll: 1.046802 \n",
      "(GPU: 0, epoch: 6, iters: 124576, time: 0.008) nll: 0.560944 \n",
      "(GPU: 0, epoch: 6, iters: 125376, time: 0.008) nll: 0.789111 \n",
      "(GPU: 0, epoch: 6, iters: 126176, time: 0.008) nll: 0.627754 \n",
      "(GPU: 0, epoch: 6, iters: 126976, time: 0.008) nll: 0.719932 \n",
      "(GPU: 0, epoch: 6, iters: 127776, time: 0.008) nll: 0.584789 \n",
      "(GPU: 0, epoch: 6, iters: 128576, time: 0.008) nll: 0.532587 \n",
      "(GPU: 0, epoch: 6, iters: 129376, time: 0.008) nll: 0.681151 \n",
      "(GPU: 0, epoch: 6, iters: 130176, time: 0.008) nll: 0.532919 \n",
      "(GPU: 0, epoch: 6, iters: 130976, time: 0.008) nll: 0.632959 \n",
      "(GPU: 0, epoch: 6, iters: 131776, time: 0.008) nll: 0.741758 \n",
      "(GPU: 0, epoch: 6, iters: 132576, time: 0.008) nll: 0.654829 \n",
      "(GPU: 0, epoch: 6, iters: 133376, time: 0.008) nll: 0.801032 \n",
      "(GPU: 0, epoch: 6, iters: 134176, time: 0.008) nll: 0.635858 \n",
      "(GPU: 0, epoch: 6, iters: 134976, time: 0.008) nll: 0.409519 \n",
      "(GPU: 0, epoch: 6, iters: 135776, time: 0.008) nll: 0.753091 \n",
      "saving the latest model (epoch 6, total_steps 980000)\n",
      "(GPU: 0, epoch: 6, iters: 136576, time: 0.008) nll: 0.703193 \n",
      "(GPU: 0, epoch: 6, iters: 137376, time: 0.008) nll: 0.758986 \n",
      "(GPU: 0, epoch: 6, iters: 138176, time: 0.008) nll: 0.525663 \n",
      "(GPU: 0, epoch: 6, iters: 138976, time: 0.008) nll: 0.926309 \n",
      "(GPU: 0, epoch: 6, iters: 139776, time: 0.008) nll: 0.721397 \n",
      "(GPU: 0, epoch: 6, iters: 140576, time: 0.008) nll: 0.628238 \n",
      "saving the model at the end of epoch 6, iters 984928\n",
      "([test] GPU: 0, epoch: 6) \n",
      "OrderedDict()\n",
      "[*] End of epoch 6 / 25 \t Time Taken: 1265 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000700\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3170/4397 [14:55<05:15,  3.89it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 32, time: 0.004) nll: 0.895328 \n",
      "(GPU: 0, epoch: 7, iters: 32, time: 0.004) nll: 0.746984 \n",
      "(GPU: 0, epoch: 7, iters: 672, time: 0.008) nll: 0.858661 \n",
      "(GPU: 0, epoch: 7, iters: 1472, time: 0.008) nll: 0.676015 \n",
      "(GPU: 0, epoch: 7, iters: 2272, time: 0.008) nll: 0.632957 \n",
      "(GPU: 0, epoch: 7, iters: 3072, time: 0.008) nll: 0.705829 \n",
      "(GPU: 0, epoch: 7, iters: 3872, time: 0.008) nll: 0.911409 \n",
      "(GPU: 0, epoch: 7, iters: 4672, time: 0.008) nll: 0.527666 \n",
      "(GPU: 0, epoch: 7, iters: 5472, time: 0.008) nll: 0.675500 \n",
      "(GPU: 0, epoch: 7, iters: 6272, time: 0.008) nll: 0.611055 \n",
      "(GPU: 0, epoch: 7, iters: 7072, time: 0.008) nll: 0.965964 \n",
      "(GPU: 0, epoch: 7, iters: 7872, time: 0.008) nll: 0.748445 \n",
      "(GPU: 0, epoch: 7, iters: 8672, time: 0.008) nll: 0.705607 \n",
      "(GPU: 0, epoch: 7, iters: 9472, time: 0.008) nll: 0.775590 \n",
      "(GPU: 0, epoch: 7, iters: 10272, time: 0.008) nll: 0.546461 \n",
      "(GPU: 0, epoch: 7, iters: 11072, time: 0.008) nll: 0.549120 \n",
      "(GPU: 0, epoch: 7, iters: 11872, time: 0.008) nll: 0.412899 \n",
      "(GPU: 0, epoch: 7, iters: 12672, time: 0.008) nll: 0.842474 \n",
      "(GPU: 0, epoch: 7, iters: 13472, time: 0.008) nll: 0.582985 \n",
      "(GPU: 0, epoch: 7, iters: 14272, time: 0.008) nll: 0.643747 \n",
      "(GPU: 0, epoch: 7, iters: 15072, time: 0.007) nll: 0.819976 \n",
      "saving the latest model (epoch 7, total_steps 1000000)\n",
      "(GPU: 0, epoch: 7, iters: 15872, time: 0.008) nll: 0.585468 \n",
      "(GPU: 0, epoch: 7, iters: 16672, time: 0.008) nll: 0.494387 \n",
      "(GPU: 0, epoch: 7, iters: 17472, time: 0.008) nll: 0.790723 \n",
      "(GPU: 0, epoch: 7, iters: 18272, time: 0.008) nll: 0.833885 \n",
      "(GPU: 0, epoch: 7, iters: 19072, time: 0.008) nll: 0.655118 \n",
      "(GPU: 0, epoch: 7, iters: 19872, time: 0.008) nll: 0.535639 \n",
      "(GPU: 0, epoch: 7, iters: 20672, time: 0.008) nll: 0.781689 \n",
      "(GPU: 0, epoch: 7, iters: 21472, time: 0.008) nll: 0.825963 \n",
      "(GPU: 0, epoch: 7, iters: 22272, time: 0.008) nll: 0.793666 \n",
      "(GPU: 0, epoch: 7, iters: 23072, time: 0.008) nll: 0.607460 \n",
      "(GPU: 0, epoch: 7, iters: 23872, time: 0.008) nll: 0.917477 \n",
      "(GPU: 0, epoch: 7, iters: 24672, time: 0.008) nll: 0.671289 \n",
      "(GPU: 0, epoch: 7, iters: 25472, time: 0.008) nll: 0.539198 \n",
      "(GPU: 0, epoch: 7, iters: 26272, time: 0.008) nll: 0.618359 \n",
      "(GPU: 0, epoch: 7, iters: 27072, time: 0.008) nll: 0.553806 \n",
      "(GPU: 0, epoch: 7, iters: 27872, time: 0.008) nll: 0.561631 \n",
      "(GPU: 0, epoch: 7, iters: 28672, time: 0.008) nll: 0.678888 \n",
      "(GPU: 0, epoch: 7, iters: 29472, time: 0.008) nll: 0.744859 \n",
      "(GPU: 0, epoch: 7, iters: 30272, time: 0.008) nll: 0.816515 \n",
      "(GPU: 0, epoch: 7, iters: 31072, time: 0.008) nll: 0.609024 \n",
      "(GPU: 0, epoch: 7, iters: 31872, time: 0.008) nll: 0.432862 \n",
      "(GPU: 0, epoch: 7, iters: 32672, time: 0.008) nll: 0.735771 \n",
      "(GPU: 0, epoch: 7, iters: 33472, time: 0.008) nll: 0.669978 \n",
      "(GPU: 0, epoch: 7, iters: 34272, time: 0.008) nll: 0.945413 \n",
      "(GPU: 0, epoch: 7, iters: 35072, time: 0.008) nll: 0.723330 \n",
      "saving the latest model (epoch 7, total_steps 1020000)\n",
      "(GPU: 0, epoch: 7, iters: 35872, time: 0.008) nll: 0.884337 \n",
      "(GPU: 0, epoch: 7, iters: 36672, time: 0.008) nll: 0.768752 \n",
      "(GPU: 0, epoch: 7, iters: 37472, time: 0.008) nll: 0.670060 \n",
      "(GPU: 0, epoch: 7, iters: 38272, time: 0.008) nll: 0.574047 \n",
      "(GPU: 0, epoch: 7, iters: 39072, time: 0.008) nll: 0.585005 \n",
      "(GPU: 0, epoch: 7, iters: 39872, time: 0.008) nll: 0.604039 \n",
      "(GPU: 0, epoch: 7, iters: 40672, time: 0.008) nll: 0.635852 \n",
      "(GPU: 0, epoch: 7, iters: 41472, time: 0.008) nll: 0.608075 \n",
      "(GPU: 0, epoch: 7, iters: 42272, time: 0.008) nll: 0.713713 \n",
      "(GPU: 0, epoch: 7, iters: 43072, time: 0.008) nll: 0.678812 \n",
      "(GPU: 0, epoch: 7, iters: 43872, time: 0.008) nll: 0.591204 \n",
      "(GPU: 0, epoch: 7, iters: 44672, time: 0.008) nll: 0.768044 \n",
      "(GPU: 0, epoch: 7, iters: 45472, time: 0.008) nll: 0.831037 \n",
      "(GPU: 0, epoch: 7, iters: 46272, time: 0.008) nll: 0.612243 \n",
      "(GPU: 0, epoch: 7, iters: 47072, time: 0.008) nll: 0.565190 \n",
      "(GPU: 0, epoch: 7, iters: 47872, time: 0.008) nll: 0.870341 \n",
      "(GPU: 0, epoch: 7, iters: 48672, time: 0.008) nll: 0.860624 \n",
      "(GPU: 0, epoch: 7, iters: 49472, time: 0.008) nll: 0.524261 \n",
      "(GPU: 0, epoch: 7, iters: 50272, time: 0.008) nll: 0.653749 \n",
      "(GPU: 0, epoch: 7, iters: 51072, time: 0.008) nll: 0.659438 \n",
      "(GPU: 0, epoch: 7, iters: 51872, time: 0.008) nll: 0.678268 \n",
      "(GPU: 0, epoch: 7, iters: 52672, time: 0.008) nll: 0.946328 \n",
      "(GPU: 0, epoch: 7, iters: 53472, time: 0.008) nll: 0.662871 \n",
      "(GPU: 0, epoch: 7, iters: 54272, time: 0.008) nll: 0.782283 \n",
      "(GPU: 0, epoch: 7, iters: 55072, time: 0.008) nll: 0.750186 \n",
      "saving the latest model (epoch 7, total_steps 1040000)\n",
      "(GPU: 0, epoch: 7, iters: 55872, time: 0.008) nll: 0.828858 \n",
      "(GPU: 0, epoch: 7, iters: 56672, time: 0.008) nll: 0.704723 \n",
      "(GPU: 0, epoch: 7, iters: 57472, time: 0.008) nll: 0.696790 \n",
      "(GPU: 0, epoch: 7, iters: 58272, time: 0.008) nll: 0.688708 \n",
      "(GPU: 0, epoch: 7, iters: 59072, time: 0.008) nll: 0.847467 \n",
      "(GPU: 0, epoch: 7, iters: 59872, time: 0.008) nll: 0.572966 \n",
      "(GPU: 0, epoch: 7, iters: 60672, time: 0.008) nll: 0.704133 \n",
      "(GPU: 0, epoch: 7, iters: 61472, time: 0.008) nll: 0.679883 \n",
      "(GPU: 0, epoch: 7, iters: 62272, time: 0.008) nll: 0.736732 \n",
      "(GPU: 0, epoch: 7, iters: 63072, time: 0.008) nll: 0.623523 \n",
      "(GPU: 0, epoch: 7, iters: 63872, time: 0.008) nll: 0.695182 \n",
      "(GPU: 0, epoch: 7, iters: 64672, time: 0.008) nll: 0.691297 \n",
      "(GPU: 0, epoch: 7, iters: 65472, time: 0.008) nll: 0.512226 \n",
      "(GPU: 0, epoch: 7, iters: 66272, time: 0.007) nll: 0.507036 \n",
      "(GPU: 0, epoch: 7, iters: 67072, time: 0.008) nll: 0.696040 \n",
      "(GPU: 0, epoch: 7, iters: 67872, time: 0.008) nll: 0.694429 \n",
      "(GPU: 0, epoch: 7, iters: 68672, time: 0.008) nll: 0.626868 \n",
      "(GPU: 0, epoch: 7, iters: 69472, time: 0.008) nll: 0.673414 \n",
      "(GPU: 0, epoch: 7, iters: 70272, time: 0.008) nll: 0.623628 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.008) nll: 0.681227 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.013) nll: 0.673165 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.013) nll: 0.857289 \n",
      "(GPU: 0, epoch: 7, iters: 71872, time: 0.008) nll: 0.752447 \n",
      "(GPU: 0, epoch: 7, iters: 72672, time: 0.008) nll: 0.802124 \n",
      "(GPU: 0, epoch: 7, iters: 73472, time: 0.008) nll: 0.553993 \n",
      "(GPU: 0, epoch: 7, iters: 74272, time: 0.008) nll: 0.927327 \n",
      "(GPU: 0, epoch: 7, iters: 75072, time: 0.008) nll: 0.701124 \n",
      "saving the latest model (epoch 7, total_steps 1060000)\n",
      "(GPU: 0, epoch: 7, iters: 75872, time: 0.008) nll: 0.654421 \n",
      "(GPU: 0, epoch: 7, iters: 76672, time: 0.008) nll: 0.721759 \n",
      "(GPU: 0, epoch: 7, iters: 77472, time: 0.008) nll: 0.731741 \n",
      "(GPU: 0, epoch: 7, iters: 78272, time: 0.008) nll: 0.757055 \n",
      "(GPU: 0, epoch: 7, iters: 79072, time: 0.008) nll: 0.681482 \n",
      "(GPU: 0, epoch: 7, iters: 79872, time: 0.008) nll: 0.836702 \n",
      "(GPU: 0, epoch: 7, iters: 80672, time: 0.007) nll: 0.871109 \n",
      "(GPU: 0, epoch: 7, iters: 81472, time: 0.008) nll: 0.833158 \n",
      "(GPU: 0, epoch: 7, iters: 82272, time: 0.007) nll: 0.786397 \n",
      "(GPU: 0, epoch: 7, iters: 83072, time: 0.008) nll: 0.534560 \n",
      "(GPU: 0, epoch: 7, iters: 83872, time: 0.008) nll: 1.000675 \n",
      "(GPU: 0, epoch: 7, iters: 84672, time: 0.008) nll: 0.724673 \n",
      "(GPU: 0, epoch: 7, iters: 85472, time: 0.008) nll: 1.069822 \n",
      "(GPU: 0, epoch: 7, iters: 86272, time: 0.008) nll: 0.981488 \n",
      "(GPU: 0, epoch: 7, iters: 87072, time: 0.008) nll: 0.627780 \n",
      "(GPU: 0, epoch: 7, iters: 87872, time: 0.008) nll: 0.832046 \n",
      "(GPU: 0, epoch: 7, iters: 88672, time: 0.008) nll: 0.748816 \n",
      "(GPU: 0, epoch: 7, iters: 89472, time: 0.008) nll: 0.689199 \n",
      "(GPU: 0, epoch: 7, iters: 90272, time: 0.008) nll: 0.540343 \n",
      "(GPU: 0, epoch: 7, iters: 91072, time: 0.008) nll: 0.936767 \n",
      "(GPU: 0, epoch: 7, iters: 91872, time: 0.008) nll: 1.408169 \n",
      "(GPU: 0, epoch: 7, iters: 92672, time: 0.008) nll: 0.760340 \n",
      "(GPU: 0, epoch: 7, iters: 93472, time: 0.008) nll: 0.767526 \n",
      "(GPU: 0, epoch: 7, iters: 94272, time: 0.008) nll: 0.716896 \n",
      "(GPU: 0, epoch: 7, iters: 95072, time: 0.008) nll: 0.631584 \n",
      "saving the latest model (epoch 7, total_steps 1080000)\n",
      "(GPU: 0, epoch: 7, iters: 95872, time: 0.008) nll: 0.587986 \n",
      "(GPU: 0, epoch: 7, iters: 96672, time: 0.008) nll: 0.414577 \n",
      "(GPU: 0, epoch: 7, iters: 97472, time: 0.008) nll: 0.665157 \n",
      "(GPU: 0, epoch: 7, iters: 98272, time: 0.007) nll: 0.518026 \n",
      "(GPU: 0, epoch: 7, iters: 99072, time: 0.008) nll: 0.675658 \n",
      "(GPU: 0, epoch: 7, iters: 99872, time: 0.008) nll: 0.757124 \n",
      "(GPU: 0, epoch: 7, iters: 100672, time: 0.008) nll: 0.915646 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:42<00:00,  3.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 101472, time: 0.008) nll: 0.626286 \n",
      "(GPU: 0, epoch: 7, iters: 102272, time: 0.008) nll: 1.191602 \n",
      "(GPU: 0, epoch: 7, iters: 103072, time: 0.008) nll: 0.758508 \n",
      "(GPU: 0, epoch: 7, iters: 103872, time: 0.008) nll: 0.624880 \n",
      "(GPU: 0, epoch: 7, iters: 104672, time: 0.008) nll: 0.909134 \n",
      "(GPU: 0, epoch: 7, iters: 105472, time: 0.008) nll: 1.121153 \n",
      "(GPU: 0, epoch: 7, iters: 106272, time: 0.008) nll: 0.683365 \n",
      "(GPU: 0, epoch: 7, iters: 107072, time: 0.008) nll: 0.923374 \n",
      "(GPU: 0, epoch: 7, iters: 107872, time: 0.008) nll: 0.730631 \n",
      "(GPU: 0, epoch: 7, iters: 108672, time: 0.008) nll: 0.763128 \n",
      "(GPU: 0, epoch: 7, iters: 109472, time: 0.008) nll: 0.708202 \n",
      "(GPU: 0, epoch: 7, iters: 110272, time: 0.008) nll: 0.750134 \n",
      "(GPU: 0, epoch: 7, iters: 111072, time: 0.008) nll: 0.725782 \n",
      "(GPU: 0, epoch: 7, iters: 111872, time: 0.008) nll: 0.562126 \n",
      "(GPU: 0, epoch: 7, iters: 112672, time: 0.008) nll: 0.693922 \n",
      "(GPU: 0, epoch: 7, iters: 113472, time: 0.008) nll: 0.868805 \n",
      "(GPU: 0, epoch: 7, iters: 114272, time: 0.008) nll: 0.766964 \n",
      "(GPU: 0, epoch: 7, iters: 115072, time: 0.008) nll: 0.905874 \n",
      "saving the latest model (epoch 7, total_steps 1100000)\n",
      "(GPU: 0, epoch: 7, iters: 115872, time: 0.008) nll: 0.521455 \n",
      "(GPU: 0, epoch: 7, iters: 116672, time: 0.008) nll: 0.657956 \n",
      "(GPU: 0, epoch: 7, iters: 117472, time: 0.008) nll: 1.001100 \n",
      "(GPU: 0, epoch: 7, iters: 118272, time: 0.008) nll: 0.773916 \n",
      "(GPU: 0, epoch: 7, iters: 119072, time: 0.008) nll: 0.845079 \n",
      "(GPU: 0, epoch: 7, iters: 119872, time: 0.008) nll: 0.744465 \n",
      "(GPU: 0, epoch: 7, iters: 120672, time: 0.008) nll: 1.055950 \n",
      "(GPU: 0, epoch: 7, iters: 121472, time: 0.008) nll: 0.696865 \n",
      "(GPU: 0, epoch: 7, iters: 122272, time: 0.008) nll: 0.575146 \n",
      "(GPU: 0, epoch: 7, iters: 123072, time: 0.008) nll: 0.513332 \n",
      "(GPU: 0, epoch: 7, iters: 123872, time: 0.008) nll: 0.550932 \n",
      "(GPU: 0, epoch: 7, iters: 124672, time: 0.008) nll: 0.561249 \n",
      "(GPU: 0, epoch: 7, iters: 125472, time: 0.008) nll: 0.977020 \n",
      "(GPU: 0, epoch: 7, iters: 126272, time: 0.008) nll: 0.660258 \n",
      "(GPU: 0, epoch: 7, iters: 127072, time: 0.008) nll: 0.628978 \n",
      "(GPU: 0, epoch: 7, iters: 127872, time: 0.008) nll: 0.866415 \n",
      "(GPU: 0, epoch: 7, iters: 128672, time: 0.008) nll: 0.694939 \n",
      "(GPU: 0, epoch: 7, iters: 129472, time: 0.008) nll: 0.908991 \n",
      "(GPU: 0, epoch: 7, iters: 130272, time: 0.008) nll: 0.903325 \n",
      "(GPU: 0, epoch: 7, iters: 131072, time: 0.008) nll: 0.681047 \n",
      "(GPU: 0, epoch: 7, iters: 131872, time: 0.008) nll: 0.875938 \n",
      "(GPU: 0, epoch: 7, iters: 132672, time: 0.008) nll: 0.847903 \n",
      "(GPU: 0, epoch: 7, iters: 133472, time: 0.008) nll: 1.066815 \n",
      "(GPU: 0, epoch: 7, iters: 134272, time: 0.008) nll: 0.719169 \n",
      "(GPU: 0, epoch: 7, iters: 135072, time: 0.008) nll: 0.597043 \n",
      "saving the latest model (epoch 7, total_steps 1120000)\n",
      "(GPU: 0, epoch: 7, iters: 135872, time: 0.008) nll: 0.936404 \n",
      "(GPU: 0, epoch: 7, iters: 136672, time: 0.007) nll: 0.762036 \n",
      "(GPU: 0, epoch: 7, iters: 137472, time: 0.008) nll: 0.752102 \n",
      "(GPU: 0, epoch: 7, iters: 138272, time: 0.008) nll: 0.873964 \n",
      "(GPU: 0, epoch: 7, iters: 139072, time: 0.008) nll: 0.710587 \n",
      "(GPU: 0, epoch: 7, iters: 139872, time: 0.008) nll: 0.841967 \n",
      "(GPU: 0, epoch: 7, iters: 140672, time: 0.008) nll: 0.701405 \n",
      "[*] End of epoch 7 / 25 \t Time Taken: 1242 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000800\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3173/4397 [14:49<05:16,  3.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 32, time: 0.004) nll: 0.688127 \n",
      "(GPU: 0, epoch: 8, iters: 32, time: 0.004) nll: 0.525703 \n",
      "(GPU: 0, epoch: 8, iters: 768, time: 0.008) nll: 0.959377 \n",
      "(GPU: 0, epoch: 8, iters: 1568, time: 0.008) nll: 0.945849 \n",
      "(GPU: 0, epoch: 8, iters: 2368, time: 0.008) nll: 0.793198 \n",
      "(GPU: 0, epoch: 8, iters: 3168, time: 0.008) nll: 0.994184 \n",
      "(GPU: 0, epoch: 8, iters: 3968, time: 0.008) nll: 0.787378 \n",
      "(GPU: 0, epoch: 8, iters: 4768, time: 0.008) nll: 0.680167 \n",
      "(GPU: 0, epoch: 8, iters: 5568, time: 0.008) nll: 0.824084 \n",
      "(GPU: 0, epoch: 8, iters: 6368, time: 0.008) nll: 0.733613 \n",
      "(GPU: 0, epoch: 8, iters: 7168, time: 0.008) nll: 0.849553 \n",
      "(GPU: 0, epoch: 8, iters: 7968, time: 0.008) nll: 0.954090 \n",
      "(GPU: 0, epoch: 8, iters: 8768, time: 0.008) nll: 0.748080 \n",
      "(GPU: 0, epoch: 8, iters: 9568, time: 0.008) nll: 0.891421 \n",
      "(GPU: 0, epoch: 8, iters: 10368, time: 0.008) nll: 0.750826 \n",
      "(GPU: 0, epoch: 8, iters: 11168, time: 0.008) nll: 0.556398 \n",
      "(GPU: 0, epoch: 8, iters: 11968, time: 0.008) nll: 0.586949 \n",
      "(GPU: 0, epoch: 8, iters: 12768, time: 0.008) nll: 0.722249 \n",
      "(GPU: 0, epoch: 8, iters: 13568, time: 0.008) nll: 0.894020 \n",
      "(GPU: 0, epoch: 8, iters: 14368, time: 0.008) nll: 0.599525 \n",
      "saving the latest model (epoch 8, total_steps 1140000)\n",
      "(GPU: 0, epoch: 8, iters: 15168, time: 0.008) nll: 0.767269 \n",
      "(GPU: 0, epoch: 8, iters: 15968, time: 0.008) nll: 0.796698 \n",
      "(GPU: 0, epoch: 8, iters: 16768, time: 0.008) nll: 0.793679 \n",
      "(GPU: 0, epoch: 8, iters: 17568, time: 0.008) nll: 0.806699 \n",
      "(GPU: 0, epoch: 8, iters: 18368, time: 0.008) nll: 0.695699 \n",
      "(GPU: 0, epoch: 8, iters: 19168, time: 0.008) nll: 0.666467 \n",
      "(GPU: 0, epoch: 8, iters: 19968, time: 0.008) nll: 0.437682 \n",
      "(GPU: 0, epoch: 8, iters: 20768, time: 0.008) nll: 0.633502 \n",
      "(GPU: 0, epoch: 8, iters: 21568, time: 0.008) nll: 0.575594 \n",
      "(GPU: 0, epoch: 8, iters: 22368, time: 0.008) nll: 0.517017 \n",
      "(GPU: 0, epoch: 8, iters: 23168, time: 0.008) nll: 0.861543 \n",
      "(GPU: 0, epoch: 8, iters: 23968, time: 0.008) nll: 0.519800 \n",
      "(GPU: 0, epoch: 8, iters: 24768, time: 0.008) nll: 0.688639 \n",
      "(GPU: 0, epoch: 8, iters: 25568, time: 0.008) nll: 0.627692 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.008) nll: 0.655746 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.013) nll: 0.641243 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.013) nll: 0.914274 \n",
      "(GPU: 0, epoch: 8, iters: 27168, time: 0.008) nll: 0.897584 \n",
      "(GPU: 0, epoch: 8, iters: 27968, time: 0.008) nll: 0.962803 \n",
      "(GPU: 0, epoch: 8, iters: 28768, time: 0.008) nll: 0.901511 \n",
      "(GPU: 0, epoch: 8, iters: 29568, time: 0.008) nll: 0.510353 \n",
      "(GPU: 0, epoch: 8, iters: 30368, time: 0.008) nll: 0.726847 \n",
      "(GPU: 0, epoch: 8, iters: 31168, time: 0.008) nll: 0.718179 \n",
      "(GPU: 0, epoch: 8, iters: 31968, time: 0.008) nll: 0.615312 \n",
      "(GPU: 0, epoch: 8, iters: 32768, time: 0.008) nll: 0.817407 \n",
      "(GPU: 0, epoch: 8, iters: 33568, time: 0.008) nll: 0.640953 \n",
      "(GPU: 0, epoch: 8, iters: 34368, time: 0.008) nll: 0.685723 \n",
      "saving the latest model (epoch 8, total_steps 1160000)\n",
      "(GPU: 0, epoch: 8, iters: 35168, time: 0.008) nll: 0.604544 \n",
      "(GPU: 0, epoch: 8, iters: 35968, time: 0.008) nll: 0.661498 \n",
      "(GPU: 0, epoch: 8, iters: 36768, time: 0.008) nll: 0.746914 \n",
      "(GPU: 0, epoch: 8, iters: 37568, time: 0.008) nll: 0.653697 \n",
      "(GPU: 0, epoch: 8, iters: 38368, time: 0.008) nll: 0.705337 \n",
      "(GPU: 0, epoch: 8, iters: 39168, time: 0.008) nll: 0.819766 \n",
      "(GPU: 0, epoch: 8, iters: 39968, time: 0.008) nll: 0.742458 \n",
      "(GPU: 0, epoch: 8, iters: 40768, time: 0.008) nll: 0.436981 \n",
      "(GPU: 0, epoch: 8, iters: 41568, time: 0.008) nll: 0.712598 \n",
      "(GPU: 0, epoch: 8, iters: 42368, time: 0.008) nll: 0.666508 \n",
      "(GPU: 0, epoch: 8, iters: 43168, time: 0.008) nll: 0.554725 \n",
      "(GPU: 0, epoch: 8, iters: 43968, time: 0.008) nll: 0.873072 \n",
      "(GPU: 0, epoch: 8, iters: 44768, time: 0.008) nll: 0.564751 \n",
      "(GPU: 0, epoch: 8, iters: 45568, time: 0.008) nll: 0.944495 \n",
      "(GPU: 0, epoch: 8, iters: 46368, time: 0.008) nll: 0.765720 \n",
      "(GPU: 0, epoch: 8, iters: 47168, time: 0.008) nll: 0.760389 \n",
      "(GPU: 0, epoch: 8, iters: 47968, time: 0.008) nll: 0.739378 \n",
      "(GPU: 0, epoch: 8, iters: 48768, time: 0.008) nll: 1.014251 \n",
      "(GPU: 0, epoch: 8, iters: 49568, time: 0.008) nll: 0.934158 \n",
      "(GPU: 0, epoch: 8, iters: 50368, time: 0.008) nll: 0.542296 \n",
      "(GPU: 0, epoch: 8, iters: 51168, time: 0.008) nll: 0.835550 \n",
      "(GPU: 0, epoch: 8, iters: 51968, time: 0.008) nll: 0.816516 \n",
      "(GPU: 0, epoch: 8, iters: 52768, time: 0.008) nll: 0.748337 \n",
      "(GPU: 0, epoch: 8, iters: 53568, time: 0.008) nll: 0.599675 \n",
      "(GPU: 0, epoch: 8, iters: 54368, time: 0.008) nll: 0.731926 \n",
      "saving the latest model (epoch 8, total_steps 1180000)\n",
      "(GPU: 0, epoch: 8, iters: 55168, time: 0.008) nll: 0.699015 \n",
      "(GPU: 0, epoch: 8, iters: 55968, time: 0.008) nll: 0.821037 \n",
      "(GPU: 0, epoch: 8, iters: 56768, time: 0.008) nll: 0.800021 \n",
      "(GPU: 0, epoch: 8, iters: 57568, time: 0.008) nll: 0.536818 \n",
      "(GPU: 0, epoch: 8, iters: 58368, time: 0.008) nll: 0.671215 \n",
      "(GPU: 0, epoch: 8, iters: 59168, time: 0.008) nll: 0.837755 \n",
      "(GPU: 0, epoch: 8, iters: 59968, time: 0.008) nll: 0.756576 \n",
      "(GPU: 0, epoch: 8, iters: 60768, time: 0.008) nll: 0.669498 \n",
      "(GPU: 0, epoch: 8, iters: 61568, time: 0.008) nll: 0.993536 \n",
      "(GPU: 0, epoch: 8, iters: 62368, time: 0.008) nll: 0.863538 \n",
      "(GPU: 0, epoch: 8, iters: 63168, time: 0.008) nll: 0.753063 \n",
      "(GPU: 0, epoch: 8, iters: 63968, time: 0.008) nll: 0.596704 \n",
      "(GPU: 0, epoch: 8, iters: 64768, time: 0.008) nll: 0.511377 \n",
      "(GPU: 0, epoch: 8, iters: 65568, time: 0.008) nll: 0.890323 \n",
      "(GPU: 0, epoch: 8, iters: 66368, time: 0.008) nll: 0.627050 \n",
      "(GPU: 0, epoch: 8, iters: 67168, time: 0.008) nll: 0.721138 \n",
      "(GPU: 0, epoch: 8, iters: 67968, time: 0.008) nll: 0.920199 \n",
      "(GPU: 0, epoch: 8, iters: 68768, time: 0.008) nll: 0.570228 \n",
      "(GPU: 0, epoch: 8, iters: 69568, time: 0.008) nll: 0.570434 \n",
      "(GPU: 0, epoch: 8, iters: 70368, time: 0.007) nll: 0.623980 \n",
      "(GPU: 0, epoch: 8, iters: 71168, time: 0.008) nll: 0.820420 \n",
      "(GPU: 0, epoch: 8, iters: 71968, time: 0.008) nll: 0.690795 \n",
      "(GPU: 0, epoch: 8, iters: 72768, time: 0.008) nll: 0.408919 \n",
      "(GPU: 0, epoch: 8, iters: 73568, time: 0.008) nll: 0.652068 \n",
      "(GPU: 0, epoch: 8, iters: 74368, time: 0.008) nll: 0.530247 \n",
      "saving the latest model (epoch 8, total_steps 1200000)\n",
      "(GPU: 0, epoch: 8, iters: 75168, time: 0.008) nll: 0.754499 \n",
      "(GPU: 0, epoch: 8, iters: 75968, time: 0.008) nll: 0.989754 \n",
      "(GPU: 0, epoch: 8, iters: 76768, time: 0.008) nll: 0.686678 \n",
      "(GPU: 0, epoch: 8, iters: 77568, time: 0.008) nll: 0.715461 \n",
      "(GPU: 0, epoch: 8, iters: 78368, time: 0.008) nll: 1.116024 \n",
      "(GPU: 0, epoch: 8, iters: 79168, time: 0.008) nll: 0.708893 \n",
      "(GPU: 0, epoch: 8, iters: 79968, time: 0.008) nll: 0.973931 \n",
      "(GPU: 0, epoch: 8, iters: 80768, time: 0.008) nll: 0.800380 \n",
      "(GPU: 0, epoch: 8, iters: 81568, time: 0.008) nll: 0.786556 \n",
      "(GPU: 0, epoch: 8, iters: 82368, time: 0.008) nll: 0.608312 \n",
      "(GPU: 0, epoch: 8, iters: 83168, time: 0.008) nll: 0.774596 \n",
      "(GPU: 0, epoch: 8, iters: 83968, time: 0.008) nll: 0.525996 \n",
      "(GPU: 0, epoch: 8, iters: 84768, time: 0.008) nll: 0.860356 \n",
      "(GPU: 0, epoch: 8, iters: 85568, time: 0.008) nll: 0.553817 \n",
      "(GPU: 0, epoch: 8, iters: 86368, time: 0.008) nll: 0.696321 \n",
      "(GPU: 0, epoch: 8, iters: 87168, time: 0.008) nll: 0.793919 \n",
      "(GPU: 0, epoch: 8, iters: 87968, time: 0.008) nll: 0.634959 \n",
      "(GPU: 0, epoch: 8, iters: 88768, time: 0.008) nll: 0.606298 \n",
      "(GPU: 0, epoch: 8, iters: 89568, time: 0.008) nll: 0.703233 \n",
      "(GPU: 0, epoch: 8, iters: 90368, time: 0.008) nll: 0.564492 \n",
      "(GPU: 0, epoch: 8, iters: 91168, time: 0.008) nll: 0.837027 \n",
      "(GPU: 0, epoch: 8, iters: 91968, time: 0.008) nll: 0.771233 \n",
      "(GPU: 0, epoch: 8, iters: 92768, time: 0.008) nll: 0.702362 \n",
      "(GPU: 0, epoch: 8, iters: 93568, time: 0.008) nll: 0.640628 \n",
      "(GPU: 0, epoch: 8, iters: 94368, time: 0.008) nll: 0.690609 \n",
      "saving the latest model (epoch 8, total_steps 1220000)\n",
      "(GPU: 0, epoch: 8, iters: 95168, time: 0.008) nll: 0.480850 \n",
      "(GPU: 0, epoch: 8, iters: 95968, time: 0.008) nll: 0.450577 \n",
      "(GPU: 0, epoch: 8, iters: 96768, time: 0.008) nll: 0.555761 \n",
      "(GPU: 0, epoch: 8, iters: 97568, time: 0.008) nll: 0.628970 \n",
      "(GPU: 0, epoch: 8, iters: 98368, time: 0.008) nll: 0.830137 \n",
      "(GPU: 0, epoch: 8, iters: 99168, time: 0.008) nll: 0.503075 \n",
      "(GPU: 0, epoch: 8, iters: 99968, time: 0.008) nll: 0.808219 \n",
      "(GPU: 0, epoch: 8, iters: 100768, time: 0.008) nll: 0.802824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [20:36<00:00,  3.56it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 101568, time: 0.008) nll: 0.758526 \n",
      "(GPU: 0, epoch: 8, iters: 102368, time: 0.008) nll: 0.749223 \n",
      "(GPU: 0, epoch: 8, iters: 103168, time: 0.008) nll: 0.479705 \n",
      "(GPU: 0, epoch: 8, iters: 103968, time: 0.008) nll: 0.646098 \n",
      "(GPU: 0, epoch: 8, iters: 104768, time: 0.008) nll: 0.847658 \n",
      "(GPU: 0, epoch: 8, iters: 105568, time: 0.008) nll: 0.518851 \n",
      "(GPU: 0, epoch: 8, iters: 106368, time: 0.008) nll: 0.763548 \n",
      "(GPU: 0, epoch: 8, iters: 107168, time: 0.008) nll: 0.685814 \n",
      "(GPU: 0, epoch: 8, iters: 107968, time: 0.008) nll: 0.850421 \n",
      "(GPU: 0, epoch: 8, iters: 108768, time: 0.008) nll: 0.673030 \n",
      "(GPU: 0, epoch: 8, iters: 109568, time: 0.008) nll: 0.628886 \n",
      "(GPU: 0, epoch: 8, iters: 110368, time: 0.008) nll: 0.387084 \n",
      "(GPU: 0, epoch: 8, iters: 111168, time: 0.008) nll: 0.688897 \n",
      "(GPU: 0, epoch: 8, iters: 111968, time: 0.008) nll: 0.441419 \n",
      "(GPU: 0, epoch: 8, iters: 112768, time: 0.008) nll: 0.921634 \n",
      "(GPU: 0, epoch: 8, iters: 113568, time: 0.008) nll: 0.513125 \n",
      "(GPU: 0, epoch: 8, iters: 114368, time: 0.008) nll: 0.689353 \n",
      "saving the latest model (epoch 8, total_steps 1240000)\n",
      "(GPU: 0, epoch: 8, iters: 115168, time: 0.008) nll: 0.495029 \n",
      "(GPU: 0, epoch: 8, iters: 115968, time: 0.008) nll: 0.836857 \n",
      "(GPU: 0, epoch: 8, iters: 116768, time: 0.008) nll: 0.802146 \n",
      "(GPU: 0, epoch: 8, iters: 117568, time: 0.008) nll: 0.669639 \n",
      "(GPU: 0, epoch: 8, iters: 118368, time: 0.008) nll: 0.607974 \n",
      "(GPU: 0, epoch: 8, iters: 119168, time: 0.008) nll: 0.572775 \n",
      "(GPU: 0, epoch: 8, iters: 119968, time: 0.008) nll: 0.290675 \n",
      "(GPU: 0, epoch: 8, iters: 120768, time: 0.008) nll: 0.558746 \n",
      "(GPU: 0, epoch: 8, iters: 121568, time: 0.008) nll: 0.624649 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.008) nll: 0.710673 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.013) nll: 0.697102 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.013) nll: 0.746034 \n",
      "(GPU: 0, epoch: 8, iters: 123168, time: 0.008) nll: 0.655240 \n",
      "(GPU: 0, epoch: 8, iters: 123968, time: 0.008) nll: 0.616000 \n",
      "(GPU: 0, epoch: 8, iters: 124768, time: 0.008) nll: 0.923960 \n",
      "(GPU: 0, epoch: 8, iters: 125568, time: 0.008) nll: 0.778050 \n",
      "(GPU: 0, epoch: 8, iters: 126368, time: 0.008) nll: 0.579033 \n",
      "(GPU: 0, epoch: 8, iters: 127168, time: 0.008) nll: 0.903974 \n",
      "(GPU: 0, epoch: 8, iters: 127968, time: 0.008) nll: 0.739985 \n",
      "(GPU: 0, epoch: 8, iters: 128768, time: 0.008) nll: 0.648642 \n",
      "(GPU: 0, epoch: 8, iters: 129568, time: 0.008) nll: 0.676685 \n",
      "(GPU: 0, epoch: 8, iters: 130368, time: 0.008) nll: 0.689098 \n",
      "(GPU: 0, epoch: 8, iters: 131168, time: 0.007) nll: 0.728225 \n",
      "(GPU: 0, epoch: 8, iters: 131968, time: 0.008) nll: 1.120465 \n",
      "(GPU: 0, epoch: 8, iters: 132768, time: 0.008) nll: 0.575089 \n",
      "(GPU: 0, epoch: 8, iters: 133568, time: 0.008) nll: 0.788540 \n",
      "(GPU: 0, epoch: 8, iters: 134368, time: 0.008) nll: 0.885600 \n",
      "saving the latest model (epoch 8, total_steps 1260000)\n",
      "(GPU: 0, epoch: 8, iters: 135168, time: 0.008) nll: 1.105155 \n",
      "(GPU: 0, epoch: 8, iters: 135968, time: 0.008) nll: 0.721960 \n",
      "(GPU: 0, epoch: 8, iters: 136768, time: 0.008) nll: 0.528252 \n",
      "(GPU: 0, epoch: 8, iters: 137568, time: 0.008) nll: 0.584411 \n",
      "(GPU: 0, epoch: 8, iters: 138368, time: 0.008) nll: 1.096294 \n",
      "(GPU: 0, epoch: 8, iters: 139168, time: 0.008) nll: 0.787006 \n",
      "(GPU: 0, epoch: 8, iters: 139968, time: 0.008) nll: 1.119177 \n",
      "[*] End of epoch 8 / 25 \t Time Taken: 1236 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-7-network-bert-shapeInput-shapeset-crossEntropy-3\n",
      "[*] learning rate = 0.0000900\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 110/4397 [00:29<18:51,  3.79it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 159, in <module>\n",
      "    train_one_epoch()\n",
      "  File \"train.py\", line 98, in train_one_epoch\n",
      "    model.optimize_parameters(total_steps)\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py\", line 123, in optimize_parameters\n",
      "    self.backward()\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py\", line 107, in backward\n",
      "    target = self.z_target.to(self.outp.device)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 32, time: 0.004) nll: 0.633619 \n",
      "(GPU: 0, epoch: 9, iters: 32, time: 0.004) nll: 1.001806 \n",
      "(GPU: 0, epoch: 9, iters: 64, time: 0.003) nll: 0.600577 \n",
      "(GPU: 0, epoch: 9, iters: 864, time: 0.008) nll: 0.496366 \n",
      "(GPU: 0, epoch: 9, iters: 1664, time: 0.008) nll: 0.777453 \n",
      "(GPU: 0, epoch: 9, iters: 2464, time: 0.008) nll: 0.815215 \n",
      "(GPU: 0, epoch: 9, iters: 3264, time: 0.008) nll: 0.661910 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3934462/1349841514.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./launchers/train_rand_tf_snet_code.sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1804\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_rand_tf_snet_code.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf46647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
