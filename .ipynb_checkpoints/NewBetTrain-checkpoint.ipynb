{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ddad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ./launchers/train_new_bert.sh: Permission denied\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_new_bert.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9b0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autosdf.yaml\t\t      filelists\t\t      README.md\r\n",
      "Compare.ipynb\t\t      info-shapenet.json      results\r\n",
      "configs\t\t\t      launchers\t\t      shape_set_paths.json\r\n",
      "datasets\t\t      logs\t\t      Test-Reproduce.ipynb\r\n",
      "demo_data\t\t      logs2\t\t      test_samples_paper.txt\r\n",
      "demo-lang-conditional.ipynb   models\t\t      text2ShapePP.json\r\n",
      "demo_shape_comp.ipynb\t      New-Bert-Sandbox.ipynb  train.py\r\n",
      "demo_single_view_recon.ipynb  NewBetTrain.ipynb       utils\r\n",
      "extract_code.py\t\t      options\r\n",
      "file.json\t\t      preprocess\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f6cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 32\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: text2shape-seq\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: ./logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 100000000000\n",
      "model: bert2vqsc_v4\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "ndf: 64\n",
      "nepochs: 20\n",
      "nepochs_decay: 5\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: Text2Shape\n",
      "[*] # training images = 140707\n",
      "[*] # testing images = 16000\n",
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 32\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: text2shape-seq\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: ./logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 100000000000\n",
      "model: bert2vqsc_v4\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "ndf: 64\n",
      "nepochs: 20\n",
      "nepochs_decay: 5\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: Text2Shape\n",
      "[*] # training images = 140707\n",
      "[*] # testing images = 16000\n",
      "---------- Networks initialized -------------\n",
      "-----------------------------------------------\n",
      "[*] Model has been created: BERT2VQSC-Model\n",
      "[*] \"bert2vqsc_v4\" initialized.\n",
      "[*] create image directory:\n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy/images...\n",
      "[*] saving model and dataset files: /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py, /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/datasets/text2shape.py\n",
      "140707 Length train dataset\n",
      "16000 Length test dataset\n",
      "4397 Length train_dl\n",
      "500 Length test_dl\n",
      "[*] Start training. name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 42, in <module>\n",
      "    model = create_model(opt)\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/base_model.py\", line 50, in create_model\n",
      "    model.initialize(opt)\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py\", line 52, in initialize\n",
      "    self.net.to(opt.device)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 907, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n",
      "    module._apply(fn)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 601, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 905, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "KeyboardInterrupt\n",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.213) nll: 5.553204 \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3199/4397 [12:16<03:38,  5.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.213) nll: 5.572494 \n",
      "(GPU: 0, epoch: 0, iters: 800, time: 0.006) nll: 2.062866 \n",
      "(GPU: 0, epoch: 0, iters: 1600, time: 0.006) nll: 1.349700 \n",
      "(GPU: 0, epoch: 0, iters: 2400, time: 0.005) nll: 1.218815 \n",
      "(GPU: 0, epoch: 0, iters: 3200, time: 0.003) nll: 1.140755 \n",
      "(GPU: 0, epoch: 0, iters: 4000, time: 0.003) nll: 0.921950 \n",
      "(GPU: 0, epoch: 0, iters: 4800, time: 0.006) nll: 1.043536 \n",
      "(GPU: 0, epoch: 0, iters: 5600, time: 0.005) nll: 0.843278 \n",
      "(GPU: 0, epoch: 0, iters: 6400, time: 0.006) nll: 0.957917 \n",
      "(GPU: 0, epoch: 0, iters: 7200, time: 0.005) nll: 0.823519 \n",
      "(GPU: 0, epoch: 0, iters: 8000, time: 0.006) nll: 0.862971 \n",
      "(GPU: 0, epoch: 0, iters: 8800, time: 0.005) nll: 1.054764 \n",
      "(GPU: 0, epoch: 0, iters: 9600, time: 0.006) nll: 1.013833 \n",
      "(GPU: 0, epoch: 0, iters: 10400, time: 0.005) nll: 0.536733 \n",
      "(GPU: 0, epoch: 0, iters: 11200, time: 0.006) nll: 0.819057 \n",
      "(GPU: 0, epoch: 0, iters: 12000, time: 0.005) nll: 0.988579 \n",
      "(GPU: 0, epoch: 0, iters: 12800, time: 0.006) nll: 1.080795 \n",
      "(GPU: 0, epoch: 0, iters: 13600, time: 0.006) nll: 0.879453 \n",
      "(GPU: 0, epoch: 0, iters: 14400, time: 0.006) nll: 0.791238 \n",
      "(GPU: 0, epoch: 0, iters: 15200, time: 0.003) nll: 0.756143 \n",
      "(GPU: 0, epoch: 0, iters: 16000, time: 0.006) nll: 0.882087 \n",
      "(GPU: 0, epoch: 0, iters: 16800, time: 0.005) nll: 0.796963 \n",
      "(GPU: 0, epoch: 0, iters: 17600, time: 0.006) nll: 0.820092 \n",
      "(GPU: 0, epoch: 0, iters: 18400, time: 0.003) nll: 0.700248 \n",
      "(GPU: 0, epoch: 0, iters: 19200, time: 0.006) nll: 1.092439 \n",
      "(GPU: 0, epoch: 0, iters: 20000, time: 0.005) nll: 1.082651 \n",
      "saving the latest model (epoch 0, total_steps 20000)\n",
      "(GPU: 0, epoch: 0, iters: 20800, time: 0.006) nll: 0.733789 \n",
      "(GPU: 0, epoch: 0, iters: 21600, time: 0.005) nll: 0.821375 \n",
      "(GPU: 0, epoch: 0, iters: 22400, time: 0.003) nll: 0.897573 \n",
      "(GPU: 0, epoch: 0, iters: 23200, time: 0.005) nll: 0.597139 \n",
      "(GPU: 0, epoch: 0, iters: 24000, time: 0.006) nll: 0.822065 \n",
      "(GPU: 0, epoch: 0, iters: 24800, time: 0.005) nll: 0.743471 \n",
      "(GPU: 0, epoch: 0, iters: 25600, time: 0.006) nll: 1.054826 \n",
      "(GPU: 0, epoch: 0, iters: 26400, time: 0.005) nll: 0.837594 \n",
      "(GPU: 0, epoch: 0, iters: 27200, time: 0.006) nll: 0.895638 \n",
      "(GPU: 0, epoch: 0, iters: 28000, time: 0.005) nll: 0.752706 \n",
      "(GPU: 0, epoch: 0, iters: 28800, time: 0.006) nll: 0.858610 \n",
      "(GPU: 0, epoch: 0, iters: 29600, time: 0.005) nll: 0.654555 \n",
      "(GPU: 0, epoch: 0, iters: 30400, time: 0.005) nll: 0.758719 \n",
      "(GPU: 0, epoch: 0, iters: 31200, time: 0.005) nll: 0.833421 \n",
      "(GPU: 0, epoch: 0, iters: 32000, time: 0.005) nll: 0.779244 \n",
      "(GPU: 0, epoch: 0, iters: 32800, time: 0.005) nll: 0.460268 \n",
      "(GPU: 0, epoch: 0, iters: 33600, time: 0.006) nll: 1.151527 \n",
      "(GPU: 0, epoch: 0, iters: 34400, time: 0.005) nll: 0.831302 \n",
      "(GPU: 0, epoch: 0, iters: 35200, time: 0.006) nll: 1.080062 \n",
      "(GPU: 0, epoch: 0, iters: 36000, time: 0.005) nll: 0.812250 \n",
      "(GPU: 0, epoch: 0, iters: 36800, time: 0.006) nll: 0.708110 \n",
      "(GPU: 0, epoch: 0, iters: 37600, time: 0.005) nll: 0.877304 \n",
      "(GPU: 0, epoch: 0, iters: 38400, time: 0.006) nll: 0.938194 \n",
      "(GPU: 0, epoch: 0, iters: 39200, time: 0.005) nll: 0.904941 \n",
      "(GPU: 0, epoch: 0, iters: 40000, time: 0.005) nll: 0.719086 \n",
      "saving the latest model (epoch 0, total_steps 40000)\n",
      "(GPU: 0, epoch: 0, iters: 40800, time: 0.005) nll: 0.878887 \n",
      "(GPU: 0, epoch: 0, iters: 41600, time: 0.006) nll: 0.669012 \n",
      "(GPU: 0, epoch: 0, iters: 42400, time: 0.006) nll: 0.855459 \n",
      "(GPU: 0, epoch: 0, iters: 43200, time: 0.006) nll: 0.719158 \n",
      "(GPU: 0, epoch: 0, iters: 44000, time: 0.005) nll: 0.841516 \n",
      "(GPU: 0, epoch: 0, iters: 44800, time: 0.006) nll: 0.788368 \n",
      "(GPU: 0, epoch: 0, iters: 45600, time: 0.006) nll: 0.834253 \n",
      "(GPU: 0, epoch: 0, iters: 46400, time: 0.005) nll: 0.578060 \n",
      "(GPU: 0, epoch: 0, iters: 47200, time: 0.005) nll: 0.678226 \n",
      "(GPU: 0, epoch: 0, iters: 48000, time: 0.006) nll: 1.025374 \n",
      "(GPU: 0, epoch: 0, iters: 48800, time: 0.005) nll: 0.971846 \n",
      "(GPU: 0, epoch: 0, iters: 49600, time: 0.006) nll: 1.048106 \n",
      "(GPU: 0, epoch: 0, iters: 50400, time: 0.005) nll: 0.583395 \n",
      "(GPU: 0, epoch: 0, iters: 51200, time: 0.006) nll: 0.919067 \n",
      "(GPU: 0, epoch: 0, iters: 52000, time: 0.005) nll: 0.786578 \n",
      "(GPU: 0, epoch: 0, iters: 52800, time: 0.006) nll: 0.651569 \n",
      "(GPU: 0, epoch: 0, iters: 53600, time: 0.005) nll: 0.697438 \n",
      "(GPU: 0, epoch: 0, iters: 54400, time: 0.006) nll: 0.854135 \n",
      "(GPU: 0, epoch: 0, iters: 55200, time: 0.005) nll: 0.875409 \n",
      "(GPU: 0, epoch: 0, iters: 56000, time: 0.006) nll: 0.618927 \n",
      "(GPU: 0, epoch: 0, iters: 56800, time: 0.005) nll: 0.852006 \n",
      "(GPU: 0, epoch: 0, iters: 57600, time: 0.006) nll: 0.947698 \n",
      "(GPU: 0, epoch: 0, iters: 58400, time: 0.005) nll: 0.678637 \n",
      "(GPU: 0, epoch: 0, iters: 59200, time: 0.006) nll: 0.833478 \n",
      "(GPU: 0, epoch: 0, iters: 60000, time: 0.005) nll: 0.822182 \n",
      "saving the latest model (epoch 0, total_steps 60000)\n",
      "(GPU: 0, epoch: 0, iters: 60800, time: 0.006) nll: 0.909987 \n",
      "(GPU: 0, epoch: 0, iters: 61600, time: 0.005) nll: 0.898433 \n",
      "(GPU: 0, epoch: 0, iters: 62400, time: 0.006) nll: 0.658376 \n",
      "(GPU: 0, epoch: 0, iters: 63200, time: 0.005) nll: 0.896125 \n",
      "(GPU: 0, epoch: 0, iters: 64000, time: 0.006) nll: 0.837549 \n",
      "(GPU: 0, epoch: 0, iters: 64800, time: 0.005) nll: 0.611142 \n",
      "(GPU: 0, epoch: 0, iters: 65600, time: 0.005) nll: 0.795445 \n",
      "(GPU: 0, epoch: 0, iters: 66400, time: 0.005) nll: 0.621999 \n",
      "(GPU: 0, epoch: 0, iters: 67200, time: 0.006) nll: 0.901778 \n",
      "(GPU: 0, epoch: 0, iters: 68000, time: 0.005) nll: 0.934877 \n",
      "(GPU: 0, epoch: 0, iters: 68800, time: 0.006) nll: 0.991310 \n",
      "(GPU: 0, epoch: 0, iters: 69600, time: 0.005) nll: 0.888012 \n",
      "(GPU: 0, epoch: 0, iters: 70400, time: 0.006) nll: 1.340194 \n",
      "(GPU: 0, epoch: 0, iters: 71200, time: 0.005) nll: 1.192273 \n",
      "(GPU: 0, epoch: 0, iters: 72000, time: 0.006) nll: 0.731493 \n",
      "(GPU: 0, epoch: 0, iters: 72800, time: 0.005) nll: 1.200599 \n",
      "(GPU: 0, epoch: 0, iters: 73600, time: 0.006) nll: 0.655156 \n",
      "(GPU: 0, epoch: 0, iters: 74400, time: 0.005) nll: 0.776990 \n",
      "(GPU: 0, epoch: 0, iters: 75200, time: 0.006) nll: 0.760227 \n",
      "(GPU: 0, epoch: 0, iters: 76000, time: 0.005) nll: 0.920409 \n",
      "(GPU: 0, epoch: 0, iters: 76800, time: 0.006) nll: 0.813112 \n",
      "(GPU: 0, epoch: 0, iters: 77600, time: 0.006) nll: 0.705222 \n",
      "(GPU: 0, epoch: 0, iters: 78400, time: 0.005) nll: 0.973736 \n",
      "(GPU: 0, epoch: 0, iters: 79200, time: 0.005) nll: 0.827947 \n",
      "(GPU: 0, epoch: 0, iters: 80000, time: 0.006) nll: 0.870126 \n",
      "saving the latest model (epoch 0, total_steps 80000)\n",
      "(GPU: 0, epoch: 0, iters: 80800, time: 0.006) nll: 0.926837 \n",
      "(GPU: 0, epoch: 0, iters: 81600, time: 0.006) nll: 0.731619 \n",
      "(GPU: 0, epoch: 0, iters: 82400, time: 0.005) nll: 0.801682 \n",
      "(GPU: 0, epoch: 0, iters: 83200, time: 0.006) nll: 0.827709 \n",
      "(GPU: 0, epoch: 0, iters: 84000, time: 0.005) nll: 0.664648 \n",
      "(GPU: 0, epoch: 0, iters: 84800, time: 0.006) nll: 0.956570 \n",
      "(GPU: 0, epoch: 0, iters: 85600, time: 0.005) nll: 0.945349 \n",
      "(GPU: 0, epoch: 0, iters: 86400, time: 0.006) nll: 0.710295 \n",
      "(GPU: 0, epoch: 0, iters: 87200, time: 0.005) nll: 0.902895 \n",
      "(GPU: 0, epoch: 0, iters: 88000, time: 0.006) nll: 1.211776 \n",
      "(GPU: 0, epoch: 0, iters: 88800, time: 0.005) nll: 0.711223 \n",
      "(GPU: 0, epoch: 0, iters: 89600, time: 0.006) nll: 0.828477 \n",
      "(GPU: 0, epoch: 0, iters: 90400, time: 0.005) nll: 0.624838 \n",
      "(GPU: 0, epoch: 0, iters: 91200, time: 0.006) nll: 1.028824 \n",
      "(GPU: 0, epoch: 0, iters: 92000, time: 0.006) nll: 0.788896 \n",
      "(GPU: 0, epoch: 0, iters: 92800, time: 0.006) nll: 0.804062 \n",
      "(GPU: 0, epoch: 0, iters: 93600, time: 0.005) nll: 0.881340 \n",
      "(GPU: 0, epoch: 0, iters: 94400, time: 0.005) nll: 0.596216 \n",
      "(GPU: 0, epoch: 0, iters: 95200, time: 0.005) nll: 1.026794 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.006) nll: 0.728745 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.009) nll: 0.725151 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.009) nll: 0.926098 \n",
      "(GPU: 0, epoch: 0, iters: 96800, time: 0.005) nll: 0.715394 \n",
      "(GPU: 0, epoch: 0, iters: 97600, time: 0.006) nll: 0.865667 \n",
      "(GPU: 0, epoch: 0, iters: 98400, time: 0.005) nll: 0.947274 \n",
      "(GPU: 0, epoch: 0, iters: 99200, time: 0.006) nll: 0.822957 \n",
      "(GPU: 0, epoch: 0, iters: 100000, time: 0.006) nll: 0.836316 \n",
      "saving the latest model (epoch 0, total_steps 100000)\n",
      "(GPU: 0, epoch: 0, iters: 100800, time: 0.006) nll: 0.908240 \n",
      "(GPU: 0, epoch: 0, iters: 101600, time: 0.005) nll: 0.759579 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [16:04<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 102400, time: 0.006) nll: 0.493430 \n",
      "(GPU: 0, epoch: 0, iters: 103200, time: 0.005) nll: 1.098467 \n",
      "(GPU: 0, epoch: 0, iters: 104000, time: 0.006) nll: 0.702002 \n",
      "(GPU: 0, epoch: 0, iters: 104800, time: 0.005) nll: 1.015352 \n",
      "(GPU: 0, epoch: 0, iters: 105600, time: 0.006) nll: 1.301371 \n",
      "(GPU: 0, epoch: 0, iters: 106400, time: 0.005) nll: 0.835258 \n",
      "(GPU: 0, epoch: 0, iters: 107200, time: 0.006) nll: 0.745101 \n",
      "(GPU: 0, epoch: 0, iters: 108000, time: 0.006) nll: 0.841584 \n",
      "(GPU: 0, epoch: 0, iters: 108800, time: 0.006) nll: 0.974285 \n",
      "(GPU: 0, epoch: 0, iters: 109600, time: 0.005) nll: 0.761610 \n",
      "(GPU: 0, epoch: 0, iters: 110400, time: 0.006) nll: 0.716013 \n",
      "(GPU: 0, epoch: 0, iters: 111200, time: 0.006) nll: 0.847904 \n",
      "(GPU: 0, epoch: 0, iters: 112000, time: 0.006) nll: 1.182924 \n",
      "(GPU: 0, epoch: 0, iters: 112800, time: 0.006) nll: 0.784536 \n",
      "(GPU: 0, epoch: 0, iters: 113600, time: 0.006) nll: 0.957467 \n",
      "(GPU: 0, epoch: 0, iters: 114400, time: 0.005) nll: 0.756603 \n",
      "(GPU: 0, epoch: 0, iters: 115200, time: 0.006) nll: 1.095143 \n",
      "(GPU: 0, epoch: 0, iters: 116000, time: 0.006) nll: 0.732862 \n",
      "(GPU: 0, epoch: 0, iters: 116800, time: 0.006) nll: 0.600514 \n",
      "(GPU: 0, epoch: 0, iters: 117600, time: 0.005) nll: 0.959889 \n",
      "(GPU: 0, epoch: 0, iters: 118400, time: 0.006) nll: 0.804036 \n",
      "(GPU: 0, epoch: 0, iters: 119200, time: 0.005) nll: 0.780174 \n",
      "(GPU: 0, epoch: 0, iters: 120000, time: 0.006) nll: 0.887563 \n",
      "saving the latest model (epoch 0, total_steps 120000)\n",
      "(GPU: 0, epoch: 0, iters: 120800, time: 0.005) nll: 0.766551 \n",
      "(GPU: 0, epoch: 0, iters: 121600, time: 0.006) nll: 0.752898 \n",
      "(GPU: 0, epoch: 0, iters: 122400, time: 0.005) nll: 0.716143 \n",
      "(GPU: 0, epoch: 0, iters: 123200, time: 0.006) nll: 0.689409 \n",
      "(GPU: 0, epoch: 0, iters: 124000, time: 0.005) nll: 0.689544 \n",
      "(GPU: 0, epoch: 0, iters: 124800, time: 0.006) nll: 0.796048 \n",
      "(GPU: 0, epoch: 0, iters: 125600, time: 0.006) nll: 0.858770 \n",
      "(GPU: 0, epoch: 0, iters: 126400, time: 0.006) nll: 0.704609 \n",
      "(GPU: 0, epoch: 0, iters: 127200, time: 0.005) nll: 1.106525 \n",
      "(GPU: 0, epoch: 0, iters: 128000, time: 0.006) nll: 0.605660 \n",
      "(GPU: 0, epoch: 0, iters: 128800, time: 0.005) nll: 0.709767 \n",
      "(GPU: 0, epoch: 0, iters: 129600, time: 0.006) nll: 0.841336 \n",
      "(GPU: 0, epoch: 0, iters: 130400, time: 0.005) nll: 0.938644 \n",
      "(GPU: 0, epoch: 0, iters: 131200, time: 0.006) nll: 0.719925 \n",
      "(GPU: 0, epoch: 0, iters: 132000, time: 0.006) nll: 0.603234 \n",
      "(GPU: 0, epoch: 0, iters: 132800, time: 0.006) nll: 0.817743 \n",
      "(GPU: 0, epoch: 0, iters: 133600, time: 0.006) nll: 0.700890 \n",
      "(GPU: 0, epoch: 0, iters: 134400, time: 0.006) nll: 0.637073 \n",
      "(GPU: 0, epoch: 0, iters: 135200, time: 0.005) nll: 0.781463 \n",
      "(GPU: 0, epoch: 0, iters: 136000, time: 0.006) nll: 0.995388 \n",
      "(GPU: 0, epoch: 0, iters: 136800, time: 0.006) nll: 1.287750 \n",
      "(GPU: 0, epoch: 0, iters: 137600, time: 0.006) nll: 0.662535 \n",
      "(GPU: 0, epoch: 0, iters: 138400, time: 0.006) nll: 0.691844 \n",
      "(GPU: 0, epoch: 0, iters: 139200, time: 0.006) nll: 0.621157 \n",
      "(GPU: 0, epoch: 0, iters: 140000, time: 0.005) nll: 0.684701 \n",
      "saving the latest model (epoch 0, total_steps 140000)\n",
      "saving the model at the end of epoch 0, iters 140704\n",
      "([test] GPU: 0, epoch: 0) \n",
      "OrderedDict()\n",
      "[*] End of epoch 0 / 25 \t Time Taken: 969 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000100\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3152/4397 [09:56<03:46,  5.51it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 32, time: 0.003) nll: 0.843978 \n",
      "(GPU: 0, epoch: 1, iters: 32, time: 0.003) nll: 0.860499 \n",
      "(GPU: 0, epoch: 1, iters: 96, time: 0.005) nll: 0.805104 \n",
      "(GPU: 0, epoch: 1, iters: 896, time: 0.006) nll: 0.772679 \n",
      "(GPU: 0, epoch: 1, iters: 1696, time: 0.005) nll: 0.923500 \n",
      "(GPU: 0, epoch: 1, iters: 2496, time: 0.006) nll: 0.844591 \n",
      "(GPU: 0, epoch: 1, iters: 3296, time: 0.005) nll: 0.822853 \n",
      "(GPU: 0, epoch: 1, iters: 4096, time: 0.006) nll: 0.740178 \n",
      "(GPU: 0, epoch: 1, iters: 4896, time: 0.006) nll: 0.536178 \n",
      "(GPU: 0, epoch: 1, iters: 5696, time: 0.006) nll: 0.770852 \n",
      "(GPU: 0, epoch: 1, iters: 6496, time: 0.005) nll: 0.809089 \n",
      "(GPU: 0, epoch: 1, iters: 7296, time: 0.006) nll: 1.015930 \n",
      "(GPU: 0, epoch: 1, iters: 8096, time: 0.005) nll: 0.637224 \n",
      "(GPU: 0, epoch: 1, iters: 8896, time: 0.006) nll: 1.071219 \n",
      "(GPU: 0, epoch: 1, iters: 9696, time: 0.005) nll: 0.686660 \n",
      "(GPU: 0, epoch: 1, iters: 10496, time: 0.006) nll: 0.913418 \n",
      "(GPU: 0, epoch: 1, iters: 11296, time: 0.005) nll: 0.808536 \n",
      "(GPU: 0, epoch: 1, iters: 12096, time: 0.006) nll: 0.665754 \n",
      "(GPU: 0, epoch: 1, iters: 12896, time: 0.006) nll: 0.952694 \n",
      "(GPU: 0, epoch: 1, iters: 13696, time: 0.006) nll: 0.872070 \n",
      "(GPU: 0, epoch: 1, iters: 14496, time: 0.005) nll: 0.861096 \n",
      "(GPU: 0, epoch: 1, iters: 15296, time: 0.006) nll: 0.670732 \n",
      "(GPU: 0, epoch: 1, iters: 16096, time: 0.005) nll: 0.720849 \n",
      "(GPU: 0, epoch: 1, iters: 16896, time: 0.006) nll: 0.602676 \n",
      "(GPU: 0, epoch: 1, iters: 17696, time: 0.005) nll: 0.939613 \n",
      "(GPU: 0, epoch: 1, iters: 18496, time: 0.006) nll: 0.745123 \n",
      "(GPU: 0, epoch: 1, iters: 19296, time: 0.005) nll: 0.794465 \n",
      "saving the latest model (epoch 1, total_steps 160000)\n",
      "(GPU: 0, epoch: 1, iters: 20096, time: 0.006) nll: 0.559992 \n",
      "(GPU: 0, epoch: 1, iters: 20896, time: 0.006) nll: 0.785149 \n",
      "(GPU: 0, epoch: 1, iters: 21696, time: 0.006) nll: 0.842755 \n",
      "(GPU: 0, epoch: 1, iters: 22496, time: 0.005) nll: 0.820444 \n",
      "(GPU: 0, epoch: 1, iters: 23296, time: 0.006) nll: 0.819878 \n",
      "(GPU: 0, epoch: 1, iters: 24096, time: 0.006) nll: 0.920085 \n",
      "(GPU: 0, epoch: 1, iters: 24896, time: 0.005) nll: 0.627551 \n",
      "(GPU: 0, epoch: 1, iters: 25696, time: 0.005) nll: 0.693482 \n",
      "(GPU: 0, epoch: 1, iters: 26496, time: 0.006) nll: 0.882903 \n",
      "(GPU: 0, epoch: 1, iters: 27296, time: 0.005) nll: 0.792394 \n",
      "(GPU: 0, epoch: 1, iters: 28096, time: 0.006) nll: 0.906789 \n",
      "(GPU: 0, epoch: 1, iters: 28896, time: 0.005) nll: 0.826697 \n",
      "(GPU: 0, epoch: 1, iters: 29696, time: 0.006) nll: 0.627223 \n",
      "(GPU: 0, epoch: 1, iters: 30496, time: 0.005) nll: 0.917125 \n",
      "(GPU: 0, epoch: 1, iters: 31296, time: 0.006) nll: 1.221837 \n",
      "(GPU: 0, epoch: 1, iters: 32096, time: 0.005) nll: 1.121709 \n",
      "(GPU: 0, epoch: 1, iters: 32896, time: 0.006) nll: 0.854971 \n",
      "(GPU: 0, epoch: 1, iters: 33696, time: 0.005) nll: 0.788263 \n",
      "(GPU: 0, epoch: 1, iters: 34496, time: 0.005) nll: 0.583283 \n",
      "(GPU: 0, epoch: 1, iters: 35296, time: 0.005) nll: 0.810955 \n",
      "(GPU: 0, epoch: 1, iters: 36096, time: 0.006) nll: 0.581997 \n",
      "(GPU: 0, epoch: 1, iters: 36896, time: 0.005) nll: 0.628812 \n",
      "(GPU: 0, epoch: 1, iters: 37696, time: 0.006) nll: 0.840691 \n",
      "(GPU: 0, epoch: 1, iters: 38496, time: 0.005) nll: 0.906368 \n",
      "(GPU: 0, epoch: 1, iters: 39296, time: 0.006) nll: 0.804207 \n",
      "saving the latest model (epoch 1, total_steps 180000)\n",
      "(GPU: 0, epoch: 1, iters: 40096, time: 0.005) nll: 0.563328 \n",
      "(GPU: 0, epoch: 1, iters: 40896, time: 0.006) nll: 0.875695 \n",
      "(GPU: 0, epoch: 1, iters: 41696, time: 0.005) nll: 0.723318 \n",
      "(GPU: 0, epoch: 1, iters: 42496, time: 0.006) nll: 1.119787 \n",
      "(GPU: 0, epoch: 1, iters: 43296, time: 0.005) nll: 0.966067 \n",
      "(GPU: 0, epoch: 1, iters: 44096, time: 0.006) nll: 1.362894 \n",
      "(GPU: 0, epoch: 1, iters: 44896, time: 0.005) nll: 0.844131 \n",
      "(GPU: 0, epoch: 1, iters: 45696, time: 0.006) nll: 0.803299 \n",
      "(GPU: 0, epoch: 1, iters: 46496, time: 0.006) nll: 0.669476 \n",
      "(GPU: 0, epoch: 1, iters: 47296, time: 0.006) nll: 0.804236 \n",
      "(GPU: 0, epoch: 1, iters: 48096, time: 0.005) nll: 0.492650 \n",
      "(GPU: 0, epoch: 1, iters: 48896, time: 0.006) nll: 1.031538 \n",
      "(GPU: 0, epoch: 1, iters: 49696, time: 0.006) nll: 0.574910 \n",
      "(GPU: 0, epoch: 1, iters: 50496, time: 0.006) nll: 0.966914 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.005) nll: 0.815481 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.008) nll: 0.814443 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.008) nll: 0.699887 \n",
      "(GPU: 0, epoch: 1, iters: 52096, time: 0.006) nll: 0.798219 \n",
      "(GPU: 0, epoch: 1, iters: 52896, time: 0.006) nll: 0.560517 \n",
      "(GPU: 0, epoch: 1, iters: 53696, time: 0.005) nll: 0.999389 \n",
      "(GPU: 0, epoch: 1, iters: 54496, time: 0.005) nll: 0.747587 \n",
      "(GPU: 0, epoch: 1, iters: 55296, time: 0.006) nll: 0.696657 \n",
      "(GPU: 0, epoch: 1, iters: 56096, time: 0.006) nll: 0.579614 \n",
      "(GPU: 0, epoch: 1, iters: 56896, time: 0.005) nll: 0.793821 \n",
      "(GPU: 0, epoch: 1, iters: 57696, time: 0.005) nll: 0.836633 \n",
      "(GPU: 0, epoch: 1, iters: 58496, time: 0.006) nll: 0.746795 \n",
      "(GPU: 0, epoch: 1, iters: 59296, time: 0.005) nll: 0.865204 \n",
      "saving the latest model (epoch 1, total_steps 200000)\n",
      "(GPU: 0, epoch: 1, iters: 60096, time: 0.006) nll: 0.772543 \n",
      "(GPU: 0, epoch: 1, iters: 60896, time: 0.005) nll: 0.699671 \n",
      "(GPU: 0, epoch: 1, iters: 61696, time: 0.006) nll: 0.796342 \n",
      "(GPU: 0, epoch: 1, iters: 62496, time: 0.005) nll: 0.940280 \n",
      "(GPU: 0, epoch: 1, iters: 63296, time: 0.006) nll: 0.592477 \n",
      "(GPU: 0, epoch: 1, iters: 64096, time: 0.005) nll: 0.858114 \n",
      "(GPU: 0, epoch: 1, iters: 64896, time: 0.006) nll: 1.005201 \n",
      "(GPU: 0, epoch: 1, iters: 65696, time: 0.005) nll: 0.598253 \n",
      "(GPU: 0, epoch: 1, iters: 66496, time: 0.006) nll: 0.775905 \n",
      "(GPU: 0, epoch: 1, iters: 67296, time: 0.005) nll: 0.670552 \n",
      "(GPU: 0, epoch: 1, iters: 68096, time: 0.006) nll: 0.835707 \n",
      "(GPU: 0, epoch: 1, iters: 68896, time: 0.005) nll: 0.756909 \n",
      "(GPU: 0, epoch: 1, iters: 69696, time: 0.006) nll: 0.792923 \n",
      "(GPU: 0, epoch: 1, iters: 70496, time: 0.005) nll: 0.797279 \n",
      "(GPU: 0, epoch: 1, iters: 71296, time: 0.006) nll: 0.724609 \n",
      "(GPU: 0, epoch: 1, iters: 72096, time: 0.005) nll: 0.736877 \n",
      "(GPU: 0, epoch: 1, iters: 72896, time: 0.005) nll: 0.758282 \n",
      "(GPU: 0, epoch: 1, iters: 73696, time: 0.006) nll: 0.668511 \n",
      "(GPU: 0, epoch: 1, iters: 74496, time: 0.006) nll: 0.824636 \n",
      "(GPU: 0, epoch: 1, iters: 75296, time: 0.005) nll: 0.621406 \n",
      "(GPU: 0, epoch: 1, iters: 76096, time: 0.006) nll: 0.710856 \n",
      "(GPU: 0, epoch: 1, iters: 76896, time: 0.005) nll: 0.576613 \n",
      "(GPU: 0, epoch: 1, iters: 77696, time: 0.006) nll: 0.622258 \n",
      "(GPU: 0, epoch: 1, iters: 78496, time: 0.005) nll: 1.245691 \n",
      "(GPU: 0, epoch: 1, iters: 79296, time: 0.006) nll: 0.891830 \n",
      "saving the latest model (epoch 1, total_steps 220000)\n",
      "(GPU: 0, epoch: 1, iters: 80096, time: 0.005) nll: 0.816340 \n",
      "(GPU: 0, epoch: 1, iters: 80896, time: 0.006) nll: 1.074741 \n",
      "(GPU: 0, epoch: 1, iters: 81696, time: 0.006) nll: 0.719887 \n",
      "(GPU: 0, epoch: 1, iters: 82496, time: 0.006) nll: 0.775863 \n",
      "(GPU: 0, epoch: 1, iters: 83296, time: 0.005) nll: 1.556760 \n",
      "(GPU: 0, epoch: 1, iters: 84096, time: 0.006) nll: 0.689992 \n",
      "(GPU: 0, epoch: 1, iters: 84896, time: 0.005) nll: 0.610644 \n",
      "(GPU: 0, epoch: 1, iters: 85696, time: 0.006) nll: 0.915676 \n",
      "(GPU: 0, epoch: 1, iters: 86496, time: 0.006) nll: 1.041816 \n",
      "(GPU: 0, epoch: 1, iters: 87296, time: 0.006) nll: 0.521120 \n",
      "(GPU: 0, epoch: 1, iters: 88096, time: 0.005) nll: 0.765587 \n",
      "(GPU: 0, epoch: 1, iters: 88896, time: 0.006) nll: 0.718791 \n",
      "(GPU: 0, epoch: 1, iters: 89696, time: 0.005) nll: 1.063670 \n",
      "(GPU: 0, epoch: 1, iters: 90496, time: 0.006) nll: 0.832829 \n",
      "(GPU: 0, epoch: 1, iters: 91296, time: 0.006) nll: 0.755965 \n",
      "(GPU: 0, epoch: 1, iters: 92096, time: 0.006) nll: 0.747769 \n",
      "(GPU: 0, epoch: 1, iters: 92896, time: 0.005) nll: 0.877870 \n",
      "(GPU: 0, epoch: 1, iters: 93696, time: 0.006) nll: 0.748984 \n",
      "(GPU: 0, epoch: 1, iters: 94496, time: 0.005) nll: 0.613828 \n",
      "(GPU: 0, epoch: 1, iters: 95296, time: 0.006) nll: 0.860709 \n",
      "(GPU: 0, epoch: 1, iters: 96096, time: 0.005) nll: 0.801111 \n",
      "(GPU: 0, epoch: 1, iters: 96896, time: 0.006) nll: 0.686072 \n",
      "(GPU: 0, epoch: 1, iters: 97696, time: 0.005) nll: 0.943400 \n",
      "(GPU: 0, epoch: 1, iters: 98496, time: 0.006) nll: 0.803715 \n",
      "(GPU: 0, epoch: 1, iters: 99296, time: 0.005) nll: 0.869667 \n",
      "saving the latest model (epoch 1, total_steps 240000)\n",
      "(GPU: 0, epoch: 1, iters: 100096, time: 0.006) nll: 0.908733 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:52<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 100896, time: 0.005) nll: 0.673950 \n",
      "(GPU: 0, epoch: 1, iters: 101696, time: 0.006) nll: 0.884550 \n",
      "(GPU: 0, epoch: 1, iters: 102496, time: 0.005) nll: 0.776115 \n",
      "(GPU: 0, epoch: 1, iters: 103296, time: 0.006) nll: 0.647131 \n",
      "(GPU: 0, epoch: 1, iters: 104096, time: 0.005) nll: 0.807226 \n",
      "(GPU: 0, epoch: 1, iters: 104896, time: 0.006) nll: 0.698592 \n",
      "(GPU: 0, epoch: 1, iters: 105696, time: 0.005) nll: 0.578813 \n",
      "(GPU: 0, epoch: 1, iters: 106496, time: 0.006) nll: 0.993439 \n",
      "(GPU: 0, epoch: 1, iters: 107296, time: 0.005) nll: 0.887447 \n",
      "(GPU: 0, epoch: 1, iters: 108096, time: 0.006) nll: 0.665405 \n",
      "(GPU: 0, epoch: 1, iters: 108896, time: 0.005) nll: 0.699188 \n",
      "(GPU: 0, epoch: 1, iters: 109696, time: 0.005) nll: 1.037814 \n",
      "(GPU: 0, epoch: 1, iters: 110496, time: 0.005) nll: 0.877746 \n",
      "(GPU: 0, epoch: 1, iters: 111296, time: 0.006) nll: 0.618484 \n",
      "(GPU: 0, epoch: 1, iters: 112096, time: 0.005) nll: 0.760266 \n",
      "(GPU: 0, epoch: 1, iters: 112896, time: 0.006) nll: 0.895689 \n",
      "(GPU: 0, epoch: 1, iters: 113696, time: 0.005) nll: 0.817334 \n",
      "(GPU: 0, epoch: 1, iters: 114496, time: 0.006) nll: 1.292578 \n",
      "(GPU: 0, epoch: 1, iters: 115296, time: 0.005) nll: 0.758673 \n",
      "(GPU: 0, epoch: 1, iters: 116096, time: 0.006) nll: 0.902670 \n",
      "(GPU: 0, epoch: 1, iters: 116896, time: 0.005) nll: 1.170949 \n",
      "(GPU: 0, epoch: 1, iters: 117696, time: 0.006) nll: 0.636989 \n",
      "(GPU: 0, epoch: 1, iters: 118496, time: 0.006) nll: 0.635081 \n",
      "(GPU: 0, epoch: 1, iters: 119296, time: 0.006) nll: 0.751588 \n",
      "saving the latest model (epoch 1, total_steps 260000)\n",
      "(GPU: 0, epoch: 1, iters: 120096, time: 0.005) nll: 0.772029 \n",
      "(GPU: 0, epoch: 1, iters: 120896, time: 0.006) nll: 0.783773 \n",
      "(GPU: 0, epoch: 1, iters: 121696, time: 0.005) nll: 0.684927 \n",
      "(GPU: 0, epoch: 1, iters: 122496, time: 0.006) nll: 0.961531 \n",
      "(GPU: 0, epoch: 1, iters: 123296, time: 0.006) nll: 0.817665 \n",
      "(GPU: 0, epoch: 1, iters: 124096, time: 0.006) nll: 0.867830 \n",
      "(GPU: 0, epoch: 1, iters: 124896, time: 0.006) nll: 0.869101 \n",
      "(GPU: 0, epoch: 1, iters: 125696, time: 0.006) nll: 0.824032 \n",
      "(GPU: 0, epoch: 1, iters: 126496, time: 0.005) nll: 0.691002 \n",
      "(GPU: 0, epoch: 1, iters: 127296, time: 0.006) nll: 0.779525 \n",
      "(GPU: 0, epoch: 1, iters: 128096, time: 0.005) nll: 0.999947 \n",
      "(GPU: 0, epoch: 1, iters: 128896, time: 0.006) nll: 1.113032 \n",
      "(GPU: 0, epoch: 1, iters: 129696, time: 0.006) nll: 0.700268 \n",
      "(GPU: 0, epoch: 1, iters: 130496, time: 0.006) nll: 0.780942 \n",
      "(GPU: 0, epoch: 1, iters: 131296, time: 0.005) nll: 0.744118 \n",
      "(GPU: 0, epoch: 1, iters: 132096, time: 0.006) nll: 0.928106 \n",
      "(GPU: 0, epoch: 1, iters: 132896, time: 0.005) nll: 0.944713 \n",
      "(GPU: 0, epoch: 1, iters: 133696, time: 0.006) nll: 0.856032 \n",
      "(GPU: 0, epoch: 1, iters: 134496, time: 0.005) nll: 0.844463 \n",
      "(GPU: 0, epoch: 1, iters: 135296, time: 0.006) nll: 0.880717 \n",
      "(GPU: 0, epoch: 1, iters: 136096, time: 0.005) nll: 0.628666 \n",
      "(GPU: 0, epoch: 1, iters: 136896, time: 0.006) nll: 0.687260 \n",
      "(GPU: 0, epoch: 1, iters: 137696, time: 0.005) nll: 0.994370 \n",
      "(GPU: 0, epoch: 1, iters: 138496, time: 0.006) nll: 0.616283 \n",
      "(GPU: 0, epoch: 1, iters: 139296, time: 0.005) nll: 0.716946 \n",
      "saving the latest model (epoch 1, total_steps 280000)\n",
      "(GPU: 0, epoch: 1, iters: 140096, time: 0.006) nll: 0.932117 \n",
      "[*] End of epoch 1 / 25 \t Time Taken: 832 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000200\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3155/4397 [09:57<03:46,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 32, time: 0.003) nll: 0.698613 \n",
      "(GPU: 0, epoch: 2, iters: 32, time: 0.003) nll: 0.536758 \n",
      "(GPU: 0, epoch: 2, iters: 192, time: 0.006) nll: 0.761478 \n",
      "(GPU: 0, epoch: 2, iters: 992, time: 0.005) nll: 0.775176 \n",
      "(GPU: 0, epoch: 2, iters: 1792, time: 0.006) nll: 1.051219 \n",
      "(GPU: 0, epoch: 2, iters: 2592, time: 0.006) nll: 0.944316 \n",
      "(GPU: 0, epoch: 2, iters: 3392, time: 0.006) nll: 0.739535 \n",
      "(GPU: 0, epoch: 2, iters: 4192, time: 0.005) nll: 0.872273 \n",
      "(GPU: 0, epoch: 2, iters: 4992, time: 0.006) nll: 0.605125 \n",
      "(GPU: 0, epoch: 2, iters: 5792, time: 0.005) nll: 0.730061 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.006) nll: 0.837921 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.009) nll: 0.835674 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.009) nll: 0.601810 \n",
      "(GPU: 0, epoch: 2, iters: 7392, time: 0.005) nll: 0.823828 \n",
      "(GPU: 0, epoch: 2, iters: 8192, time: 0.006) nll: 1.147990 \n",
      "(GPU: 0, epoch: 2, iters: 8992, time: 0.006) nll: 1.135605 \n",
      "(GPU: 0, epoch: 2, iters: 9792, time: 0.006) nll: 0.656554 \n",
      "(GPU: 0, epoch: 2, iters: 10592, time: 0.005) nll: 0.678752 \n",
      "(GPU: 0, epoch: 2, iters: 11392, time: 0.006) nll: 0.628658 \n",
      "(GPU: 0, epoch: 2, iters: 12192, time: 0.005) nll: 0.718099 \n",
      "(GPU: 0, epoch: 2, iters: 12992, time: 0.006) nll: 0.694782 \n",
      "(GPU: 0, epoch: 2, iters: 13792, time: 0.005) nll: 0.590964 \n",
      "(GPU: 0, epoch: 2, iters: 14592, time: 0.005) nll: 0.991023 \n",
      "(GPU: 0, epoch: 2, iters: 15392, time: 0.005) nll: 0.548425 \n",
      "(GPU: 0, epoch: 2, iters: 16192, time: 0.006) nll: 0.824948 \n",
      "(GPU: 0, epoch: 2, iters: 16992, time: 0.005) nll: 0.845069 \n",
      "(GPU: 0, epoch: 2, iters: 17792, time: 0.006) nll: 0.886388 \n",
      "(GPU: 0, epoch: 2, iters: 18592, time: 0.005) nll: 0.763357 \n",
      "saving the latest model (epoch 2, total_steps 300000)\n",
      "(GPU: 0, epoch: 2, iters: 19392, time: 0.006) nll: 0.909863 \n",
      "(GPU: 0, epoch: 2, iters: 20192, time: 0.005) nll: 0.739081 \n",
      "(GPU: 0, epoch: 2, iters: 20992, time: 0.006) nll: 0.877351 \n",
      "(GPU: 0, epoch: 2, iters: 21792, time: 0.005) nll: 0.831668 \n",
      "(GPU: 0, epoch: 2, iters: 22592, time: 0.006) nll: 0.489491 \n",
      "(GPU: 0, epoch: 2, iters: 23392, time: 0.006) nll: 0.840335 \n",
      "(GPU: 0, epoch: 2, iters: 24192, time: 0.006) nll: 0.817090 \n",
      "(GPU: 0, epoch: 2, iters: 24992, time: 0.005) nll: 0.717630 \n",
      "(GPU: 0, epoch: 2, iters: 25792, time: 0.006) nll: 0.805822 \n",
      "(GPU: 0, epoch: 2, iters: 26592, time: 0.005) nll: 0.567442 \n",
      "(GPU: 0, epoch: 2, iters: 27392, time: 0.006) nll: 0.850770 \n",
      "(GPU: 0, epoch: 2, iters: 28192, time: 0.005) nll: 0.788220 \n",
      "(GPU: 0, epoch: 2, iters: 28992, time: 0.006) nll: 1.029953 \n",
      "(GPU: 0, epoch: 2, iters: 29792, time: 0.005) nll: 0.819828 \n",
      "(GPU: 0, epoch: 2, iters: 30592, time: 0.006) nll: 1.142229 \n",
      "(GPU: 0, epoch: 2, iters: 31392, time: 0.005) nll: 0.794731 \n",
      "(GPU: 0, epoch: 2, iters: 32192, time: 0.006) nll: 0.721167 \n",
      "(GPU: 0, epoch: 2, iters: 32992, time: 0.005) nll: 0.664455 \n",
      "(GPU: 0, epoch: 2, iters: 33792, time: 0.006) nll: 0.564417 \n",
      "(GPU: 0, epoch: 2, iters: 34592, time: 0.005) nll: 0.856277 \n",
      "(GPU: 0, epoch: 2, iters: 35392, time: 0.006) nll: 0.785923 \n",
      "(GPU: 0, epoch: 2, iters: 36192, time: 0.005) nll: 0.851394 \n",
      "(GPU: 0, epoch: 2, iters: 36992, time: 0.006) nll: 0.977440 \n",
      "(GPU: 0, epoch: 2, iters: 37792, time: 0.005) nll: 0.689900 \n",
      "(GPU: 0, epoch: 2, iters: 38592, time: 0.006) nll: 0.636220 \n",
      "saving the latest model (epoch 2, total_steps 320000)\n",
      "(GPU: 0, epoch: 2, iters: 39392, time: 0.005) nll: 0.736336 \n",
      "(GPU: 0, epoch: 2, iters: 40192, time: 0.006) nll: 1.110724 \n",
      "(GPU: 0, epoch: 2, iters: 40992, time: 0.005) nll: 0.751955 \n",
      "(GPU: 0, epoch: 2, iters: 41792, time: 0.006) nll: 0.785601 \n",
      "(GPU: 0, epoch: 2, iters: 42592, time: 0.005) nll: 0.728024 \n",
      "(GPU: 0, epoch: 2, iters: 43392, time: 0.006) nll: 0.961428 \n",
      "(GPU: 0, epoch: 2, iters: 44192, time: 0.005) nll: 0.776175 \n",
      "(GPU: 0, epoch: 2, iters: 44992, time: 0.006) nll: 0.776359 \n",
      "(GPU: 0, epoch: 2, iters: 45792, time: 0.006) nll: 1.157932 \n",
      "(GPU: 0, epoch: 2, iters: 46592, time: 0.006) nll: 0.675385 \n",
      "(GPU: 0, epoch: 2, iters: 47392, time: 0.005) nll: 0.863599 \n",
      "(GPU: 0, epoch: 2, iters: 48192, time: 0.006) nll: 1.225183 \n",
      "(GPU: 0, epoch: 2, iters: 48992, time: 0.005) nll: 0.675142 \n",
      "(GPU: 0, epoch: 2, iters: 49792, time: 0.006) nll: 0.796626 \n",
      "(GPU: 0, epoch: 2, iters: 50592, time: 0.005) nll: 0.874633 \n",
      "(GPU: 0, epoch: 2, iters: 51392, time: 0.006) nll: 0.770311 \n",
      "(GPU: 0, epoch: 2, iters: 52192, time: 0.005) nll: 0.666598 \n",
      "(GPU: 0, epoch: 2, iters: 52992, time: 0.006) nll: 1.050510 \n",
      "(GPU: 0, epoch: 2, iters: 53792, time: 0.005) nll: 0.627307 \n",
      "(GPU: 0, epoch: 2, iters: 54592, time: 0.006) nll: 0.551525 \n",
      "(GPU: 0, epoch: 2, iters: 55392, time: 0.005) nll: 0.850450 \n",
      "(GPU: 0, epoch: 2, iters: 56192, time: 0.006) nll: 0.767003 \n",
      "(GPU: 0, epoch: 2, iters: 56992, time: 0.005) nll: 0.783960 \n",
      "(GPU: 0, epoch: 2, iters: 57792, time: 0.006) nll: 0.777686 \n",
      "(GPU: 0, epoch: 2, iters: 58592, time: 0.005) nll: 0.752076 \n",
      "saving the latest model (epoch 2, total_steps 340000)\n",
      "(GPU: 0, epoch: 2, iters: 59392, time: 0.006) nll: 0.648132 \n",
      "(GPU: 0, epoch: 2, iters: 60192, time: 0.005) nll: 0.708996 \n",
      "(GPU: 0, epoch: 2, iters: 60992, time: 0.006) nll: 0.664287 \n",
      "(GPU: 0, epoch: 2, iters: 61792, time: 0.005) nll: 0.818396 \n",
      "(GPU: 0, epoch: 2, iters: 62592, time: 0.006) nll: 0.685405 \n",
      "(GPU: 0, epoch: 2, iters: 63392, time: 0.005) nll: 0.745497 \n",
      "(GPU: 0, epoch: 2, iters: 64192, time: 0.006) nll: 0.647795 \n",
      "(GPU: 0, epoch: 2, iters: 64992, time: 0.005) nll: 1.029266 \n",
      "(GPU: 0, epoch: 2, iters: 65792, time: 0.006) nll: 0.784369 \n",
      "(GPU: 0, epoch: 2, iters: 66592, time: 0.006) nll: 0.701878 \n",
      "(GPU: 0, epoch: 2, iters: 67392, time: 0.006) nll: 0.796287 \n",
      "(GPU: 0, epoch: 2, iters: 68192, time: 0.005) nll: 0.672030 \n",
      "(GPU: 0, epoch: 2, iters: 68992, time: 0.006) nll: 1.042709 \n",
      "(GPU: 0, epoch: 2, iters: 69792, time: 0.005) nll: 0.731027 \n",
      "(GPU: 0, epoch: 2, iters: 70592, time: 0.006) nll: 0.989367 \n",
      "(GPU: 0, epoch: 2, iters: 71392, time: 0.005) nll: 1.114791 \n",
      "(GPU: 0, epoch: 2, iters: 72192, time: 0.006) nll: 0.890150 \n",
      "(GPU: 0, epoch: 2, iters: 72992, time: 0.005) nll: 0.842484 \n",
      "(GPU: 0, epoch: 2, iters: 73792, time: 0.006) nll: 0.847415 \n",
      "(GPU: 0, epoch: 2, iters: 74592, time: 0.005) nll: 0.903197 \n",
      "(GPU: 0, epoch: 2, iters: 75392, time: 0.006) nll: 0.793944 \n",
      "(GPU: 0, epoch: 2, iters: 76192, time: 0.006) nll: 0.616665 \n",
      "(GPU: 0, epoch: 2, iters: 76992, time: 0.006) nll: 0.640722 \n",
      "(GPU: 0, epoch: 2, iters: 77792, time: 0.005) nll: 0.646173 \n",
      "(GPU: 0, epoch: 2, iters: 78592, time: 0.006) nll: 0.665762 \n",
      "saving the latest model (epoch 2, total_steps 360000)\n",
      "(GPU: 0, epoch: 2, iters: 79392, time: 0.005) nll: 0.853475 \n",
      "(GPU: 0, epoch: 2, iters: 80192, time: 0.006) nll: 0.749897 \n",
      "(GPU: 0, epoch: 2, iters: 80992, time: 0.005) nll: 0.691376 \n",
      "(GPU: 0, epoch: 2, iters: 81792, time: 0.006) nll: 0.569154 \n",
      "(GPU: 0, epoch: 2, iters: 82592, time: 0.005) nll: 0.563873 \n",
      "(GPU: 0, epoch: 2, iters: 83392, time: 0.006) nll: 1.158779 \n",
      "(GPU: 0, epoch: 2, iters: 84192, time: 0.005) nll: 0.936755 \n",
      "(GPU: 0, epoch: 2, iters: 84992, time: 0.006) nll: 0.918160 \n",
      "(GPU: 0, epoch: 2, iters: 85792, time: 0.006) nll: 0.600695 \n",
      "(GPU: 0, epoch: 2, iters: 86592, time: 0.006) nll: 0.833832 \n",
      "(GPU: 0, epoch: 2, iters: 87392, time: 0.005) nll: 1.086973 \n",
      "(GPU: 0, epoch: 2, iters: 88192, time: 0.006) nll: 0.701181 \n",
      "(GPU: 0, epoch: 2, iters: 88992, time: 0.005) nll: 0.776438 \n",
      "(GPU: 0, epoch: 2, iters: 89792, time: 0.006) nll: 0.917973 \n",
      "(GPU: 0, epoch: 2, iters: 90592, time: 0.005) nll: 0.733177 \n",
      "(GPU: 0, epoch: 2, iters: 91392, time: 0.006) nll: 0.837195 \n",
      "(GPU: 0, epoch: 2, iters: 92192, time: 0.005) nll: 0.863598 \n",
      "(GPU: 0, epoch: 2, iters: 92992, time: 0.006) nll: 1.030808 \n",
      "(GPU: 0, epoch: 2, iters: 93792, time: 0.005) nll: 1.003662 \n",
      "(GPU: 0, epoch: 2, iters: 94592, time: 0.006) nll: 0.747815 \n",
      "(GPU: 0, epoch: 2, iters: 95392, time: 0.005) nll: 0.649764 \n",
      "(GPU: 0, epoch: 2, iters: 96192, time: 0.006) nll: 0.781342 \n",
      "(GPU: 0, epoch: 2, iters: 96992, time: 0.005) nll: 0.646288 \n",
      "(GPU: 0, epoch: 2, iters: 97792, time: 0.006) nll: 0.659346 \n",
      "(GPU: 0, epoch: 2, iters: 98592, time: 0.005) nll: 0.575722 \n",
      "saving the latest model (epoch 2, total_steps 380000)\n",
      "(GPU: 0, epoch: 2, iters: 99392, time: 0.006) nll: 0.690743 \n",
      "(GPU: 0, epoch: 2, iters: 100192, time: 0.006) nll: 0.912950 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 100992, time: 0.006) nll: 0.995865 \n",
      "(GPU: 0, epoch: 2, iters: 101792, time: 0.005) nll: 0.927583 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.006) nll: 0.687225 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.009) nll: 0.682959 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.009) nll: 0.836553 \n",
      "(GPU: 0, epoch: 2, iters: 103392, time: 0.005) nll: 0.644722 \n",
      "(GPU: 0, epoch: 2, iters: 104192, time: 0.006) nll: 0.726383 \n",
      "(GPU: 0, epoch: 2, iters: 104992, time: 0.005) nll: 0.711325 \n",
      "(GPU: 0, epoch: 2, iters: 105792, time: 0.006) nll: 1.405570 \n",
      "(GPU: 0, epoch: 2, iters: 106592, time: 0.005) nll: 0.731165 \n",
      "(GPU: 0, epoch: 2, iters: 107392, time: 0.006) nll: 0.658738 \n",
      "(GPU: 0, epoch: 2, iters: 108192, time: 0.005) nll: 0.944460 \n",
      "(GPU: 0, epoch: 2, iters: 108992, time: 0.006) nll: 0.691200 \n",
      "(GPU: 0, epoch: 2, iters: 109792, time: 0.005) nll: 1.026814 \n",
      "(GPU: 0, epoch: 2, iters: 110592, time: 0.006) nll: 0.791647 \n",
      "(GPU: 0, epoch: 2, iters: 111392, time: 0.005) nll: 0.953526 \n",
      "(GPU: 0, epoch: 2, iters: 112192, time: 0.006) nll: 0.690913 \n",
      "(GPU: 0, epoch: 2, iters: 112992, time: 0.006) nll: 0.743060 \n",
      "(GPU: 0, epoch: 2, iters: 113792, time: 0.006) nll: 0.815741 \n",
      "(GPU: 0, epoch: 2, iters: 114592, time: 0.005) nll: 0.870588 \n",
      "(GPU: 0, epoch: 2, iters: 115392, time: 0.006) nll: 0.899945 \n",
      "(GPU: 0, epoch: 2, iters: 116192, time: 0.005) nll: 0.927316 \n",
      "(GPU: 0, epoch: 2, iters: 116992, time: 0.006) nll: 1.038188 \n",
      "(GPU: 0, epoch: 2, iters: 117792, time: 0.005) nll: 0.864914 \n",
      "(GPU: 0, epoch: 2, iters: 118592, time: 0.006) nll: 0.918467 \n",
      "saving the latest model (epoch 2, total_steps 400000)\n",
      "(GPU: 0, epoch: 2, iters: 119392, time: 0.005) nll: 0.745965 \n",
      "(GPU: 0, epoch: 2, iters: 120192, time: 0.006) nll: 0.807132 \n",
      "(GPU: 0, epoch: 2, iters: 120992, time: 0.005) nll: 0.635385 \n",
      "(GPU: 0, epoch: 2, iters: 121792, time: 0.006) nll: 0.759801 \n",
      "(GPU: 0, epoch: 2, iters: 122592, time: 0.005) nll: 0.792793 \n",
      "(GPU: 0, epoch: 2, iters: 123392, time: 0.006) nll: 1.020240 \n",
      "(GPU: 0, epoch: 2, iters: 124192, time: 0.005) nll: 0.782335 \n",
      "(GPU: 0, epoch: 2, iters: 124992, time: 0.006) nll: 0.871058 \n",
      "(GPU: 0, epoch: 2, iters: 125792, time: 0.005) nll: 0.804798 \n",
      "(GPU: 0, epoch: 2, iters: 126592, time: 0.006) nll: 0.733188 \n",
      "(GPU: 0, epoch: 2, iters: 127392, time: 0.005) nll: 0.757098 \n",
      "(GPU: 0, epoch: 2, iters: 128192, time: 0.006) nll: 0.803445 \n",
      "(GPU: 0, epoch: 2, iters: 128992, time: 0.005) nll: 0.905301 \n",
      "(GPU: 0, epoch: 2, iters: 129792, time: 0.006) nll: 0.840599 \n",
      "(GPU: 0, epoch: 2, iters: 130592, time: 0.005) nll: 0.742060 \n",
      "(GPU: 0, epoch: 2, iters: 131392, time: 0.006) nll: 0.675691 \n",
      "(GPU: 0, epoch: 2, iters: 132192, time: 0.005) nll: 0.780359 \n",
      "(GPU: 0, epoch: 2, iters: 132992, time: 0.006) nll: 0.824120 \n",
      "(GPU: 0, epoch: 2, iters: 133792, time: 0.005) nll: 0.766328 \n",
      "(GPU: 0, epoch: 2, iters: 134592, time: 0.006) nll: 0.873074 \n",
      "(GPU: 0, epoch: 2, iters: 135392, time: 0.005) nll: 0.624760 \n",
      "(GPU: 0, epoch: 2, iters: 136192, time: 0.006) nll: 0.915391 \n",
      "(GPU: 0, epoch: 2, iters: 136992, time: 0.005) nll: 0.779889 \n",
      "(GPU: 0, epoch: 2, iters: 137792, time: 0.006) nll: 0.897508 \n",
      "(GPU: 0, epoch: 2, iters: 138592, time: 0.005) nll: 0.669304 \n",
      "saving the latest model (epoch 2, total_steps 420000)\n",
      "(GPU: 0, epoch: 2, iters: 139392, time: 0.006) nll: 0.778377 \n",
      "(GPU: 0, epoch: 2, iters: 140192, time: 0.006) nll: 0.819894 \n",
      "[*] End of epoch 2 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000300\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3158/4397 [09:59<03:47,  5.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.926600 \n",
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.837569 \n",
      "(GPU: 0, epoch: 3, iters: 288, time: 0.005) nll: 0.999139 \n",
      "(GPU: 0, epoch: 3, iters: 1088, time: 0.006) nll: 0.601667 \n",
      "(GPU: 0, epoch: 3, iters: 1888, time: 0.005) nll: 0.739486 \n",
      "(GPU: 0, epoch: 3, iters: 2688, time: 0.006) nll: 0.790028 \n",
      "(GPU: 0, epoch: 3, iters: 3488, time: 0.005) nll: 0.933116 \n",
      "(GPU: 0, epoch: 3, iters: 4288, time: 0.006) nll: 0.722506 \n",
      "(GPU: 0, epoch: 3, iters: 5088, time: 0.005) nll: 0.737567 \n",
      "(GPU: 0, epoch: 3, iters: 5888, time: 0.006) nll: 0.676337 \n",
      "(GPU: 0, epoch: 3, iters: 6688, time: 0.005) nll: 0.641013 \n",
      "(GPU: 0, epoch: 3, iters: 7488, time: 0.006) nll: 0.806345 \n",
      "(GPU: 0, epoch: 3, iters: 8288, time: 0.005) nll: 0.788820 \n",
      "(GPU: 0, epoch: 3, iters: 9088, time: 0.006) nll: 0.736466 \n",
      "(GPU: 0, epoch: 3, iters: 9888, time: 0.005) nll: 0.700458 \n",
      "(GPU: 0, epoch: 3, iters: 10688, time: 0.006) nll: 0.880643 \n",
      "(GPU: 0, epoch: 3, iters: 11488, time: 0.005) nll: 0.839706 \n",
      "(GPU: 0, epoch: 3, iters: 12288, time: 0.006) nll: 0.801399 \n",
      "(GPU: 0, epoch: 3, iters: 13088, time: 0.005) nll: 0.671235 \n",
      "(GPU: 0, epoch: 3, iters: 13888, time: 0.006) nll: 0.818331 \n",
      "(GPU: 0, epoch: 3, iters: 14688, time: 0.005) nll: 0.761611 \n",
      "(GPU: 0, epoch: 3, iters: 15488, time: 0.006) nll: 0.734564 \n",
      "(GPU: 0, epoch: 3, iters: 16288, time: 0.005) nll: 0.823377 \n",
      "(GPU: 0, epoch: 3, iters: 17088, time: 0.006) nll: 0.935266 \n",
      "(GPU: 0, epoch: 3, iters: 17888, time: 0.005) nll: 1.063038 \n",
      "saving the latest model (epoch 3, total_steps 440000)\n",
      "(GPU: 0, epoch: 3, iters: 18688, time: 0.006) nll: 0.778252 \n",
      "(GPU: 0, epoch: 3, iters: 19488, time: 0.006) nll: 0.874137 \n",
      "(GPU: 0, epoch: 3, iters: 20288, time: 0.006) nll: 0.767150 \n",
      "(GPU: 0, epoch: 3, iters: 21088, time: 0.005) nll: 0.633381 \n",
      "(GPU: 0, epoch: 3, iters: 21888, time: 0.006) nll: 0.753266 \n",
      "(GPU: 0, epoch: 3, iters: 22688, time: 0.005) nll: 0.666823 \n",
      "(GPU: 0, epoch: 3, iters: 23488, time: 0.006) nll: 1.012975 \n",
      "(GPU: 0, epoch: 3, iters: 24288, time: 0.005) nll: 0.639715 \n",
      "(GPU: 0, epoch: 3, iters: 25088, time: 0.006) nll: 0.835323 \n",
      "(GPU: 0, epoch: 3, iters: 25888, time: 0.006) nll: 0.617108 \n",
      "(GPU: 0, epoch: 3, iters: 26688, time: 0.006) nll: 0.993707 \n",
      "(GPU: 0, epoch: 3, iters: 27488, time: 0.005) nll: 0.741079 \n",
      "(GPU: 0, epoch: 3, iters: 28288, time: 0.006) nll: 0.844942 \n",
      "(GPU: 0, epoch: 3, iters: 29088, time: 0.005) nll: 0.846735 \n",
      "(GPU: 0, epoch: 3, iters: 29888, time: 0.006) nll: 0.803052 \n",
      "(GPU: 0, epoch: 3, iters: 30688, time: 0.005) nll: 0.738185 \n",
      "(GPU: 0, epoch: 3, iters: 31488, time: 0.006) nll: 0.769374 \n",
      "(GPU: 0, epoch: 3, iters: 32288, time: 0.005) nll: 1.173510 \n",
      "(GPU: 0, epoch: 3, iters: 33088, time: 0.006) nll: 0.940156 \n",
      "(GPU: 0, epoch: 3, iters: 33888, time: 0.005) nll: 0.451117 \n",
      "(GPU: 0, epoch: 3, iters: 34688, time: 0.006) nll: 0.631444 \n",
      "(GPU: 0, epoch: 3, iters: 35488, time: 0.005) nll: 0.700348 \n",
      "(GPU: 0, epoch: 3, iters: 36288, time: 0.006) nll: 0.926104 \n",
      "(GPU: 0, epoch: 3, iters: 37088, time: 0.005) nll: 0.854617 \n",
      "(GPU: 0, epoch: 3, iters: 37888, time: 0.006) nll: 0.716972 \n",
      "saving the latest model (epoch 3, total_steps 460000)\n",
      "(GPU: 0, epoch: 3, iters: 38688, time: 0.005) nll: 0.831104 \n",
      "(GPU: 0, epoch: 3, iters: 39488, time: 0.006) nll: 0.766829 \n",
      "(GPU: 0, epoch: 3, iters: 40288, time: 0.006) nll: 0.875314 \n",
      "(GPU: 0, epoch: 3, iters: 41088, time: 0.006) nll: 0.593979 \n",
      "(GPU: 0, epoch: 3, iters: 41888, time: 0.005) nll: 0.819917 \n",
      "(GPU: 0, epoch: 3, iters: 42688, time: 0.006) nll: 0.933214 \n",
      "(GPU: 0, epoch: 3, iters: 43488, time: 0.005) nll: 1.020967 \n",
      "(GPU: 0, epoch: 3, iters: 44288, time: 0.006) nll: 0.595086 \n",
      "(GPU: 0, epoch: 3, iters: 45088, time: 0.005) nll: 0.899523 \n",
      "(GPU: 0, epoch: 3, iters: 45888, time: 0.006) nll: 0.628834 \n",
      "(GPU: 0, epoch: 3, iters: 46688, time: 0.006) nll: 0.728980 \n",
      "(GPU: 0, epoch: 3, iters: 47488, time: 0.006) nll: 0.614327 \n",
      "(GPU: 0, epoch: 3, iters: 48288, time: 0.006) nll: 0.557532 \n",
      "(GPU: 0, epoch: 3, iters: 49088, time: 0.006) nll: 0.791496 \n",
      "(GPU: 0, epoch: 3, iters: 49888, time: 0.005) nll: 0.753560 \n",
      "(GPU: 0, epoch: 3, iters: 50688, time: 0.006) nll: 1.183598 \n",
      "(GPU: 0, epoch: 3, iters: 51488, time: 0.005) nll: 0.835887 \n",
      "(GPU: 0, epoch: 3, iters: 52288, time: 0.006) nll: 0.828481 \n",
      "(GPU: 0, epoch: 3, iters: 53088, time: 0.006) nll: 0.691086 \n",
      "(GPU: 0, epoch: 3, iters: 53888, time: 0.006) nll: 0.927831 \n",
      "(GPU: 0, epoch: 3, iters: 54688, time: 0.006) nll: 0.683499 \n",
      "(GPU: 0, epoch: 3, iters: 55488, time: 0.006) nll: 0.916879 \n",
      "(GPU: 0, epoch: 3, iters: 56288, time: 0.005) nll: 0.661545 \n",
      "(GPU: 0, epoch: 3, iters: 57088, time: 0.006) nll: 0.853419 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.005) nll: 0.670984 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.008) nll: 0.668875 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.008) nll: 0.740135 \n",
      "saving the latest model (epoch 3, total_steps 480000)\n",
      "(GPU: 0, epoch: 3, iters: 58688, time: 0.006) nll: 0.736269 \n",
      "(GPU: 0, epoch: 3, iters: 59488, time: 0.005) nll: 0.669749 \n",
      "(GPU: 0, epoch: 3, iters: 60288, time: 0.006) nll: 0.803300 \n",
      "(GPU: 0, epoch: 3, iters: 61088, time: 0.005) nll: 0.764621 \n",
      "(GPU: 0, epoch: 3, iters: 61888, time: 0.006) nll: 1.288120 \n",
      "(GPU: 0, epoch: 3, iters: 62688, time: 0.005) nll: 0.844441 \n",
      "(GPU: 0, epoch: 3, iters: 63488, time: 0.006) nll: 0.961914 \n",
      "(GPU: 0, epoch: 3, iters: 64288, time: 0.005) nll: 0.878341 \n",
      "(GPU: 0, epoch: 3, iters: 65088, time: 0.006) nll: 0.671466 \n",
      "(GPU: 0, epoch: 3, iters: 65888, time: 0.005) nll: 0.732870 \n",
      "(GPU: 0, epoch: 3, iters: 66688, time: 0.006) nll: 0.795082 \n",
      "(GPU: 0, epoch: 3, iters: 67488, time: 0.005) nll: 0.728073 \n",
      "(GPU: 0, epoch: 3, iters: 68288, time: 0.006) nll: 0.989238 \n",
      "(GPU: 0, epoch: 3, iters: 69088, time: 0.005) nll: 0.787286 \n",
      "(GPU: 0, epoch: 3, iters: 69888, time: 0.006) nll: 0.686154 \n",
      "(GPU: 0, epoch: 3, iters: 70688, time: 0.005) nll: 0.805136 \n",
      "(GPU: 0, epoch: 3, iters: 71488, time: 0.006) nll: 0.876625 \n",
      "(GPU: 0, epoch: 3, iters: 72288, time: 0.006) nll: 0.697676 \n",
      "(GPU: 0, epoch: 3, iters: 73088, time: 0.006) nll: 0.716782 \n",
      "(GPU: 0, epoch: 3, iters: 73888, time: 0.005) nll: 0.753658 \n",
      "(GPU: 0, epoch: 3, iters: 74688, time: 0.006) nll: 0.817722 \n",
      "(GPU: 0, epoch: 3, iters: 75488, time: 0.005) nll: 0.711073 \n",
      "(GPU: 0, epoch: 3, iters: 76288, time: 0.006) nll: 0.822753 \n",
      "(GPU: 0, epoch: 3, iters: 77088, time: 0.005) nll: 0.887194 \n",
      "(GPU: 0, epoch: 3, iters: 77888, time: 0.006) nll: 0.774706 \n",
      "saving the latest model (epoch 3, total_steps 500000)\n",
      "(GPU: 0, epoch: 3, iters: 78688, time: 0.005) nll: 0.935153 \n",
      "(GPU: 0, epoch: 3, iters: 79488, time: 0.006) nll: 0.835059 \n",
      "(GPU: 0, epoch: 3, iters: 80288, time: 0.006) nll: 0.838922 \n",
      "(GPU: 0, epoch: 3, iters: 81088, time: 0.006) nll: 1.423717 \n",
      "(GPU: 0, epoch: 3, iters: 81888, time: 0.005) nll: 0.631200 \n",
      "(GPU: 0, epoch: 3, iters: 82688, time: 0.006) nll: 0.780787 \n",
      "(GPU: 0, epoch: 3, iters: 83488, time: 0.005) nll: 0.828696 \n",
      "(GPU: 0, epoch: 3, iters: 84288, time: 0.006) nll: 0.652395 \n",
      "(GPU: 0, epoch: 3, iters: 85088, time: 0.005) nll: 0.898691 \n",
      "(GPU: 0, epoch: 3, iters: 85888, time: 0.006) nll: 0.611322 \n",
      "(GPU: 0, epoch: 3, iters: 86688, time: 0.005) nll: 0.799799 \n",
      "(GPU: 0, epoch: 3, iters: 87488, time: 0.006) nll: 0.706014 \n",
      "(GPU: 0, epoch: 3, iters: 88288, time: 0.005) nll: 0.650050 \n",
      "(GPU: 0, epoch: 3, iters: 89088, time: 0.006) nll: 0.664402 \n",
      "(GPU: 0, epoch: 3, iters: 89888, time: 0.005) nll: 0.574084 \n",
      "(GPU: 0, epoch: 3, iters: 90688, time: 0.006) nll: 1.277065 \n",
      "(GPU: 0, epoch: 3, iters: 91488, time: 0.006) nll: 0.851373 \n",
      "(GPU: 0, epoch: 3, iters: 92288, time: 0.006) nll: 0.727889 \n",
      "(GPU: 0, epoch: 3, iters: 93088, time: 0.005) nll: 0.780695 \n",
      "(GPU: 0, epoch: 3, iters: 93888, time: 0.006) nll: 0.902555 \n",
      "(GPU: 0, epoch: 3, iters: 94688, time: 0.005) nll: 0.506278 \n",
      "(GPU: 0, epoch: 3, iters: 95488, time: 0.006) nll: 0.659539 \n",
      "(GPU: 0, epoch: 3, iters: 96288, time: 0.005) nll: 1.040140 \n",
      "(GPU: 0, epoch: 3, iters: 97088, time: 0.006) nll: 0.419097 \n",
      "(GPU: 0, epoch: 3, iters: 97888, time: 0.006) nll: 0.858869 \n",
      "saving the latest model (epoch 3, total_steps 520000)\n",
      "(GPU: 0, epoch: 3, iters: 98688, time: 0.006) nll: 1.076232 \n",
      "(GPU: 0, epoch: 3, iters: 99488, time: 0.006) nll: 0.781659 \n",
      "(GPU: 0, epoch: 3, iters: 100288, time: 0.006) nll: 0.828940 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 101088, time: 0.005) nll: 1.356017 \n",
      "(GPU: 0, epoch: 3, iters: 101888, time: 0.006) nll: 0.840876 \n",
      "(GPU: 0, epoch: 3, iters: 102688, time: 0.005) nll: 0.743940 \n",
      "(GPU: 0, epoch: 3, iters: 103488, time: 0.006) nll: 0.912532 \n",
      "(GPU: 0, epoch: 3, iters: 104288, time: 0.005) nll: 0.920466 \n",
      "(GPU: 0, epoch: 3, iters: 105088, time: 0.006) nll: 0.745006 \n",
      "(GPU: 0, epoch: 3, iters: 105888, time: 0.005) nll: 0.687837 \n",
      "(GPU: 0, epoch: 3, iters: 106688, time: 0.006) nll: 0.991304 \n",
      "(GPU: 0, epoch: 3, iters: 107488, time: 0.005) nll: 0.617116 \n",
      "(GPU: 0, epoch: 3, iters: 108288, time: 0.006) nll: 0.781118 \n",
      "(GPU: 0, epoch: 3, iters: 109088, time: 0.005) nll: 0.791133 \n",
      "(GPU: 0, epoch: 3, iters: 109888, time: 0.006) nll: 0.943910 \n",
      "(GPU: 0, epoch: 3, iters: 110688, time: 0.005) nll: 1.049577 \n",
      "(GPU: 0, epoch: 3, iters: 111488, time: 0.006) nll: 0.870958 \n",
      "(GPU: 0, epoch: 3, iters: 112288, time: 0.005) nll: 0.653072 \n",
      "(GPU: 0, epoch: 3, iters: 113088, time: 0.006) nll: 0.742641 \n",
      "(GPU: 0, epoch: 3, iters: 113888, time: 0.005) nll: 0.863509 \n",
      "(GPU: 0, epoch: 3, iters: 114688, time: 0.006) nll: 0.900781 \n",
      "(GPU: 0, epoch: 3, iters: 115488, time: 0.005) nll: 0.790643 \n",
      "(GPU: 0, epoch: 3, iters: 116288, time: 0.006) nll: 0.735786 \n",
      "(GPU: 0, epoch: 3, iters: 117088, time: 0.005) nll: 0.973035 \n",
      "(GPU: 0, epoch: 3, iters: 117888, time: 0.006) nll: 0.789623 \n",
      "saving the latest model (epoch 3, total_steps 540000)\n",
      "(GPU: 0, epoch: 3, iters: 118688, time: 0.006) nll: 0.931301 \n",
      "(GPU: 0, epoch: 3, iters: 119488, time: 0.006) nll: 0.839283 \n",
      "(GPU: 0, epoch: 3, iters: 120288, time: 0.006) nll: 0.700554 \n",
      "(GPU: 0, epoch: 3, iters: 121088, time: 0.006) nll: 0.633865 \n",
      "(GPU: 0, epoch: 3, iters: 121888, time: 0.005) nll: 0.757141 \n",
      "(GPU: 0, epoch: 3, iters: 122688, time: 0.006) nll: 0.874257 \n",
      "(GPU: 0, epoch: 3, iters: 123488, time: 0.005) nll: 0.760424 \n",
      "(GPU: 0, epoch: 3, iters: 124288, time: 0.006) nll: 0.674301 \n",
      "(GPU: 0, epoch: 3, iters: 125088, time: 0.006) nll: 0.704795 \n",
      "(GPU: 0, epoch: 3, iters: 125888, time: 0.006) nll: 0.751092 \n",
      "(GPU: 0, epoch: 3, iters: 126688, time: 0.006) nll: 0.908359 \n",
      "(GPU: 0, epoch: 3, iters: 127488, time: 0.006) nll: 0.931121 \n",
      "(GPU: 0, epoch: 3, iters: 128288, time: 0.005) nll: 0.693245 \n",
      "(GPU: 0, epoch: 3, iters: 129088, time: 0.006) nll: 0.992429 \n",
      "(GPU: 0, epoch: 3, iters: 129888, time: 0.005) nll: 0.758683 \n",
      "(GPU: 0, epoch: 3, iters: 130688, time: 0.006) nll: 0.874559 \n",
      "(GPU: 0, epoch: 3, iters: 131488, time: 0.005) nll: 0.875271 \n",
      "(GPU: 0, epoch: 3, iters: 132288, time: 0.006) nll: 0.906013 \n",
      "(GPU: 0, epoch: 3, iters: 133088, time: 0.005) nll: 0.834478 \n",
      "(GPU: 0, epoch: 3, iters: 133888, time: 0.006) nll: 0.781089 \n",
      "(GPU: 0, epoch: 3, iters: 134688, time: 0.005) nll: 0.888123 \n",
      "(GPU: 0, epoch: 3, iters: 135488, time: 0.006) nll: 0.791042 \n",
      "(GPU: 0, epoch: 3, iters: 136288, time: 0.005) nll: 0.768993 \n",
      "(GPU: 0, epoch: 3, iters: 137088, time: 0.006) nll: 0.849117 \n",
      "(GPU: 0, epoch: 3, iters: 137888, time: 0.005) nll: 0.703841 \n",
      "saving the latest model (epoch 3, total_steps 560000)\n",
      "(GPU: 0, epoch: 3, iters: 138688, time: 0.006) nll: 0.687340 \n",
      "(GPU: 0, epoch: 3, iters: 139488, time: 0.005) nll: 0.759135 \n",
      "(GPU: 0, epoch: 3, iters: 140288, time: 0.006) nll: 0.919464 \n",
      "saving the model at the end of epoch 3, iters 562816\n",
      "([test] GPU: 0, epoch: 3) \n",
      "OrderedDict()\n",
      "[*] End of epoch 3 / 25 \t Time Taken: 839 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000400\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3161/4397 [09:59<03:48,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 32, time: 0.003) nll: 0.939385 \n",
      "(GPU: 0, epoch: 4, iters: 32, time: 0.003) nll: 0.899796 \n",
      "(GPU: 0, epoch: 4, iters: 384, time: 0.006) nll: 0.799338 \n",
      "(GPU: 0, epoch: 4, iters: 1184, time: 0.006) nll: 0.861978 \n",
      "(GPU: 0, epoch: 4, iters: 1984, time: 0.006) nll: 0.789756 \n",
      "(GPU: 0, epoch: 4, iters: 2784, time: 0.005) nll: 0.871197 \n",
      "(GPU: 0, epoch: 4, iters: 3584, time: 0.006) nll: 0.716567 \n",
      "(GPU: 0, epoch: 4, iters: 4384, time: 0.005) nll: 0.565750 \n",
      "(GPU: 0, epoch: 4, iters: 5184, time: 0.006) nll: 0.799074 \n",
      "(GPU: 0, epoch: 4, iters: 5984, time: 0.006) nll: 0.934579 \n",
      "(GPU: 0, epoch: 4, iters: 6784, time: 0.006) nll: 0.790937 \n",
      "(GPU: 0, epoch: 4, iters: 7584, time: 0.005) nll: 0.374611 \n",
      "(GPU: 0, epoch: 4, iters: 8384, time: 0.006) nll: 1.148612 \n",
      "(GPU: 0, epoch: 4, iters: 9184, time: 0.005) nll: 0.880304 \n",
      "(GPU: 0, epoch: 4, iters: 9984, time: 0.006) nll: 0.889548 \n",
      "(GPU: 0, epoch: 4, iters: 10784, time: 0.005) nll: 0.781094 \n",
      "(GPU: 0, epoch: 4, iters: 11584, time: 0.006) nll: 0.666553 \n",
      "(GPU: 0, epoch: 4, iters: 12384, time: 0.005) nll: 0.853735 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.006) nll: 0.650641 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.009) nll: 0.647893 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.009) nll: 0.656607 \n",
      "(GPU: 0, epoch: 4, iters: 13984, time: 0.005) nll: 0.821709 \n",
      "(GPU: 0, epoch: 4, iters: 14784, time: 0.006) nll: 0.562271 \n",
      "(GPU: 0, epoch: 4, iters: 15584, time: 0.005) nll: 0.800268 \n",
      "(GPU: 0, epoch: 4, iters: 16384, time: 0.006) nll: 0.604011 \n",
      "(GPU: 0, epoch: 4, iters: 17184, time: 0.005) nll: 0.728942 \n",
      "saving the latest model (epoch 4, total_steps 580000)\n",
      "(GPU: 0, epoch: 4, iters: 17984, time: 0.006) nll: 0.530372 \n",
      "(GPU: 0, epoch: 4, iters: 18784, time: 0.005) nll: 0.904324 \n",
      "(GPU: 0, epoch: 4, iters: 19584, time: 0.006) nll: 0.741930 \n",
      "(GPU: 0, epoch: 4, iters: 20384, time: 0.005) nll: 0.583772 \n",
      "(GPU: 0, epoch: 4, iters: 21184, time: 0.006) nll: 0.503418 \n",
      "(GPU: 0, epoch: 4, iters: 21984, time: 0.005) nll: 0.785436 \n",
      "(GPU: 0, epoch: 4, iters: 22784, time: 0.006) nll: 0.802611 \n",
      "(GPU: 0, epoch: 4, iters: 23584, time: 0.006) nll: 0.813020 \n",
      "(GPU: 0, epoch: 4, iters: 24384, time: 0.006) nll: 0.782929 \n",
      "(GPU: 0, epoch: 4, iters: 25184, time: 0.005) nll: 0.649327 \n",
      "(GPU: 0, epoch: 4, iters: 25984, time: 0.006) nll: 0.610283 \n",
      "(GPU: 0, epoch: 4, iters: 26784, time: 0.005) nll: 1.043893 \n",
      "(GPU: 0, epoch: 4, iters: 27584, time: 0.006) nll: 0.865089 \n",
      "(GPU: 0, epoch: 4, iters: 28384, time: 0.006) nll: 0.867868 \n",
      "(GPU: 0, epoch: 4, iters: 29184, time: 0.006) nll: 1.090743 \n",
      "(GPU: 0, epoch: 4, iters: 29984, time: 0.005) nll: 1.042829 \n",
      "(GPU: 0, epoch: 4, iters: 30784, time: 0.006) nll: 0.583311 \n",
      "(GPU: 0, epoch: 4, iters: 31584, time: 0.005) nll: 0.887925 \n",
      "(GPU: 0, epoch: 4, iters: 32384, time: 0.006) nll: 0.836614 \n",
      "(GPU: 0, epoch: 4, iters: 33184, time: 0.006) nll: 0.876153 \n",
      "(GPU: 0, epoch: 4, iters: 33984, time: 0.006) nll: 0.683988 \n",
      "(GPU: 0, epoch: 4, iters: 34784, time: 0.005) nll: 0.734541 \n",
      "(GPU: 0, epoch: 4, iters: 35584, time: 0.006) nll: 0.740267 \n",
      "(GPU: 0, epoch: 4, iters: 36384, time: 0.005) nll: 1.028070 \n",
      "(GPU: 0, epoch: 4, iters: 37184, time: 0.006) nll: 1.095386 \n",
      "saving the latest model (epoch 4, total_steps 600000)\n",
      "(GPU: 0, epoch: 4, iters: 37984, time: 0.005) nll: 0.895405 \n",
      "(GPU: 0, epoch: 4, iters: 38784, time: 0.006) nll: 0.705304 \n",
      "(GPU: 0, epoch: 4, iters: 39584, time: 0.005) nll: 0.806468 \n",
      "(GPU: 0, epoch: 4, iters: 40384, time: 0.006) nll: 0.737964 \n",
      "(GPU: 0, epoch: 4, iters: 41184, time: 0.005) nll: 1.021870 \n",
      "(GPU: 0, epoch: 4, iters: 41984, time: 0.006) nll: 0.647778 \n",
      "(GPU: 0, epoch: 4, iters: 42784, time: 0.005) nll: 0.728183 \n",
      "(GPU: 0, epoch: 4, iters: 43584, time: 0.006) nll: 0.755651 \n",
      "(GPU: 0, epoch: 4, iters: 44384, time: 0.006) nll: 0.524706 \n",
      "(GPU: 0, epoch: 4, iters: 45184, time: 0.006) nll: 0.722150 \n",
      "(GPU: 0, epoch: 4, iters: 45984, time: 0.005) nll: 0.648322 \n",
      "(GPU: 0, epoch: 4, iters: 46784, time: 0.006) nll: 0.696933 \n",
      "(GPU: 0, epoch: 4, iters: 47584, time: 0.005) nll: 0.920700 \n",
      "(GPU: 0, epoch: 4, iters: 48384, time: 0.006) nll: 1.055455 \n",
      "(GPU: 0, epoch: 4, iters: 49184, time: 0.005) nll: 0.884186 \n",
      "(GPU: 0, epoch: 4, iters: 49984, time: 0.006) nll: 0.829999 \n",
      "(GPU: 0, epoch: 4, iters: 50784, time: 0.005) nll: 0.929597 \n",
      "(GPU: 0, epoch: 4, iters: 51584, time: 0.006) nll: 0.757022 \n",
      "(GPU: 0, epoch: 4, iters: 52384, time: 0.005) nll: 0.825888 \n",
      "(GPU: 0, epoch: 4, iters: 53184, time: 0.006) nll: 0.709841 \n",
      "(GPU: 0, epoch: 4, iters: 53984, time: 0.006) nll: 0.751472 \n",
      "(GPU: 0, epoch: 4, iters: 54784, time: 0.006) nll: 0.693249 \n",
      "(GPU: 0, epoch: 4, iters: 55584, time: 0.005) nll: 0.590955 \n",
      "(GPU: 0, epoch: 4, iters: 56384, time: 0.006) nll: 0.925805 \n",
      "(GPU: 0, epoch: 4, iters: 57184, time: 0.005) nll: 0.734850 \n",
      "saving the latest model (epoch 4, total_steps 620000)\n",
      "(GPU: 0, epoch: 4, iters: 57984, time: 0.006) nll: 0.597375 \n",
      "(GPU: 0, epoch: 4, iters: 58784, time: 0.005) nll: 0.664380 \n",
      "(GPU: 0, epoch: 4, iters: 59584, time: 0.006) nll: 0.741784 \n",
      "(GPU: 0, epoch: 4, iters: 60384, time: 0.005) nll: 0.713160 \n",
      "(GPU: 0, epoch: 4, iters: 61184, time: 0.006) nll: 0.747777 \n",
      "(GPU: 0, epoch: 4, iters: 61984, time: 0.005) nll: 0.600987 \n",
      "(GPU: 0, epoch: 4, iters: 62784, time: 0.006) nll: 0.881549 \n",
      "(GPU: 0, epoch: 4, iters: 63584, time: 0.005) nll: 0.852425 \n",
      "(GPU: 0, epoch: 4, iters: 64384, time: 0.006) nll: 0.887640 \n",
      "(GPU: 0, epoch: 4, iters: 65184, time: 0.005) nll: 0.677674 \n",
      "(GPU: 0, epoch: 4, iters: 65984, time: 0.006) nll: 0.816926 \n",
      "(GPU: 0, epoch: 4, iters: 66784, time: 0.005) nll: 0.732586 \n",
      "(GPU: 0, epoch: 4, iters: 67584, time: 0.006) nll: 0.830544 \n",
      "(GPU: 0, epoch: 4, iters: 68384, time: 0.005) nll: 0.955671 \n",
      "(GPU: 0, epoch: 4, iters: 69184, time: 0.006) nll: 0.942570 \n",
      "(GPU: 0, epoch: 4, iters: 69984, time: 0.005) nll: 0.597357 \n",
      "(GPU: 0, epoch: 4, iters: 70784, time: 0.006) nll: 1.247344 \n",
      "(GPU: 0, epoch: 4, iters: 71584, time: 0.005) nll: 0.803595 \n",
      "(GPU: 0, epoch: 4, iters: 72384, time: 0.006) nll: 0.736867 \n",
      "(GPU: 0, epoch: 4, iters: 73184, time: 0.005) nll: 1.122811 \n",
      "(GPU: 0, epoch: 4, iters: 73984, time: 0.006) nll: 0.720539 \n",
      "(GPU: 0, epoch: 4, iters: 74784, time: 0.005) nll: 0.656361 \n",
      "(GPU: 0, epoch: 4, iters: 75584, time: 0.006) nll: 0.632601 \n",
      "(GPU: 0, epoch: 4, iters: 76384, time: 0.005) nll: 0.993227 \n",
      "(GPU: 0, epoch: 4, iters: 77184, time: 0.006) nll: 0.877182 \n",
      "saving the latest model (epoch 4, total_steps 640000)\n",
      "(GPU: 0, epoch: 4, iters: 77984, time: 0.005) nll: 0.761990 \n",
      "(GPU: 0, epoch: 4, iters: 78784, time: 0.006) nll: 0.719206 \n",
      "(GPU: 0, epoch: 4, iters: 79584, time: 0.005) nll: 0.704436 \n",
      "(GPU: 0, epoch: 4, iters: 80384, time: 0.006) nll: 0.920145 \n",
      "(GPU: 0, epoch: 4, iters: 81184, time: 0.006) nll: 0.691306 \n",
      "(GPU: 0, epoch: 4, iters: 81984, time: 0.006) nll: 0.760447 \n",
      "(GPU: 0, epoch: 4, iters: 82784, time: 0.005) nll: 0.728825 \n",
      "(GPU: 0, epoch: 4, iters: 83584, time: 0.006) nll: 0.700730 \n",
      "(GPU: 0, epoch: 4, iters: 84384, time: 0.005) nll: 0.774007 \n",
      "(GPU: 0, epoch: 4, iters: 85184, time: 0.006) nll: 0.782312 \n",
      "(GPU: 0, epoch: 4, iters: 85984, time: 0.005) nll: 0.680165 \n",
      "(GPU: 0, epoch: 4, iters: 86784, time: 0.006) nll: 0.830545 \n",
      "(GPU: 0, epoch: 4, iters: 87584, time: 0.006) nll: 0.850993 \n",
      "(GPU: 0, epoch: 4, iters: 88384, time: 0.006) nll: 0.788350 \n",
      "(GPU: 0, epoch: 4, iters: 89184, time: 0.005) nll: 0.969477 \n",
      "(GPU: 0, epoch: 4, iters: 89984, time: 0.006) nll: 0.734683 \n",
      "(GPU: 0, epoch: 4, iters: 90784, time: 0.005) nll: 0.685827 \n",
      "(GPU: 0, epoch: 4, iters: 91584, time: 0.006) nll: 0.661049 \n",
      "(GPU: 0, epoch: 4, iters: 92384, time: 0.005) nll: 0.813756 \n",
      "(GPU: 0, epoch: 4, iters: 93184, time: 0.006) nll: 0.691371 \n",
      "(GPU: 0, epoch: 4, iters: 93984, time: 0.005) nll: 0.900468 \n",
      "(GPU: 0, epoch: 4, iters: 94784, time: 0.006) nll: 0.627064 \n",
      "(GPU: 0, epoch: 4, iters: 95584, time: 0.005) nll: 0.873238 \n",
      "(GPU: 0, epoch: 4, iters: 96384, time: 0.006) nll: 0.843245 \n",
      "(GPU: 0, epoch: 4, iters: 97184, time: 0.005) nll: 0.783372 \n",
      "saving the latest model (epoch 4, total_steps 660000)\n",
      "(GPU: 0, epoch: 4, iters: 97984, time: 0.006) nll: 0.904649 \n",
      "(GPU: 0, epoch: 4, iters: 98784, time: 0.005) nll: 0.628559 \n",
      "(GPU: 0, epoch: 4, iters: 99584, time: 0.006) nll: 0.807965 \n",
      "(GPU: 0, epoch: 4, iters: 100384, time: 0.005) nll: 0.416968 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 101184, time: 0.006) nll: 1.090470 \n",
      "(GPU: 0, epoch: 4, iters: 101984, time: 0.005) nll: 0.849999 \n",
      "(GPU: 0, epoch: 4, iters: 102784, time: 0.006) nll: 1.068174 \n",
      "(GPU: 0, epoch: 4, iters: 103584, time: 0.005) nll: 0.897369 \n",
      "(GPU: 0, epoch: 4, iters: 104384, time: 0.006) nll: 0.728615 \n",
      "(GPU: 0, epoch: 4, iters: 105184, time: 0.005) nll: 0.799533 \n",
      "(GPU: 0, epoch: 4, iters: 105984, time: 0.006) nll: 0.804079 \n",
      "(GPU: 0, epoch: 4, iters: 106784, time: 0.005) nll: 0.904303 \n",
      "(GPU: 0, epoch: 4, iters: 107584, time: 0.006) nll: 0.635216 \n",
      "(GPU: 0, epoch: 4, iters: 108384, time: 0.005) nll: 0.824712 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.006) nll: 0.730547 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.009) nll: 0.726839 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.009) nll: 0.891854 \n",
      "(GPU: 0, epoch: 4, iters: 109984, time: 0.006) nll: 0.858310 \n",
      "(GPU: 0, epoch: 4, iters: 110784, time: 0.006) nll: 0.595536 \n",
      "(GPU: 0, epoch: 4, iters: 111584, time: 0.006) nll: 1.027279 \n",
      "(GPU: 0, epoch: 4, iters: 112384, time: 0.006) nll: 0.593375 \n",
      "(GPU: 0, epoch: 4, iters: 113184, time: 0.005) nll: 0.737689 \n",
      "(GPU: 0, epoch: 4, iters: 113984, time: 0.006) nll: 0.714330 \n",
      "(GPU: 0, epoch: 4, iters: 114784, time: 0.005) nll: 0.700742 \n",
      "(GPU: 0, epoch: 4, iters: 115584, time: 0.006) nll: 0.879746 \n",
      "(GPU: 0, epoch: 4, iters: 116384, time: 0.005) nll: 0.774312 \n",
      "(GPU: 0, epoch: 4, iters: 117184, time: 0.006) nll: 1.172252 \n",
      "saving the latest model (epoch 4, total_steps 680000)\n",
      "(GPU: 0, epoch: 4, iters: 117984, time: 0.005) nll: 0.982700 \n",
      "(GPU: 0, epoch: 4, iters: 118784, time: 0.006) nll: 0.811911 \n",
      "(GPU: 0, epoch: 4, iters: 119584, time: 0.005) nll: 0.767444 \n",
      "(GPU: 0, epoch: 4, iters: 120384, time: 0.006) nll: 0.595969 \n",
      "(GPU: 0, epoch: 4, iters: 121184, time: 0.006) nll: 1.024104 \n",
      "(GPU: 0, epoch: 4, iters: 121984, time: 0.006) nll: 0.854072 \n",
      "(GPU: 0, epoch: 4, iters: 122784, time: 0.005) nll: 0.872782 \n",
      "(GPU: 0, epoch: 4, iters: 123584, time: 0.006) nll: 0.974777 \n",
      "(GPU: 0, epoch: 4, iters: 124384, time: 0.005) nll: 0.708761 \n",
      "(GPU: 0, epoch: 4, iters: 125184, time: 0.006) nll: 0.837453 \n",
      "(GPU: 0, epoch: 4, iters: 125984, time: 0.005) nll: 0.699312 \n",
      "(GPU: 0, epoch: 4, iters: 126784, time: 0.006) nll: 1.060528 \n",
      "(GPU: 0, epoch: 4, iters: 127584, time: 0.005) nll: 0.944830 \n",
      "(GPU: 0, epoch: 4, iters: 128384, time: 0.006) nll: 0.697536 \n",
      "(GPU: 0, epoch: 4, iters: 129184, time: 0.005) nll: 0.527698 \n",
      "(GPU: 0, epoch: 4, iters: 129984, time: 0.006) nll: 0.922233 \n",
      "(GPU: 0, epoch: 4, iters: 130784, time: 0.005) nll: 1.181766 \n",
      "(GPU: 0, epoch: 4, iters: 131584, time: 0.006) nll: 0.853237 \n",
      "(GPU: 0, epoch: 4, iters: 132384, time: 0.005) nll: 0.687087 \n",
      "(GPU: 0, epoch: 4, iters: 133184, time: 0.006) nll: 0.722906 \n",
      "(GPU: 0, epoch: 4, iters: 133984, time: 0.005) nll: 0.756143 \n",
      "(GPU: 0, epoch: 4, iters: 134784, time: 0.006) nll: 0.817023 \n",
      "(GPU: 0, epoch: 4, iters: 135584, time: 0.005) nll: 0.789672 \n",
      "(GPU: 0, epoch: 4, iters: 136384, time: 0.006) nll: 0.679346 \n",
      "(GPU: 0, epoch: 4, iters: 137184, time: 0.005) nll: 0.883709 \n",
      "saving the latest model (epoch 4, total_steps 700000)\n",
      "(GPU: 0, epoch: 4, iters: 137984, time: 0.006) nll: 0.853640 \n",
      "(GPU: 0, epoch: 4, iters: 138784, time: 0.005) nll: 1.153448 \n",
      "(GPU: 0, epoch: 4, iters: 139584, time: 0.006) nll: 0.762319 \n",
      "(GPU: 0, epoch: 4, iters: 140384, time: 0.005) nll: 0.822218 \n",
      "[*] End of epoch 4 / 25 \t Time Taken: 835 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000500\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3164/4397 [10:00<03:47,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 32, time: 0.003) nll: 0.701356 \n",
      "(GPU: 0, epoch: 5, iters: 32, time: 0.003) nll: 0.637667 \n",
      "(GPU: 0, epoch: 5, iters: 480, time: 0.005) nll: 0.646924 \n",
      "(GPU: 0, epoch: 5, iters: 1280, time: 0.006) nll: 0.932068 \n",
      "(GPU: 0, epoch: 5, iters: 2080, time: 0.005) nll: 0.813870 \n",
      "(GPU: 0, epoch: 5, iters: 2880, time: 0.006) nll: 0.702610 \n",
      "(GPU: 0, epoch: 5, iters: 3680, time: 0.005) nll: 0.660409 \n",
      "(GPU: 0, epoch: 5, iters: 4480, time: 0.006) nll: 0.803203 \n",
      "(GPU: 0, epoch: 5, iters: 5280, time: 0.005) nll: 0.795093 \n",
      "(GPU: 0, epoch: 5, iters: 6080, time: 0.006) nll: 0.869928 \n",
      "(GPU: 0, epoch: 5, iters: 6880, time: 0.006) nll: 0.799165 \n",
      "(GPU: 0, epoch: 5, iters: 7680, time: 0.006) nll: 0.912636 \n",
      "(GPU: 0, epoch: 5, iters: 8480, time: 0.005) nll: 0.866733 \n",
      "(GPU: 0, epoch: 5, iters: 9280, time: 0.006) nll: 0.849631 \n",
      "(GPU: 0, epoch: 5, iters: 10080, time: 0.005) nll: 0.981450 \n",
      "(GPU: 0, epoch: 5, iters: 10880, time: 0.006) nll: 1.043381 \n",
      "(GPU: 0, epoch: 5, iters: 11680, time: 0.005) nll: 0.871658 \n",
      "(GPU: 0, epoch: 5, iters: 12480, time: 0.006) nll: 0.750369 \n",
      "(GPU: 0, epoch: 5, iters: 13280, time: 0.006) nll: 0.853256 \n",
      "(GPU: 0, epoch: 5, iters: 14080, time: 0.006) nll: 0.947319 \n",
      "(GPU: 0, epoch: 5, iters: 14880, time: 0.005) nll: 0.865180 \n",
      "(GPU: 0, epoch: 5, iters: 15680, time: 0.006) nll: 0.658646 \n",
      "(GPU: 0, epoch: 5, iters: 16480, time: 0.005) nll: 0.770601 \n",
      "saving the latest model (epoch 5, total_steps 720000)\n",
      "(GPU: 0, epoch: 5, iters: 17280, time: 0.006) nll: 0.602943 \n",
      "(GPU: 0, epoch: 5, iters: 18080, time: 0.005) nll: 0.789485 \n",
      "(GPU: 0, epoch: 5, iters: 18880, time: 0.006) nll: 0.802894 \n",
      "(GPU: 0, epoch: 5, iters: 19680, time: 0.005) nll: 0.756240 \n",
      "(GPU: 0, epoch: 5, iters: 20480, time: 0.006) nll: 0.983710 \n",
      "(GPU: 0, epoch: 5, iters: 21280, time: 0.005) nll: 0.596351 \n",
      "(GPU: 0, epoch: 5, iters: 22080, time: 0.006) nll: 0.833917 \n",
      "(GPU: 0, epoch: 5, iters: 22880, time: 0.005) nll: 0.906239 \n",
      "(GPU: 0, epoch: 5, iters: 23680, time: 0.006) nll: 0.750661 \n",
      "(GPU: 0, epoch: 5, iters: 24480, time: 0.006) nll: 0.704441 \n",
      "(GPU: 0, epoch: 5, iters: 25280, time: 0.006) nll: 0.575097 \n",
      "(GPU: 0, epoch: 5, iters: 26080, time: 0.005) nll: 0.499646 \n",
      "(GPU: 0, epoch: 5, iters: 26880, time: 0.006) nll: 0.919814 \n",
      "(GPU: 0, epoch: 5, iters: 27680, time: 0.005) nll: 0.573127 \n",
      "(GPU: 0, epoch: 5, iters: 28480, time: 0.006) nll: 0.502719 \n",
      "(GPU: 0, epoch: 5, iters: 29280, time: 0.005) nll: 0.844657 \n",
      "(GPU: 0, epoch: 5, iters: 30080, time: 0.006) nll: 0.682749 \n",
      "(GPU: 0, epoch: 5, iters: 30880, time: 0.006) nll: 0.735510 \n",
      "(GPU: 0, epoch: 5, iters: 31680, time: 0.006) nll: 0.785334 \n",
      "(GPU: 0, epoch: 5, iters: 32480, time: 0.005) nll: 0.677990 \n",
      "(GPU: 0, epoch: 5, iters: 33280, time: 0.006) nll: 1.010424 \n",
      "(GPU: 0, epoch: 5, iters: 34080, time: 0.006) nll: 1.075202 \n",
      "(GPU: 0, epoch: 5, iters: 34880, time: 0.006) nll: 0.760877 \n",
      "(GPU: 0, epoch: 5, iters: 35680, time: 0.006) nll: 0.642655 \n",
      "(GPU: 0, epoch: 5, iters: 36480, time: 0.006) nll: 0.992228 \n",
      "saving the latest model (epoch 5, total_steps 740000)\n",
      "(GPU: 0, epoch: 5, iters: 37280, time: 0.006) nll: 0.919972 \n",
      "(GPU: 0, epoch: 5, iters: 38080, time: 0.006) nll: 0.698860 \n",
      "(GPU: 0, epoch: 5, iters: 38880, time: 0.005) nll: 0.786251 \n",
      "(GPU: 0, epoch: 5, iters: 39680, time: 0.006) nll: 0.780439 \n",
      "(GPU: 0, epoch: 5, iters: 40480, time: 0.005) nll: 0.801356 \n",
      "(GPU: 0, epoch: 5, iters: 41280, time: 0.006) nll: 1.039456 \n",
      "(GPU: 0, epoch: 5, iters: 42080, time: 0.006) nll: 0.552387 \n",
      "(GPU: 0, epoch: 5, iters: 42880, time: 0.006) nll: 0.426032 \n",
      "(GPU: 0, epoch: 5, iters: 43680, time: 0.006) nll: 0.787851 \n",
      "(GPU: 0, epoch: 5, iters: 44480, time: 0.006) nll: 0.981772 \n",
      "(GPU: 0, epoch: 5, iters: 45280, time: 0.006) nll: 0.639802 \n",
      "(GPU: 0, epoch: 5, iters: 46080, time: 0.006) nll: 0.720890 \n",
      "(GPU: 0, epoch: 5, iters: 46880, time: 0.005) nll: 0.964089 \n",
      "(GPU: 0, epoch: 5, iters: 47680, time: 0.006) nll: 1.007287 \n",
      "(GPU: 0, epoch: 5, iters: 48480, time: 0.005) nll: 0.594976 \n",
      "(GPU: 0, epoch: 5, iters: 49280, time: 0.006) nll: 0.904035 \n",
      "(GPU: 0, epoch: 5, iters: 50080, time: 0.005) nll: 0.681752 \n",
      "(GPU: 0, epoch: 5, iters: 50880, time: 0.006) nll: 0.990410 \n",
      "(GPU: 0, epoch: 5, iters: 51680, time: 0.005) nll: 0.828024 \n",
      "(GPU: 0, epoch: 5, iters: 52480, time: 0.006) nll: 0.872921 \n",
      "(GPU: 0, epoch: 5, iters: 53280, time: 0.005) nll: 0.756614 \n",
      "(GPU: 0, epoch: 5, iters: 54080, time: 0.006) nll: 0.606571 \n",
      "(GPU: 0, epoch: 5, iters: 54880, time: 0.005) nll: 0.680037 \n",
      "(GPU: 0, epoch: 5, iters: 55680, time: 0.006) nll: 0.548047 \n",
      "(GPU: 0, epoch: 5, iters: 56480, time: 0.005) nll: 1.130451 \n",
      "saving the latest model (epoch 5, total_steps 760000)\n",
      "(GPU: 0, epoch: 5, iters: 57280, time: 0.006) nll: 0.636394 \n",
      "(GPU: 0, epoch: 5, iters: 58080, time: 0.005) nll: 0.883077 \n",
      "(GPU: 0, epoch: 5, iters: 58880, time: 0.006) nll: 0.740304 \n",
      "(GPU: 0, epoch: 5, iters: 59680, time: 0.005) nll: 0.731320 \n",
      "(GPU: 0, epoch: 5, iters: 60480, time: 0.006) nll: 0.597700 \n",
      "(GPU: 0, epoch: 5, iters: 61280, time: 0.005) nll: 0.971181 \n",
      "(GPU: 0, epoch: 5, iters: 62080, time: 0.006) nll: 0.536726 \n",
      "(GPU: 0, epoch: 5, iters: 62880, time: 0.005) nll: 0.493523 \n",
      "(GPU: 0, epoch: 5, iters: 63680, time: 0.006) nll: 0.838316 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.005) nll: 0.565136 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.008) nll: 0.563903 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.008) nll: 0.695384 \n",
      "(GPU: 0, epoch: 5, iters: 65280, time: 0.006) nll: 0.824286 \n",
      "(GPU: 0, epoch: 5, iters: 66080, time: 0.006) nll: 0.834861 \n",
      "(GPU: 0, epoch: 5, iters: 66880, time: 0.006) nll: 0.729184 \n",
      "(GPU: 0, epoch: 5, iters: 67680, time: 0.005) nll: 1.001468 \n",
      "(GPU: 0, epoch: 5, iters: 68480, time: 0.006) nll: 0.723593 \n",
      "(GPU: 0, epoch: 5, iters: 69280, time: 0.005) nll: 0.704129 \n",
      "(GPU: 0, epoch: 5, iters: 70080, time: 0.006) nll: 0.653232 \n",
      "(GPU: 0, epoch: 5, iters: 70880, time: 0.005) nll: 0.605119 \n",
      "(GPU: 0, epoch: 5, iters: 71680, time: 0.006) nll: 0.866543 \n",
      "(GPU: 0, epoch: 5, iters: 72480, time: 0.005) nll: 0.573337 \n",
      "(GPU: 0, epoch: 5, iters: 73280, time: 0.006) nll: 1.213853 \n",
      "(GPU: 0, epoch: 5, iters: 74080, time: 0.005) nll: 0.915563 \n",
      "(GPU: 0, epoch: 5, iters: 74880, time: 0.006) nll: 0.907222 \n",
      "(GPU: 0, epoch: 5, iters: 75680, time: 0.005) nll: 0.977011 \n",
      "(GPU: 0, epoch: 5, iters: 76480, time: 0.006) nll: 0.644913 \n",
      "saving the latest model (epoch 5, total_steps 780000)\n",
      "(GPU: 0, epoch: 5, iters: 77280, time: 0.005) nll: 0.929658 \n",
      "(GPU: 0, epoch: 5, iters: 78080, time: 0.006) nll: 0.669667 \n",
      "(GPU: 0, epoch: 5, iters: 78880, time: 0.005) nll: 0.697950 \n",
      "(GPU: 0, epoch: 5, iters: 79680, time: 0.006) nll: 0.666830 \n",
      "(GPU: 0, epoch: 5, iters: 80480, time: 0.005) nll: 0.912171 \n",
      "(GPU: 0, epoch: 5, iters: 81280, time: 0.006) nll: 0.867026 \n",
      "(GPU: 0, epoch: 5, iters: 82080, time: 0.005) nll: 1.014228 \n",
      "(GPU: 0, epoch: 5, iters: 82880, time: 0.006) nll: 0.883199 \n",
      "(GPU: 0, epoch: 5, iters: 83680, time: 0.006) nll: 0.818158 \n",
      "(GPU: 0, epoch: 5, iters: 84480, time: 0.006) nll: 0.832600 \n",
      "(GPU: 0, epoch: 5, iters: 85280, time: 0.005) nll: 0.979187 \n",
      "(GPU: 0, epoch: 5, iters: 86080, time: 0.006) nll: 0.830827 \n",
      "(GPU: 0, epoch: 5, iters: 86880, time: 0.005) nll: 0.773561 \n",
      "(GPU: 0, epoch: 5, iters: 87680, time: 0.006) nll: 0.707391 \n",
      "(GPU: 0, epoch: 5, iters: 88480, time: 0.005) nll: 0.940374 \n",
      "(GPU: 0, epoch: 5, iters: 89280, time: 0.006) nll: 0.798476 \n",
      "(GPU: 0, epoch: 5, iters: 90080, time: 0.005) nll: 0.704672 \n",
      "(GPU: 0, epoch: 5, iters: 90880, time: 0.006) nll: 0.745234 \n",
      "(GPU: 0, epoch: 5, iters: 91680, time: 0.005) nll: 0.597712 \n",
      "(GPU: 0, epoch: 5, iters: 92480, time: 0.006) nll: 0.834590 \n",
      "(GPU: 0, epoch: 5, iters: 93280, time: 0.005) nll: 0.730101 \n",
      "(GPU: 0, epoch: 5, iters: 94080, time: 0.006) nll: 1.149246 \n",
      "(GPU: 0, epoch: 5, iters: 94880, time: 0.005) nll: 0.888925 \n",
      "(GPU: 0, epoch: 5, iters: 95680, time: 0.006) nll: 0.906772 \n",
      "(GPU: 0, epoch: 5, iters: 96480, time: 0.005) nll: 0.818241 \n",
      "saving the latest model (epoch 5, total_steps 800000)\n",
      "(GPU: 0, epoch: 5, iters: 97280, time: 0.006) nll: 0.751734 \n",
      "(GPU: 0, epoch: 5, iters: 98080, time: 0.006) nll: 1.153979 \n",
      "(GPU: 0, epoch: 5, iters: 98880, time: 0.006) nll: 0.606336 \n",
      "(GPU: 0, epoch: 5, iters: 99680, time: 0.005) nll: 1.149466 \n",
      "(GPU: 0, epoch: 5, iters: 100480, time: 0.006) nll: 0.735873 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 101280, time: 0.006) nll: 0.671910 \n",
      "(GPU: 0, epoch: 5, iters: 102080, time: 0.006) nll: 0.738161 \n",
      "(GPU: 0, epoch: 5, iters: 102880, time: 0.005) nll: 0.811568 \n",
      "(GPU: 0, epoch: 5, iters: 103680, time: 0.006) nll: 0.609715 \n",
      "(GPU: 0, epoch: 5, iters: 104480, time: 0.005) nll: 0.694471 \n",
      "(GPU: 0, epoch: 5, iters: 105280, time: 0.006) nll: 0.776567 \n",
      "(GPU: 0, epoch: 5, iters: 106080, time: 0.005) nll: 0.808809 \n",
      "(GPU: 0, epoch: 5, iters: 106880, time: 0.006) nll: 0.765311 \n",
      "(GPU: 0, epoch: 5, iters: 107680, time: 0.005) nll: 0.712992 \n",
      "(GPU: 0, epoch: 5, iters: 108480, time: 0.006) nll: 0.732192 \n",
      "(GPU: 0, epoch: 5, iters: 109280, time: 0.005) nll: 0.792554 \n",
      "(GPU: 0, epoch: 5, iters: 110080, time: 0.006) nll: 0.927551 \n",
      "(GPU: 0, epoch: 5, iters: 110880, time: 0.005) nll: 0.553530 \n",
      "(GPU: 0, epoch: 5, iters: 111680, time: 0.006) nll: 0.870157 \n",
      "(GPU: 0, epoch: 5, iters: 112480, time: 0.005) nll: 0.658321 \n",
      "(GPU: 0, epoch: 5, iters: 113280, time: 0.006) nll: 0.932319 \n",
      "(GPU: 0, epoch: 5, iters: 114080, time: 0.005) nll: 0.913074 \n",
      "(GPU: 0, epoch: 5, iters: 114880, time: 0.006) nll: 0.820485 \n",
      "(GPU: 0, epoch: 5, iters: 115680, time: 0.005) nll: 1.143890 \n",
      "(GPU: 0, epoch: 5, iters: 116480, time: 0.006) nll: 0.748661 \n",
      "saving the latest model (epoch 5, total_steps 820000)\n",
      "(GPU: 0, epoch: 5, iters: 117280, time: 0.005) nll: 0.784021 \n",
      "(GPU: 0, epoch: 5, iters: 118080, time: 0.006) nll: 0.957766 \n",
      "(GPU: 0, epoch: 5, iters: 118880, time: 0.005) nll: 0.950518 \n",
      "(GPU: 0, epoch: 5, iters: 119680, time: 0.006) nll: 0.722406 \n",
      "(GPU: 0, epoch: 5, iters: 120480, time: 0.005) nll: 0.675515 \n",
      "(GPU: 0, epoch: 5, iters: 121280, time: 0.006) nll: 0.940697 \n",
      "(GPU: 0, epoch: 5, iters: 122080, time: 0.005) nll: 0.846156 \n",
      "(GPU: 0, epoch: 5, iters: 122880, time: 0.006) nll: 0.924300 \n",
      "(GPU: 0, epoch: 5, iters: 123680, time: 0.005) nll: 1.245669 \n",
      "(GPU: 0, epoch: 5, iters: 124480, time: 0.006) nll: 0.908303 \n",
      "(GPU: 0, epoch: 5, iters: 125280, time: 0.005) nll: 0.665993 \n",
      "(GPU: 0, epoch: 5, iters: 126080, time: 0.005) nll: 0.837964 \n",
      "(GPU: 0, epoch: 5, iters: 126880, time: 0.006) nll: 0.865999 \n",
      "(GPU: 0, epoch: 5, iters: 127680, time: 0.006) nll: 0.487680 \n",
      "(GPU: 0, epoch: 5, iters: 128480, time: 0.006) nll: 0.758163 \n",
      "(GPU: 0, epoch: 5, iters: 129280, time: 0.006) nll: 0.830407 \n",
      "(GPU: 0, epoch: 5, iters: 130080, time: 0.005) nll: 0.659353 \n",
      "(GPU: 0, epoch: 5, iters: 130880, time: 0.006) nll: 0.778254 \n",
      "(GPU: 0, epoch: 5, iters: 131680, time: 0.005) nll: 0.775105 \n",
      "(GPU: 0, epoch: 5, iters: 132480, time: 0.006) nll: 0.731528 \n",
      "(GPU: 0, epoch: 5, iters: 133280, time: 0.005) nll: 0.857514 \n",
      "(GPU: 0, epoch: 5, iters: 134080, time: 0.006) nll: 0.574251 \n",
      "(GPU: 0, epoch: 5, iters: 134880, time: 0.005) nll: 0.740428 \n",
      "(GPU: 0, epoch: 5, iters: 135680, time: 0.006) nll: 0.836538 \n",
      "(GPU: 0, epoch: 5, iters: 136480, time: 0.005) nll: 0.855727 \n",
      "saving the latest model (epoch 5, total_steps 840000)\n",
      "(GPU: 0, epoch: 5, iters: 137280, time: 0.006) nll: 0.898044 \n",
      "(GPU: 0, epoch: 5, iters: 138080, time: 0.005) nll: 0.814508 \n",
      "(GPU: 0, epoch: 5, iters: 138880, time: 0.006) nll: 0.950138 \n",
      "(GPU: 0, epoch: 5, iters: 139680, time: 0.006) nll: 0.911494 \n",
      "(GPU: 0, epoch: 5, iters: 140480, time: 0.006) nll: 0.717513 \n",
      "[*] End of epoch 5 / 25 \t Time Taken: 835 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000600\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3167/4397 [10:00<03:44,  5.49it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 32, time: 0.003) nll: 0.818351 \n",
      "(GPU: 0, epoch: 6, iters: 32, time: 0.003) nll: 0.780610 \n",
      "(GPU: 0, epoch: 6, iters: 576, time: 0.006) nll: 0.707542 \n",
      "(GPU: 0, epoch: 6, iters: 1376, time: 0.005) nll: 0.688875 \n",
      "(GPU: 0, epoch: 6, iters: 2176, time: 0.006) nll: 0.747072 \n",
      "(GPU: 0, epoch: 6, iters: 2976, time: 0.005) nll: 0.675278 \n",
      "(GPU: 0, epoch: 6, iters: 3776, time: 0.006) nll: 0.741700 \n",
      "(GPU: 0, epoch: 6, iters: 4576, time: 0.005) nll: 0.692133 \n",
      "(GPU: 0, epoch: 6, iters: 5376, time: 0.006) nll: 0.859374 \n",
      "(GPU: 0, epoch: 6, iters: 6176, time: 0.005) nll: 0.772891 \n",
      "(GPU: 0, epoch: 6, iters: 6976, time: 0.006) nll: 0.651194 \n",
      "(GPU: 0, epoch: 6, iters: 7776, time: 0.005) nll: 0.568335 \n",
      "(GPU: 0, epoch: 6, iters: 8576, time: 0.006) nll: 0.941359 \n",
      "(GPU: 0, epoch: 6, iters: 9376, time: 0.005) nll: 0.603427 \n",
      "(GPU: 0, epoch: 6, iters: 10176, time: 0.006) nll: 1.015880 \n",
      "(GPU: 0, epoch: 6, iters: 10976, time: 0.005) nll: 0.867459 \n",
      "(GPU: 0, epoch: 6, iters: 11776, time: 0.006) nll: 0.922702 \n",
      "(GPU: 0, epoch: 6, iters: 12576, time: 0.005) nll: 1.194288 \n",
      "(GPU: 0, epoch: 6, iters: 13376, time: 0.006) nll: 0.990651 \n",
      "(GPU: 0, epoch: 6, iters: 14176, time: 0.005) nll: 0.860346 \n",
      "(GPU: 0, epoch: 6, iters: 14976, time: 0.006) nll: 0.828791 \n",
      "(GPU: 0, epoch: 6, iters: 15776, time: 0.005) nll: 0.678967 \n",
      "saving the latest model (epoch 6, total_steps 860000)\n",
      "(GPU: 0, epoch: 6, iters: 16576, time: 0.006) nll: 0.677295 \n",
      "(GPU: 0, epoch: 6, iters: 17376, time: 0.006) nll: 0.919934 \n",
      "(GPU: 0, epoch: 6, iters: 18176, time: 0.006) nll: 0.716464 \n",
      "(GPU: 0, epoch: 6, iters: 18976, time: 0.005) nll: 0.816178 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.006) nll: 0.926473 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.009) nll: 0.920737 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.009) nll: 0.763640 \n",
      "(GPU: 0, epoch: 6, iters: 20576, time: 0.005) nll: 0.911811 \n",
      "(GPU: 0, epoch: 6, iters: 21376, time: 0.006) nll: 0.706915 \n",
      "(GPU: 0, epoch: 6, iters: 22176, time: 0.006) nll: 0.571433 \n",
      "(GPU: 0, epoch: 6, iters: 22976, time: 0.006) nll: 0.833537 \n",
      "(GPU: 0, epoch: 6, iters: 23776, time: 0.005) nll: 0.972161 \n",
      "(GPU: 0, epoch: 6, iters: 24576, time: 0.006) nll: 0.884665 \n",
      "(GPU: 0, epoch: 6, iters: 25376, time: 0.005) nll: 0.955141 \n",
      "(GPU: 0, epoch: 6, iters: 26176, time: 0.006) nll: 1.013585 \n",
      "(GPU: 0, epoch: 6, iters: 26976, time: 0.006) nll: 0.606765 \n",
      "(GPU: 0, epoch: 6, iters: 27776, time: 0.006) nll: 1.129016 \n",
      "(GPU: 0, epoch: 6, iters: 28576, time: 0.005) nll: 0.615873 \n",
      "(GPU: 0, epoch: 6, iters: 29376, time: 0.006) nll: 0.750851 \n",
      "(GPU: 0, epoch: 6, iters: 30176, time: 0.005) nll: 0.891501 \n",
      "(GPU: 0, epoch: 6, iters: 30976, time: 0.006) nll: 0.834049 \n",
      "(GPU: 0, epoch: 6, iters: 31776, time: 0.005) nll: 0.672229 \n",
      "(GPU: 0, epoch: 6, iters: 32576, time: 0.006) nll: 0.746483 \n",
      "(GPU: 0, epoch: 6, iters: 33376, time: 0.006) nll: 0.729301 \n",
      "(GPU: 0, epoch: 6, iters: 34176, time: 0.006) nll: 0.773888 \n",
      "(GPU: 0, epoch: 6, iters: 34976, time: 0.005) nll: 0.616756 \n",
      "(GPU: 0, epoch: 6, iters: 35776, time: 0.006) nll: 0.639646 \n",
      "saving the latest model (epoch 6, total_steps 880000)\n",
      "(GPU: 0, epoch: 6, iters: 36576, time: 0.005) nll: 0.724811 \n",
      "(GPU: 0, epoch: 6, iters: 37376, time: 0.006) nll: 0.599611 \n",
      "(GPU: 0, epoch: 6, iters: 38176, time: 0.005) nll: 0.505207 \n",
      "(GPU: 0, epoch: 6, iters: 38976, time: 0.006) nll: 0.767486 \n",
      "(GPU: 0, epoch: 6, iters: 39776, time: 0.005) nll: 0.861986 \n",
      "(GPU: 0, epoch: 6, iters: 40576, time: 0.006) nll: 0.744059 \n",
      "(GPU: 0, epoch: 6, iters: 41376, time: 0.005) nll: 0.740930 \n",
      "(GPU: 0, epoch: 6, iters: 42176, time: 0.006) nll: 0.914764 \n",
      "(GPU: 0, epoch: 6, iters: 42976, time: 0.005) nll: 0.808265 \n",
      "(GPU: 0, epoch: 6, iters: 43776, time: 0.006) nll: 0.709068 \n",
      "(GPU: 0, epoch: 6, iters: 44576, time: 0.005) nll: 0.727102 \n",
      "(GPU: 0, epoch: 6, iters: 45376, time: 0.006) nll: 0.668423 \n",
      "(GPU: 0, epoch: 6, iters: 46176, time: 0.005) nll: 0.876257 \n",
      "(GPU: 0, epoch: 6, iters: 46976, time: 0.006) nll: 0.851661 \n",
      "(GPU: 0, epoch: 6, iters: 47776, time: 0.005) nll: 0.610289 \n",
      "(GPU: 0, epoch: 6, iters: 48576, time: 0.006) nll: 0.810766 \n",
      "(GPU: 0, epoch: 6, iters: 49376, time: 0.005) nll: 0.837369 \n",
      "(GPU: 0, epoch: 6, iters: 50176, time: 0.006) nll: 0.639887 \n",
      "(GPU: 0, epoch: 6, iters: 50976, time: 0.005) nll: 0.789324 \n",
      "(GPU: 0, epoch: 6, iters: 51776, time: 0.006) nll: 0.892633 \n",
      "(GPU: 0, epoch: 6, iters: 52576, time: 0.005) nll: 1.048288 \n",
      "(GPU: 0, epoch: 6, iters: 53376, time: 0.006) nll: 0.791020 \n",
      "(GPU: 0, epoch: 6, iters: 54176, time: 0.006) nll: 0.918361 \n",
      "(GPU: 0, epoch: 6, iters: 54976, time: 0.006) nll: 0.647259 \n",
      "(GPU: 0, epoch: 6, iters: 55776, time: 0.005) nll: 0.731622 \n",
      "saving the latest model (epoch 6, total_steps 900000)\n",
      "(GPU: 0, epoch: 6, iters: 56576, time: 0.006) nll: 0.701563 \n",
      "(GPU: 0, epoch: 6, iters: 57376, time: 0.005) nll: 1.087879 \n",
      "(GPU: 0, epoch: 6, iters: 58176, time: 0.006) nll: 0.669400 \n",
      "(GPU: 0, epoch: 6, iters: 58976, time: 0.006) nll: 1.188207 \n",
      "(GPU: 0, epoch: 6, iters: 59776, time: 0.006) nll: 0.703856 \n",
      "(GPU: 0, epoch: 6, iters: 60576, time: 0.005) nll: 0.637130 \n",
      "(GPU: 0, epoch: 6, iters: 61376, time: 0.006) nll: 0.867724 \n",
      "(GPU: 0, epoch: 6, iters: 62176, time: 0.005) nll: 0.996753 \n",
      "(GPU: 0, epoch: 6, iters: 62976, time: 0.006) nll: 0.784526 \n",
      "(GPU: 0, epoch: 6, iters: 63776, time: 0.005) nll: 0.674953 \n",
      "(GPU: 0, epoch: 6, iters: 64576, time: 0.006) nll: 0.820980 \n",
      "(GPU: 0, epoch: 6, iters: 65376, time: 0.005) nll: 0.981761 \n",
      "(GPU: 0, epoch: 6, iters: 66176, time: 0.006) nll: 0.703062 \n",
      "(GPU: 0, epoch: 6, iters: 66976, time: 0.006) nll: 0.659400 \n",
      "(GPU: 0, epoch: 6, iters: 67776, time: 0.006) nll: 0.725844 \n",
      "(GPU: 0, epoch: 6, iters: 68576, time: 0.005) nll: 0.674507 \n",
      "(GPU: 0, epoch: 6, iters: 69376, time: 0.006) nll: 1.233739 \n",
      "(GPU: 0, epoch: 6, iters: 70176, time: 0.005) nll: 0.590431 \n",
      "(GPU: 0, epoch: 6, iters: 70976, time: 0.006) nll: 0.614893 \n",
      "(GPU: 0, epoch: 6, iters: 71776, time: 0.005) nll: 0.726448 \n",
      "(GPU: 0, epoch: 6, iters: 72576, time: 0.006) nll: 0.714461 \n",
      "(GPU: 0, epoch: 6, iters: 73376, time: 0.005) nll: 0.663382 \n",
      "(GPU: 0, epoch: 6, iters: 74176, time: 0.006) nll: 0.884360 \n",
      "(GPU: 0, epoch: 6, iters: 74976, time: 0.005) nll: 0.629246 \n",
      "(GPU: 0, epoch: 6, iters: 75776, time: 0.006) nll: 0.523745 \n",
      "saving the latest model (epoch 6, total_steps 920000)\n",
      "(GPU: 0, epoch: 6, iters: 76576, time: 0.005) nll: 0.774639 \n",
      "(GPU: 0, epoch: 6, iters: 77376, time: 0.006) nll: 0.767524 \n",
      "(GPU: 0, epoch: 6, iters: 78176, time: 0.005) nll: 0.826388 \n",
      "(GPU: 0, epoch: 6, iters: 78976, time: 0.006) nll: 0.893534 \n",
      "(GPU: 0, epoch: 6, iters: 79776, time: 0.005) nll: 0.798079 \n",
      "(GPU: 0, epoch: 6, iters: 80576, time: 0.006) nll: 0.903892 \n",
      "(GPU: 0, epoch: 6, iters: 81376, time: 0.006) nll: 0.744814 \n",
      "(GPU: 0, epoch: 6, iters: 82176, time: 0.006) nll: 1.023516 \n",
      "(GPU: 0, epoch: 6, iters: 82976, time: 0.005) nll: 0.951793 \n",
      "(GPU: 0, epoch: 6, iters: 83776, time: 0.006) nll: 0.728956 \n",
      "(GPU: 0, epoch: 6, iters: 84576, time: 0.006) nll: 0.861385 \n",
      "(GPU: 0, epoch: 6, iters: 85376, time: 0.006) nll: 1.092191 \n",
      "(GPU: 0, epoch: 6, iters: 86176, time: 0.005) nll: 0.847574 \n",
      "(GPU: 0, epoch: 6, iters: 86976, time: 0.006) nll: 0.770019 \n",
      "(GPU: 0, epoch: 6, iters: 87776, time: 0.006) nll: 0.969319 \n",
      "(GPU: 0, epoch: 6, iters: 88576, time: 0.006) nll: 0.689672 \n",
      "(GPU: 0, epoch: 6, iters: 89376, time: 0.006) nll: 0.885206 \n",
      "(GPU: 0, epoch: 6, iters: 90176, time: 0.006) nll: 0.747323 \n",
      "(GPU: 0, epoch: 6, iters: 90976, time: 0.005) nll: 0.854543 \n",
      "(GPU: 0, epoch: 6, iters: 91776, time: 0.006) nll: 0.867577 \n",
      "(GPU: 0, epoch: 6, iters: 92576, time: 0.005) nll: 0.562062 \n",
      "(GPU: 0, epoch: 6, iters: 93376, time: 0.006) nll: 0.717345 \n",
      "(GPU: 0, epoch: 6, iters: 94176, time: 0.005) nll: 0.675366 \n",
      "(GPU: 0, epoch: 6, iters: 94976, time: 0.006) nll: 1.239772 \n",
      "(GPU: 0, epoch: 6, iters: 95776, time: 0.005) nll: 0.769267 \n",
      "saving the latest model (epoch 6, total_steps 940000)\n",
      "(GPU: 0, epoch: 6, iters: 96576, time: 0.006) nll: 0.714209 \n",
      "(GPU: 0, epoch: 6, iters: 97376, time: 0.005) nll: 0.958759 \n",
      "(GPU: 0, epoch: 6, iters: 98176, time: 0.006) nll: 0.728628 \n",
      "(GPU: 0, epoch: 6, iters: 98976, time: 0.005) nll: 1.021417 \n",
      "(GPU: 0, epoch: 6, iters: 99776, time: 0.006) nll: 0.846161 \n",
      "(GPU: 0, epoch: 6, iters: 100576, time: 0.006) nll: 1.028692 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 101376, time: 0.006) nll: 0.981816 \n",
      "(GPU: 0, epoch: 6, iters: 102176, time: 0.005) nll: 0.883799 \n",
      "(GPU: 0, epoch: 6, iters: 102976, time: 0.006) nll: 0.976236 \n",
      "(GPU: 0, epoch: 6, iters: 103776, time: 0.006) nll: 0.522768 \n",
      "(GPU: 0, epoch: 6, iters: 104576, time: 0.006) nll: 0.470031 \n",
      "(GPU: 0, epoch: 6, iters: 105376, time: 0.006) nll: 0.641238 \n",
      "(GPU: 0, epoch: 6, iters: 106176, time: 0.006) nll: 1.044789 \n",
      "(GPU: 0, epoch: 6, iters: 106976, time: 0.005) nll: 0.882430 \n",
      "(GPU: 0, epoch: 6, iters: 107776, time: 0.006) nll: 0.673035 \n",
      "(GPU: 0, epoch: 6, iters: 108576, time: 0.005) nll: 0.715938 \n",
      "(GPU: 0, epoch: 6, iters: 109376, time: 0.006) nll: 0.897602 \n",
      "(GPU: 0, epoch: 6, iters: 110176, time: 0.005) nll: 0.769063 \n",
      "(GPU: 0, epoch: 6, iters: 110976, time: 0.006) nll: 0.669097 \n",
      "(GPU: 0, epoch: 6, iters: 111776, time: 0.005) nll: 0.744118 \n",
      "(GPU: 0, epoch: 6, iters: 112576, time: 0.006) nll: 0.701415 \n",
      "(GPU: 0, epoch: 6, iters: 113376, time: 0.005) nll: 0.922513 \n",
      "(GPU: 0, epoch: 6, iters: 114176, time: 0.006) nll: 0.778173 \n",
      "(GPU: 0, epoch: 6, iters: 114976, time: 0.005) nll: 0.618206 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.006) nll: 0.684212 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.009) nll: 0.678830 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.009) nll: 0.665316 \n",
      "saving the latest model (epoch 6, total_steps 960000)\n",
      "(GPU: 0, epoch: 6, iters: 116576, time: 0.006) nll: 0.866482 \n",
      "(GPU: 0, epoch: 6, iters: 117376, time: 0.006) nll: 0.789570 \n",
      "(GPU: 0, epoch: 6, iters: 118176, time: 0.005) nll: 0.802752 \n",
      "(GPU: 0, epoch: 6, iters: 118976, time: 0.006) nll: 0.697457 \n",
      "(GPU: 0, epoch: 6, iters: 119776, time: 0.005) nll: 0.783194 \n",
      "(GPU: 0, epoch: 6, iters: 120576, time: 0.006) nll: 0.736805 \n",
      "(GPU: 0, epoch: 6, iters: 121376, time: 0.005) nll: 0.783283 \n",
      "(GPU: 0, epoch: 6, iters: 122176, time: 0.006) nll: 0.549103 \n",
      "(GPU: 0, epoch: 6, iters: 122976, time: 0.005) nll: 0.628352 \n",
      "(GPU: 0, epoch: 6, iters: 123776, time: 0.006) nll: 0.793776 \n",
      "(GPU: 0, epoch: 6, iters: 124576, time: 0.005) nll: 0.739425 \n",
      "(GPU: 0, epoch: 6, iters: 125376, time: 0.006) nll: 0.663287 \n",
      "(GPU: 0, epoch: 6, iters: 126176, time: 0.005) nll: 0.651574 \n",
      "(GPU: 0, epoch: 6, iters: 126976, time: 0.006) nll: 0.780049 \n",
      "(GPU: 0, epoch: 6, iters: 127776, time: 0.005) nll: 0.699025 \n",
      "(GPU: 0, epoch: 6, iters: 128576, time: 0.006) nll: 0.852013 \n",
      "(GPU: 0, epoch: 6, iters: 129376, time: 0.005) nll: 0.756147 \n",
      "(GPU: 0, epoch: 6, iters: 130176, time: 0.006) nll: 0.845819 \n",
      "(GPU: 0, epoch: 6, iters: 130976, time: 0.005) nll: 0.983812 \n",
      "(GPU: 0, epoch: 6, iters: 131776, time: 0.006) nll: 0.710760 \n",
      "(GPU: 0, epoch: 6, iters: 132576, time: 0.006) nll: 0.805495 \n",
      "(GPU: 0, epoch: 6, iters: 133376, time: 0.006) nll: 0.530599 \n",
      "(GPU: 0, epoch: 6, iters: 134176, time: 0.005) nll: 0.716445 \n",
      "(GPU: 0, epoch: 6, iters: 134976, time: 0.006) nll: 0.736394 \n",
      "(GPU: 0, epoch: 6, iters: 135776, time: 0.005) nll: 0.825983 \n",
      "saving the latest model (epoch 6, total_steps 980000)\n",
      "(GPU: 0, epoch: 6, iters: 136576, time: 0.006) nll: 0.900852 \n",
      "(GPU: 0, epoch: 6, iters: 137376, time: 0.005) nll: 0.871172 \n",
      "(GPU: 0, epoch: 6, iters: 138176, time: 0.006) nll: 0.676308 \n",
      "(GPU: 0, epoch: 6, iters: 138976, time: 0.005) nll: 0.798058 \n",
      "(GPU: 0, epoch: 6, iters: 139776, time: 0.006) nll: 0.751439 \n",
      "(GPU: 0, epoch: 6, iters: 140576, time: 0.006) nll: 0.760498 \n",
      "saving the model at the end of epoch 6, iters 984928\n",
      "([test] GPU: 0, epoch: 6) \n",
      "OrderedDict()\n",
      "[*] End of epoch 6 / 25 \t Time Taken: 839 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000700\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3170/4397 [09:59<03:45,  5.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 32, time: 0.003) nll: 0.571520 \n",
      "(GPU: 0, epoch: 7, iters: 32, time: 0.003) nll: 0.816920 \n",
      "(GPU: 0, epoch: 7, iters: 672, time: 0.005) nll: 0.698143 \n",
      "(GPU: 0, epoch: 7, iters: 1472, time: 0.006) nll: 0.737515 \n",
      "(GPU: 0, epoch: 7, iters: 2272, time: 0.006) nll: 0.740791 \n",
      "(GPU: 0, epoch: 7, iters: 3072, time: 0.006) nll: 0.703798 \n",
      "(GPU: 0, epoch: 7, iters: 3872, time: 0.005) nll: 0.640405 \n",
      "(GPU: 0, epoch: 7, iters: 4672, time: 0.006) nll: 0.735502 \n",
      "(GPU: 0, epoch: 7, iters: 5472, time: 0.006) nll: 0.725000 \n",
      "(GPU: 0, epoch: 7, iters: 6272, time: 0.006) nll: 0.794236 \n",
      "(GPU: 0, epoch: 7, iters: 7072, time: 0.006) nll: 0.740181 \n",
      "(GPU: 0, epoch: 7, iters: 7872, time: 0.006) nll: 0.756182 \n",
      "(GPU: 0, epoch: 7, iters: 8672, time: 0.005) nll: 0.964898 \n",
      "(GPU: 0, epoch: 7, iters: 9472, time: 0.006) nll: 0.770564 \n",
      "(GPU: 0, epoch: 7, iters: 10272, time: 0.005) nll: 0.729630 \n",
      "(GPU: 0, epoch: 7, iters: 11072, time: 0.006) nll: 0.628474 \n",
      "(GPU: 0, epoch: 7, iters: 11872, time: 0.005) nll: 0.694619 \n",
      "(GPU: 0, epoch: 7, iters: 12672, time: 0.006) nll: 0.534457 \n",
      "(GPU: 0, epoch: 7, iters: 13472, time: 0.005) nll: 0.907054 \n",
      "(GPU: 0, epoch: 7, iters: 14272, time: 0.006) nll: 0.743204 \n",
      "(GPU: 0, epoch: 7, iters: 15072, time: 0.005) nll: 0.873126 \n",
      "saving the latest model (epoch 7, total_steps 1000000)\n",
      "(GPU: 0, epoch: 7, iters: 15872, time: 0.006) nll: 0.658625 \n",
      "(GPU: 0, epoch: 7, iters: 16672, time: 0.005) nll: 1.066058 \n",
      "(GPU: 0, epoch: 7, iters: 17472, time: 0.006) nll: 0.524471 \n",
      "(GPU: 0, epoch: 7, iters: 18272, time: 0.005) nll: 0.598345 \n",
      "(GPU: 0, epoch: 7, iters: 19072, time: 0.006) nll: 1.085391 \n",
      "(GPU: 0, epoch: 7, iters: 19872, time: 0.005) nll: 0.850028 \n",
      "(GPU: 0, epoch: 7, iters: 20672, time: 0.006) nll: 0.854736 \n",
      "(GPU: 0, epoch: 7, iters: 21472, time: 0.006) nll: 0.852870 \n",
      "(GPU: 0, epoch: 7, iters: 22272, time: 0.006) nll: 0.687174 \n",
      "(GPU: 0, epoch: 7, iters: 23072, time: 0.005) nll: 1.054715 \n",
      "(GPU: 0, epoch: 7, iters: 23872, time: 0.006) nll: 0.878713 \n",
      "(GPU: 0, epoch: 7, iters: 24672, time: 0.006) nll: 0.979568 \n",
      "(GPU: 0, epoch: 7, iters: 25472, time: 0.006) nll: 0.510830 \n",
      "(GPU: 0, epoch: 7, iters: 26272, time: 0.005) nll: 0.770705 \n",
      "(GPU: 0, epoch: 7, iters: 27072, time: 0.006) nll: 0.527044 \n",
      "(GPU: 0, epoch: 7, iters: 27872, time: 0.005) nll: 0.868324 \n",
      "(GPU: 0, epoch: 7, iters: 28672, time: 0.006) nll: 0.900175 \n",
      "(GPU: 0, epoch: 7, iters: 29472, time: 0.005) nll: 0.809251 \n",
      "(GPU: 0, epoch: 7, iters: 30272, time: 0.006) nll: 0.774196 \n",
      "(GPU: 0, epoch: 7, iters: 31072, time: 0.006) nll: 0.821936 \n",
      "(GPU: 0, epoch: 7, iters: 31872, time: 0.006) nll: 0.688176 \n",
      "(GPU: 0, epoch: 7, iters: 32672, time: 0.006) nll: 0.571934 \n",
      "(GPU: 0, epoch: 7, iters: 33472, time: 0.006) nll: 0.729216 \n",
      "(GPU: 0, epoch: 7, iters: 34272, time: 0.005) nll: 0.811608 \n",
      "(GPU: 0, epoch: 7, iters: 35072, time: 0.006) nll: 0.726966 \n",
      "saving the latest model (epoch 7, total_steps 1020000)\n",
      "(GPU: 0, epoch: 7, iters: 35872, time: 0.005) nll: 0.729392 \n",
      "(GPU: 0, epoch: 7, iters: 36672, time: 0.006) nll: 0.683293 \n",
      "(GPU: 0, epoch: 7, iters: 37472, time: 0.005) nll: 0.811143 \n",
      "(GPU: 0, epoch: 7, iters: 38272, time: 0.006) nll: 0.710543 \n",
      "(GPU: 0, epoch: 7, iters: 39072, time: 0.005) nll: 0.844659 \n",
      "(GPU: 0, epoch: 7, iters: 39872, time: 0.006) nll: 0.790818 \n",
      "(GPU: 0, epoch: 7, iters: 40672, time: 0.005) nll: 0.653016 \n",
      "(GPU: 0, epoch: 7, iters: 41472, time: 0.006) nll: 0.741611 \n",
      "(GPU: 0, epoch: 7, iters: 42272, time: 0.005) nll: 0.761675 \n",
      "(GPU: 0, epoch: 7, iters: 43072, time: 0.006) nll: 0.790660 \n",
      "(GPU: 0, epoch: 7, iters: 43872, time: 0.005) nll: 0.701405 \n",
      "(GPU: 0, epoch: 7, iters: 44672, time: 0.006) nll: 0.761695 \n",
      "(GPU: 0, epoch: 7, iters: 45472, time: 0.005) nll: 0.848555 \n",
      "(GPU: 0, epoch: 7, iters: 46272, time: 0.006) nll: 0.842911 \n",
      "(GPU: 0, epoch: 7, iters: 47072, time: 0.005) nll: 0.560550 \n",
      "(GPU: 0, epoch: 7, iters: 47872, time: 0.006) nll: 0.820362 \n",
      "(GPU: 0, epoch: 7, iters: 48672, time: 0.005) nll: 1.215834 \n",
      "(GPU: 0, epoch: 7, iters: 49472, time: 0.006) nll: 0.558943 \n",
      "(GPU: 0, epoch: 7, iters: 50272, time: 0.005) nll: 0.715429 \n",
      "(GPU: 0, epoch: 7, iters: 51072, time: 0.006) nll: 0.911505 \n",
      "(GPU: 0, epoch: 7, iters: 51872, time: 0.005) nll: 0.955266 \n",
      "(GPU: 0, epoch: 7, iters: 52672, time: 0.006) nll: 1.014767 \n",
      "(GPU: 0, epoch: 7, iters: 53472, time: 0.005) nll: 0.869995 \n",
      "(GPU: 0, epoch: 7, iters: 54272, time: 0.006) nll: 0.744699 \n",
      "(GPU: 0, epoch: 7, iters: 55072, time: 0.006) nll: 1.004333 \n",
      "saving the latest model (epoch 7, total_steps 1040000)\n",
      "(GPU: 0, epoch: 7, iters: 55872, time: 0.006) nll: 0.805999 \n",
      "(GPU: 0, epoch: 7, iters: 56672, time: 0.005) nll: 0.660500 \n",
      "(GPU: 0, epoch: 7, iters: 57472, time: 0.006) nll: 0.597735 \n",
      "(GPU: 0, epoch: 7, iters: 58272, time: 0.005) nll: 0.631376 \n",
      "(GPU: 0, epoch: 7, iters: 59072, time: 0.006) nll: 0.947361 \n",
      "(GPU: 0, epoch: 7, iters: 59872, time: 0.005) nll: 1.035042 \n",
      "(GPU: 0, epoch: 7, iters: 60672, time: 0.006) nll: 0.564684 \n",
      "(GPU: 0, epoch: 7, iters: 61472, time: 0.005) nll: 0.740256 \n",
      "(GPU: 0, epoch: 7, iters: 62272, time: 0.006) nll: 0.818964 \n",
      "(GPU: 0, epoch: 7, iters: 63072, time: 0.005) nll: 0.673139 \n",
      "(GPU: 0, epoch: 7, iters: 63872, time: 0.006) nll: 0.734742 \n",
      "(GPU: 0, epoch: 7, iters: 64672, time: 0.005) nll: 0.829654 \n",
      "(GPU: 0, epoch: 7, iters: 65472, time: 0.006) nll: 0.757718 \n",
      "(GPU: 0, epoch: 7, iters: 66272, time: 0.006) nll: 0.726675 \n",
      "(GPU: 0, epoch: 7, iters: 67072, time: 0.006) nll: 0.683703 \n",
      "(GPU: 0, epoch: 7, iters: 67872, time: 0.005) nll: 0.667390 \n",
      "(GPU: 0, epoch: 7, iters: 68672, time: 0.006) nll: 0.746492 \n",
      "(GPU: 0, epoch: 7, iters: 69472, time: 0.006) nll: 0.908286 \n",
      "(GPU: 0, epoch: 7, iters: 70272, time: 0.006) nll: 0.879400 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.005) nll: 0.471468 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.008) nll: 0.463015 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.008) nll: 1.007430 \n",
      "(GPU: 0, epoch: 7, iters: 71872, time: 0.006) nll: 0.779749 \n",
      "(GPU: 0, epoch: 7, iters: 72672, time: 0.005) nll: 0.832513 \n",
      "(GPU: 0, epoch: 7, iters: 73472, time: 0.006) nll: 0.776201 \n",
      "(GPU: 0, epoch: 7, iters: 74272, time: 0.005) nll: 1.027035 \n",
      "(GPU: 0, epoch: 7, iters: 75072, time: 0.006) nll: 0.629238 \n",
      "saving the latest model (epoch 7, total_steps 1060000)\n",
      "(GPU: 0, epoch: 7, iters: 75872, time: 0.006) nll: 0.904651 \n",
      "(GPU: 0, epoch: 7, iters: 76672, time: 0.006) nll: 0.751571 \n",
      "(GPU: 0, epoch: 7, iters: 77472, time: 0.005) nll: 0.794742 \n",
      "(GPU: 0, epoch: 7, iters: 78272, time: 0.006) nll: 0.929546 \n",
      "(GPU: 0, epoch: 7, iters: 79072, time: 0.006) nll: 0.900364 \n",
      "(GPU: 0, epoch: 7, iters: 79872, time: 0.006) nll: 0.745468 \n",
      "(GPU: 0, epoch: 7, iters: 80672, time: 0.005) nll: 0.655806 \n",
      "(GPU: 0, epoch: 7, iters: 81472, time: 0.006) nll: 1.000514 \n",
      "(GPU: 0, epoch: 7, iters: 82272, time: 0.005) nll: 0.958228 \n",
      "(GPU: 0, epoch: 7, iters: 83072, time: 0.006) nll: 0.685178 \n",
      "(GPU: 0, epoch: 7, iters: 83872, time: 0.005) nll: 0.546721 \n",
      "(GPU: 0, epoch: 7, iters: 84672, time: 0.006) nll: 0.858396 \n",
      "(GPU: 0, epoch: 7, iters: 85472, time: 0.006) nll: 1.142346 \n",
      "(GPU: 0, epoch: 7, iters: 86272, time: 0.006) nll: 0.814442 \n",
      "(GPU: 0, epoch: 7, iters: 87072, time: 0.005) nll: 1.041505 \n",
      "(GPU: 0, epoch: 7, iters: 87872, time: 0.006) nll: 0.841525 \n",
      "(GPU: 0, epoch: 7, iters: 88672, time: 0.005) nll: 0.485963 \n",
      "(GPU: 0, epoch: 7, iters: 89472, time: 0.006) nll: 0.740612 \n",
      "(GPU: 0, epoch: 7, iters: 90272, time: 0.005) nll: 0.849880 \n",
      "(GPU: 0, epoch: 7, iters: 91072, time: 0.006) nll: 0.660732 \n",
      "(GPU: 0, epoch: 7, iters: 91872, time: 0.006) nll: 0.799248 \n",
      "(GPU: 0, epoch: 7, iters: 92672, time: 0.006) nll: 0.733500 \n",
      "(GPU: 0, epoch: 7, iters: 93472, time: 0.005) nll: 0.750987 \n",
      "(GPU: 0, epoch: 7, iters: 94272, time: 0.006) nll: 0.822204 \n",
      "(GPU: 0, epoch: 7, iters: 95072, time: 0.005) nll: 0.580336 \n",
      "saving the latest model (epoch 7, total_steps 1080000)\n",
      "(GPU: 0, epoch: 7, iters: 95872, time: 0.006) nll: 0.602881 \n",
      "(GPU: 0, epoch: 7, iters: 96672, time: 0.005) nll: 0.998096 \n",
      "(GPU: 0, epoch: 7, iters: 97472, time: 0.006) nll: 0.766072 \n",
      "(GPU: 0, epoch: 7, iters: 98272, time: 0.005) nll: 0.826933 \n",
      "(GPU: 0, epoch: 7, iters: 99072, time: 0.006) nll: 0.679314 \n",
      "(GPU: 0, epoch: 7, iters: 99872, time: 0.005) nll: 0.708769 \n",
      "(GPU: 0, epoch: 7, iters: 100672, time: 0.006) nll: 0.815451 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:52<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 101472, time: 0.006) nll: 0.703149 \n",
      "(GPU: 0, epoch: 7, iters: 102272, time: 0.006) nll: 0.720690 \n",
      "(GPU: 0, epoch: 7, iters: 103072, time: 0.005) nll: 0.624018 \n",
      "(GPU: 0, epoch: 7, iters: 103872, time: 0.006) nll: 0.652838 \n",
      "(GPU: 0, epoch: 7, iters: 104672, time: 0.006) nll: 0.720108 \n",
      "(GPU: 0, epoch: 7, iters: 105472, time: 0.006) nll: 0.746785 \n",
      "(GPU: 0, epoch: 7, iters: 106272, time: 0.006) nll: 0.999823 \n",
      "(GPU: 0, epoch: 7, iters: 107072, time: 0.006) nll: 0.628656 \n",
      "(GPU: 0, epoch: 7, iters: 107872, time: 0.006) nll: 0.942272 \n",
      "(GPU: 0, epoch: 7, iters: 108672, time: 0.006) nll: 0.718607 \n",
      "(GPU: 0, epoch: 7, iters: 109472, time: 0.005) nll: 0.988856 \n",
      "(GPU: 0, epoch: 7, iters: 110272, time: 0.006) nll: 0.931708 \n",
      "(GPU: 0, epoch: 7, iters: 111072, time: 0.005) nll: 0.673143 \n",
      "(GPU: 0, epoch: 7, iters: 111872, time: 0.006) nll: 0.832056 \n",
      "(GPU: 0, epoch: 7, iters: 112672, time: 0.006) nll: 0.599914 \n",
      "(GPU: 0, epoch: 7, iters: 113472, time: 0.006) nll: 0.912163 \n",
      "(GPU: 0, epoch: 7, iters: 114272, time: 0.006) nll: 0.787450 \n",
      "(GPU: 0, epoch: 7, iters: 115072, time: 0.006) nll: 1.187591 \n",
      "saving the latest model (epoch 7, total_steps 1100000)\n",
      "(GPU: 0, epoch: 7, iters: 115872, time: 0.005) nll: 0.603952 \n",
      "(GPU: 0, epoch: 7, iters: 116672, time: 0.006) nll: 0.651056 \n",
      "(GPU: 0, epoch: 7, iters: 117472, time: 0.005) nll: 0.861174 \n",
      "(GPU: 0, epoch: 7, iters: 118272, time: 0.006) nll: 0.746288 \n",
      "(GPU: 0, epoch: 7, iters: 119072, time: 0.005) nll: 0.700777 \n",
      "(GPU: 0, epoch: 7, iters: 119872, time: 0.006) nll: 0.991244 \n",
      "(GPU: 0, epoch: 7, iters: 120672, time: 0.005) nll: 0.810425 \n",
      "(GPU: 0, epoch: 7, iters: 121472, time: 0.006) nll: 0.861853 \n",
      "(GPU: 0, epoch: 7, iters: 122272, time: 0.006) nll: 0.845758 \n",
      "(GPU: 0, epoch: 7, iters: 123072, time: 0.006) nll: 0.773951 \n",
      "(GPU: 0, epoch: 7, iters: 123872, time: 0.005) nll: 0.845785 \n",
      "(GPU: 0, epoch: 7, iters: 124672, time: 0.006) nll: 0.804021 \n",
      "(GPU: 0, epoch: 7, iters: 125472, time: 0.005) nll: 1.043889 \n",
      "(GPU: 0, epoch: 7, iters: 126272, time: 0.006) nll: 0.678348 \n",
      "(GPU: 0, epoch: 7, iters: 127072, time: 0.005) nll: 0.716112 \n",
      "(GPU: 0, epoch: 7, iters: 127872, time: 0.006) nll: 0.662771 \n",
      "(GPU: 0, epoch: 7, iters: 128672, time: 0.005) nll: 0.845835 \n",
      "(GPU: 0, epoch: 7, iters: 129472, time: 0.006) nll: 0.702339 \n",
      "(GPU: 0, epoch: 7, iters: 130272, time: 0.005) nll: 1.268667 \n",
      "(GPU: 0, epoch: 7, iters: 131072, time: 0.006) nll: 0.767169 \n",
      "(GPU: 0, epoch: 7, iters: 131872, time: 0.005) nll: 0.772344 \n",
      "(GPU: 0, epoch: 7, iters: 132672, time: 0.006) nll: 0.804164 \n",
      "(GPU: 0, epoch: 7, iters: 133472, time: 0.005) nll: 0.904263 \n",
      "(GPU: 0, epoch: 7, iters: 134272, time: 0.006) nll: 0.739934 \n",
      "(GPU: 0, epoch: 7, iters: 135072, time: 0.005) nll: 0.799725 \n",
      "saving the latest model (epoch 7, total_steps 1120000)\n",
      "(GPU: 0, epoch: 7, iters: 135872, time: 0.006) nll: 1.013681 \n",
      "(GPU: 0, epoch: 7, iters: 136672, time: 0.005) nll: 0.995416 \n",
      "(GPU: 0, epoch: 7, iters: 137472, time: 0.006) nll: 0.757432 \n",
      "(GPU: 0, epoch: 7, iters: 138272, time: 0.005) nll: 0.778950 \n",
      "(GPU: 0, epoch: 7, iters: 139072, time: 0.006) nll: 0.801365 \n",
      "(GPU: 0, epoch: 7, iters: 139872, time: 0.005) nll: 0.809191 \n",
      "(GPU: 0, epoch: 7, iters: 140672, time: 0.006) nll: 0.901404 \n",
      "[*] End of epoch 7 / 25 \t Time Taken: 833 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000800\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3173/4397 [10:01<03:47,  5.39it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 32, time: 0.003) nll: 0.703109 \n",
      "(GPU: 0, epoch: 8, iters: 32, time: 0.003) nll: 0.553850 \n",
      "(GPU: 0, epoch: 8, iters: 768, time: 0.006) nll: 0.725366 \n",
      "(GPU: 0, epoch: 8, iters: 1568, time: 0.005) nll: 0.605253 \n",
      "(GPU: 0, epoch: 8, iters: 2368, time: 0.006) nll: 0.525698 \n",
      "(GPU: 0, epoch: 8, iters: 3168, time: 0.006) nll: 0.896898 \n",
      "(GPU: 0, epoch: 8, iters: 3968, time: 0.006) nll: 0.783197 \n",
      "(GPU: 0, epoch: 8, iters: 4768, time: 0.006) nll: 0.703846 \n",
      "(GPU: 0, epoch: 8, iters: 5568, time: 0.006) nll: 0.721026 \n",
      "(GPU: 0, epoch: 8, iters: 6368, time: 0.005) nll: 0.829670 \n",
      "(GPU: 0, epoch: 8, iters: 7168, time: 0.006) nll: 0.977063 \n",
      "(GPU: 0, epoch: 8, iters: 7968, time: 0.005) nll: 0.723122 \n",
      "(GPU: 0, epoch: 8, iters: 8768, time: 0.006) nll: 0.754224 \n",
      "(GPU: 0, epoch: 8, iters: 9568, time: 0.005) nll: 1.050836 \n",
      "(GPU: 0, epoch: 8, iters: 10368, time: 0.006) nll: 0.789424 \n",
      "(GPU: 0, epoch: 8, iters: 11168, time: 0.005) nll: 0.567696 \n",
      "(GPU: 0, epoch: 8, iters: 11968, time: 0.006) nll: 0.755509 \n",
      "(GPU: 0, epoch: 8, iters: 12768, time: 0.005) nll: 0.735979 \n",
      "(GPU: 0, epoch: 8, iters: 13568, time: 0.006) nll: 0.766041 \n",
      "(GPU: 0, epoch: 8, iters: 14368, time: 0.005) nll: 0.751617 \n",
      "saving the latest model (epoch 8, total_steps 1140000)\n",
      "(GPU: 0, epoch: 8, iters: 15168, time: 0.006) nll: 0.589108 \n",
      "(GPU: 0, epoch: 8, iters: 15968, time: 0.005) nll: 0.641159 \n",
      "(GPU: 0, epoch: 8, iters: 16768, time: 0.006) nll: 0.998216 \n",
      "(GPU: 0, epoch: 8, iters: 17568, time: 0.005) nll: 0.833872 \n",
      "(GPU: 0, epoch: 8, iters: 18368, time: 0.006) nll: 0.777732 \n",
      "(GPU: 0, epoch: 8, iters: 19168, time: 0.005) nll: 0.907058 \n",
      "(GPU: 0, epoch: 8, iters: 19968, time: 0.006) nll: 0.714569 \n",
      "(GPU: 0, epoch: 8, iters: 20768, time: 0.006) nll: 0.756667 \n",
      "(GPU: 0, epoch: 8, iters: 21568, time: 0.006) nll: 0.719007 \n",
      "(GPU: 0, epoch: 8, iters: 22368, time: 0.005) nll: 0.851305 \n",
      "(GPU: 0, epoch: 8, iters: 23168, time: 0.006) nll: 0.837582 \n",
      "(GPU: 0, epoch: 8, iters: 23968, time: 0.005) nll: 0.790696 \n",
      "(GPU: 0, epoch: 8, iters: 24768, time: 0.006) nll: 0.799677 \n",
      "(GPU: 0, epoch: 8, iters: 25568, time: 0.005) nll: 0.487224 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.006) nll: 0.763076 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.009) nll: 0.759833 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.009) nll: 0.870543 \n",
      "(GPU: 0, epoch: 8, iters: 27168, time: 0.005) nll: 1.145554 \n",
      "(GPU: 0, epoch: 8, iters: 27968, time: 0.006) nll: 0.788988 \n",
      "(GPU: 0, epoch: 8, iters: 28768, time: 0.005) nll: 0.647393 \n",
      "(GPU: 0, epoch: 8, iters: 29568, time: 0.006) nll: 0.810495 \n",
      "(GPU: 0, epoch: 8, iters: 30368, time: 0.005) nll: 0.702441 \n",
      "(GPU: 0, epoch: 8, iters: 31168, time: 0.006) nll: 0.803045 \n",
      "(GPU: 0, epoch: 8, iters: 31968, time: 0.005) nll: 0.860508 \n",
      "(GPU: 0, epoch: 8, iters: 32768, time: 0.006) nll: 0.460000 \n",
      "(GPU: 0, epoch: 8, iters: 33568, time: 0.005) nll: 0.570310 \n",
      "(GPU: 0, epoch: 8, iters: 34368, time: 0.006) nll: 0.641632 \n",
      "saving the latest model (epoch 8, total_steps 1160000)\n",
      "(GPU: 0, epoch: 8, iters: 35168, time: 0.005) nll: 1.003066 \n",
      "(GPU: 0, epoch: 8, iters: 35968, time: 0.006) nll: 0.757371 \n",
      "(GPU: 0, epoch: 8, iters: 36768, time: 0.005) nll: 0.684198 \n",
      "(GPU: 0, epoch: 8, iters: 37568, time: 0.006) nll: 0.889588 \n",
      "(GPU: 0, epoch: 8, iters: 38368, time: 0.005) nll: 0.870093 \n",
      "(GPU: 0, epoch: 8, iters: 39168, time: 0.006) nll: 0.990086 \n",
      "(GPU: 0, epoch: 8, iters: 39968, time: 0.005) nll: 1.084092 \n",
      "(GPU: 0, epoch: 8, iters: 40768, time: 0.006) nll: 0.551096 \n",
      "(GPU: 0, epoch: 8, iters: 41568, time: 0.005) nll: 1.155356 \n",
      "(GPU: 0, epoch: 8, iters: 42368, time: 0.006) nll: 0.473211 \n",
      "(GPU: 0, epoch: 8, iters: 43168, time: 0.006) nll: 0.917133 \n",
      "(GPU: 0, epoch: 8, iters: 43968, time: 0.006) nll: 1.292022 \n",
      "(GPU: 0, epoch: 8, iters: 44768, time: 0.006) nll: 0.890083 \n",
      "(GPU: 0, epoch: 8, iters: 45568, time: 0.006) nll: 0.778045 \n",
      "(GPU: 0, epoch: 8, iters: 46368, time: 0.005) nll: 1.009084 \n",
      "(GPU: 0, epoch: 8, iters: 47168, time: 0.006) nll: 0.796350 \n",
      "(GPU: 0, epoch: 8, iters: 47968, time: 0.005) nll: 0.797517 \n",
      "(GPU: 0, epoch: 8, iters: 48768, time: 0.006) nll: 0.869283 \n",
      "(GPU: 0, epoch: 8, iters: 49568, time: 0.006) nll: 0.789804 \n",
      "(GPU: 0, epoch: 8, iters: 50368, time: 0.006) nll: 0.625672 \n",
      "(GPU: 0, epoch: 8, iters: 51168, time: 0.005) nll: 0.552269 \n",
      "(GPU: 0, epoch: 8, iters: 51968, time: 0.006) nll: 0.543149 \n",
      "(GPU: 0, epoch: 8, iters: 52768, time: 0.006) nll: 0.835936 \n",
      "(GPU: 0, epoch: 8, iters: 53568, time: 0.006) nll: 0.677353 \n",
      "(GPU: 0, epoch: 8, iters: 54368, time: 0.005) nll: 0.713559 \n",
      "saving the latest model (epoch 8, total_steps 1180000)\n",
      "(GPU: 0, epoch: 8, iters: 55168, time: 0.006) nll: 1.126852 \n",
      "(GPU: 0, epoch: 8, iters: 55968, time: 0.005) nll: 0.801704 \n",
      "(GPU: 0, epoch: 8, iters: 56768, time: 0.006) nll: 0.601599 \n",
      "(GPU: 0, epoch: 8, iters: 57568, time: 0.005) nll: 0.856567 \n",
      "(GPU: 0, epoch: 8, iters: 58368, time: 0.006) nll: 0.698331 \n",
      "(GPU: 0, epoch: 8, iters: 59168, time: 0.005) nll: 0.966736 \n",
      "(GPU: 0, epoch: 8, iters: 59968, time: 0.006) nll: 0.591403 \n",
      "(GPU: 0, epoch: 8, iters: 60768, time: 0.005) nll: 0.738178 \n",
      "(GPU: 0, epoch: 8, iters: 61568, time: 0.006) nll: 0.895466 \n",
      "(GPU: 0, epoch: 8, iters: 62368, time: 0.005) nll: 0.694937 \n",
      "(GPU: 0, epoch: 8, iters: 63168, time: 0.006) nll: 0.710064 \n",
      "(GPU: 0, epoch: 8, iters: 63968, time: 0.005) nll: 0.795624 \n",
      "(GPU: 0, epoch: 8, iters: 64768, time: 0.006) nll: 0.635869 \n",
      "(GPU: 0, epoch: 8, iters: 65568, time: 0.005) nll: 0.727917 \n",
      "(GPU: 0, epoch: 8, iters: 66368, time: 0.006) nll: 0.765560 \n",
      "(GPU: 0, epoch: 8, iters: 67168, time: 0.005) nll: 0.942485 \n",
      "(GPU: 0, epoch: 8, iters: 67968, time: 0.006) nll: 0.664327 \n",
      "(GPU: 0, epoch: 8, iters: 68768, time: 0.006) nll: 0.811970 \n",
      "(GPU: 0, epoch: 8, iters: 69568, time: 0.006) nll: 0.648436 \n",
      "(GPU: 0, epoch: 8, iters: 70368, time: 0.005) nll: 0.510947 \n",
      "(GPU: 0, epoch: 8, iters: 71168, time: 0.006) nll: 0.487218 \n",
      "(GPU: 0, epoch: 8, iters: 71968, time: 0.005) nll: 0.524984 \n",
      "(GPU: 0, epoch: 8, iters: 72768, time: 0.006) nll: 0.851226 \n",
      "(GPU: 0, epoch: 8, iters: 73568, time: 0.006) nll: 0.938428 \n",
      "(GPU: 0, epoch: 8, iters: 74368, time: 0.006) nll: 0.647873 \n",
      "saving the latest model (epoch 8, total_steps 1200000)\n",
      "(GPU: 0, epoch: 8, iters: 75168, time: 0.005) nll: 0.710222 \n",
      "(GPU: 0, epoch: 8, iters: 75968, time: 0.006) nll: 0.778737 \n",
      "(GPU: 0, epoch: 8, iters: 76768, time: 0.005) nll: 0.616819 \n",
      "(GPU: 0, epoch: 8, iters: 77568, time: 0.005) nll: 0.725171 \n",
      "(GPU: 0, epoch: 8, iters: 78368, time: 0.005) nll: 0.752937 \n",
      "(GPU: 0, epoch: 8, iters: 79168, time: 0.006) nll: 0.592470 \n",
      "(GPU: 0, epoch: 8, iters: 79968, time: 0.005) nll: 0.708998 \n",
      "(GPU: 0, epoch: 8, iters: 80768, time: 0.006) nll: 0.994322 \n",
      "(GPU: 0, epoch: 8, iters: 81568, time: 0.005) nll: 0.705755 \n",
      "(GPU: 0, epoch: 8, iters: 82368, time: 0.006) nll: 0.834321 \n",
      "(GPU: 0, epoch: 8, iters: 83168, time: 0.005) nll: 0.803778 \n",
      "(GPU: 0, epoch: 8, iters: 83968, time: 0.006) nll: 0.435941 \n",
      "(GPU: 0, epoch: 8, iters: 84768, time: 0.005) nll: 1.053107 \n",
      "(GPU: 0, epoch: 8, iters: 85568, time: 0.006) nll: 0.651462 \n",
      "(GPU: 0, epoch: 8, iters: 86368, time: 0.005) nll: 0.706447 \n",
      "(GPU: 0, epoch: 8, iters: 87168, time: 0.006) nll: 0.737356 \n",
      "(GPU: 0, epoch: 8, iters: 87968, time: 0.005) nll: 0.636195 \n",
      "(GPU: 0, epoch: 8, iters: 88768, time: 0.006) nll: 0.758288 \n",
      "(GPU: 0, epoch: 8, iters: 89568, time: 0.005) nll: 0.875390 \n",
      "(GPU: 0, epoch: 8, iters: 90368, time: 0.006) nll: 0.644983 \n",
      "(GPU: 0, epoch: 8, iters: 91168, time: 0.005) nll: 0.772268 \n",
      "(GPU: 0, epoch: 8, iters: 91968, time: 0.006) nll: 0.865957 \n",
      "(GPU: 0, epoch: 8, iters: 92768, time: 0.005) nll: 0.603103 \n",
      "(GPU: 0, epoch: 8, iters: 93568, time: 0.006) nll: 0.740414 \n",
      "(GPU: 0, epoch: 8, iters: 94368, time: 0.005) nll: 0.687495 \n",
      "saving the latest model (epoch 8, total_steps 1220000)\n",
      "(GPU: 0, epoch: 8, iters: 95168, time: 0.006) nll: 0.828687 \n",
      "(GPU: 0, epoch: 8, iters: 95968, time: 0.005) nll: 0.686184 \n",
      "(GPU: 0, epoch: 8, iters: 96768, time: 0.006) nll: 0.762046 \n",
      "(GPU: 0, epoch: 8, iters: 97568, time: 0.005) nll: 0.798603 \n",
      "(GPU: 0, epoch: 8, iters: 98368, time: 0.006) nll: 0.948359 \n",
      "(GPU: 0, epoch: 8, iters: 99168, time: 0.006) nll: 0.648447 \n",
      "(GPU: 0, epoch: 8, iters: 99968, time: 0.006) nll: 0.796707 \n",
      "(GPU: 0, epoch: 8, iters: 100768, time: 0.005) nll: 0.803973 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 101568, time: 0.006) nll: 0.601412 \n",
      "(GPU: 0, epoch: 8, iters: 102368, time: 0.005) nll: 0.847802 \n",
      "(GPU: 0, epoch: 8, iters: 103168, time: 0.006) nll: 0.657041 \n",
      "(GPU: 0, epoch: 8, iters: 103968, time: 0.006) nll: 0.624236 \n",
      "(GPU: 0, epoch: 8, iters: 104768, time: 0.006) nll: 0.882735 \n",
      "(GPU: 0, epoch: 8, iters: 105568, time: 0.005) nll: 0.984121 \n",
      "(GPU: 0, epoch: 8, iters: 106368, time: 0.006) nll: 0.739206 \n",
      "(GPU: 0, epoch: 8, iters: 107168, time: 0.006) nll: 0.564698 \n",
      "(GPU: 0, epoch: 8, iters: 107968, time: 0.006) nll: 0.783153 \n",
      "(GPU: 0, epoch: 8, iters: 108768, time: 0.005) nll: 0.638247 \n",
      "(GPU: 0, epoch: 8, iters: 109568, time: 0.006) nll: 0.754946 \n",
      "(GPU: 0, epoch: 8, iters: 110368, time: 0.006) nll: 0.775556 \n",
      "(GPU: 0, epoch: 8, iters: 111168, time: 0.006) nll: 0.592672 \n",
      "(GPU: 0, epoch: 8, iters: 111968, time: 0.005) nll: 0.726946 \n",
      "(GPU: 0, epoch: 8, iters: 112768, time: 0.006) nll: 0.912052 \n",
      "(GPU: 0, epoch: 8, iters: 113568, time: 0.005) nll: 0.974045 \n",
      "(GPU: 0, epoch: 8, iters: 114368, time: 0.006) nll: 0.773887 \n",
      "saving the latest model (epoch 8, total_steps 1240000)\n",
      "(GPU: 0, epoch: 8, iters: 115168, time: 0.005) nll: 0.770124 \n",
      "(GPU: 0, epoch: 8, iters: 115968, time: 0.006) nll: 0.853069 \n",
      "(GPU: 0, epoch: 8, iters: 116768, time: 0.005) nll: 1.037994 \n",
      "(GPU: 0, epoch: 8, iters: 117568, time: 0.006) nll: 0.750434 \n",
      "(GPU: 0, epoch: 8, iters: 118368, time: 0.005) nll: 0.745144 \n",
      "(GPU: 0, epoch: 8, iters: 119168, time: 0.006) nll: 0.848564 \n",
      "(GPU: 0, epoch: 8, iters: 119968, time: 0.005) nll: 0.638978 \n",
      "(GPU: 0, epoch: 8, iters: 120768, time: 0.006) nll: 0.697288 \n",
      "(GPU: 0, epoch: 8, iters: 121568, time: 0.005) nll: 0.617448 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.006) nll: 0.648375 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.009) nll: 0.643019 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.009) nll: 0.809460 \n",
      "(GPU: 0, epoch: 8, iters: 123168, time: 0.005) nll: 1.158885 \n",
      "(GPU: 0, epoch: 8, iters: 123968, time: 0.006) nll: 0.882563 \n",
      "(GPU: 0, epoch: 8, iters: 124768, time: 0.006) nll: 0.903411 \n",
      "(GPU: 0, epoch: 8, iters: 125568, time: 0.006) nll: 0.759776 \n",
      "(GPU: 0, epoch: 8, iters: 126368, time: 0.005) nll: 0.934984 \n",
      "(GPU: 0, epoch: 8, iters: 127168, time: 0.006) nll: 0.986743 \n",
      "(GPU: 0, epoch: 8, iters: 127968, time: 0.005) nll: 1.006877 \n",
      "(GPU: 0, epoch: 8, iters: 128768, time: 0.006) nll: 0.924993 \n",
      "(GPU: 0, epoch: 8, iters: 129568, time: 0.005) nll: 0.601822 \n",
      "(GPU: 0, epoch: 8, iters: 130368, time: 0.006) nll: 0.827478 \n",
      "(GPU: 0, epoch: 8, iters: 131168, time: 0.005) nll: 0.651492 \n",
      "(GPU: 0, epoch: 8, iters: 131968, time: 0.006) nll: 0.883531 \n",
      "(GPU: 0, epoch: 8, iters: 132768, time: 0.005) nll: 0.751107 \n",
      "(GPU: 0, epoch: 8, iters: 133568, time: 0.006) nll: 0.612227 \n",
      "(GPU: 0, epoch: 8, iters: 134368, time: 0.005) nll: 0.804577 \n",
      "saving the latest model (epoch 8, total_steps 1260000)\n",
      "(GPU: 0, epoch: 8, iters: 135168, time: 0.006) nll: 0.483925 \n",
      "(GPU: 0, epoch: 8, iters: 135968, time: 0.006) nll: 0.756797 \n",
      "(GPU: 0, epoch: 8, iters: 136768, time: 0.006) nll: 0.728837 \n",
      "(GPU: 0, epoch: 8, iters: 137568, time: 0.005) nll: 0.804038 \n",
      "(GPU: 0, epoch: 8, iters: 138368, time: 0.006) nll: 0.861182 \n",
      "(GPU: 0, epoch: 8, iters: 139168, time: 0.005) nll: 0.735554 \n",
      "(GPU: 0, epoch: 8, iters: 139968, time: 0.006) nll: 0.915265 \n",
      "[*] End of epoch 8 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000900\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3151/4397 [09:56<03:50,  5.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 32, time: 0.003) nll: 0.966446 \n",
      "(GPU: 0, epoch: 9, iters: 32, time: 0.003) nll: 0.851787 \n",
      "(GPU: 0, epoch: 9, iters: 64, time: 0.003) nll: 0.684534 \n",
      "(GPU: 0, epoch: 9, iters: 864, time: 0.005) nll: 0.652391 \n",
      "(GPU: 0, epoch: 9, iters: 1664, time: 0.006) nll: 0.609303 \n",
      "(GPU: 0, epoch: 9, iters: 2464, time: 0.005) nll: 0.939817 \n",
      "(GPU: 0, epoch: 9, iters: 3264, time: 0.006) nll: 0.828243 \n",
      "(GPU: 0, epoch: 9, iters: 4064, time: 0.005) nll: 0.845353 \n",
      "(GPU: 0, epoch: 9, iters: 4864, time: 0.006) nll: 1.034908 \n",
      "(GPU: 0, epoch: 9, iters: 5664, time: 0.005) nll: 0.857623 \n",
      "(GPU: 0, epoch: 9, iters: 6464, time: 0.006) nll: 0.729297 \n",
      "(GPU: 0, epoch: 9, iters: 7264, time: 0.006) nll: 0.775944 \n",
      "(GPU: 0, epoch: 9, iters: 8064, time: 0.006) nll: 0.798670 \n",
      "(GPU: 0, epoch: 9, iters: 8864, time: 0.005) nll: 0.890735 \n",
      "(GPU: 0, epoch: 9, iters: 9664, time: 0.006) nll: 0.826712 \n",
      "(GPU: 0, epoch: 9, iters: 10464, time: 0.006) nll: 0.911994 \n",
      "(GPU: 0, epoch: 9, iters: 11264, time: 0.006) nll: 0.920072 \n",
      "(GPU: 0, epoch: 9, iters: 12064, time: 0.005) nll: 0.645699 \n",
      "(GPU: 0, epoch: 9, iters: 12864, time: 0.006) nll: 0.736626 \n",
      "(GPU: 0, epoch: 9, iters: 13664, time: 0.005) nll: 0.820929 \n",
      "saving the latest model (epoch 9, total_steps 1280000)\n",
      "(GPU: 0, epoch: 9, iters: 14464, time: 0.006) nll: 0.651998 \n",
      "(GPU: 0, epoch: 9, iters: 15264, time: 0.005) nll: 0.725672 \n",
      "(GPU: 0, epoch: 9, iters: 16064, time: 0.006) nll: 0.755028 \n",
      "(GPU: 0, epoch: 9, iters: 16864, time: 0.006) nll: 0.575398 \n",
      "(GPU: 0, epoch: 9, iters: 17664, time: 0.006) nll: 0.832381 \n",
      "(GPU: 0, epoch: 9, iters: 18464, time: 0.005) nll: 0.541448 \n",
      "(GPU: 0, epoch: 9, iters: 19264, time: 0.006) nll: 0.664149 \n",
      "(GPU: 0, epoch: 9, iters: 20064, time: 0.005) nll: 0.694307 \n",
      "(GPU: 0, epoch: 9, iters: 20864, time: 0.006) nll: 0.780027 \n",
      "(GPU: 0, epoch: 9, iters: 21664, time: 0.005) nll: 0.697804 \n",
      "(GPU: 0, epoch: 9, iters: 22464, time: 0.006) nll: 0.890730 \n",
      "(GPU: 0, epoch: 9, iters: 23264, time: 0.006) nll: 0.736807 \n",
      "(GPU: 0, epoch: 9, iters: 24064, time: 0.006) nll: 0.793842 \n",
      "(GPU: 0, epoch: 9, iters: 24864, time: 0.005) nll: 0.934895 \n",
      "(GPU: 0, epoch: 9, iters: 25664, time: 0.006) nll: 1.441387 \n",
      "(GPU: 0, epoch: 9, iters: 26464, time: 0.005) nll: 0.787741 \n",
      "(GPU: 0, epoch: 9, iters: 27264, time: 0.006) nll: 0.820976 \n",
      "(GPU: 0, epoch: 9, iters: 28064, time: 0.005) nll: 0.676036 \n",
      "(GPU: 0, epoch: 9, iters: 28864, time: 0.006) nll: 1.241688 \n",
      "(GPU: 0, epoch: 9, iters: 29664, time: 0.005) nll: 0.757529 \n",
      "(GPU: 0, epoch: 9, iters: 30464, time: 0.006) nll: 0.577251 \n",
      "(GPU: 0, epoch: 9, iters: 31264, time: 0.005) nll: 0.746965 \n",
      "(GPU: 0, epoch: 9, iters: 32064, time: 0.006) nll: 0.654312 \n",
      "(GPU: 0, epoch: 9, iters: 32864, time: 0.006) nll: 0.688395 \n",
      "(GPU: 0, epoch: 9, iters: 33664, time: 0.006) nll: 0.589751 \n",
      "saving the latest model (epoch 9, total_steps 1300000)\n",
      "(GPU: 0, epoch: 9, iters: 34464, time: 0.005) nll: 0.961076 \n",
      "(GPU: 0, epoch: 9, iters: 35264, time: 0.006) nll: 0.721368 \n",
      "(GPU: 0, epoch: 9, iters: 36064, time: 0.005) nll: 0.707061 \n",
      "(GPU: 0, epoch: 9, iters: 36864, time: 0.006) nll: 0.777358 \n",
      "(GPU: 0, epoch: 9, iters: 37664, time: 0.006) nll: 0.745611 \n",
      "(GPU: 0, epoch: 9, iters: 38464, time: 0.006) nll: 0.800703 \n",
      "(GPU: 0, epoch: 9, iters: 39264, time: 0.006) nll: 0.516553 \n",
      "(GPU: 0, epoch: 9, iters: 40064, time: 0.006) nll: 0.688509 \n",
      "(GPU: 0, epoch: 9, iters: 40864, time: 0.005) nll: 0.905178 \n",
      "(GPU: 0, epoch: 9, iters: 41664, time: 0.006) nll: 1.000774 \n",
      "(GPU: 0, epoch: 9, iters: 42464, time: 0.006) nll: 0.549094 \n",
      "(GPU: 0, epoch: 9, iters: 43264, time: 0.006) nll: 0.814670 \n",
      "(GPU: 0, epoch: 9, iters: 44064, time: 0.005) nll: 0.841131 \n",
      "(GPU: 0, epoch: 9, iters: 44864, time: 0.006) nll: 0.865694 \n",
      "(GPU: 0, epoch: 9, iters: 45664, time: 0.005) nll: 0.694393 \n",
      "(GPU: 0, epoch: 9, iters: 46464, time: 0.006) nll: 0.698434 \n",
      "(GPU: 0, epoch: 9, iters: 47264, time: 0.005) nll: 0.685493 \n",
      "(GPU: 0, epoch: 9, iters: 48064, time: 0.006) nll: 0.672422 \n",
      "(GPU: 0, epoch: 9, iters: 48864, time: 0.005) nll: 0.841445 \n",
      "(GPU: 0, epoch: 9, iters: 49664, time: 0.006) nll: 0.713981 \n",
      "(GPU: 0, epoch: 9, iters: 50464, time: 0.005) nll: 1.035980 \n",
      "(GPU: 0, epoch: 9, iters: 51264, time: 0.006) nll: 0.831682 \n",
      "(GPU: 0, epoch: 9, iters: 52064, time: 0.005) nll: 0.659462 \n",
      "(GPU: 0, epoch: 9, iters: 52864, time: 0.006) nll: 0.828240 \n",
      "(GPU: 0, epoch: 9, iters: 53664, time: 0.005) nll: 0.766614 \n",
      "saving the latest model (epoch 9, total_steps 1320000)\n",
      "(GPU: 0, epoch: 9, iters: 54464, time: 0.006) nll: 0.707712 \n",
      "(GPU: 0, epoch: 9, iters: 55264, time: 0.005) nll: 0.584537 \n",
      "(GPU: 0, epoch: 9, iters: 56064, time: 0.006) nll: 0.941985 \n",
      "(GPU: 0, epoch: 9, iters: 56864, time: 0.005) nll: 0.995933 \n",
      "(GPU: 0, epoch: 9, iters: 57664, time: 0.006) nll: 1.061982 \n",
      "(GPU: 0, epoch: 9, iters: 58464, time: 0.005) nll: 0.877001 \n",
      "(GPU: 0, epoch: 9, iters: 59264, time: 0.006) nll: 0.830387 \n",
      "(GPU: 0, epoch: 9, iters: 60064, time: 0.005) nll: 0.746819 \n",
      "(GPU: 0, epoch: 9, iters: 60864, time: 0.006) nll: 0.659894 \n",
      "(GPU: 0, epoch: 9, iters: 61664, time: 0.006) nll: 0.747484 \n",
      "(GPU: 0, epoch: 9, iters: 62464, time: 0.006) nll: 0.711966 \n",
      "(GPU: 0, epoch: 9, iters: 63264, time: 0.005) nll: 0.499877 \n",
      "(GPU: 0, epoch: 9, iters: 64064, time: 0.006) nll: 0.830116 \n",
      "(GPU: 0, epoch: 9, iters: 64864, time: 0.006) nll: 0.611273 \n",
      "(GPU: 0, epoch: 9, iters: 65664, time: 0.006) nll: 0.888006 \n",
      "(GPU: 0, epoch: 9, iters: 66464, time: 0.005) nll: 0.913270 \n",
      "(GPU: 0, epoch: 9, iters: 67264, time: 0.006) nll: 0.554720 \n",
      "(GPU: 0, epoch: 9, iters: 68064, time: 0.005) nll: 0.762813 \n",
      "(GPU: 0, epoch: 9, iters: 68864, time: 0.006) nll: 0.729146 \n",
      "(GPU: 0, epoch: 9, iters: 69664, time: 0.005) nll: 0.681278 \n",
      "(GPU: 0, epoch: 9, iters: 70464, time: 0.006) nll: 0.804628 \n",
      "(GPU: 0, epoch: 9, iters: 71264, time: 0.005) nll: 0.791166 \n",
      "(GPU: 0, epoch: 9, iters: 72064, time: 0.006) nll: 0.860472 \n",
      "(GPU: 0, epoch: 9, iters: 72864, time: 0.005) nll: 0.916619 \n",
      "(GPU: 0, epoch: 9, iters: 73664, time: 0.006) nll: 0.561269 \n",
      "saving the latest model (epoch 9, total_steps 1340000)\n",
      "(GPU: 0, epoch: 9, iters: 74464, time: 0.005) nll: 1.230959 \n",
      "(GPU: 0, epoch: 9, iters: 75264, time: 0.006) nll: 0.859232 \n",
      "(GPU: 0, epoch: 9, iters: 76064, time: 0.005) nll: 0.775523 \n",
      "(GPU: 0, epoch: 9, iters: 76864, time: 0.006) nll: 0.622693 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.005) nll: 0.589054 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.008) nll: 0.584796 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.008) nll: 0.684542 \n",
      "(GPU: 0, epoch: 9, iters: 78464, time: 0.006) nll: 0.757520 \n",
      "(GPU: 0, epoch: 9, iters: 79264, time: 0.005) nll: 0.771211 \n",
      "(GPU: 0, epoch: 9, iters: 80064, time: 0.006) nll: 0.580379 \n",
      "(GPU: 0, epoch: 9, iters: 80864, time: 0.005) nll: 0.699518 \n",
      "(GPU: 0, epoch: 9, iters: 81664, time: 0.006) nll: 0.963458 \n",
      "(GPU: 0, epoch: 9, iters: 82464, time: 0.005) nll: 0.771001 \n",
      "(GPU: 0, epoch: 9, iters: 83264, time: 0.006) nll: 0.895991 \n",
      "(GPU: 0, epoch: 9, iters: 84064, time: 0.006) nll: 0.907573 \n",
      "(GPU: 0, epoch: 9, iters: 84864, time: 0.006) nll: 0.803777 \n",
      "(GPU: 0, epoch: 9, iters: 85664, time: 0.005) nll: 0.795764 \n",
      "(GPU: 0, epoch: 9, iters: 86464, time: 0.006) nll: 0.792561 \n",
      "(GPU: 0, epoch: 9, iters: 87264, time: 0.005) nll: 0.566745 \n",
      "(GPU: 0, epoch: 9, iters: 88064, time: 0.006) nll: 0.914501 \n",
      "(GPU: 0, epoch: 9, iters: 88864, time: 0.005) nll: 0.553200 \n",
      "(GPU: 0, epoch: 9, iters: 89664, time: 0.006) nll: 0.689004 \n",
      "(GPU: 0, epoch: 9, iters: 90464, time: 0.005) nll: 0.986108 \n",
      "(GPU: 0, epoch: 9, iters: 91264, time: 0.006) nll: 0.816531 \n",
      "(GPU: 0, epoch: 9, iters: 92064, time: 0.005) nll: 0.691012 \n",
      "(GPU: 0, epoch: 9, iters: 92864, time: 0.006) nll: 0.660142 \n",
      "(GPU: 0, epoch: 9, iters: 93664, time: 0.005) nll: 0.770753 \n",
      "saving the latest model (epoch 9, total_steps 1360000)\n",
      "(GPU: 0, epoch: 9, iters: 94464, time: 0.006) nll: 0.651240 \n",
      "(GPU: 0, epoch: 9, iters: 95264, time: 0.006) nll: 0.685427 \n",
      "(GPU: 0, epoch: 9, iters: 96064, time: 0.006) nll: 1.059045 \n",
      "(GPU: 0, epoch: 9, iters: 96864, time: 0.005) nll: 0.738553 \n",
      "(GPU: 0, epoch: 9, iters: 97664, time: 0.006) nll: 0.896520 \n",
      "(GPU: 0, epoch: 9, iters: 98464, time: 0.005) nll: 0.951241 \n",
      "(GPU: 0, epoch: 9, iters: 99264, time: 0.006) nll: 0.792393 \n",
      "(GPU: 0, epoch: 9, iters: 100064, time: 0.005) nll: 0.610476 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 100864, time: 0.006) nll: 0.856824 \n",
      "(GPU: 0, epoch: 9, iters: 101664, time: 0.005) nll: 0.656631 \n",
      "(GPU: 0, epoch: 9, iters: 102464, time: 0.006) nll: 0.706267 \n",
      "(GPU: 0, epoch: 9, iters: 103264, time: 0.005) nll: 0.860553 \n",
      "(GPU: 0, epoch: 9, iters: 104064, time: 0.006) nll: 0.651777 \n",
      "(GPU: 0, epoch: 9, iters: 104864, time: 0.005) nll: 0.973002 \n",
      "(GPU: 0, epoch: 9, iters: 105664, time: 0.006) nll: 0.896708 \n",
      "(GPU: 0, epoch: 9, iters: 106464, time: 0.005) nll: 0.669439 \n",
      "(GPU: 0, epoch: 9, iters: 107264, time: 0.006) nll: 0.690785 \n",
      "(GPU: 0, epoch: 9, iters: 108064, time: 0.005) nll: 0.699975 \n",
      "(GPU: 0, epoch: 9, iters: 108864, time: 0.006) nll: 0.824876 \n",
      "(GPU: 0, epoch: 9, iters: 109664, time: 0.005) nll: 0.874455 \n",
      "(GPU: 0, epoch: 9, iters: 110464, time: 0.006) nll: 0.734451 \n",
      "(GPU: 0, epoch: 9, iters: 111264, time: 0.006) nll: 0.567012 \n",
      "(GPU: 0, epoch: 9, iters: 112064, time: 0.006) nll: 0.735721 \n",
      "(GPU: 0, epoch: 9, iters: 112864, time: 0.005) nll: 0.925285 \n",
      "(GPU: 0, epoch: 9, iters: 113664, time: 0.006) nll: 0.642089 \n",
      "saving the latest model (epoch 9, total_steps 1380000)\n",
      "(GPU: 0, epoch: 9, iters: 114464, time: 0.005) nll: 0.899926 \n",
      "(GPU: 0, epoch: 9, iters: 115264, time: 0.006) nll: 0.825573 \n",
      "(GPU: 0, epoch: 9, iters: 116064, time: 0.006) nll: 0.733940 \n",
      "(GPU: 0, epoch: 9, iters: 116864, time: 0.006) nll: 0.613623 \n",
      "(GPU: 0, epoch: 9, iters: 117664, time: 0.005) nll: 0.937476 \n",
      "(GPU: 0, epoch: 9, iters: 118464, time: 0.006) nll: 0.748876 \n",
      "(GPU: 0, epoch: 9, iters: 119264, time: 0.005) nll: 0.938049 \n",
      "(GPU: 0, epoch: 9, iters: 120064, time: 0.006) nll: 0.833060 \n",
      "(GPU: 0, epoch: 9, iters: 120864, time: 0.005) nll: 0.989375 \n",
      "(GPU: 0, epoch: 9, iters: 121664, time: 0.006) nll: 0.659886 \n",
      "(GPU: 0, epoch: 9, iters: 122464, time: 0.005) nll: 0.804531 \n",
      "(GPU: 0, epoch: 9, iters: 123264, time: 0.006) nll: 0.599492 \n",
      "(GPU: 0, epoch: 9, iters: 124064, time: 0.005) nll: 0.736633 \n",
      "(GPU: 0, epoch: 9, iters: 124864, time: 0.006) nll: 0.687467 \n",
      "(GPU: 0, epoch: 9, iters: 125664, time: 0.006) nll: 0.687752 \n",
      "(GPU: 0, epoch: 9, iters: 126464, time: 0.006) nll: 0.706132 \n",
      "(GPU: 0, epoch: 9, iters: 127264, time: 0.005) nll: 0.553450 \n",
      "(GPU: 0, epoch: 9, iters: 128064, time: 0.006) nll: 0.874934 \n",
      "(GPU: 0, epoch: 9, iters: 128864, time: 0.005) nll: 0.968104 \n",
      "(GPU: 0, epoch: 9, iters: 129664, time: 0.006) nll: 0.812859 \n",
      "(GPU: 0, epoch: 9, iters: 130464, time: 0.006) nll: 0.657832 \n",
      "(GPU: 0, epoch: 9, iters: 131264, time: 0.006) nll: 0.761306 \n",
      "(GPU: 0, epoch: 9, iters: 132064, time: 0.006) nll: 0.784804 \n",
      "(GPU: 0, epoch: 9, iters: 132864, time: 0.006) nll: 0.730168 \n",
      "(GPU: 0, epoch: 9, iters: 133664, time: 0.005) nll: 0.802850 \n",
      "saving the latest model (epoch 9, total_steps 1400000)\n",
      "(GPU: 0, epoch: 9, iters: 134464, time: 0.006) nll: 0.657446 \n",
      "(GPU: 0, epoch: 9, iters: 135264, time: 0.005) nll: 0.821894 \n",
      "(GPU: 0, epoch: 9, iters: 136064, time: 0.006) nll: 0.787162 \n",
      "(GPU: 0, epoch: 9, iters: 136864, time: 0.005) nll: 0.815109 \n",
      "(GPU: 0, epoch: 9, iters: 137664, time: 0.006) nll: 0.608075 \n",
      "(GPU: 0, epoch: 9, iters: 138464, time: 0.005) nll: 1.019199 \n",
      "(GPU: 0, epoch: 9, iters: 139264, time: 0.006) nll: 0.610906 \n",
      "(GPU: 0, epoch: 9, iters: 140064, time: 0.005) nll: 0.756745 \n",
      "saving the model at the end of epoch 9, iters 1407040\n",
      "([test] GPU: 0, epoch: 9) \n",
      "OrderedDict()\n",
      "[*] End of epoch 9 / 25 \t Time Taken: 838 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0001000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3079/4397 [09:43<04:00,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 32, time: 0.003) nll: 0.643426 \n",
      "(GPU: 0, epoch: 10, iters: 32, time: 0.003) nll: 0.846420 \n",
      "(GPU: 0, epoch: 10, iters: 160, time: 0.005) nll: 0.828046 \n",
      "(GPU: 0, epoch: 10, iters: 960, time: 0.006) nll: 0.669780 \n",
      "(GPU: 0, epoch: 10, iters: 1760, time: 0.005) nll: 0.767989 \n",
      "(GPU: 0, epoch: 10, iters: 2560, time: 0.006) nll: 0.935259 \n",
      "(GPU: 0, epoch: 10, iters: 3360, time: 0.005) nll: 0.724065 \n",
      "(GPU: 0, epoch: 10, iters: 4160, time: 0.006) nll: 0.629467 \n",
      "(GPU: 0, epoch: 10, iters: 4960, time: 0.005) nll: 0.698392 \n",
      "(GPU: 0, epoch: 10, iters: 5760, time: 0.006) nll: 0.688145 \n",
      "(GPU: 0, epoch: 10, iters: 6560, time: 0.005) nll: 0.848214 \n",
      "(GPU: 0, epoch: 10, iters: 7360, time: 0.006) nll: 0.868457 \n",
      "(GPU: 0, epoch: 10, iters: 8160, time: 0.005) nll: 0.742605 \n",
      "(GPU: 0, epoch: 10, iters: 8960, time: 0.006) nll: 1.046941 \n",
      "(GPU: 0, epoch: 10, iters: 9760, time: 0.006) nll: 0.696154 \n",
      "(GPU: 0, epoch: 10, iters: 10560, time: 0.006) nll: 0.828292 \n",
      "(GPU: 0, epoch: 10, iters: 11360, time: 0.005) nll: 0.639201 \n",
      "(GPU: 0, epoch: 10, iters: 12160, time: 0.006) nll: 0.860911 \n",
      "(GPU: 0, epoch: 10, iters: 12960, time: 0.005) nll: 0.731017 \n",
      "saving the latest model (epoch 10, total_steps 1420000)\n",
      "(GPU: 0, epoch: 10, iters: 13760, time: 0.006) nll: 0.879880 \n",
      "(GPU: 0, epoch: 10, iters: 14560, time: 0.006) nll: 0.809750 \n",
      "(GPU: 0, epoch: 10, iters: 15360, time: 0.006) nll: 0.762316 \n",
      "(GPU: 0, epoch: 10, iters: 16160, time: 0.005) nll: 0.747705 \n",
      "(GPU: 0, epoch: 10, iters: 16960, time: 0.006) nll: 1.071710 \n",
      "(GPU: 0, epoch: 10, iters: 17760, time: 0.006) nll: 0.781368 \n",
      "(GPU: 0, epoch: 10, iters: 18560, time: 0.006) nll: 0.571258 \n",
      "(GPU: 0, epoch: 10, iters: 19360, time: 0.006) nll: 0.552481 \n",
      "(GPU: 0, epoch: 10, iters: 20160, time: 0.006) nll: 0.733058 \n",
      "(GPU: 0, epoch: 10, iters: 20960, time: 0.005) nll: 0.741510 \n",
      "(GPU: 0, epoch: 10, iters: 21760, time: 0.006) nll: 0.915999 \n",
      "(GPU: 0, epoch: 10, iters: 22560, time: 0.005) nll: 0.565069 \n",
      "(GPU: 0, epoch: 10, iters: 23360, time: 0.006) nll: 0.711978 \n",
      "(GPU: 0, epoch: 10, iters: 24160, time: 0.006) nll: 0.677349 \n",
      "(GPU: 0, epoch: 10, iters: 24960, time: 0.006) nll: 0.869886 \n",
      "(GPU: 0, epoch: 10, iters: 25760, time: 0.006) nll: 0.688218 \n",
      "(GPU: 0, epoch: 10, iters: 26560, time: 0.006) nll: 0.843291 \n",
      "(GPU: 0, epoch: 10, iters: 27360, time: 0.005) nll: 0.736464 \n",
      "(GPU: 0, epoch: 10, iters: 28160, time: 0.006) nll: 1.383422 \n",
      "(GPU: 0, epoch: 10, iters: 28960, time: 0.005) nll: 0.813322 \n",
      "(GPU: 0, epoch: 10, iters: 29760, time: 0.006) nll: 0.879239 \n",
      "(GPU: 0, epoch: 10, iters: 30560, time: 0.006) nll: 0.778780 \n",
      "(GPU: 0, epoch: 10, iters: 31360, time: 0.006) nll: 0.583296 \n",
      "(GPU: 0, epoch: 10, iters: 32160, time: 0.005) nll: 0.659222 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.006) nll: 0.713474 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.009) nll: 0.711141 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.009) nll: 0.453665 \n",
      "saving the latest model (epoch 10, total_steps 1440000)\n",
      "(GPU: 0, epoch: 10, iters: 33760, time: 0.005) nll: 0.695913 \n",
      "(GPU: 0, epoch: 10, iters: 34560, time: 0.006) nll: 0.798733 \n",
      "(GPU: 0, epoch: 10, iters: 35360, time: 0.006) nll: 0.653637 \n",
      "(GPU: 0, epoch: 10, iters: 36160, time: 0.006) nll: 0.779257 \n",
      "(GPU: 0, epoch: 10, iters: 36960, time: 0.005) nll: 0.729074 \n",
      "(GPU: 0, epoch: 10, iters: 37760, time: 0.006) nll: 0.829102 \n",
      "(GPU: 0, epoch: 10, iters: 38560, time: 0.005) nll: 0.821376 \n",
      "(GPU: 0, epoch: 10, iters: 39360, time: 0.006) nll: 0.685281 \n",
      "(GPU: 0, epoch: 10, iters: 40160, time: 0.006) nll: 0.650803 \n",
      "(GPU: 0, epoch: 10, iters: 40960, time: 0.006) nll: 0.850986 \n",
      "(GPU: 0, epoch: 10, iters: 41760, time: 0.005) nll: 0.599417 \n",
      "(GPU: 0, epoch: 10, iters: 42560, time: 0.006) nll: 0.713499 \n",
      "(GPU: 0, epoch: 10, iters: 43360, time: 0.006) nll: 0.707186 \n",
      "(GPU: 0, epoch: 10, iters: 44160, time: 0.006) nll: 0.722373 \n",
      "(GPU: 0, epoch: 10, iters: 44960, time: 0.005) nll: 0.922535 \n",
      "(GPU: 0, epoch: 10, iters: 45760, time: 0.006) nll: 0.836886 \n",
      "(GPU: 0, epoch: 10, iters: 46560, time: 0.006) nll: 0.669892 \n",
      "(GPU: 0, epoch: 10, iters: 47360, time: 0.006) nll: 0.637466 \n",
      "(GPU: 0, epoch: 10, iters: 48160, time: 0.005) nll: 0.888022 \n",
      "(GPU: 0, epoch: 10, iters: 48960, time: 0.006) nll: 0.751561 \n",
      "(GPU: 0, epoch: 10, iters: 49760, time: 0.005) nll: 0.697673 \n",
      "(GPU: 0, epoch: 10, iters: 50560, time: 0.006) nll: 0.659079 \n",
      "(GPU: 0, epoch: 10, iters: 51360, time: 0.005) nll: 0.796963 \n",
      "(GPU: 0, epoch: 10, iters: 52160, time: 0.006) nll: 0.515112 \n",
      "(GPU: 0, epoch: 10, iters: 52960, time: 0.005) nll: 0.843064 \n",
      "saving the latest model (epoch 10, total_steps 1460000)\n",
      "(GPU: 0, epoch: 10, iters: 53760, time: 0.006) nll: 0.994686 \n",
      "(GPU: 0, epoch: 10, iters: 54560, time: 0.005) nll: 0.672552 \n",
      "(GPU: 0, epoch: 10, iters: 55360, time: 0.006) nll: 0.710276 \n",
      "(GPU: 0, epoch: 10, iters: 56160, time: 0.005) nll: 0.564669 \n",
      "(GPU: 0, epoch: 10, iters: 56960, time: 0.006) nll: 0.891889 \n",
      "(GPU: 0, epoch: 10, iters: 57760, time: 0.005) nll: 1.130738 \n",
      "(GPU: 0, epoch: 10, iters: 58560, time: 0.006) nll: 0.805906 \n",
      "(GPU: 0, epoch: 10, iters: 59360, time: 0.006) nll: 0.598298 \n",
      "(GPU: 0, epoch: 10, iters: 60160, time: 0.006) nll: 1.149331 \n",
      "(GPU: 0, epoch: 10, iters: 60960, time: 0.005) nll: 0.837928 \n",
      "(GPU: 0, epoch: 10, iters: 61760, time: 0.006) nll: 0.845815 \n",
      "(GPU: 0, epoch: 10, iters: 62560, time: 0.006) nll: 0.989604 \n",
      "(GPU: 0, epoch: 10, iters: 63360, time: 0.006) nll: 0.743670 \n",
      "(GPU: 0, epoch: 10, iters: 64160, time: 0.005) nll: 0.558946 \n",
      "(GPU: 0, epoch: 10, iters: 64960, time: 0.006) nll: 0.608220 \n",
      "(GPU: 0, epoch: 10, iters: 65760, time: 0.005) nll: 0.975898 \n",
      "(GPU: 0, epoch: 10, iters: 66560, time: 0.006) nll: 0.761868 \n",
      "(GPU: 0, epoch: 10, iters: 67360, time: 0.005) nll: 0.672078 \n",
      "(GPU: 0, epoch: 10, iters: 68160, time: 0.006) nll: 1.026220 \n",
      "(GPU: 0, epoch: 10, iters: 68960, time: 0.005) nll: 0.879329 \n",
      "(GPU: 0, epoch: 10, iters: 69760, time: 0.006) nll: 0.830694 \n",
      "(GPU: 0, epoch: 10, iters: 70560, time: 0.006) nll: 0.714682 \n",
      "(GPU: 0, epoch: 10, iters: 71360, time: 0.006) nll: 0.840629 \n",
      "(GPU: 0, epoch: 10, iters: 72160, time: 0.005) nll: 1.030539 \n",
      "(GPU: 0, epoch: 10, iters: 72960, time: 0.006) nll: 0.842691 \n",
      "saving the latest model (epoch 10, total_steps 1480000)\n",
      "(GPU: 0, epoch: 10, iters: 73760, time: 0.005) nll: 0.771977 \n",
      "(GPU: 0, epoch: 10, iters: 74560, time: 0.006) nll: 0.595395 \n",
      "(GPU: 0, epoch: 10, iters: 75360, time: 0.005) nll: 0.596997 \n",
      "(GPU: 0, epoch: 10, iters: 76160, time: 0.006) nll: 0.652487 \n",
      "(GPU: 0, epoch: 10, iters: 76960, time: 0.005) nll: 0.592890 \n",
      "(GPU: 0, epoch: 10, iters: 77760, time: 0.006) nll: 0.648406 \n",
      "(GPU: 0, epoch: 10, iters: 78560, time: 0.005) nll: 0.733565 \n",
      "(GPU: 0, epoch: 10, iters: 79360, time: 0.006) nll: 0.904648 \n",
      "(GPU: 0, epoch: 10, iters: 80160, time: 0.006) nll: 0.952247 \n",
      "(GPU: 0, epoch: 10, iters: 80960, time: 0.006) nll: 0.659166 \n",
      "(GPU: 0, epoch: 10, iters: 81760, time: 0.005) nll: 0.752037 \n",
      "(GPU: 0, epoch: 10, iters: 82560, time: 0.006) nll: 0.684580 \n",
      "(GPU: 0, epoch: 10, iters: 83360, time: 0.005) nll: 0.892371 \n",
      "(GPU: 0, epoch: 10, iters: 84160, time: 0.006) nll: 0.743121 \n",
      "(GPU: 0, epoch: 10, iters: 84960, time: 0.005) nll: 0.742029 \n",
      "(GPU: 0, epoch: 10, iters: 85760, time: 0.006) nll: 0.849826 \n",
      "(GPU: 0, epoch: 10, iters: 86560, time: 0.006) nll: 0.793099 \n",
      "(GPU: 0, epoch: 10, iters: 87360, time: 0.006) nll: 0.821998 \n",
      "(GPU: 0, epoch: 10, iters: 88160, time: 0.005) nll: 0.703933 \n",
      "(GPU: 0, epoch: 10, iters: 88960, time: 0.006) nll: 0.626478 \n",
      "(GPU: 0, epoch: 10, iters: 89760, time: 0.005) nll: 0.851461 \n",
      "(GPU: 0, epoch: 10, iters: 90560, time: 0.006) nll: 0.841907 \n",
      "(GPU: 0, epoch: 10, iters: 91360, time: 0.006) nll: 1.011279 \n",
      "(GPU: 0, epoch: 10, iters: 92160, time: 0.006) nll: 0.838230 \n",
      "(GPU: 0, epoch: 10, iters: 92960, time: 0.005) nll: 0.773643 \n",
      "saving the latest model (epoch 10, total_steps 1500000)\n",
      "(GPU: 0, epoch: 10, iters: 93760, time: 0.006) nll: 0.801837 \n",
      "(GPU: 0, epoch: 10, iters: 94560, time: 0.005) nll: 0.782950 \n",
      "(GPU: 0, epoch: 10, iters: 95360, time: 0.006) nll: 0.835441 \n",
      "(GPU: 0, epoch: 10, iters: 96160, time: 0.006) nll: 0.871303 \n",
      "(GPU: 0, epoch: 10, iters: 96960, time: 0.006) nll: 0.692407 \n",
      "(GPU: 0, epoch: 10, iters: 97760, time: 0.006) nll: 0.816458 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 98560, time: 0.006) nll: 0.755648 \n",
      "(GPU: 0, epoch: 10, iters: 99360, time: 0.005) nll: 0.600959 \n",
      "(GPU: 0, epoch: 10, iters: 100160, time: 0.006) nll: 0.780805 \n",
      "(GPU: 0, epoch: 10, iters: 100960, time: 0.005) nll: 0.818932 \n",
      "(GPU: 0, epoch: 10, iters: 101760, time: 0.006) nll: 0.837965 \n",
      "(GPU: 0, epoch: 10, iters: 102560, time: 0.005) nll: 0.817982 \n",
      "(GPU: 0, epoch: 10, iters: 103360, time: 0.006) nll: 0.743212 \n",
      "(GPU: 0, epoch: 10, iters: 104160, time: 0.005) nll: 0.693721 \n",
      "(GPU: 0, epoch: 10, iters: 104960, time: 0.006) nll: 0.729567 \n",
      "(GPU: 0, epoch: 10, iters: 105760, time: 0.005) nll: 0.973840 \n",
      "(GPU: 0, epoch: 10, iters: 106560, time: 0.006) nll: 1.028992 \n",
      "(GPU: 0, epoch: 10, iters: 107360, time: 0.005) nll: 1.011862 \n",
      "(GPU: 0, epoch: 10, iters: 108160, time: 0.006) nll: 0.995117 \n",
      "(GPU: 0, epoch: 10, iters: 108960, time: 0.005) nll: 0.762218 \n",
      "(GPU: 0, epoch: 10, iters: 109760, time: 0.006) nll: 0.705300 \n",
      "(GPU: 0, epoch: 10, iters: 110560, time: 0.005) nll: 0.851505 \n",
      "(GPU: 0, epoch: 10, iters: 111360, time: 0.006) nll: 0.715365 \n",
      "(GPU: 0, epoch: 10, iters: 112160, time: 0.005) nll: 0.985827 \n",
      "(GPU: 0, epoch: 10, iters: 112960, time: 0.006) nll: 0.781378 \n",
      "saving the latest model (epoch 10, total_steps 1520000)\n",
      "(GPU: 0, epoch: 10, iters: 113760, time: 0.005) nll: 0.652095 \n",
      "(GPU: 0, epoch: 10, iters: 114560, time: 0.006) nll: 0.678186 \n",
      "(GPU: 0, epoch: 10, iters: 115360, time: 0.005) nll: 0.976000 \n",
      "(GPU: 0, epoch: 10, iters: 116160, time: 0.006) nll: 1.050360 \n",
      "(GPU: 0, epoch: 10, iters: 116960, time: 0.006) nll: 0.632541 \n",
      "(GPU: 0, epoch: 10, iters: 117760, time: 0.006) nll: 0.563286 \n",
      "(GPU: 0, epoch: 10, iters: 118560, time: 0.006) nll: 0.715952 \n",
      "(GPU: 0, epoch: 10, iters: 119360, time: 0.006) nll: 0.889780 \n",
      "(GPU: 0, epoch: 10, iters: 120160, time: 0.005) nll: 0.800493 \n",
      "(GPU: 0, epoch: 10, iters: 120960, time: 0.006) nll: 0.727181 \n",
      "(GPU: 0, epoch: 10, iters: 121760, time: 0.005) nll: 0.618960 \n",
      "(GPU: 0, epoch: 10, iters: 122560, time: 0.006) nll: 0.687595 \n",
      "(GPU: 0, epoch: 10, iters: 123360, time: 0.005) nll: 0.850055 \n",
      "(GPU: 0, epoch: 10, iters: 124160, time: 0.006) nll: 0.869082 \n",
      "(GPU: 0, epoch: 10, iters: 124960, time: 0.005) nll: 0.946262 \n",
      "(GPU: 0, epoch: 10, iters: 125760, time: 0.006) nll: 0.662613 \n",
      "(GPU: 0, epoch: 10, iters: 126560, time: 0.005) nll: 0.936472 \n",
      "(GPU: 0, epoch: 10, iters: 127360, time: 0.006) nll: 0.796296 \n",
      "(GPU: 0, epoch: 10, iters: 128160, time: 0.005) nll: 0.684842 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.006) nll: 0.888946 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.009) nll: 0.880819 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.009) nll: 0.836014 \n",
      "(GPU: 0, epoch: 10, iters: 129760, time: 0.005) nll: 0.815931 \n",
      "(GPU: 0, epoch: 10, iters: 130560, time: 0.006) nll: 0.923071 \n",
      "(GPU: 0, epoch: 10, iters: 131360, time: 0.005) nll: 0.788842 \n",
      "(GPU: 0, epoch: 10, iters: 132160, time: 0.006) nll: 0.843852 \n",
      "(GPU: 0, epoch: 10, iters: 132960, time: 0.005) nll: 0.758525 \n",
      "saving the latest model (epoch 10, total_steps 1540000)\n",
      "(GPU: 0, epoch: 10, iters: 133760, time: 0.006) nll: 0.917293 \n",
      "(GPU: 0, epoch: 10, iters: 134560, time: 0.005) nll: 0.720584 \n",
      "(GPU: 0, epoch: 10, iters: 135360, time: 0.006) nll: 0.945909 \n",
      "(GPU: 0, epoch: 10, iters: 136160, time: 0.006) nll: 0.746740 \n",
      "(GPU: 0, epoch: 10, iters: 136960, time: 0.006) nll: 0.985202 \n",
      "(GPU: 0, epoch: 10, iters: 137760, time: 0.005) nll: 0.691930 \n",
      "(GPU: 0, epoch: 10, iters: 138560, time: 0.006) nll: 0.955540 \n",
      "(GPU: 0, epoch: 10, iters: 139360, time: 0.005) nll: 0.635809 \n",
      "(GPU: 0, epoch: 10, iters: 140160, time: 0.006) nll: 1.116850 \n",
      "[*] End of epoch 10 / 25 \t Time Taken: 833 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000953\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3082/4397 [09:44<04:02,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 32, time: 0.003) nll: 0.685060 \n",
      "(GPU: 0, epoch: 11, iters: 32, time: 0.003) nll: 0.857007 \n",
      "(GPU: 0, epoch: 11, iters: 256, time: 0.006) nll: 0.835255 \n",
      "(GPU: 0, epoch: 11, iters: 1056, time: 0.005) nll: 0.834926 \n",
      "(GPU: 0, epoch: 11, iters: 1856, time: 0.006) nll: 0.816316 \n",
      "(GPU: 0, epoch: 11, iters: 2656, time: 0.005) nll: 0.914557 \n",
      "(GPU: 0, epoch: 11, iters: 3456, time: 0.006) nll: 0.851918 \n",
      "(GPU: 0, epoch: 11, iters: 4256, time: 0.006) nll: 0.690750 \n",
      "(GPU: 0, epoch: 11, iters: 5056, time: 0.006) nll: 0.810874 \n",
      "(GPU: 0, epoch: 11, iters: 5856, time: 0.005) nll: 0.964877 \n",
      "(GPU: 0, epoch: 11, iters: 6656, time: 0.006) nll: 0.654478 \n",
      "(GPU: 0, epoch: 11, iters: 7456, time: 0.005) nll: 0.729176 \n",
      "(GPU: 0, epoch: 11, iters: 8256, time: 0.006) nll: 0.736095 \n",
      "(GPU: 0, epoch: 11, iters: 9056, time: 0.005) nll: 0.965248 \n",
      "(GPU: 0, epoch: 11, iters: 9856, time: 0.006) nll: 1.060644 \n",
      "(GPU: 0, epoch: 11, iters: 10656, time: 0.005) nll: 0.676849 \n",
      "(GPU: 0, epoch: 11, iters: 11456, time: 0.006) nll: 0.787562 \n",
      "(GPU: 0, epoch: 11, iters: 12256, time: 0.005) nll: 0.814509 \n",
      "saving the latest model (epoch 11, total_steps 1560000)\n",
      "(GPU: 0, epoch: 11, iters: 13056, time: 0.006) nll: 0.654468 \n",
      "(GPU: 0, epoch: 11, iters: 13856, time: 0.005) nll: 0.792564 \n",
      "(GPU: 0, epoch: 11, iters: 14656, time: 0.006) nll: 0.692220 \n",
      "(GPU: 0, epoch: 11, iters: 15456, time: 0.005) nll: 1.027957 \n",
      "(GPU: 0, epoch: 11, iters: 16256, time: 0.006) nll: 0.870383 \n",
      "(GPU: 0, epoch: 11, iters: 17056, time: 0.005) nll: 0.657487 \n",
      "(GPU: 0, epoch: 11, iters: 17856, time: 0.006) nll: 0.681681 \n",
      "(GPU: 0, epoch: 11, iters: 18656, time: 0.005) nll: 0.763048 \n",
      "(GPU: 0, epoch: 11, iters: 19456, time: 0.006) nll: 0.808559 \n",
      "(GPU: 0, epoch: 11, iters: 20256, time: 0.005) nll: 0.604439 \n",
      "(GPU: 0, epoch: 11, iters: 21056, time: 0.006) nll: 0.866381 \n",
      "(GPU: 0, epoch: 11, iters: 21856, time: 0.005) nll: 0.751938 \n",
      "(GPU: 0, epoch: 11, iters: 22656, time: 0.006) nll: 0.820198 \n",
      "(GPU: 0, epoch: 11, iters: 23456, time: 0.005) nll: 0.705841 \n",
      "(GPU: 0, epoch: 11, iters: 24256, time: 0.006) nll: 0.809366 \n",
      "(GPU: 0, epoch: 11, iters: 25056, time: 0.005) nll: 0.651778 \n",
      "(GPU: 0, epoch: 11, iters: 25856, time: 0.006) nll: 0.860974 \n",
      "(GPU: 0, epoch: 11, iters: 26656, time: 0.005) nll: 0.856995 \n",
      "(GPU: 0, epoch: 11, iters: 27456, time: 0.006) nll: 0.746138 \n",
      "(GPU: 0, epoch: 11, iters: 28256, time: 0.005) nll: 0.767493 \n",
      "(GPU: 0, epoch: 11, iters: 29056, time: 0.006) nll: 0.811057 \n",
      "(GPU: 0, epoch: 11, iters: 29856, time: 0.005) nll: 0.862633 \n",
      "(GPU: 0, epoch: 11, iters: 30656, time: 0.006) nll: 0.980297 \n",
      "(GPU: 0, epoch: 11, iters: 31456, time: 0.005) nll: 0.745961 \n",
      "(GPU: 0, epoch: 11, iters: 32256, time: 0.006) nll: 0.762924 \n",
      "saving the latest model (epoch 11, total_steps 1580000)\n",
      "(GPU: 0, epoch: 11, iters: 33056, time: 0.006) nll: 0.613920 \n",
      "(GPU: 0, epoch: 11, iters: 33856, time: 0.006) nll: 0.796088 \n",
      "(GPU: 0, epoch: 11, iters: 34656, time: 0.005) nll: 0.744898 \n",
      "(GPU: 0, epoch: 11, iters: 35456, time: 0.006) nll: 0.461250 \n",
      "(GPU: 0, epoch: 11, iters: 36256, time: 0.006) nll: 0.828038 \n",
      "(GPU: 0, epoch: 11, iters: 37056, time: 0.006) nll: 0.806482 \n",
      "(GPU: 0, epoch: 11, iters: 37856, time: 0.005) nll: 1.199680 \n",
      "(GPU: 0, epoch: 11, iters: 38656, time: 0.006) nll: 0.875933 \n",
      "(GPU: 0, epoch: 11, iters: 39456, time: 0.005) nll: 0.873827 \n",
      "(GPU: 0, epoch: 11, iters: 40256, time: 0.006) nll: 0.687635 \n",
      "(GPU: 0, epoch: 11, iters: 41056, time: 0.006) nll: 0.711778 \n",
      "(GPU: 0, epoch: 11, iters: 41856, time: 0.006) nll: 0.766830 \n",
      "(GPU: 0, epoch: 11, iters: 42656, time: 0.005) nll: 0.690841 \n",
      "(GPU: 0, epoch: 11, iters: 43456, time: 0.006) nll: 0.515047 \n",
      "(GPU: 0, epoch: 11, iters: 44256, time: 0.005) nll: 0.812412 \n",
      "(GPU: 0, epoch: 11, iters: 45056, time: 0.006) nll: 0.661776 \n",
      "(GPU: 0, epoch: 11, iters: 45856, time: 0.006) nll: 0.752354 \n",
      "(GPU: 0, epoch: 11, iters: 46656, time: 0.006) nll: 0.733155 \n",
      "(GPU: 0, epoch: 11, iters: 47456, time: 0.005) nll: 0.869144 \n",
      "(GPU: 0, epoch: 11, iters: 48256, time: 0.006) nll: 0.843028 \n",
      "(GPU: 0, epoch: 11, iters: 49056, time: 0.005) nll: 0.779167 \n",
      "(GPU: 0, epoch: 11, iters: 49856, time: 0.006) nll: 0.631509 \n",
      "(GPU: 0, epoch: 11, iters: 50656, time: 0.005) nll: 0.924910 \n",
      "(GPU: 0, epoch: 11, iters: 51456, time: 0.006) nll: 0.810796 \n",
      "(GPU: 0, epoch: 11, iters: 52256, time: 0.005) nll: 0.993531 \n",
      "saving the latest model (epoch 11, total_steps 1600000)\n",
      "(GPU: 0, epoch: 11, iters: 53056, time: 0.006) nll: 0.558756 \n",
      "(GPU: 0, epoch: 11, iters: 53856, time: 0.005) nll: 0.883111 \n",
      "(GPU: 0, epoch: 11, iters: 54656, time: 0.006) nll: 0.678723 \n",
      "(GPU: 0, epoch: 11, iters: 55456, time: 0.006) nll: 1.029465 \n",
      "(GPU: 0, epoch: 11, iters: 56256, time: 0.006) nll: 0.751170 \n",
      "(GPU: 0, epoch: 11, iters: 57056, time: 0.005) nll: 0.693006 \n",
      "(GPU: 0, epoch: 11, iters: 57856, time: 0.006) nll: 0.816333 \n",
      "(GPU: 0, epoch: 11, iters: 58656, time: 0.005) nll: 0.834146 \n",
      "(GPU: 0, epoch: 11, iters: 59456, time: 0.006) nll: 0.561139 \n",
      "(GPU: 0, epoch: 11, iters: 60256, time: 0.005) nll: 0.838541 \n",
      "(GPU: 0, epoch: 11, iters: 61056, time: 0.006) nll: 0.894229 \n",
      "(GPU: 0, epoch: 11, iters: 61856, time: 0.005) nll: 0.678964 \n",
      "(GPU: 0, epoch: 11, iters: 62656, time: 0.006) nll: 0.587026 \n",
      "(GPU: 0, epoch: 11, iters: 63456, time: 0.005) nll: 0.712063 \n",
      "(GPU: 0, epoch: 11, iters: 64256, time: 0.006) nll: 0.823577 \n",
      "(GPU: 0, epoch: 11, iters: 65056, time: 0.005) nll: 0.951104 \n",
      "(GPU: 0, epoch: 11, iters: 65856, time: 0.006) nll: 0.665328 \n",
      "(GPU: 0, epoch: 11, iters: 66656, time: 0.005) nll: 0.719289 \n",
      "(GPU: 0, epoch: 11, iters: 67456, time: 0.006) nll: 0.712207 \n",
      "(GPU: 0, epoch: 11, iters: 68256, time: 0.005) nll: 0.773898 \n",
      "(GPU: 0, epoch: 11, iters: 69056, time: 0.006) nll: 0.626948 \n",
      "(GPU: 0, epoch: 11, iters: 69856, time: 0.005) nll: 0.833575 \n",
      "(GPU: 0, epoch: 11, iters: 70656, time: 0.006) nll: 0.853809 \n",
      "(GPU: 0, epoch: 11, iters: 71456, time: 0.005) nll: 0.705090 \n",
      "(GPU: 0, epoch: 11, iters: 72256, time: 0.006) nll: 0.764143 \n",
      "saving the latest model (epoch 11, total_steps 1620000)\n",
      "(GPU: 0, epoch: 11, iters: 73056, time: 0.005) nll: 0.635417 \n",
      "(GPU: 0, epoch: 11, iters: 73856, time: 0.006) nll: 0.737736 \n",
      "(GPU: 0, epoch: 11, iters: 74656, time: 0.005) nll: 0.758274 \n",
      "(GPU: 0, epoch: 11, iters: 75456, time: 0.006) nll: 0.657311 \n",
      "(GPU: 0, epoch: 11, iters: 76256, time: 0.005) nll: 0.836563 \n",
      "(GPU: 0, epoch: 11, iters: 77056, time: 0.006) nll: 0.655362 \n",
      "(GPU: 0, epoch: 11, iters: 77856, time: 0.005) nll: 0.966746 \n",
      "(GPU: 0, epoch: 11, iters: 78656, time: 0.006) nll: 0.600916 \n",
      "(GPU: 0, epoch: 11, iters: 79456, time: 0.005) nll: 0.777048 \n",
      "(GPU: 0, epoch: 11, iters: 80256, time: 0.006) nll: 0.867329 \n",
      "(GPU: 0, epoch: 11, iters: 81056, time: 0.005) nll: 0.685927 \n",
      "(GPU: 0, epoch: 11, iters: 81856, time: 0.006) nll: 0.756050 \n",
      "(GPU: 0, epoch: 11, iters: 82656, time: 0.006) nll: 0.678658 \n",
      "(GPU: 0, epoch: 11, iters: 83456, time: 0.006) nll: 0.711682 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.005) nll: 0.746385 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.008) nll: 0.739359 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.008) nll: 0.839916 \n",
      "(GPU: 0, epoch: 11, iters: 85056, time: 0.006) nll: 0.883661 \n",
      "(GPU: 0, epoch: 11, iters: 85856, time: 0.005) nll: 0.655243 \n",
      "(GPU: 0, epoch: 11, iters: 86656, time: 0.006) nll: 0.923926 \n",
      "(GPU: 0, epoch: 11, iters: 87456, time: 0.006) nll: 0.764913 \n",
      "(GPU: 0, epoch: 11, iters: 88256, time: 0.006) nll: 0.827626 \n",
      "(GPU: 0, epoch: 11, iters: 89056, time: 0.005) nll: 0.776304 \n",
      "(GPU: 0, epoch: 11, iters: 89856, time: 0.006) nll: 0.857781 \n",
      "(GPU: 0, epoch: 11, iters: 90656, time: 0.005) nll: 1.127863 \n",
      "(GPU: 0, epoch: 11, iters: 91456, time: 0.006) nll: 0.730824 \n",
      "(GPU: 0, epoch: 11, iters: 92256, time: 0.005) nll: 1.012602 \n",
      "saving the latest model (epoch 11, total_steps 1640000)\n",
      "(GPU: 0, epoch: 11, iters: 93056, time: 0.006) nll: 0.588613 \n",
      "(GPU: 0, epoch: 11, iters: 93856, time: 0.006) nll: 0.918012 \n",
      "(GPU: 0, epoch: 11, iters: 94656, time: 0.006) nll: 0.941283 \n",
      "(GPU: 0, epoch: 11, iters: 95456, time: 0.005) nll: 0.661926 \n",
      "(GPU: 0, epoch: 11, iters: 96256, time: 0.006) nll: 0.792649 \n",
      "(GPU: 0, epoch: 11, iters: 97056, time: 0.005) nll: 0.642082 \n",
      "(GPU: 0, epoch: 11, iters: 97856, time: 0.006) nll: 0.870607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 98656, time: 0.005) nll: 0.701585 \n",
      "(GPU: 0, epoch: 11, iters: 99456, time: 0.006) nll: 0.627055 \n",
      "(GPU: 0, epoch: 11, iters: 100256, time: 0.005) nll: 0.851503 \n",
      "(GPU: 0, epoch: 11, iters: 101056, time: 0.006) nll: 0.907535 \n",
      "(GPU: 0, epoch: 11, iters: 101856, time: 0.006) nll: 0.669020 \n",
      "(GPU: 0, epoch: 11, iters: 102656, time: 0.006) nll: 0.932357 \n",
      "(GPU: 0, epoch: 11, iters: 103456, time: 0.005) nll: 0.769114 \n",
      "(GPU: 0, epoch: 11, iters: 104256, time: 0.006) nll: 0.698307 \n",
      "(GPU: 0, epoch: 11, iters: 105056, time: 0.005) nll: 0.581500 \n",
      "(GPU: 0, epoch: 11, iters: 105856, time: 0.006) nll: 0.535028 \n",
      "(GPU: 0, epoch: 11, iters: 106656, time: 0.005) nll: 0.720109 \n",
      "(GPU: 0, epoch: 11, iters: 107456, time: 0.006) nll: 0.943475 \n",
      "(GPU: 0, epoch: 11, iters: 108256, time: 0.006) nll: 0.745950 \n",
      "(GPU: 0, epoch: 11, iters: 109056, time: 0.006) nll: 0.717789 \n",
      "(GPU: 0, epoch: 11, iters: 109856, time: 0.005) nll: 0.874853 \n",
      "(GPU: 0, epoch: 11, iters: 110656, time: 0.006) nll: 0.831978 \n",
      "(GPU: 0, epoch: 11, iters: 111456, time: 0.005) nll: 0.690540 \n",
      "(GPU: 0, epoch: 11, iters: 112256, time: 0.006) nll: 0.826126 \n",
      "saving the latest model (epoch 11, total_steps 1660000)\n",
      "(GPU: 0, epoch: 11, iters: 113056, time: 0.005) nll: 0.832534 \n",
      "(GPU: 0, epoch: 11, iters: 113856, time: 0.006) nll: 0.908772 \n",
      "(GPU: 0, epoch: 11, iters: 114656, time: 0.006) nll: 0.953423 \n",
      "(GPU: 0, epoch: 11, iters: 115456, time: 0.006) nll: 0.789523 \n",
      "(GPU: 0, epoch: 11, iters: 116256, time: 0.006) nll: 0.606852 \n",
      "(GPU: 0, epoch: 11, iters: 117056, time: 0.006) nll: 0.928688 \n",
      "(GPU: 0, epoch: 11, iters: 117856, time: 0.005) nll: 0.622975 \n",
      "(GPU: 0, epoch: 11, iters: 118656, time: 0.006) nll: 0.691210 \n",
      "(GPU: 0, epoch: 11, iters: 119456, time: 0.005) nll: 0.905513 \n",
      "(GPU: 0, epoch: 11, iters: 120256, time: 0.006) nll: 0.720894 \n",
      "(GPU: 0, epoch: 11, iters: 121056, time: 0.005) nll: 0.749190 \n",
      "(GPU: 0, epoch: 11, iters: 121856, time: 0.006) nll: 0.572614 \n",
      "(GPU: 0, epoch: 11, iters: 122656, time: 0.005) nll: 0.932972 \n",
      "(GPU: 0, epoch: 11, iters: 123456, time: 0.006) nll: 0.916705 \n",
      "(GPU: 0, epoch: 11, iters: 124256, time: 0.005) nll: 0.802346 \n",
      "(GPU: 0, epoch: 11, iters: 125056, time: 0.006) nll: 0.727239 \n",
      "(GPU: 0, epoch: 11, iters: 125856, time: 0.005) nll: 0.815122 \n",
      "(GPU: 0, epoch: 11, iters: 126656, time: 0.006) nll: 0.660967 \n",
      "(GPU: 0, epoch: 11, iters: 127456, time: 0.005) nll: 0.885276 \n",
      "(GPU: 0, epoch: 11, iters: 128256, time: 0.006) nll: 0.619204 \n",
      "(GPU: 0, epoch: 11, iters: 129056, time: 0.005) nll: 0.894025 \n",
      "(GPU: 0, epoch: 11, iters: 129856, time: 0.006) nll: 0.869291 \n",
      "(GPU: 0, epoch: 11, iters: 130656, time: 0.005) nll: 0.756664 \n",
      "(GPU: 0, epoch: 11, iters: 131456, time: 0.006) nll: 0.852055 \n",
      "(GPU: 0, epoch: 11, iters: 132256, time: 0.005) nll: 0.792231 \n",
      "saving the latest model (epoch 11, total_steps 1680000)\n",
      "(GPU: 0, epoch: 11, iters: 133056, time: 0.006) nll: 0.906556 \n",
      "(GPU: 0, epoch: 11, iters: 133856, time: 0.005) nll: 0.582031 \n",
      "(GPU: 0, epoch: 11, iters: 134656, time: 0.006) nll: 1.124781 \n",
      "(GPU: 0, epoch: 11, iters: 135456, time: 0.005) nll: 0.833323 \n",
      "(GPU: 0, epoch: 11, iters: 136256, time: 0.006) nll: 1.055569 \n",
      "(GPU: 0, epoch: 11, iters: 137056, time: 0.005) nll: 0.955834 \n",
      "(GPU: 0, epoch: 11, iters: 137856, time: 0.006) nll: 0.859732 \n",
      "(GPU: 0, epoch: 11, iters: 138656, time: 0.006) nll: 0.818583 \n",
      "(GPU: 0, epoch: 11, iters: 139456, time: 0.006) nll: 0.588691 \n",
      "(GPU: 0, epoch: 11, iters: 140256, time: 0.005) nll: 0.856222 \n",
      "[*] End of epoch 11 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000913\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3085/4397 [09:45<04:00,  5.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 32, time: 0.003) nll: 0.603982 \n",
      "(GPU: 0, epoch: 12, iters: 32, time: 0.003) nll: 0.700306 \n",
      "(GPU: 0, epoch: 12, iters: 352, time: 0.005) nll: 0.904397 \n",
      "(GPU: 0, epoch: 12, iters: 1152, time: 0.006) nll: 0.898158 \n",
      "(GPU: 0, epoch: 12, iters: 1952, time: 0.005) nll: 0.601530 \n",
      "(GPU: 0, epoch: 12, iters: 2752, time: 0.006) nll: 0.847731 \n",
      "(GPU: 0, epoch: 12, iters: 3552, time: 0.005) nll: 1.011849 \n",
      "(GPU: 0, epoch: 12, iters: 4352, time: 0.006) nll: 0.590767 \n",
      "(GPU: 0, epoch: 12, iters: 5152, time: 0.005) nll: 1.004857 \n",
      "(GPU: 0, epoch: 12, iters: 5952, time: 0.006) nll: 0.917703 \n",
      "(GPU: 0, epoch: 12, iters: 6752, time: 0.005) nll: 0.604495 \n",
      "(GPU: 0, epoch: 12, iters: 7552, time: 0.006) nll: 0.631524 \n",
      "(GPU: 0, epoch: 12, iters: 8352, time: 0.005) nll: 0.422095 \n",
      "(GPU: 0, epoch: 12, iters: 9152, time: 0.006) nll: 0.721141 \n",
      "(GPU: 0, epoch: 12, iters: 9952, time: 0.005) nll: 0.547542 \n",
      "(GPU: 0, epoch: 12, iters: 10752, time: 0.006) nll: 0.574473 \n",
      "(GPU: 0, epoch: 12, iters: 11552, time: 0.005) nll: 0.664026 \n",
      "saving the latest model (epoch 12, total_steps 1700000)\n",
      "(GPU: 0, epoch: 12, iters: 12352, time: 0.006) nll: 0.934265 \n",
      "(GPU: 0, epoch: 12, iters: 13152, time: 0.005) nll: 1.022066 \n",
      "(GPU: 0, epoch: 12, iters: 13952, time: 0.006) nll: 0.701228 \n",
      "(GPU: 0, epoch: 12, iters: 14752, time: 0.005) nll: 0.548412 \n",
      "(GPU: 0, epoch: 12, iters: 15552, time: 0.006) nll: 0.755721 \n",
      "(GPU: 0, epoch: 12, iters: 16352, time: 0.005) nll: 0.683879 \n",
      "(GPU: 0, epoch: 12, iters: 17152, time: 0.006) nll: 0.580038 \n",
      "(GPU: 0, epoch: 12, iters: 17952, time: 0.005) nll: 0.590573 \n",
      "(GPU: 0, epoch: 12, iters: 18752, time: 0.006) nll: 0.900822 \n",
      "(GPU: 0, epoch: 12, iters: 19552, time: 0.005) nll: 0.925252 \n",
      "(GPU: 0, epoch: 12, iters: 20352, time: 0.006) nll: 0.723587 \n",
      "(GPU: 0, epoch: 12, iters: 21152, time: 0.005) nll: 0.766817 \n",
      "(GPU: 0, epoch: 12, iters: 21952, time: 0.006) nll: 0.575004 \n",
      "(GPU: 0, epoch: 12, iters: 22752, time: 0.005) nll: 0.776331 \n",
      "(GPU: 0, epoch: 12, iters: 23552, time: 0.006) nll: 0.782956 \n",
      "(GPU: 0, epoch: 12, iters: 24352, time: 0.005) nll: 0.933195 \n",
      "(GPU: 0, epoch: 12, iters: 25152, time: 0.006) nll: 0.513617 \n",
      "(GPU: 0, epoch: 12, iters: 25952, time: 0.005) nll: 0.898536 \n",
      "(GPU: 0, epoch: 12, iters: 26752, time: 0.006) nll: 0.873572 \n",
      "(GPU: 0, epoch: 12, iters: 27552, time: 0.005) nll: 0.649577 \n",
      "(GPU: 0, epoch: 12, iters: 28352, time: 0.006) nll: 0.994676 \n",
      "(GPU: 0, epoch: 12, iters: 29152, time: 0.005) nll: 0.575106 \n",
      "(GPU: 0, epoch: 12, iters: 29952, time: 0.006) nll: 0.708804 \n",
      "(GPU: 0, epoch: 12, iters: 30752, time: 0.005) nll: 0.816739 \n",
      "(GPU: 0, epoch: 12, iters: 31552, time: 0.006) nll: 0.767604 \n",
      "saving the latest model (epoch 12, total_steps 1720000)\n",
      "(GPU: 0, epoch: 12, iters: 32352, time: 0.005) nll: 0.645894 \n",
      "(GPU: 0, epoch: 12, iters: 33152, time: 0.006) nll: 0.778647 \n",
      "(GPU: 0, epoch: 12, iters: 33952, time: 0.005) nll: 0.746644 \n",
      "(GPU: 0, epoch: 12, iters: 34752, time: 0.006) nll: 0.625590 \n",
      "(GPU: 0, epoch: 12, iters: 35552, time: 0.005) nll: 0.760162 \n",
      "(GPU: 0, epoch: 12, iters: 36352, time: 0.006) nll: 1.006717 \n",
      "(GPU: 0, epoch: 12, iters: 37152, time: 0.006) nll: 0.605770 \n",
      "(GPU: 0, epoch: 12, iters: 37952, time: 0.006) nll: 0.511375 \n",
      "(GPU: 0, epoch: 12, iters: 38752, time: 0.005) nll: 0.919155 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.006) nll: 0.827306 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.009) nll: 0.816615 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.009) nll: 0.713454 \n",
      "(GPU: 0, epoch: 12, iters: 40352, time: 0.005) nll: 0.641697 \n",
      "(GPU: 0, epoch: 12, iters: 41152, time: 0.006) nll: 0.951601 \n",
      "(GPU: 0, epoch: 12, iters: 41952, time: 0.005) nll: 1.001099 \n",
      "(GPU: 0, epoch: 12, iters: 42752, time: 0.006) nll: 0.803485 \n",
      "(GPU: 0, epoch: 12, iters: 43552, time: 0.005) nll: 0.875230 \n",
      "(GPU: 0, epoch: 12, iters: 44352, time: 0.006) nll: 0.827922 \n",
      "(GPU: 0, epoch: 12, iters: 45152, time: 0.005) nll: 0.864699 \n",
      "(GPU: 0, epoch: 12, iters: 45952, time: 0.006) nll: 0.694552 \n",
      "(GPU: 0, epoch: 12, iters: 46752, time: 0.006) nll: 0.686813 \n",
      "(GPU: 0, epoch: 12, iters: 47552, time: 0.006) nll: 0.636558 \n",
      "(GPU: 0, epoch: 12, iters: 48352, time: 0.005) nll: 0.741953 \n",
      "(GPU: 0, epoch: 12, iters: 49152, time: 0.006) nll: 0.805371 \n",
      "(GPU: 0, epoch: 12, iters: 49952, time: 0.005) nll: 0.673088 \n",
      "(GPU: 0, epoch: 12, iters: 50752, time: 0.006) nll: 0.591341 \n",
      "(GPU: 0, epoch: 12, iters: 51552, time: 0.005) nll: 0.747376 \n",
      "saving the latest model (epoch 12, total_steps 1740000)\n",
      "(GPU: 0, epoch: 12, iters: 52352, time: 0.006) nll: 1.191670 \n",
      "(GPU: 0, epoch: 12, iters: 53152, time: 0.005) nll: 1.034376 \n",
      "(GPU: 0, epoch: 12, iters: 53952, time: 0.006) nll: 0.869729 \n",
      "(GPU: 0, epoch: 12, iters: 54752, time: 0.006) nll: 0.970377 \n",
      "(GPU: 0, epoch: 12, iters: 55552, time: 0.006) nll: 0.962188 \n",
      "(GPU: 0, epoch: 12, iters: 56352, time: 0.005) nll: 0.695669 \n",
      "(GPU: 0, epoch: 12, iters: 57152, time: 0.006) nll: 0.497511 \n",
      "(GPU: 0, epoch: 12, iters: 57952, time: 0.005) nll: 0.673409 \n",
      "(GPU: 0, epoch: 12, iters: 58752, time: 0.006) nll: 0.737111 \n",
      "(GPU: 0, epoch: 12, iters: 59552, time: 0.005) nll: 0.631285 \n",
      "(GPU: 0, epoch: 12, iters: 60352, time: 0.006) nll: 0.840581 \n",
      "(GPU: 0, epoch: 12, iters: 61152, time: 0.005) nll: 0.730031 \n",
      "(GPU: 0, epoch: 12, iters: 61952, time: 0.006) nll: 0.552037 \n",
      "(GPU: 0, epoch: 12, iters: 62752, time: 0.006) nll: 0.587225 \n",
      "(GPU: 0, epoch: 12, iters: 63552, time: 0.006) nll: 0.720128 \n",
      "(GPU: 0, epoch: 12, iters: 64352, time: 0.005) nll: 0.694954 \n",
      "(GPU: 0, epoch: 12, iters: 65152, time: 0.006) nll: 0.930134 \n",
      "(GPU: 0, epoch: 12, iters: 65952, time: 0.005) nll: 0.613665 \n",
      "(GPU: 0, epoch: 12, iters: 66752, time: 0.006) nll: 0.885489 \n",
      "(GPU: 0, epoch: 12, iters: 67552, time: 0.005) nll: 0.944254 \n",
      "(GPU: 0, epoch: 12, iters: 68352, time: 0.006) nll: 0.670713 \n",
      "(GPU: 0, epoch: 12, iters: 69152, time: 0.005) nll: 0.582260 \n",
      "(GPU: 0, epoch: 12, iters: 69952, time: 0.006) nll: 0.635121 \n",
      "(GPU: 0, epoch: 12, iters: 70752, time: 0.005) nll: 0.957823 \n",
      "(GPU: 0, epoch: 12, iters: 71552, time: 0.006) nll: 0.602195 \n",
      "saving the latest model (epoch 12, total_steps 1760000)\n",
      "(GPU: 0, epoch: 12, iters: 72352, time: 0.005) nll: 0.766558 \n",
      "(GPU: 0, epoch: 12, iters: 73152, time: 0.006) nll: 0.864797 \n",
      "(GPU: 0, epoch: 12, iters: 73952, time: 0.005) nll: 0.739476 \n",
      "(GPU: 0, epoch: 12, iters: 74752, time: 0.006) nll: 0.884429 \n",
      "(GPU: 0, epoch: 12, iters: 75552, time: 0.006) nll: 0.549704 \n",
      "(GPU: 0, epoch: 12, iters: 76352, time: 0.006) nll: 0.715567 \n",
      "(GPU: 0, epoch: 12, iters: 77152, time: 0.005) nll: 0.694883 \n",
      "(GPU: 0, epoch: 12, iters: 77952, time: 0.006) nll: 0.800192 \n",
      "(GPU: 0, epoch: 12, iters: 78752, time: 0.005) nll: 0.806854 \n",
      "(GPU: 0, epoch: 12, iters: 79552, time: 0.006) nll: 0.842354 \n",
      "(GPU: 0, epoch: 12, iters: 80352, time: 0.005) nll: 1.057626 \n",
      "(GPU: 0, epoch: 12, iters: 81152, time: 0.006) nll: 1.262471 \n",
      "(GPU: 0, epoch: 12, iters: 81952, time: 0.005) nll: 0.766216 \n",
      "(GPU: 0, epoch: 12, iters: 82752, time: 0.006) nll: 0.725828 \n",
      "(GPU: 0, epoch: 12, iters: 83552, time: 0.005) nll: 0.804583 \n",
      "(GPU: 0, epoch: 12, iters: 84352, time: 0.006) nll: 0.874900 \n",
      "(GPU: 0, epoch: 12, iters: 85152, time: 0.006) nll: 0.840973 \n",
      "(GPU: 0, epoch: 12, iters: 85952, time: 0.006) nll: 0.683646 \n",
      "(GPU: 0, epoch: 12, iters: 86752, time: 0.005) nll: 0.723729 \n",
      "(GPU: 0, epoch: 12, iters: 87552, time: 0.006) nll: 0.690519 \n",
      "(GPU: 0, epoch: 12, iters: 88352, time: 0.005) nll: 0.692103 \n",
      "(GPU: 0, epoch: 12, iters: 89152, time: 0.006) nll: 0.700704 \n",
      "(GPU: 0, epoch: 12, iters: 89952, time: 0.005) nll: 0.739483 \n",
      "(GPU: 0, epoch: 12, iters: 90752, time: 0.006) nll: 0.680151 \n",
      "(GPU: 0, epoch: 12, iters: 91552, time: 0.005) nll: 0.901318 \n",
      "saving the latest model (epoch 12, total_steps 1780000)\n",
      "(GPU: 0, epoch: 12, iters: 92352, time: 0.006) nll: 0.686197 \n",
      "(GPU: 0, epoch: 12, iters: 93152, time: 0.005) nll: 0.728859 \n",
      "(GPU: 0, epoch: 12, iters: 93952, time: 0.006) nll: 0.573000 \n",
      "(GPU: 0, epoch: 12, iters: 94752, time: 0.005) nll: 0.910396 \n",
      "(GPU: 0, epoch: 12, iters: 95552, time: 0.006) nll: 0.852072 \n",
      "(GPU: 0, epoch: 12, iters: 96352, time: 0.005) nll: 0.774327 \n",
      "(GPU: 0, epoch: 12, iters: 97152, time: 0.006) nll: 0.894993 \n",
      "(GPU: 0, epoch: 12, iters: 97952, time: 0.005) nll: 0.870552 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 98752, time: 0.006) nll: 0.628341 \n",
      "(GPU: 0, epoch: 12, iters: 99552, time: 0.005) nll: 0.816515 \n",
      "(GPU: 0, epoch: 12, iters: 100352, time: 0.006) nll: 0.705749 \n",
      "(GPU: 0, epoch: 12, iters: 101152, time: 0.005) nll: 0.727506 \n",
      "(GPU: 0, epoch: 12, iters: 101952, time: 0.006) nll: 0.666952 \n",
      "(GPU: 0, epoch: 12, iters: 102752, time: 0.005) nll: 0.926333 \n",
      "(GPU: 0, epoch: 12, iters: 103552, time: 0.006) nll: 0.689726 \n",
      "(GPU: 0, epoch: 12, iters: 104352, time: 0.005) nll: 0.956248 \n",
      "(GPU: 0, epoch: 12, iters: 105152, time: 0.006) nll: 0.619541 \n",
      "(GPU: 0, epoch: 12, iters: 105952, time: 0.005) nll: 0.766667 \n",
      "(GPU: 0, epoch: 12, iters: 106752, time: 0.006) nll: 0.624931 \n",
      "(GPU: 0, epoch: 12, iters: 107552, time: 0.005) nll: 0.768898 \n",
      "(GPU: 0, epoch: 12, iters: 108352, time: 0.006) nll: 0.649923 \n",
      "(GPU: 0, epoch: 12, iters: 109152, time: 0.005) nll: 0.684999 \n",
      "(GPU: 0, epoch: 12, iters: 109952, time: 0.006) nll: 0.928785 \n",
      "(GPU: 0, epoch: 12, iters: 110752, time: 0.005) nll: 0.782906 \n",
      "(GPU: 0, epoch: 12, iters: 111552, time: 0.006) nll: 0.714477 \n",
      "saving the latest model (epoch 12, total_steps 1800000)\n",
      "(GPU: 0, epoch: 12, iters: 112352, time: 0.005) nll: 0.815986 \n",
      "(GPU: 0, epoch: 12, iters: 113152, time: 0.006) nll: 0.568151 \n",
      "(GPU: 0, epoch: 12, iters: 113952, time: 0.005) nll: 0.599265 \n",
      "(GPU: 0, epoch: 12, iters: 114752, time: 0.006) nll: 0.785280 \n",
      "(GPU: 0, epoch: 12, iters: 115552, time: 0.005) nll: 0.890639 \n",
      "(GPU: 0, epoch: 12, iters: 116352, time: 0.006) nll: 1.028616 \n",
      "(GPU: 0, epoch: 12, iters: 117152, time: 0.006) nll: 0.606497 \n",
      "(GPU: 0, epoch: 12, iters: 117952, time: 0.006) nll: 0.728065 \n",
      "(GPU: 0, epoch: 12, iters: 118752, time: 0.005) nll: 0.668316 \n",
      "(GPU: 0, epoch: 12, iters: 119552, time: 0.006) nll: 0.798784 \n",
      "(GPU: 0, epoch: 12, iters: 120352, time: 0.005) nll: 0.880863 \n",
      "(GPU: 0, epoch: 12, iters: 121152, time: 0.006) nll: 0.696173 \n",
      "(GPU: 0, epoch: 12, iters: 121952, time: 0.005) nll: 0.800842 \n",
      "(GPU: 0, epoch: 12, iters: 122752, time: 0.006) nll: 0.796538 \n",
      "(GPU: 0, epoch: 12, iters: 123552, time: 0.006) nll: 1.092876 \n",
      "(GPU: 0, epoch: 12, iters: 124352, time: 0.006) nll: 0.772862 \n",
      "(GPU: 0, epoch: 12, iters: 125152, time: 0.005) nll: 0.686304 \n",
      "(GPU: 0, epoch: 12, iters: 125952, time: 0.006) nll: 0.942515 \n",
      "(GPU: 0, epoch: 12, iters: 126752, time: 0.005) nll: 0.817215 \n",
      "(GPU: 0, epoch: 12, iters: 127552, time: 0.006) nll: 0.878272 \n",
      "(GPU: 0, epoch: 12, iters: 128352, time: 0.005) nll: 0.668003 \n",
      "(GPU: 0, epoch: 12, iters: 129152, time: 0.006) nll: 0.743385 \n",
      "(GPU: 0, epoch: 12, iters: 129952, time: 0.005) nll: 0.833426 \n",
      "(GPU: 0, epoch: 12, iters: 130752, time: 0.006) nll: 0.768123 \n",
      "(GPU: 0, epoch: 12, iters: 131552, time: 0.006) nll: 0.877112 \n",
      "saving the latest model (epoch 12, total_steps 1820000)\n",
      "(GPU: 0, epoch: 12, iters: 132352, time: 0.006) nll: 0.643539 \n",
      "(GPU: 0, epoch: 12, iters: 133152, time: 0.005) nll: 0.724412 \n",
      "(GPU: 0, epoch: 12, iters: 133952, time: 0.006) nll: 0.720038 \n",
      "(GPU: 0, epoch: 12, iters: 134752, time: 0.005) nll: 0.781895 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.006) nll: 0.643839 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.009) nll: 0.635052 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.009) nll: 0.893218 \n",
      "(GPU: 0, epoch: 12, iters: 136352, time: 0.005) nll: 0.807644 \n",
      "(GPU: 0, epoch: 12, iters: 137152, time: 0.006) nll: 0.666662 \n",
      "(GPU: 0, epoch: 12, iters: 137952, time: 0.005) nll: 1.024389 \n",
      "(GPU: 0, epoch: 12, iters: 138752, time: 0.006) nll: 0.765405 \n",
      "(GPU: 0, epoch: 12, iters: 139552, time: 0.005) nll: 0.797247 \n",
      "(GPU: 0, epoch: 12, iters: 140352, time: 0.006) nll: 0.730604 \n",
      "saving the model at the end of epoch 12, iters 1829152\n",
      "([test] GPU: 0, epoch: 12) \n",
      "OrderedDict()\n",
      "[*] End of epoch 12 / 25 \t Time Taken: 839 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000877\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3088/4397 [09:45<03:59,  5.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 32, time: 0.003) nll: 0.738002 \n",
      "(GPU: 0, epoch: 13, iters: 32, time: 0.003) nll: 0.615431 \n",
      "(GPU: 0, epoch: 13, iters: 448, time: 0.006) nll: 0.656811 \n",
      "(GPU: 0, epoch: 13, iters: 1248, time: 0.006) nll: 0.743487 \n",
      "(GPU: 0, epoch: 13, iters: 2048, time: 0.006) nll: 0.717132 \n",
      "(GPU: 0, epoch: 13, iters: 2848, time: 0.005) nll: 0.517953 \n",
      "(GPU: 0, epoch: 13, iters: 3648, time: 0.006) nll: 0.523432 \n",
      "(GPU: 0, epoch: 13, iters: 4448, time: 0.005) nll: 1.060237 \n",
      "(GPU: 0, epoch: 13, iters: 5248, time: 0.006) nll: 0.769813 \n",
      "(GPU: 0, epoch: 13, iters: 6048, time: 0.005) nll: 0.625690 \n",
      "(GPU: 0, epoch: 13, iters: 6848, time: 0.006) nll: 0.748598 \n",
      "(GPU: 0, epoch: 13, iters: 7648, time: 0.005) nll: 0.593435 \n",
      "(GPU: 0, epoch: 13, iters: 8448, time: 0.006) nll: 0.590309 \n",
      "(GPU: 0, epoch: 13, iters: 9248, time: 0.005) nll: 0.820685 \n",
      "(GPU: 0, epoch: 13, iters: 10048, time: 0.006) nll: 0.745560 \n",
      "(GPU: 0, epoch: 13, iters: 10848, time: 0.005) nll: 0.722572 \n",
      "saving the latest model (epoch 13, total_steps 1840000)\n",
      "(GPU: 0, epoch: 13, iters: 11648, time: 0.006) nll: 0.756284 \n",
      "(GPU: 0, epoch: 13, iters: 12448, time: 0.005) nll: 0.830198 \n",
      "(GPU: 0, epoch: 13, iters: 13248, time: 0.006) nll: 0.602275 \n",
      "(GPU: 0, epoch: 13, iters: 14048, time: 0.005) nll: 0.776024 \n",
      "(GPU: 0, epoch: 13, iters: 14848, time: 0.006) nll: 0.534808 \n",
      "(GPU: 0, epoch: 13, iters: 15648, time: 0.005) nll: 0.814674 \n",
      "(GPU: 0, epoch: 13, iters: 16448, time: 0.006) nll: 0.950221 \n",
      "(GPU: 0, epoch: 13, iters: 17248, time: 0.005) nll: 0.869369 \n",
      "(GPU: 0, epoch: 13, iters: 18048, time: 0.006) nll: 0.825314 \n",
      "(GPU: 0, epoch: 13, iters: 18848, time: 0.005) nll: 0.788550 \n",
      "(GPU: 0, epoch: 13, iters: 19648, time: 0.006) nll: 0.773513 \n",
      "(GPU: 0, epoch: 13, iters: 20448, time: 0.005) nll: 0.802704 \n",
      "(GPU: 0, epoch: 13, iters: 21248, time: 0.006) nll: 0.769998 \n",
      "(GPU: 0, epoch: 13, iters: 22048, time: 0.005) nll: 0.659739 \n",
      "(GPU: 0, epoch: 13, iters: 22848, time: 0.006) nll: 0.709358 \n",
      "(GPU: 0, epoch: 13, iters: 23648, time: 0.005) nll: 0.676060 \n",
      "(GPU: 0, epoch: 13, iters: 24448, time: 0.006) nll: 0.630264 \n",
      "(GPU: 0, epoch: 13, iters: 25248, time: 0.005) nll: 0.746614 \n",
      "(GPU: 0, epoch: 13, iters: 26048, time: 0.006) nll: 0.740221 \n",
      "(GPU: 0, epoch: 13, iters: 26848, time: 0.006) nll: 0.855407 \n",
      "(GPU: 0, epoch: 13, iters: 27648, time: 0.006) nll: 0.866580 \n",
      "(GPU: 0, epoch: 13, iters: 28448, time: 0.005) nll: 0.751539 \n",
      "(GPU: 0, epoch: 13, iters: 29248, time: 0.006) nll: 0.672291 \n",
      "(GPU: 0, epoch: 13, iters: 30048, time: 0.005) nll: 0.821343 \n",
      "(GPU: 0, epoch: 13, iters: 30848, time: 0.006) nll: 0.800586 \n",
      "saving the latest model (epoch 13, total_steps 1860000)\n",
      "(GPU: 0, epoch: 13, iters: 31648, time: 0.005) nll: 0.768304 \n",
      "(GPU: 0, epoch: 13, iters: 32448, time: 0.006) nll: 0.630559 \n",
      "(GPU: 0, epoch: 13, iters: 33248, time: 0.006) nll: 0.630288 \n",
      "(GPU: 0, epoch: 13, iters: 34048, time: 0.006) nll: 0.736335 \n",
      "(GPU: 0, epoch: 13, iters: 34848, time: 0.006) nll: 0.756286 \n",
      "(GPU: 0, epoch: 13, iters: 35648, time: 0.006) nll: 0.759085 \n",
      "(GPU: 0, epoch: 13, iters: 36448, time: 0.006) nll: 0.544183 \n",
      "(GPU: 0, epoch: 13, iters: 37248, time: 0.006) nll: 0.708816 \n",
      "(GPU: 0, epoch: 13, iters: 38048, time: 0.005) nll: 0.663839 \n",
      "(GPU: 0, epoch: 13, iters: 38848, time: 0.006) nll: 0.882051 \n",
      "(GPU: 0, epoch: 13, iters: 39648, time: 0.005) nll: 0.870120 \n",
      "(GPU: 0, epoch: 13, iters: 40448, time: 0.006) nll: 0.705126 \n",
      "(GPU: 0, epoch: 13, iters: 41248, time: 0.005) nll: 0.657539 \n",
      "(GPU: 0, epoch: 13, iters: 42048, time: 0.006) nll: 0.759689 \n",
      "(GPU: 0, epoch: 13, iters: 42848, time: 0.005) nll: 0.857966 \n",
      "(GPU: 0, epoch: 13, iters: 43648, time: 0.006) nll: 0.864976 \n",
      "(GPU: 0, epoch: 13, iters: 44448, time: 0.006) nll: 0.615585 \n",
      "(GPU: 0, epoch: 13, iters: 45248, time: 0.006) nll: 0.649019 \n",
      "(GPU: 0, epoch: 13, iters: 46048, time: 0.005) nll: 0.901162 \n",
      "(GPU: 0, epoch: 13, iters: 46848, time: 0.006) nll: 0.622617 \n",
      "(GPU: 0, epoch: 13, iters: 47648, time: 0.005) nll: 0.829515 \n",
      "(GPU: 0, epoch: 13, iters: 48448, time: 0.006) nll: 0.961299 \n",
      "(GPU: 0, epoch: 13, iters: 49248, time: 0.005) nll: 1.092021 \n",
      "(GPU: 0, epoch: 13, iters: 50048, time: 0.006) nll: 0.691279 \n",
      "(GPU: 0, epoch: 13, iters: 50848, time: 0.005) nll: 0.709751 \n",
      "saving the latest model (epoch 13, total_steps 1880000)\n",
      "(GPU: 0, epoch: 13, iters: 51648, time: 0.006) nll: 0.850008 \n",
      "(GPU: 0, epoch: 13, iters: 52448, time: 0.005) nll: 0.809541 \n",
      "(GPU: 0, epoch: 13, iters: 53248, time: 0.006) nll: 1.083675 \n",
      "(GPU: 0, epoch: 13, iters: 54048, time: 0.005) nll: 0.885371 \n",
      "(GPU: 0, epoch: 13, iters: 54848, time: 0.006) nll: 0.659729 \n",
      "(GPU: 0, epoch: 13, iters: 55648, time: 0.005) nll: 0.534578 \n",
      "(GPU: 0, epoch: 13, iters: 56448, time: 0.006) nll: 0.787497 \n",
      "(GPU: 0, epoch: 13, iters: 57248, time: 0.005) nll: 0.618592 \n",
      "(GPU: 0, epoch: 13, iters: 58048, time: 0.006) nll: 0.963687 \n",
      "(GPU: 0, epoch: 13, iters: 58848, time: 0.005) nll: 0.822470 \n",
      "(GPU: 0, epoch: 13, iters: 59648, time: 0.006) nll: 0.850738 \n",
      "(GPU: 0, epoch: 13, iters: 60448, time: 0.005) nll: 0.982748 \n",
      "(GPU: 0, epoch: 13, iters: 61248, time: 0.006) nll: 0.791393 \n",
      "(GPU: 0, epoch: 13, iters: 62048, time: 0.005) nll: 0.887909 \n",
      "(GPU: 0, epoch: 13, iters: 62848, time: 0.006) nll: 0.726948 \n",
      "(GPU: 0, epoch: 13, iters: 63648, time: 0.006) nll: 0.920608 \n",
      "(GPU: 0, epoch: 13, iters: 64448, time: 0.006) nll: 0.784215 \n",
      "(GPU: 0, epoch: 13, iters: 65248, time: 0.005) nll: 0.794325 \n",
      "(GPU: 0, epoch: 13, iters: 66048, time: 0.006) nll: 0.753799 \n",
      "(GPU: 0, epoch: 13, iters: 66848, time: 0.005) nll: 0.989923 \n",
      "(GPU: 0, epoch: 13, iters: 67648, time: 0.006) nll: 0.734769 \n",
      "(GPU: 0, epoch: 13, iters: 68448, time: 0.005) nll: 0.594113 \n",
      "(GPU: 0, epoch: 13, iters: 69248, time: 0.006) nll: 0.675955 \n",
      "(GPU: 0, epoch: 13, iters: 70048, time: 0.006) nll: 0.716179 \n",
      "(GPU: 0, epoch: 13, iters: 70848, time: 0.006) nll: 0.617242 \n",
      "saving the latest model (epoch 13, total_steps 1900000)\n",
      "(GPU: 0, epoch: 13, iters: 71648, time: 0.005) nll: 0.595765 \n",
      "(GPU: 0, epoch: 13, iters: 72448, time: 0.006) nll: 0.778089 \n",
      "(GPU: 0, epoch: 13, iters: 73248, time: 0.005) nll: 0.619855 \n",
      "(GPU: 0, epoch: 13, iters: 74048, time: 0.006) nll: 0.748400 \n",
      "(GPU: 0, epoch: 13, iters: 74848, time: 0.005) nll: 0.788402 \n",
      "(GPU: 0, epoch: 13, iters: 75648, time: 0.006) nll: 0.620380 \n",
      "(GPU: 0, epoch: 13, iters: 76448, time: 0.005) nll: 0.831667 \n",
      "(GPU: 0, epoch: 13, iters: 77248, time: 0.006) nll: 0.514993 \n",
      "(GPU: 0, epoch: 13, iters: 78048, time: 0.005) nll: 0.690713 \n",
      "(GPU: 0, epoch: 13, iters: 78848, time: 0.006) nll: 0.878119 \n",
      "(GPU: 0, epoch: 13, iters: 79648, time: 0.005) nll: 0.741346 \n",
      "(GPU: 0, epoch: 13, iters: 80448, time: 0.006) nll: 0.817126 \n",
      "(GPU: 0, epoch: 13, iters: 81248, time: 0.006) nll: 0.705405 \n",
      "(GPU: 0, epoch: 13, iters: 82048, time: 0.006) nll: 0.808119 \n",
      "(GPU: 0, epoch: 13, iters: 82848, time: 0.005) nll: 0.629749 \n",
      "(GPU: 0, epoch: 13, iters: 83648, time: 0.006) nll: 0.903889 \n",
      "(GPU: 0, epoch: 13, iters: 84448, time: 0.006) nll: 0.748292 \n",
      "(GPU: 0, epoch: 13, iters: 85248, time: 0.006) nll: 0.933624 \n",
      "(GPU: 0, epoch: 13, iters: 86048, time: 0.005) nll: 0.567295 \n",
      "(GPU: 0, epoch: 13, iters: 86848, time: 0.006) nll: 0.756733 \n",
      "(GPU: 0, epoch: 13, iters: 87648, time: 0.005) nll: 0.910464 \n",
      "(GPU: 0, epoch: 13, iters: 88448, time: 0.006) nll: 0.602144 \n",
      "(GPU: 0, epoch: 13, iters: 89248, time: 0.005) nll: 0.634140 \n",
      "(GPU: 0, epoch: 13, iters: 90048, time: 0.006) nll: 0.821242 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.005) nll: 0.756032 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.009) nll: 0.751681 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.009) nll: 0.775282 \n",
      "saving the latest model (epoch 13, total_steps 1920000)\n",
      "(GPU: 0, epoch: 13, iters: 91648, time: 0.006) nll: 0.555953 \n",
      "(GPU: 0, epoch: 13, iters: 92448, time: 0.005) nll: 0.813256 \n",
      "(GPU: 0, epoch: 13, iters: 93248, time: 0.006) nll: 0.688407 \n",
      "(GPU: 0, epoch: 13, iters: 94048, time: 0.006) nll: 0.833486 \n",
      "(GPU: 0, epoch: 13, iters: 94848, time: 0.006) nll: 0.862696 \n",
      "(GPU: 0, epoch: 13, iters: 95648, time: 0.005) nll: 0.802158 \n",
      "(GPU: 0, epoch: 13, iters: 96448, time: 0.006) nll: 0.770670 \n",
      "(GPU: 0, epoch: 13, iters: 97248, time: 0.005) nll: 0.803743 \n",
      "(GPU: 0, epoch: 13, iters: 98048, time: 0.006) nll: 0.784338 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 98848, time: 0.006) nll: 0.649911 \n",
      "(GPU: 0, epoch: 13, iters: 99648, time: 0.006) nll: 0.812346 \n",
      "(GPU: 0, epoch: 13, iters: 100448, time: 0.005) nll: 0.887110 \n",
      "(GPU: 0, epoch: 13, iters: 101248, time: 0.006) nll: 0.629158 \n",
      "(GPU: 0, epoch: 13, iters: 102048, time: 0.005) nll: 0.632401 \n",
      "(GPU: 0, epoch: 13, iters: 102848, time: 0.006) nll: 0.622494 \n",
      "(GPU: 0, epoch: 13, iters: 103648, time: 0.005) nll: 0.984960 \n",
      "(GPU: 0, epoch: 13, iters: 104448, time: 0.006) nll: 1.204511 \n",
      "(GPU: 0, epoch: 13, iters: 105248, time: 0.006) nll: 0.848721 \n",
      "(GPU: 0, epoch: 13, iters: 106048, time: 0.006) nll: 0.548204 \n",
      "(GPU: 0, epoch: 13, iters: 106848, time: 0.005) nll: 0.607318 \n",
      "(GPU: 0, epoch: 13, iters: 107648, time: 0.006) nll: 0.688554 \n",
      "(GPU: 0, epoch: 13, iters: 108448, time: 0.006) nll: 0.734060 \n",
      "(GPU: 0, epoch: 13, iters: 109248, time: 0.006) nll: 1.020646 \n",
      "(GPU: 0, epoch: 13, iters: 110048, time: 0.005) nll: 1.118708 \n",
      "(GPU: 0, epoch: 13, iters: 110848, time: 0.006) nll: 0.773746 \n",
      "saving the latest model (epoch 13, total_steps 1940000)\n",
      "(GPU: 0, epoch: 13, iters: 111648, time: 0.005) nll: 0.868578 \n",
      "(GPU: 0, epoch: 13, iters: 112448, time: 0.006) nll: 0.659496 \n",
      "(GPU: 0, epoch: 13, iters: 113248, time: 0.005) nll: 0.871386 \n",
      "(GPU: 0, epoch: 13, iters: 114048, time: 0.006) nll: 0.789179 \n",
      "(GPU: 0, epoch: 13, iters: 114848, time: 0.005) nll: 0.594054 \n",
      "(GPU: 0, epoch: 13, iters: 115648, time: 0.006) nll: 0.574009 \n",
      "(GPU: 0, epoch: 13, iters: 116448, time: 0.005) nll: 0.663704 \n",
      "(GPU: 0, epoch: 13, iters: 117248, time: 0.006) nll: 0.900099 \n",
      "(GPU: 0, epoch: 13, iters: 118048, time: 0.005) nll: 0.568852 \n",
      "(GPU: 0, epoch: 13, iters: 118848, time: 0.006) nll: 0.718453 \n",
      "(GPU: 0, epoch: 13, iters: 119648, time: 0.005) nll: 0.751389 \n",
      "(GPU: 0, epoch: 13, iters: 120448, time: 0.006) nll: 0.925386 \n",
      "(GPU: 0, epoch: 13, iters: 121248, time: 0.005) nll: 0.738956 \n",
      "(GPU: 0, epoch: 13, iters: 122048, time: 0.006) nll: 0.590549 \n",
      "(GPU: 0, epoch: 13, iters: 122848, time: 0.005) nll: 0.649346 \n",
      "(GPU: 0, epoch: 13, iters: 123648, time: 0.006) nll: 0.761816 \n",
      "(GPU: 0, epoch: 13, iters: 124448, time: 0.005) nll: 0.666358 \n",
      "(GPU: 0, epoch: 13, iters: 125248, time: 0.006) nll: 0.510722 \n",
      "(GPU: 0, epoch: 13, iters: 126048, time: 0.005) nll: 0.738485 \n",
      "(GPU: 0, epoch: 13, iters: 126848, time: 0.006) nll: 0.812742 \n",
      "(GPU: 0, epoch: 13, iters: 127648, time: 0.005) nll: 0.901706 \n",
      "(GPU: 0, epoch: 13, iters: 128448, time: 0.006) nll: 0.834003 \n",
      "(GPU: 0, epoch: 13, iters: 129248, time: 0.006) nll: 0.887051 \n",
      "(GPU: 0, epoch: 13, iters: 130048, time: 0.006) nll: 0.745953 \n",
      "(GPU: 0, epoch: 13, iters: 130848, time: 0.005) nll: 0.887655 \n",
      "saving the latest model (epoch 13, total_steps 1960000)\n",
      "(GPU: 0, epoch: 13, iters: 131648, time: 0.006) nll: 0.835619 \n",
      "(GPU: 0, epoch: 13, iters: 132448, time: 0.005) nll: 0.678763 \n",
      "(GPU: 0, epoch: 13, iters: 133248, time: 0.006) nll: 0.878726 \n",
      "(GPU: 0, epoch: 13, iters: 134048, time: 0.005) nll: 0.825568 \n",
      "(GPU: 0, epoch: 13, iters: 134848, time: 0.006) nll: 0.780170 \n",
      "(GPU: 0, epoch: 13, iters: 135648, time: 0.005) nll: 0.560867 \n",
      "(GPU: 0, epoch: 13, iters: 136448, time: 0.006) nll: 0.925038 \n",
      "(GPU: 0, epoch: 13, iters: 137248, time: 0.005) nll: 0.616232 \n",
      "(GPU: 0, epoch: 13, iters: 138048, time: 0.006) nll: 0.781533 \n",
      "(GPU: 0, epoch: 13, iters: 138848, time: 0.005) nll: 0.771912 \n",
      "(GPU: 0, epoch: 13, iters: 139648, time: 0.006) nll: 0.772932 \n",
      "(GPU: 0, epoch: 13, iters: 140448, time: 0.005) nll: 0.730391 \n",
      "[*] End of epoch 13 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000845\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3091/4397 [09:46<04:01,  5.40it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 32, time: 0.003) nll: 0.691013 \n",
      "(GPU: 0, epoch: 14, iters: 32, time: 0.003) nll: 1.087384 \n",
      "(GPU: 0, epoch: 14, iters: 544, time: 0.006) nll: 0.759745 \n",
      "(GPU: 0, epoch: 14, iters: 1344, time: 0.006) nll: 0.705512 \n",
      "(GPU: 0, epoch: 14, iters: 2144, time: 0.006) nll: 0.442893 \n",
      "(GPU: 0, epoch: 14, iters: 2944, time: 0.006) nll: 0.890351 \n",
      "(GPU: 0, epoch: 14, iters: 3744, time: 0.005) nll: 1.007957 \n",
      "(GPU: 0, epoch: 14, iters: 4544, time: 0.006) nll: 0.761435 \n",
      "(GPU: 0, epoch: 14, iters: 5344, time: 0.005) nll: 1.205481 \n",
      "(GPU: 0, epoch: 14, iters: 6144, time: 0.006) nll: 0.773365 \n",
      "(GPU: 0, epoch: 14, iters: 6944, time: 0.006) nll: 0.693780 \n",
      "(GPU: 0, epoch: 14, iters: 7744, time: 0.006) nll: 0.702545 \n",
      "(GPU: 0, epoch: 14, iters: 8544, time: 0.006) nll: 0.487750 \n",
      "(GPU: 0, epoch: 14, iters: 9344, time: 0.006) nll: 0.841561 \n",
      "(GPU: 0, epoch: 14, iters: 10144, time: 0.005) nll: 0.953710 \n",
      "saving the latest model (epoch 14, total_steps 1980000)\n",
      "(GPU: 0, epoch: 14, iters: 10944, time: 0.005) nll: 0.747567 \n",
      "(GPU: 0, epoch: 14, iters: 11744, time: 0.005) nll: 1.168502 \n",
      "(GPU: 0, epoch: 14, iters: 12544, time: 0.006) nll: 0.622104 \n",
      "(GPU: 0, epoch: 14, iters: 13344, time: 0.006) nll: 0.747557 \n",
      "(GPU: 0, epoch: 14, iters: 14144, time: 0.006) nll: 0.996162 \n",
      "(GPU: 0, epoch: 14, iters: 14944, time: 0.005) nll: 0.967501 \n",
      "(GPU: 0, epoch: 14, iters: 15744, time: 0.006) nll: 0.957946 \n",
      "(GPU: 0, epoch: 14, iters: 16544, time: 0.005) nll: 0.806202 \n",
      "(GPU: 0, epoch: 14, iters: 17344, time: 0.006) nll: 0.735758 \n",
      "(GPU: 0, epoch: 14, iters: 18144, time: 0.005) nll: 0.735796 \n",
      "(GPU: 0, epoch: 14, iters: 18944, time: 0.006) nll: 0.640270 \n",
      "(GPU: 0, epoch: 14, iters: 19744, time: 0.005) nll: 0.665143 \n",
      "(GPU: 0, epoch: 14, iters: 20544, time: 0.006) nll: 0.710833 \n",
      "(GPU: 0, epoch: 14, iters: 21344, time: 0.005) nll: 0.780458 \n",
      "(GPU: 0, epoch: 14, iters: 22144, time: 0.006) nll: 0.856854 \n",
      "(GPU: 0, epoch: 14, iters: 22944, time: 0.005) nll: 1.018594 \n",
      "(GPU: 0, epoch: 14, iters: 23744, time: 0.006) nll: 0.708912 \n",
      "(GPU: 0, epoch: 14, iters: 24544, time: 0.005) nll: 0.621160 \n",
      "(GPU: 0, epoch: 14, iters: 25344, time: 0.006) nll: 0.828052 \n",
      "(GPU: 0, epoch: 14, iters: 26144, time: 0.005) nll: 0.658259 \n",
      "(GPU: 0, epoch: 14, iters: 26944, time: 0.006) nll: 0.902806 \n",
      "(GPU: 0, epoch: 14, iters: 27744, time: 0.005) nll: 0.793832 \n",
      "(GPU: 0, epoch: 14, iters: 28544, time: 0.006) nll: 0.672752 \n",
      "(GPU: 0, epoch: 14, iters: 29344, time: 0.005) nll: 0.734233 \n",
      "(GPU: 0, epoch: 14, iters: 30144, time: 0.006) nll: 0.844651 \n",
      "saving the latest model (epoch 14, total_steps 2000000)\n",
      "(GPU: 0, epoch: 14, iters: 30944, time: 0.006) nll: 0.814538 \n",
      "(GPU: 0, epoch: 14, iters: 31744, time: 0.006) nll: 1.007346 \n",
      "(GPU: 0, epoch: 14, iters: 32544, time: 0.005) nll: 0.739193 \n",
      "(GPU: 0, epoch: 14, iters: 33344, time: 0.006) nll: 0.743037 \n",
      "(GPU: 0, epoch: 14, iters: 34144, time: 0.005) nll: 0.747335 \n",
      "(GPU: 0, epoch: 14, iters: 34944, time: 0.006) nll: 0.707671 \n",
      "(GPU: 0, epoch: 14, iters: 35744, time: 0.005) nll: 0.940546 \n",
      "(GPU: 0, epoch: 14, iters: 36544, time: 0.006) nll: 0.557808 \n",
      "(GPU: 0, epoch: 14, iters: 37344, time: 0.005) nll: 0.980837 \n",
      "(GPU: 0, epoch: 14, iters: 38144, time: 0.006) nll: 0.918055 \n",
      "(GPU: 0, epoch: 14, iters: 38944, time: 0.005) nll: 0.840806 \n",
      "(GPU: 0, epoch: 14, iters: 39744, time: 0.006) nll: 0.638652 \n",
      "(GPU: 0, epoch: 14, iters: 40544, time: 0.005) nll: 0.904478 \n",
      "(GPU: 0, epoch: 14, iters: 41344, time: 0.006) nll: 0.694452 \n",
      "(GPU: 0, epoch: 14, iters: 42144, time: 0.005) nll: 0.770199 \n",
      "(GPU: 0, epoch: 14, iters: 42944, time: 0.006) nll: 0.771754 \n",
      "(GPU: 0, epoch: 14, iters: 43744, time: 0.006) nll: 0.820613 \n",
      "(GPU: 0, epoch: 14, iters: 44544, time: 0.006) nll: 0.752476 \n",
      "(GPU: 0, epoch: 14, iters: 45344, time: 0.005) nll: 0.702781 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.006) nll: 0.525454 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.009) nll: 0.520446 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.009) nll: 0.605758 \n",
      "(GPU: 0, epoch: 14, iters: 46944, time: 0.005) nll: 0.604938 \n",
      "(GPU: 0, epoch: 14, iters: 47744, time: 0.006) nll: 0.885668 \n",
      "(GPU: 0, epoch: 14, iters: 48544, time: 0.005) nll: 0.473463 \n",
      "(GPU: 0, epoch: 14, iters: 49344, time: 0.006) nll: 0.715747 \n",
      "(GPU: 0, epoch: 14, iters: 50144, time: 0.005) nll: 0.632538 \n",
      "saving the latest model (epoch 14, total_steps 2020000)\n",
      "(GPU: 0, epoch: 14, iters: 50944, time: 0.006) nll: 0.780167 \n",
      "(GPU: 0, epoch: 14, iters: 51744, time: 0.006) nll: 0.926388 \n",
      "(GPU: 0, epoch: 14, iters: 52544, time: 0.006) nll: 0.790950 \n",
      "(GPU: 0, epoch: 14, iters: 53344, time: 0.005) nll: 0.802102 \n",
      "(GPU: 0, epoch: 14, iters: 54144, time: 0.006) nll: 0.898068 \n",
      "(GPU: 0, epoch: 14, iters: 54944, time: 0.005) nll: 0.664079 \n",
      "(GPU: 0, epoch: 14, iters: 55744, time: 0.006) nll: 0.675607 \n",
      "(GPU: 0, epoch: 14, iters: 56544, time: 0.005) nll: 1.056436 \n",
      "(GPU: 0, epoch: 14, iters: 57344, time: 0.006) nll: 0.668774 \n",
      "(GPU: 0, epoch: 14, iters: 58144, time: 0.005) nll: 0.752632 \n",
      "(GPU: 0, epoch: 14, iters: 58944, time: 0.006) nll: 0.725832 \n",
      "(GPU: 0, epoch: 14, iters: 59744, time: 0.005) nll: 0.631171 \n",
      "(GPU: 0, epoch: 14, iters: 60544, time: 0.006) nll: 0.814082 \n",
      "(GPU: 0, epoch: 14, iters: 61344, time: 0.005) nll: 0.580117 \n",
      "(GPU: 0, epoch: 14, iters: 62144, time: 0.006) nll: 0.690953 \n",
      "(GPU: 0, epoch: 14, iters: 62944, time: 0.005) nll: 0.817365 \n",
      "(GPU: 0, epoch: 14, iters: 63744, time: 0.006) nll: 0.897535 \n",
      "(GPU: 0, epoch: 14, iters: 64544, time: 0.005) nll: 0.755448 \n",
      "(GPU: 0, epoch: 14, iters: 65344, time: 0.006) nll: 0.580737 \n",
      "(GPU: 0, epoch: 14, iters: 66144, time: 0.006) nll: 0.859519 \n",
      "(GPU: 0, epoch: 14, iters: 66944, time: 0.006) nll: 0.749457 \n",
      "(GPU: 0, epoch: 14, iters: 67744, time: 0.006) nll: 0.809901 \n",
      "(GPU: 0, epoch: 14, iters: 68544, time: 0.006) nll: 0.693045 \n",
      "(GPU: 0, epoch: 14, iters: 69344, time: 0.005) nll: 1.002060 \n",
      "(GPU: 0, epoch: 14, iters: 70144, time: 0.006) nll: 0.856543 \n",
      "saving the latest model (epoch 14, total_steps 2040000)\n",
      "(GPU: 0, epoch: 14, iters: 70944, time: 0.006) nll: 0.932327 \n",
      "(GPU: 0, epoch: 14, iters: 71744, time: 0.006) nll: 0.840197 \n",
      "(GPU: 0, epoch: 14, iters: 72544, time: 0.006) nll: 0.556504 \n",
      "(GPU: 0, epoch: 14, iters: 73344, time: 0.006) nll: 0.806680 \n",
      "(GPU: 0, epoch: 14, iters: 74144, time: 0.005) nll: 0.716631 \n",
      "(GPU: 0, epoch: 14, iters: 74944, time: 0.006) nll: 0.494366 \n",
      "(GPU: 0, epoch: 14, iters: 75744, time: 0.005) nll: 0.701481 \n",
      "(GPU: 0, epoch: 14, iters: 76544, time: 0.006) nll: 0.781427 \n",
      "(GPU: 0, epoch: 14, iters: 77344, time: 0.006) nll: 0.729298 \n",
      "(GPU: 0, epoch: 14, iters: 78144, time: 0.006) nll: 0.620077 \n",
      "(GPU: 0, epoch: 14, iters: 78944, time: 0.005) nll: 0.879982 \n",
      "(GPU: 0, epoch: 14, iters: 79744, time: 0.006) nll: 0.764842 \n",
      "(GPU: 0, epoch: 14, iters: 80544, time: 0.005) nll: 0.930325 \n",
      "(GPU: 0, epoch: 14, iters: 81344, time: 0.006) nll: 0.788683 \n",
      "(GPU: 0, epoch: 14, iters: 82144, time: 0.005) nll: 0.568972 \n",
      "(GPU: 0, epoch: 14, iters: 82944, time: 0.006) nll: 0.784354 \n",
      "(GPU: 0, epoch: 14, iters: 83744, time: 0.005) nll: 0.752470 \n",
      "(GPU: 0, epoch: 14, iters: 84544, time: 0.006) nll: 0.711320 \n",
      "(GPU: 0, epoch: 14, iters: 85344, time: 0.005) nll: 0.891716 \n",
      "(GPU: 0, epoch: 14, iters: 86144, time: 0.006) nll: 0.858512 \n",
      "(GPU: 0, epoch: 14, iters: 86944, time: 0.005) nll: 0.862909 \n",
      "(GPU: 0, epoch: 14, iters: 87744, time: 0.006) nll: 0.726950 \n",
      "(GPU: 0, epoch: 14, iters: 88544, time: 0.006) nll: 0.735929 \n",
      "(GPU: 0, epoch: 14, iters: 89344, time: 0.006) nll: 1.086125 \n",
      "(GPU: 0, epoch: 14, iters: 90144, time: 0.005) nll: 0.590660 \n",
      "saving the latest model (epoch 14, total_steps 2060000)\n",
      "(GPU: 0, epoch: 14, iters: 90944, time: 0.006) nll: 0.752210 \n",
      "(GPU: 0, epoch: 14, iters: 91744, time: 0.005) nll: 0.881421 \n",
      "(GPU: 0, epoch: 14, iters: 92544, time: 0.006) nll: 0.577949 \n",
      "(GPU: 0, epoch: 14, iters: 93344, time: 0.005) nll: 0.756170 \n",
      "(GPU: 0, epoch: 14, iters: 94144, time: 0.006) nll: 0.789471 \n",
      "(GPU: 0, epoch: 14, iters: 94944, time: 0.005) nll: 0.698330 \n",
      "(GPU: 0, epoch: 14, iters: 95744, time: 0.006) nll: 0.714394 \n",
      "(GPU: 0, epoch: 14, iters: 96544, time: 0.005) nll: 0.856023 \n",
      "(GPU: 0, epoch: 14, iters: 97344, time: 0.006) nll: 0.958908 \n",
      "(GPU: 0, epoch: 14, iters: 98144, time: 0.005) nll: 0.481354 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 98944, time: 0.006) nll: 0.760923 \n",
      "(GPU: 0, epoch: 14, iters: 99744, time: 0.005) nll: 0.842923 \n",
      "(GPU: 0, epoch: 14, iters: 100544, time: 0.006) nll: 0.815490 \n",
      "(GPU: 0, epoch: 14, iters: 101344, time: 0.005) nll: 0.723098 \n",
      "(GPU: 0, epoch: 14, iters: 102144, time: 0.006) nll: 0.802762 \n",
      "(GPU: 0, epoch: 14, iters: 102944, time: 0.005) nll: 0.789679 \n",
      "(GPU: 0, epoch: 14, iters: 103744, time: 0.006) nll: 0.654085 \n",
      "(GPU: 0, epoch: 14, iters: 104544, time: 0.006) nll: 0.719772 \n",
      "(GPU: 0, epoch: 14, iters: 105344, time: 0.006) nll: 0.618962 \n",
      "(GPU: 0, epoch: 14, iters: 106144, time: 0.005) nll: 0.939133 \n",
      "(GPU: 0, epoch: 14, iters: 106944, time: 0.006) nll: 0.578553 \n",
      "(GPU: 0, epoch: 14, iters: 107744, time: 0.005) nll: 0.578345 \n",
      "(GPU: 0, epoch: 14, iters: 108544, time: 0.006) nll: 0.917628 \n",
      "(GPU: 0, epoch: 14, iters: 109344, time: 0.005) nll: 0.924876 \n",
      "(GPU: 0, epoch: 14, iters: 110144, time: 0.006) nll: 0.819503 \n",
      "saving the latest model (epoch 14, total_steps 2080000)\n",
      "(GPU: 0, epoch: 14, iters: 110944, time: 0.005) nll: 0.911244 \n",
      "(GPU: 0, epoch: 14, iters: 111744, time: 0.006) nll: 0.722386 \n",
      "(GPU: 0, epoch: 14, iters: 112544, time: 0.005) nll: 0.621964 \n",
      "(GPU: 0, epoch: 14, iters: 113344, time: 0.006) nll: 0.548361 \n",
      "(GPU: 0, epoch: 14, iters: 114144, time: 0.005) nll: 0.844657 \n",
      "(GPU: 0, epoch: 14, iters: 114944, time: 0.006) nll: 0.659588 \n",
      "(GPU: 0, epoch: 14, iters: 115744, time: 0.005) nll: 0.694772 \n",
      "(GPU: 0, epoch: 14, iters: 116544, time: 0.006) nll: 0.945520 \n",
      "(GPU: 0, epoch: 14, iters: 117344, time: 0.005) nll: 0.737086 \n",
      "(GPU: 0, epoch: 14, iters: 118144, time: 0.006) nll: 0.594170 \n",
      "(GPU: 0, epoch: 14, iters: 118944, time: 0.005) nll: 0.810720 \n",
      "(GPU: 0, epoch: 14, iters: 119744, time: 0.006) nll: 0.826744 \n",
      "(GPU: 0, epoch: 14, iters: 120544, time: 0.006) nll: 0.812698 \n",
      "(GPU: 0, epoch: 14, iters: 121344, time: 0.006) nll: 0.647603 \n",
      "(GPU: 0, epoch: 14, iters: 122144, time: 0.005) nll: 0.865998 \n",
      "(GPU: 0, epoch: 14, iters: 122944, time: 0.006) nll: 0.688460 \n",
      "(GPU: 0, epoch: 14, iters: 123744, time: 0.005) nll: 0.750344 \n",
      "(GPU: 0, epoch: 14, iters: 124544, time: 0.006) nll: 0.690820 \n",
      "(GPU: 0, epoch: 14, iters: 125344, time: 0.005) nll: 0.779860 \n",
      "(GPU: 0, epoch: 14, iters: 126144, time: 0.006) nll: 0.721671 \n",
      "(GPU: 0, epoch: 14, iters: 126944, time: 0.005) nll: 0.704503 \n",
      "(GPU: 0, epoch: 14, iters: 127744, time: 0.006) nll: 0.785086 \n",
      "(GPU: 0, epoch: 14, iters: 128544, time: 0.005) nll: 0.615044 \n",
      "(GPU: 0, epoch: 14, iters: 129344, time: 0.006) nll: 0.780905 \n",
      "(GPU: 0, epoch: 14, iters: 130144, time: 0.005) nll: 0.605912 \n",
      "saving the latest model (epoch 14, total_steps 2100000)\n",
      "(GPU: 0, epoch: 14, iters: 130944, time: 0.006) nll: 0.671609 \n",
      "(GPU: 0, epoch: 14, iters: 131744, time: 0.005) nll: 0.740704 \n",
      "(GPU: 0, epoch: 14, iters: 132544, time: 0.006) nll: 0.575710 \n",
      "(GPU: 0, epoch: 14, iters: 133344, time: 0.006) nll: 0.905871 \n",
      "(GPU: 0, epoch: 14, iters: 134144, time: 0.006) nll: 0.730165 \n",
      "(GPU: 0, epoch: 14, iters: 134944, time: 0.005) nll: 0.611177 \n",
      "(GPU: 0, epoch: 14, iters: 135744, time: 0.006) nll: 0.782619 \n",
      "(GPU: 0, epoch: 14, iters: 136544, time: 0.006) nll: 0.571723 \n",
      "(GPU: 0, epoch: 14, iters: 137344, time: 0.006) nll: 0.667056 \n",
      "(GPU: 0, epoch: 14, iters: 138144, time: 0.006) nll: 0.641619 \n",
      "(GPU: 0, epoch: 14, iters: 138944, time: 0.006) nll: 0.715820 \n",
      "(GPU: 0, epoch: 14, iters: 139744, time: 0.005) nll: 0.784072 \n",
      "(GPU: 0, epoch: 14, iters: 140544, time: 0.006) nll: 0.648846 \n",
      "[*] End of epoch 14 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000816\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3044/4397 [09:38<04:09,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 32, time: 0.003) nll: 0.665496 \n",
      "(GPU: 0, epoch: 15, iters: 32, time: 0.003) nll: 0.612217 \n",
      "(GPU: 0, epoch: 15, iters: 640, time: 0.006) nll: 0.552004 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.005) nll: 0.807308 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.008) nll: 0.798987 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.008) nll: 0.756107 \n",
      "(GPU: 0, epoch: 15, iters: 2240, time: 0.006) nll: 0.738174 \n",
      "(GPU: 0, epoch: 15, iters: 3040, time: 0.006) nll: 0.965290 \n",
      "(GPU: 0, epoch: 15, iters: 3840, time: 0.006) nll: 0.742966 \n",
      "(GPU: 0, epoch: 15, iters: 4640, time: 0.005) nll: 0.748246 \n",
      "(GPU: 0, epoch: 15, iters: 5440, time: 0.006) nll: 0.847590 \n",
      "(GPU: 0, epoch: 15, iters: 6240, time: 0.005) nll: 0.724749 \n",
      "(GPU: 0, epoch: 15, iters: 7040, time: 0.006) nll: 0.621488 \n",
      "(GPU: 0, epoch: 15, iters: 7840, time: 0.006) nll: 0.813730 \n",
      "(GPU: 0, epoch: 15, iters: 8640, time: 0.006) nll: 1.130987 \n",
      "(GPU: 0, epoch: 15, iters: 9440, time: 0.005) nll: 0.794122 \n",
      "saving the latest model (epoch 15, total_steps 2120000)\n",
      "(GPU: 0, epoch: 15, iters: 10240, time: 0.006) nll: 0.845349 \n",
      "(GPU: 0, epoch: 15, iters: 11040, time: 0.005) nll: 0.616952 \n",
      "(GPU: 0, epoch: 15, iters: 11840, time: 0.006) nll: 0.766788 \n",
      "(GPU: 0, epoch: 15, iters: 12640, time: 0.005) nll: 0.786771 \n",
      "(GPU: 0, epoch: 15, iters: 13440, time: 0.006) nll: 0.854870 \n",
      "(GPU: 0, epoch: 15, iters: 14240, time: 0.005) nll: 0.751730 \n",
      "(GPU: 0, epoch: 15, iters: 15040, time: 0.006) nll: 0.656923 \n",
      "(GPU: 0, epoch: 15, iters: 15840, time: 0.005) nll: 0.715671 \n",
      "(GPU: 0, epoch: 15, iters: 16640, time: 0.006) nll: 0.823672 \n",
      "(GPU: 0, epoch: 15, iters: 17440, time: 0.005) nll: 0.822475 \n",
      "(GPU: 0, epoch: 15, iters: 18240, time: 0.006) nll: 0.934283 \n",
      "(GPU: 0, epoch: 15, iters: 19040, time: 0.005) nll: 0.780617 \n",
      "(GPU: 0, epoch: 15, iters: 19840, time: 0.006) nll: 0.744515 \n",
      "(GPU: 0, epoch: 15, iters: 20640, time: 0.006) nll: 0.567366 \n",
      "(GPU: 0, epoch: 15, iters: 21440, time: 0.006) nll: 0.710204 \n",
      "(GPU: 0, epoch: 15, iters: 22240, time: 0.005) nll: 0.936039 \n",
      "(GPU: 0, epoch: 15, iters: 23040, time: 0.006) nll: 0.735419 \n",
      "(GPU: 0, epoch: 15, iters: 23840, time: 0.005) nll: 0.701643 \n",
      "(GPU: 0, epoch: 15, iters: 24640, time: 0.006) nll: 0.748839 \n",
      "(GPU: 0, epoch: 15, iters: 25440, time: 0.005) nll: 0.810387 \n",
      "(GPU: 0, epoch: 15, iters: 26240, time: 0.006) nll: 0.689201 \n",
      "(GPU: 0, epoch: 15, iters: 27040, time: 0.005) nll: 0.849736 \n",
      "(GPU: 0, epoch: 15, iters: 27840, time: 0.006) nll: 0.571448 \n",
      "(GPU: 0, epoch: 15, iters: 28640, time: 0.005) nll: 0.756670 \n",
      "(GPU: 0, epoch: 15, iters: 29440, time: 0.006) nll: 0.795969 \n",
      "saving the latest model (epoch 15, total_steps 2140000)\n",
      "(GPU: 0, epoch: 15, iters: 30240, time: 0.005) nll: 1.050110 \n",
      "(GPU: 0, epoch: 15, iters: 31040, time: 0.006) nll: 0.739831 \n",
      "(GPU: 0, epoch: 15, iters: 31840, time: 0.005) nll: 0.771112 \n",
      "(GPU: 0, epoch: 15, iters: 32640, time: 0.006) nll: 0.880002 \n",
      "(GPU: 0, epoch: 15, iters: 33440, time: 0.005) nll: 0.714295 \n",
      "(GPU: 0, epoch: 15, iters: 34240, time: 0.006) nll: 0.742285 \n",
      "(GPU: 0, epoch: 15, iters: 35040, time: 0.005) nll: 0.693349 \n",
      "(GPU: 0, epoch: 15, iters: 35840, time: 0.006) nll: 0.711538 \n",
      "(GPU: 0, epoch: 15, iters: 36640, time: 0.005) nll: 0.760498 \n",
      "(GPU: 0, epoch: 15, iters: 37440, time: 0.006) nll: 0.762989 \n",
      "(GPU: 0, epoch: 15, iters: 38240, time: 0.005) nll: 0.578915 \n",
      "(GPU: 0, epoch: 15, iters: 39040, time: 0.006) nll: 0.715188 \n",
      "(GPU: 0, epoch: 15, iters: 39840, time: 0.006) nll: 0.713474 \n",
      "(GPU: 0, epoch: 15, iters: 40640, time: 0.006) nll: 0.577412 \n",
      "(GPU: 0, epoch: 15, iters: 41440, time: 0.005) nll: 0.710475 \n",
      "(GPU: 0, epoch: 15, iters: 42240, time: 0.006) nll: 0.910368 \n",
      "(GPU: 0, epoch: 15, iters: 43040, time: 0.005) nll: 0.552085 \n",
      "(GPU: 0, epoch: 15, iters: 43840, time: 0.006) nll: 1.037457 \n",
      "(GPU: 0, epoch: 15, iters: 44640, time: 0.005) nll: 0.771062 \n",
      "(GPU: 0, epoch: 15, iters: 45440, time: 0.006) nll: 0.706457 \n",
      "(GPU: 0, epoch: 15, iters: 46240, time: 0.005) nll: 0.672521 \n",
      "(GPU: 0, epoch: 15, iters: 47040, time: 0.006) nll: 0.695294 \n",
      "(GPU: 0, epoch: 15, iters: 47840, time: 0.005) nll: 0.643176 \n",
      "(GPU: 0, epoch: 15, iters: 48640, time: 0.006) nll: 0.685170 \n",
      "(GPU: 0, epoch: 15, iters: 49440, time: 0.005) nll: 0.633593 \n",
      "saving the latest model (epoch 15, total_steps 2160000)\n",
      "(GPU: 0, epoch: 15, iters: 50240, time: 0.006) nll: 0.871056 \n",
      "(GPU: 0, epoch: 15, iters: 51040, time: 0.005) nll: 0.860689 \n",
      "(GPU: 0, epoch: 15, iters: 51840, time: 0.006) nll: 0.664984 \n",
      "(GPU: 0, epoch: 15, iters: 52640, time: 0.005) nll: 0.794400 \n",
      "(GPU: 0, epoch: 15, iters: 53440, time: 0.006) nll: 0.456204 \n",
      "(GPU: 0, epoch: 15, iters: 54240, time: 0.005) nll: 0.725513 \n",
      "(GPU: 0, epoch: 15, iters: 55040, time: 0.006) nll: 0.801687 \n",
      "(GPU: 0, epoch: 15, iters: 55840, time: 0.005) nll: 0.777122 \n",
      "(GPU: 0, epoch: 15, iters: 56640, time: 0.006) nll: 0.937444 \n",
      "(GPU: 0, epoch: 15, iters: 57440, time: 0.005) nll: 0.611834 \n",
      "(GPU: 0, epoch: 15, iters: 58240, time: 0.006) nll: 0.888622 \n",
      "(GPU: 0, epoch: 15, iters: 59040, time: 0.005) nll: 1.028885 \n",
      "(GPU: 0, epoch: 15, iters: 59840, time: 0.006) nll: 0.926960 \n",
      "(GPU: 0, epoch: 15, iters: 60640, time: 0.005) nll: 0.625059 \n",
      "(GPU: 0, epoch: 15, iters: 61440, time: 0.006) nll: 0.823489 \n",
      "(GPU: 0, epoch: 15, iters: 62240, time: 0.005) nll: 0.627944 \n",
      "(GPU: 0, epoch: 15, iters: 63040, time: 0.006) nll: 0.720344 \n",
      "(GPU: 0, epoch: 15, iters: 63840, time: 0.005) nll: 0.990814 \n",
      "(GPU: 0, epoch: 15, iters: 64640, time: 0.006) nll: 0.705132 \n",
      "(GPU: 0, epoch: 15, iters: 65440, time: 0.005) nll: 0.831158 \n",
      "(GPU: 0, epoch: 15, iters: 66240, time: 0.006) nll: 0.571859 \n",
      "(GPU: 0, epoch: 15, iters: 67040, time: 0.005) nll: 0.630614 \n",
      "(GPU: 0, epoch: 15, iters: 67840, time: 0.006) nll: 0.651897 \n",
      "(GPU: 0, epoch: 15, iters: 68640, time: 0.005) nll: 0.885814 \n",
      "(GPU: 0, epoch: 15, iters: 69440, time: 0.006) nll: 0.740881 \n",
      "saving the latest model (epoch 15, total_steps 2180000)\n",
      "(GPU: 0, epoch: 15, iters: 70240, time: 0.005) nll: 0.683533 \n",
      "(GPU: 0, epoch: 15, iters: 71040, time: 0.006) nll: 0.737919 \n",
      "(GPU: 0, epoch: 15, iters: 71840, time: 0.005) nll: 0.786488 \n",
      "(GPU: 0, epoch: 15, iters: 72640, time: 0.006) nll: 0.797212 \n",
      "(GPU: 0, epoch: 15, iters: 73440, time: 0.006) nll: 0.690254 \n",
      "(GPU: 0, epoch: 15, iters: 74240, time: 0.006) nll: 0.860353 \n",
      "(GPU: 0, epoch: 15, iters: 75040, time: 0.005) nll: 0.681302 \n",
      "(GPU: 0, epoch: 15, iters: 75840, time: 0.006) nll: 0.922049 \n",
      "(GPU: 0, epoch: 15, iters: 76640, time: 0.005) nll: 1.039804 \n",
      "(GPU: 0, epoch: 15, iters: 77440, time: 0.006) nll: 0.798539 \n",
      "(GPU: 0, epoch: 15, iters: 78240, time: 0.005) nll: 0.773206 \n",
      "(GPU: 0, epoch: 15, iters: 79040, time: 0.006) nll: 0.794616 \n",
      "(GPU: 0, epoch: 15, iters: 79840, time: 0.005) nll: 0.718135 \n",
      "(GPU: 0, epoch: 15, iters: 80640, time: 0.006) nll: 0.842198 \n",
      "(GPU: 0, epoch: 15, iters: 81440, time: 0.005) nll: 0.751091 \n",
      "(GPU: 0, epoch: 15, iters: 82240, time: 0.006) nll: 0.728769 \n",
      "(GPU: 0, epoch: 15, iters: 83040, time: 0.005) nll: 0.868030 \n",
      "(GPU: 0, epoch: 15, iters: 83840, time: 0.006) nll: 0.908466 \n",
      "(GPU: 0, epoch: 15, iters: 84640, time: 0.005) nll: 0.772368 \n",
      "(GPU: 0, epoch: 15, iters: 85440, time: 0.006) nll: 0.798276 \n",
      "(GPU: 0, epoch: 15, iters: 86240, time: 0.005) nll: 0.687025 \n",
      "(GPU: 0, epoch: 15, iters: 87040, time: 0.006) nll: 0.843046 \n",
      "(GPU: 0, epoch: 15, iters: 87840, time: 0.005) nll: 0.604342 \n",
      "(GPU: 0, epoch: 15, iters: 88640, time: 0.006) nll: 0.797149 \n",
      "(GPU: 0, epoch: 15, iters: 89440, time: 0.005) nll: 0.793252 \n",
      "saving the latest model (epoch 15, total_steps 2200000)\n",
      "(GPU: 0, epoch: 15, iters: 90240, time: 0.006) nll: 0.890328 \n",
      "(GPU: 0, epoch: 15, iters: 91040, time: 0.005) nll: 0.620944 \n",
      "(GPU: 0, epoch: 15, iters: 91840, time: 0.006) nll: 0.679568 \n",
      "(GPU: 0, epoch: 15, iters: 92640, time: 0.005) nll: 0.842318 \n",
      "(GPU: 0, epoch: 15, iters: 93440, time: 0.006) nll: 0.657007 \n",
      "(GPU: 0, epoch: 15, iters: 94240, time: 0.005) nll: 0.700867 \n",
      "(GPU: 0, epoch: 15, iters: 95040, time: 0.006) nll: 0.573088 \n",
      "(GPU: 0, epoch: 15, iters: 95840, time: 0.005) nll: 0.597599 \n",
      "(GPU: 0, epoch: 15, iters: 96640, time: 0.006) nll: 0.720606 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.005) nll: 0.756833 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.008) nll: 0.752025 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.008) nll: 0.737047 \n",
      "(GPU: 0, epoch: 15, iters: 98240, time: 0.006) nll: 0.733944 \n",
      "(GPU: 0, epoch: 15, iters: 99040, time: 0.005) nll: 0.801710 \n",
      "(GPU: 0, epoch: 15, iters: 99840, time: 0.006) nll: 0.851236 \n",
      "(GPU: 0, epoch: 15, iters: 100640, time: 0.005) nll: 0.872560 \n",
      "(GPU: 0, epoch: 15, iters: 101440, time: 0.006) nll: 0.710470 \n",
      "(GPU: 0, epoch: 15, iters: 102240, time: 0.005) nll: 0.959168 \n",
      "(GPU: 0, epoch: 15, iters: 103040, time: 0.006) nll: 0.634280 \n",
      "(GPU: 0, epoch: 15, iters: 103840, time: 0.005) nll: 0.510881 \n",
      "(GPU: 0, epoch: 15, iters: 104640, time: 0.006) nll: 0.823185 \n",
      "(GPU: 0, epoch: 15, iters: 105440, time: 0.005) nll: 0.909368 \n",
      "(GPU: 0, epoch: 15, iters: 106240, time: 0.006) nll: 0.829189 \n",
      "(GPU: 0, epoch: 15, iters: 107040, time: 0.005) nll: 0.749210 \n",
      "(GPU: 0, epoch: 15, iters: 107840, time: 0.006) nll: 0.991458 \n",
      "(GPU: 0, epoch: 15, iters: 108640, time: 0.005) nll: 0.935958 \n",
      "(GPU: 0, epoch: 15, iters: 109440, time: 0.006) nll: 0.760311 \n",
      "saving the latest model (epoch 15, total_steps 2220000)\n",
      "(GPU: 0, epoch: 15, iters: 110240, time: 0.005) nll: 0.624216 \n",
      "(GPU: 0, epoch: 15, iters: 111040, time: 0.006) nll: 0.662685 \n",
      "(GPU: 0, epoch: 15, iters: 111840, time: 0.005) nll: 0.861539 \n",
      "(GPU: 0, epoch: 15, iters: 112640, time: 0.006) nll: 0.789244 \n",
      "(GPU: 0, epoch: 15, iters: 113440, time: 0.005) nll: 0.721388 \n",
      "(GPU: 0, epoch: 15, iters: 114240, time: 0.006) nll: 0.717133 \n",
      "(GPU: 0, epoch: 15, iters: 115040, time: 0.005) nll: 0.549143 \n",
      "(GPU: 0, epoch: 15, iters: 115840, time: 0.006) nll: 0.621294 \n",
      "(GPU: 0, epoch: 15, iters: 116640, time: 0.005) nll: 0.565102 \n",
      "(GPU: 0, epoch: 15, iters: 117440, time: 0.006) nll: 0.989474 \n",
      "(GPU: 0, epoch: 15, iters: 118240, time: 0.005) nll: 0.804840 \n",
      "(GPU: 0, epoch: 15, iters: 119040, time: 0.006) nll: 0.747933 \n",
      "(GPU: 0, epoch: 15, iters: 119840, time: 0.005) nll: 0.743960 \n",
      "(GPU: 0, epoch: 15, iters: 120640, time: 0.006) nll: 0.807263 \n",
      "(GPU: 0, epoch: 15, iters: 121440, time: 0.005) nll: 0.627663 \n",
      "(GPU: 0, epoch: 15, iters: 122240, time: 0.006) nll: 0.749289 \n",
      "(GPU: 0, epoch: 15, iters: 123040, time: 0.005) nll: 0.737046 \n",
      "(GPU: 0, epoch: 15, iters: 123840, time: 0.006) nll: 0.730172 \n",
      "(GPU: 0, epoch: 15, iters: 124640, time: 0.005) nll: 0.778329 \n",
      "(GPU: 0, epoch: 15, iters: 125440, time: 0.006) nll: 0.713698 \n",
      "(GPU: 0, epoch: 15, iters: 126240, time: 0.005) nll: 0.682205 \n",
      "(GPU: 0, epoch: 15, iters: 127040, time: 0.006) nll: 0.839069 \n",
      "(GPU: 0, epoch: 15, iters: 127840, time: 0.005) nll: 0.812032 \n",
      "(GPU: 0, epoch: 15, iters: 128640, time: 0.006) nll: 0.784536 \n",
      "(GPU: 0, epoch: 15, iters: 129440, time: 0.005) nll: 0.692525 \n",
      "saving the latest model (epoch 15, total_steps 2240000)\n",
      "(GPU: 0, epoch: 15, iters: 130240, time: 0.006) nll: 0.694715 \n",
      "(GPU: 0, epoch: 15, iters: 131040, time: 0.005) nll: 0.590821 \n",
      "(GPU: 0, epoch: 15, iters: 131840, time: 0.006) nll: 0.573499 \n",
      "(GPU: 0, epoch: 15, iters: 132640, time: 0.005) nll: 0.846388 \n",
      "(GPU: 0, epoch: 15, iters: 133440, time: 0.006) nll: 0.723168 \n",
      "(GPU: 0, epoch: 15, iters: 134240, time: 0.005) nll: 0.564912 \n",
      "(GPU: 0, epoch: 15, iters: 135040, time: 0.006) nll: 0.601941 \n",
      "(GPU: 0, epoch: 15, iters: 135840, time: 0.005) nll: 0.736982 \n",
      "(GPU: 0, epoch: 15, iters: 136640, time: 0.006) nll: 1.081532 \n",
      "(GPU: 0, epoch: 15, iters: 137440, time: 0.005) nll: 0.797234 \n",
      "(GPU: 0, epoch: 15, iters: 138240, time: 0.006) nll: 0.949741 \n",
      "(GPU: 0, epoch: 15, iters: 139040, time: 0.006) nll: 0.525812 \n",
      "(GPU: 0, epoch: 15, iters: 139840, time: 0.006) nll: 0.790291 \n",
      "(GPU: 0, epoch: 15, iters: 140640, time: 0.005) nll: 0.836042 \n",
      "saving the model at the end of epoch 15, iters 2251264\n",
      "([test] GPU: 0, epoch: 15) \n",
      "OrderedDict()\n",
      "[*] End of epoch 15 / 25 \t Time Taken: 839 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000791\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3097/4397 [09:46<03:58,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 32, time: 0.003) nll: 0.650118 \n",
      "(GPU: 0, epoch: 16, iters: 32, time: 0.003) nll: 0.627845 \n",
      "(GPU: 0, epoch: 16, iters: 736, time: 0.005) nll: 0.638435 \n",
      "(GPU: 0, epoch: 16, iters: 1536, time: 0.006) nll: 0.740066 \n",
      "(GPU: 0, epoch: 16, iters: 2336, time: 0.005) nll: 0.678804 \n",
      "(GPU: 0, epoch: 16, iters: 3136, time: 0.006) nll: 0.765662 \n",
      "(GPU: 0, epoch: 16, iters: 3936, time: 0.005) nll: 0.912867 \n",
      "(GPU: 0, epoch: 16, iters: 4736, time: 0.006) nll: 0.507777 \n",
      "(GPU: 0, epoch: 16, iters: 5536, time: 0.005) nll: 0.574637 \n",
      "(GPU: 0, epoch: 16, iters: 6336, time: 0.006) nll: 0.499344 \n",
      "(GPU: 0, epoch: 16, iters: 7136, time: 0.005) nll: 0.757247 \n",
      "(GPU: 0, epoch: 16, iters: 7936, time: 0.006) nll: 0.640189 \n",
      "(GPU: 0, epoch: 16, iters: 8736, time: 0.005) nll: 0.884977 \n",
      "saving the latest model (epoch 16, total_steps 2260000)\n",
      "(GPU: 0, epoch: 16, iters: 9536, time: 0.006) nll: 0.697117 \n",
      "(GPU: 0, epoch: 16, iters: 10336, time: 0.005) nll: 0.720254 \n",
      "(GPU: 0, epoch: 16, iters: 11136, time: 0.006) nll: 0.725042 \n",
      "(GPU: 0, epoch: 16, iters: 11936, time: 0.005) nll: 0.508182 \n",
      "(GPU: 0, epoch: 16, iters: 12736, time: 0.006) nll: 0.724955 \n",
      "(GPU: 0, epoch: 16, iters: 13536, time: 0.005) nll: 0.553707 \n",
      "(GPU: 0, epoch: 16, iters: 14336, time: 0.006) nll: 0.796057 \n",
      "(GPU: 0, epoch: 16, iters: 15136, time: 0.005) nll: 0.668027 \n",
      "(GPU: 0, epoch: 16, iters: 15936, time: 0.006) nll: 0.537616 \n",
      "(GPU: 0, epoch: 16, iters: 16736, time: 0.005) nll: 0.623231 \n",
      "(GPU: 0, epoch: 16, iters: 17536, time: 0.006) nll: 0.895315 \n",
      "(GPU: 0, epoch: 16, iters: 18336, time: 0.005) nll: 0.844139 \n",
      "(GPU: 0, epoch: 16, iters: 19136, time: 0.006) nll: 0.875106 \n",
      "(GPU: 0, epoch: 16, iters: 19936, time: 0.005) nll: 0.697087 \n",
      "(GPU: 0, epoch: 16, iters: 20736, time: 0.006) nll: 0.766359 \n",
      "(GPU: 0, epoch: 16, iters: 21536, time: 0.005) nll: 0.704785 \n",
      "(GPU: 0, epoch: 16, iters: 22336, time: 0.006) nll: 0.685930 \n",
      "(GPU: 0, epoch: 16, iters: 23136, time: 0.005) nll: 0.626375 \n",
      "(GPU: 0, epoch: 16, iters: 23936, time: 0.006) nll: 0.679245 \n",
      "(GPU: 0, epoch: 16, iters: 24736, time: 0.006) nll: 0.641780 \n",
      "(GPU: 0, epoch: 16, iters: 25536, time: 0.006) nll: 0.544875 \n",
      "(GPU: 0, epoch: 16, iters: 26336, time: 0.005) nll: 0.579707 \n",
      "(GPU: 0, epoch: 16, iters: 27136, time: 0.006) nll: 0.687220 \n",
      "(GPU: 0, epoch: 16, iters: 27936, time: 0.005) nll: 0.819320 \n",
      "(GPU: 0, epoch: 16, iters: 28736, time: 0.006) nll: 0.705804 \n",
      "saving the latest model (epoch 16, total_steps 2280000)\n",
      "(GPU: 0, epoch: 16, iters: 29536, time: 0.005) nll: 0.756878 \n",
      "(GPU: 0, epoch: 16, iters: 30336, time: 0.006) nll: 0.852567 \n",
      "(GPU: 0, epoch: 16, iters: 31136, time: 0.005) nll: 0.894646 \n",
      "(GPU: 0, epoch: 16, iters: 31936, time: 0.006) nll: 0.879858 \n",
      "(GPU: 0, epoch: 16, iters: 32736, time: 0.005) nll: 0.996241 \n",
      "(GPU: 0, epoch: 16, iters: 33536, time: 0.006) nll: 0.734546 \n",
      "(GPU: 0, epoch: 16, iters: 34336, time: 0.005) nll: 0.765883 \n",
      "(GPU: 0, epoch: 16, iters: 35136, time: 0.006) nll: 0.635811 \n",
      "(GPU: 0, epoch: 16, iters: 35936, time: 0.006) nll: 0.809513 \n",
      "(GPU: 0, epoch: 16, iters: 36736, time: 0.006) nll: 0.823088 \n",
      "(GPU: 0, epoch: 16, iters: 37536, time: 0.006) nll: 0.639685 \n",
      "(GPU: 0, epoch: 16, iters: 38336, time: 0.006) nll: 0.593335 \n",
      "(GPU: 0, epoch: 16, iters: 39136, time: 0.005) nll: 0.869084 \n",
      "(GPU: 0, epoch: 16, iters: 39936, time: 0.006) nll: 0.764026 \n",
      "(GPU: 0, epoch: 16, iters: 40736, time: 0.005) nll: 0.837326 \n",
      "(GPU: 0, epoch: 16, iters: 41536, time: 0.006) nll: 0.798112 \n",
      "(GPU: 0, epoch: 16, iters: 42336, time: 0.005) nll: 0.887792 \n",
      "(GPU: 0, epoch: 16, iters: 43136, time: 0.006) nll: 1.022140 \n",
      "(GPU: 0, epoch: 16, iters: 43936, time: 0.005) nll: 0.672192 \n",
      "(GPU: 0, epoch: 16, iters: 44736, time: 0.006) nll: 0.614658 \n",
      "(GPU: 0, epoch: 16, iters: 45536, time: 0.005) nll: 0.690468 \n",
      "(GPU: 0, epoch: 16, iters: 46336, time: 0.006) nll: 0.778532 \n",
      "(GPU: 0, epoch: 16, iters: 47136, time: 0.005) nll: 0.934183 \n",
      "(GPU: 0, epoch: 16, iters: 47936, time: 0.006) nll: 0.782346 \n",
      "(GPU: 0, epoch: 16, iters: 48736, time: 0.005) nll: 0.745869 \n",
      "saving the latest model (epoch 16, total_steps 2300000)\n",
      "(GPU: 0, epoch: 16, iters: 49536, time: 0.006) nll: 0.836593 \n",
      "(GPU: 0, epoch: 16, iters: 50336, time: 0.005) nll: 0.717956 \n",
      "(GPU: 0, epoch: 16, iters: 51136, time: 0.006) nll: 0.714214 \n",
      "(GPU: 0, epoch: 16, iters: 51936, time: 0.005) nll: 0.699878 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.006) nll: 0.835818 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.009) nll: 0.829989 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.009) nll: 0.592224 \n",
      "(GPU: 0, epoch: 16, iters: 53536, time: 0.005) nll: 0.636681 \n",
      "(GPU: 0, epoch: 16, iters: 54336, time: 0.005) nll: 0.836456 \n",
      "(GPU: 0, epoch: 16, iters: 55136, time: 0.005) nll: 0.776264 \n",
      "(GPU: 0, epoch: 16, iters: 55936, time: 0.006) nll: 0.987425 \n",
      "(GPU: 0, epoch: 16, iters: 56736, time: 0.005) nll: 0.891318 \n",
      "(GPU: 0, epoch: 16, iters: 57536, time: 0.006) nll: 0.832060 \n",
      "(GPU: 0, epoch: 16, iters: 58336, time: 0.005) nll: 0.762136 \n",
      "(GPU: 0, epoch: 16, iters: 59136, time: 0.006) nll: 0.717537 \n",
      "(GPU: 0, epoch: 16, iters: 59936, time: 0.006) nll: 0.674418 \n",
      "(GPU: 0, epoch: 16, iters: 60736, time: 0.006) nll: 0.622606 \n",
      "(GPU: 0, epoch: 16, iters: 61536, time: 0.005) nll: 0.798557 \n",
      "(GPU: 0, epoch: 16, iters: 62336, time: 0.006) nll: 0.815627 \n",
      "(GPU: 0, epoch: 16, iters: 63136, time: 0.005) nll: 0.800617 \n",
      "(GPU: 0, epoch: 16, iters: 63936, time: 0.006) nll: 0.799759 \n",
      "(GPU: 0, epoch: 16, iters: 64736, time: 0.005) nll: 0.660457 \n",
      "(GPU: 0, epoch: 16, iters: 65536, time: 0.006) nll: 0.810427 \n",
      "(GPU: 0, epoch: 16, iters: 66336, time: 0.005) nll: 0.469635 \n",
      "(GPU: 0, epoch: 16, iters: 67136, time: 0.006) nll: 0.649323 \n",
      "(GPU: 0, epoch: 16, iters: 67936, time: 0.005) nll: 0.797139 \n",
      "(GPU: 0, epoch: 16, iters: 68736, time: 0.006) nll: 0.928021 \n",
      "saving the latest model (epoch 16, total_steps 2320000)\n",
      "(GPU: 0, epoch: 16, iters: 69536, time: 0.005) nll: 0.889801 \n",
      "(GPU: 0, epoch: 16, iters: 70336, time: 0.006) nll: 0.730558 \n",
      "(GPU: 0, epoch: 16, iters: 71136, time: 0.005) nll: 0.663437 \n",
      "(GPU: 0, epoch: 16, iters: 71936, time: 0.006) nll: 0.774997 \n",
      "(GPU: 0, epoch: 16, iters: 72736, time: 0.005) nll: 0.830633 \n",
      "(GPU: 0, epoch: 16, iters: 73536, time: 0.006) nll: 0.786256 \n",
      "(GPU: 0, epoch: 16, iters: 74336, time: 0.005) nll: 0.743810 \n",
      "(GPU: 0, epoch: 16, iters: 75136, time: 0.006) nll: 0.998670 \n",
      "(GPU: 0, epoch: 16, iters: 75936, time: 0.005) nll: 0.612798 \n",
      "(GPU: 0, epoch: 16, iters: 76736, time: 0.006) nll: 0.880756 \n",
      "(GPU: 0, epoch: 16, iters: 77536, time: 0.005) nll: 0.663888 \n",
      "(GPU: 0, epoch: 16, iters: 78336, time: 0.006) nll: 0.702299 \n",
      "(GPU: 0, epoch: 16, iters: 79136, time: 0.006) nll: 0.950110 \n",
      "(GPU: 0, epoch: 16, iters: 79936, time: 0.006) nll: 0.897196 \n",
      "(GPU: 0, epoch: 16, iters: 80736, time: 0.005) nll: 0.890474 \n",
      "(GPU: 0, epoch: 16, iters: 81536, time: 0.006) nll: 1.202417 \n",
      "(GPU: 0, epoch: 16, iters: 82336, time: 0.005) nll: 0.625653 \n",
      "(GPU: 0, epoch: 16, iters: 83136, time: 0.006) nll: 0.977869 \n",
      "(GPU: 0, epoch: 16, iters: 83936, time: 0.005) nll: 0.920173 \n",
      "(GPU: 0, epoch: 16, iters: 84736, time: 0.006) nll: 0.693548 \n",
      "(GPU: 0, epoch: 16, iters: 85536, time: 0.005) nll: 0.836821 \n",
      "(GPU: 0, epoch: 16, iters: 86336, time: 0.006) nll: 0.536084 \n",
      "(GPU: 0, epoch: 16, iters: 87136, time: 0.005) nll: 0.790145 \n",
      "(GPU: 0, epoch: 16, iters: 87936, time: 0.006) nll: 0.656367 \n",
      "(GPU: 0, epoch: 16, iters: 88736, time: 0.006) nll: 0.846643 \n",
      "saving the latest model (epoch 16, total_steps 2340000)\n",
      "(GPU: 0, epoch: 16, iters: 89536, time: 0.006) nll: 1.197888 \n",
      "(GPU: 0, epoch: 16, iters: 90336, time: 0.005) nll: 0.817915 \n",
      "(GPU: 0, epoch: 16, iters: 91136, time: 0.006) nll: 0.553185 \n",
      "(GPU: 0, epoch: 16, iters: 91936, time: 0.005) nll: 0.653014 \n",
      "(GPU: 0, epoch: 16, iters: 92736, time: 0.006) nll: 0.984586 \n",
      "(GPU: 0, epoch: 16, iters: 93536, time: 0.005) nll: 0.886715 \n",
      "(GPU: 0, epoch: 16, iters: 94336, time: 0.006) nll: 0.544958 \n",
      "(GPU: 0, epoch: 16, iters: 95136, time: 0.006) nll: 0.601055 \n",
      "(GPU: 0, epoch: 16, iters: 95936, time: 0.006) nll: 0.781803 \n",
      "(GPU: 0, epoch: 16, iters: 96736, time: 0.005) nll: 0.836724 \n",
      "(GPU: 0, epoch: 16, iters: 97536, time: 0.006) nll: 1.079216 \n",
      "(GPU: 0, epoch: 16, iters: 98336, time: 0.005) nll: 0.722135 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 99136, time: 0.006) nll: 0.740101 \n",
      "(GPU: 0, epoch: 16, iters: 99936, time: 0.005) nll: 0.772975 \n",
      "(GPU: 0, epoch: 16, iters: 100736, time: 0.006) nll: 0.715255 \n",
      "(GPU: 0, epoch: 16, iters: 101536, time: 0.005) nll: 0.752229 \n",
      "(GPU: 0, epoch: 16, iters: 102336, time: 0.006) nll: 0.714573 \n",
      "(GPU: 0, epoch: 16, iters: 103136, time: 0.005) nll: 0.731818 \n",
      "(GPU: 0, epoch: 16, iters: 103936, time: 0.006) nll: 0.700320 \n",
      "(GPU: 0, epoch: 16, iters: 104736, time: 0.005) nll: 1.097371 \n",
      "(GPU: 0, epoch: 16, iters: 105536, time: 0.006) nll: 0.833016 \n",
      "(GPU: 0, epoch: 16, iters: 106336, time: 0.005) nll: 1.076333 \n",
      "(GPU: 0, epoch: 16, iters: 107136, time: 0.006) nll: 0.802171 \n",
      "(GPU: 0, epoch: 16, iters: 107936, time: 0.005) nll: 0.687731 \n",
      "(GPU: 0, epoch: 16, iters: 108736, time: 0.006) nll: 0.964533 \n",
      "saving the latest model (epoch 16, total_steps 2360000)\n",
      "(GPU: 0, epoch: 16, iters: 109536, time: 0.006) nll: 1.000118 \n",
      "(GPU: 0, epoch: 16, iters: 110336, time: 0.006) nll: 0.720521 \n",
      "(GPU: 0, epoch: 16, iters: 111136, time: 0.005) nll: 0.954694 \n",
      "(GPU: 0, epoch: 16, iters: 111936, time: 0.006) nll: 0.760621 \n",
      "(GPU: 0, epoch: 16, iters: 112736, time: 0.006) nll: 0.762093 \n",
      "(GPU: 0, epoch: 16, iters: 113536, time: 0.006) nll: 0.695277 \n",
      "(GPU: 0, epoch: 16, iters: 114336, time: 0.005) nll: 0.512527 \n",
      "(GPU: 0, epoch: 16, iters: 115136, time: 0.006) nll: 0.545599 \n",
      "(GPU: 0, epoch: 16, iters: 115936, time: 0.005) nll: 0.596098 \n",
      "(GPU: 0, epoch: 16, iters: 116736, time: 0.006) nll: 0.784640 \n",
      "(GPU: 0, epoch: 16, iters: 117536, time: 0.005) nll: 0.712109 \n",
      "(GPU: 0, epoch: 16, iters: 118336, time: 0.006) nll: 0.676044 \n",
      "(GPU: 0, epoch: 16, iters: 119136, time: 0.005) nll: 0.720462 \n",
      "(GPU: 0, epoch: 16, iters: 119936, time: 0.006) nll: 0.612764 \n",
      "(GPU: 0, epoch: 16, iters: 120736, time: 0.005) nll: 0.757913 \n",
      "(GPU: 0, epoch: 16, iters: 121536, time: 0.006) nll: 0.603095 \n",
      "(GPU: 0, epoch: 16, iters: 122336, time: 0.005) nll: 0.601229 \n",
      "(GPU: 0, epoch: 16, iters: 123136, time: 0.006) nll: 0.788607 \n",
      "(GPU: 0, epoch: 16, iters: 123936, time: 0.005) nll: 0.572117 \n",
      "(GPU: 0, epoch: 16, iters: 124736, time: 0.006) nll: 0.789520 \n",
      "(GPU: 0, epoch: 16, iters: 125536, time: 0.005) nll: 0.625596 \n",
      "(GPU: 0, epoch: 16, iters: 126336, time: 0.006) nll: 0.653337 \n",
      "(GPU: 0, epoch: 16, iters: 127136, time: 0.005) nll: 0.691891 \n",
      "(GPU: 0, epoch: 16, iters: 127936, time: 0.006) nll: 0.619965 \n",
      "(GPU: 0, epoch: 16, iters: 128736, time: 0.005) nll: 0.705681 \n",
      "saving the latest model (epoch 16, total_steps 2380000)\n",
      "(GPU: 0, epoch: 16, iters: 129536, time: 0.006) nll: 1.191979 \n",
      "(GPU: 0, epoch: 16, iters: 130336, time: 0.006) nll: 0.704883 \n",
      "(GPU: 0, epoch: 16, iters: 131136, time: 0.006) nll: 0.715526 \n",
      "(GPU: 0, epoch: 16, iters: 131936, time: 0.005) nll: 0.649279 \n",
      "(GPU: 0, epoch: 16, iters: 132736, time: 0.006) nll: 0.769173 \n",
      "(GPU: 0, epoch: 16, iters: 133536, time: 0.005) nll: 0.609717 \n",
      "(GPU: 0, epoch: 16, iters: 134336, time: 0.006) nll: 0.694055 \n",
      "(GPU: 0, epoch: 16, iters: 135136, time: 0.005) nll: 1.000944 \n",
      "(GPU: 0, epoch: 16, iters: 135936, time: 0.006) nll: 0.782989 \n",
      "(GPU: 0, epoch: 16, iters: 136736, time: 0.005) nll: 0.618931 \n",
      "(GPU: 0, epoch: 16, iters: 137536, time: 0.006) nll: 0.981083 \n",
      "(GPU: 0, epoch: 16, iters: 138336, time: 0.005) nll: 0.487978 \n",
      "(GPU: 0, epoch: 16, iters: 139136, time: 0.006) nll: 0.808399 \n",
      "(GPU: 0, epoch: 16, iters: 139936, time: 0.006) nll: 0.702689 \n",
      "[*] End of epoch 16 / 25 \t Time Taken: 833 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000767\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3075/4397 [09:43<04:01,  5.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 32, time: 0.003) nll: 0.766751 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.006) nll: 0.763182 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.006) nll: 0.781804 \n",
      "(GPU: 0, epoch: 17, iters: 832, time: 0.006) nll: 0.991223 \n",
      "(GPU: 0, epoch: 17, iters: 1632, time: 0.006) nll: 0.589929 \n",
      "(GPU: 0, epoch: 17, iters: 2432, time: 0.006) nll: 0.832665 \n",
      "(GPU: 0, epoch: 17, iters: 3232, time: 0.005) nll: 0.759996 \n",
      "(GPU: 0, epoch: 17, iters: 4032, time: 0.006) nll: 0.620490 \n",
      "(GPU: 0, epoch: 17, iters: 4832, time: 0.005) nll: 0.631279 \n",
      "(GPU: 0, epoch: 17, iters: 5632, time: 0.006) nll: 0.785288 \n",
      "(GPU: 0, epoch: 17, iters: 6432, time: 0.005) nll: 0.840964 \n",
      "(GPU: 0, epoch: 17, iters: 7232, time: 0.006) nll: 0.758665 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.005) nll: 0.877997 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.008) nll: 0.869377 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.008) nll: 0.866882 \n",
      "saving the latest model (epoch 17, total_steps 2400000)\n",
      "(GPU: 0, epoch: 17, iters: 8832, time: 0.006) nll: 0.881131 \n",
      "(GPU: 0, epoch: 17, iters: 9632, time: 0.005) nll: 1.132940 \n",
      "(GPU: 0, epoch: 17, iters: 10432, time: 0.006) nll: 0.831226 \n",
      "(GPU: 0, epoch: 17, iters: 11232, time: 0.006) nll: 0.700363 \n",
      "(GPU: 0, epoch: 17, iters: 12032, time: 0.006) nll: 0.626710 \n",
      "(GPU: 0, epoch: 17, iters: 12832, time: 0.005) nll: 0.725173 \n",
      "(GPU: 0, epoch: 17, iters: 13632, time: 0.006) nll: 0.865793 \n",
      "(GPU: 0, epoch: 17, iters: 14432, time: 0.005) nll: 0.703297 \n",
      "(GPU: 0, epoch: 17, iters: 15232, time: 0.006) nll: 0.494558 \n",
      "(GPU: 0, epoch: 17, iters: 16032, time: 0.005) nll: 0.525198 \n",
      "(GPU: 0, epoch: 17, iters: 16832, time: 0.006) nll: 0.828448 \n",
      "(GPU: 0, epoch: 17, iters: 17632, time: 0.005) nll: 0.605545 \n",
      "(GPU: 0, epoch: 17, iters: 18432, time: 0.006) nll: 0.672338 \n",
      "(GPU: 0, epoch: 17, iters: 19232, time: 0.005) nll: 0.801180 \n",
      "(GPU: 0, epoch: 17, iters: 20032, time: 0.006) nll: 0.692299 \n",
      "(GPU: 0, epoch: 17, iters: 20832, time: 0.005) nll: 0.792186 \n",
      "(GPU: 0, epoch: 17, iters: 21632, time: 0.006) nll: 0.573556 \n",
      "(GPU: 0, epoch: 17, iters: 22432, time: 0.006) nll: 0.560435 \n",
      "(GPU: 0, epoch: 17, iters: 23232, time: 0.006) nll: 0.744478 \n",
      "(GPU: 0, epoch: 17, iters: 24032, time: 0.005) nll: 0.733248 \n",
      "(GPU: 0, epoch: 17, iters: 24832, time: 0.006) nll: 0.719216 \n",
      "(GPU: 0, epoch: 17, iters: 25632, time: 0.005) nll: 0.685799 \n",
      "(GPU: 0, epoch: 17, iters: 26432, time: 0.006) nll: 0.733457 \n",
      "(GPU: 0, epoch: 17, iters: 27232, time: 0.006) nll: 0.828821 \n",
      "(GPU: 0, epoch: 17, iters: 28032, time: 0.006) nll: 0.824588 \n",
      "saving the latest model (epoch 17, total_steps 2420000)\n",
      "(GPU: 0, epoch: 17, iters: 28832, time: 0.005) nll: 0.831706 \n",
      "(GPU: 0, epoch: 17, iters: 29632, time: 0.006) nll: 0.696359 \n",
      "(GPU: 0, epoch: 17, iters: 30432, time: 0.005) nll: 0.586372 \n",
      "(GPU: 0, epoch: 17, iters: 31232, time: 0.006) nll: 0.746746 \n",
      "(GPU: 0, epoch: 17, iters: 32032, time: 0.005) nll: 0.734127 \n",
      "(GPU: 0, epoch: 17, iters: 32832, time: 0.006) nll: 0.850300 \n",
      "(GPU: 0, epoch: 17, iters: 33632, time: 0.005) nll: 0.617276 \n",
      "(GPU: 0, epoch: 17, iters: 34432, time: 0.006) nll: 0.804286 \n",
      "(GPU: 0, epoch: 17, iters: 35232, time: 0.005) nll: 0.764843 \n",
      "(GPU: 0, epoch: 17, iters: 36032, time: 0.006) nll: 0.840497 \n",
      "(GPU: 0, epoch: 17, iters: 36832, time: 0.005) nll: 0.733781 \n",
      "(GPU: 0, epoch: 17, iters: 37632, time: 0.006) nll: 0.611257 \n",
      "(GPU: 0, epoch: 17, iters: 38432, time: 0.005) nll: 0.816115 \n",
      "(GPU: 0, epoch: 17, iters: 39232, time: 0.006) nll: 0.781037 \n",
      "(GPU: 0, epoch: 17, iters: 40032, time: 0.006) nll: 0.561133 \n",
      "(GPU: 0, epoch: 17, iters: 40832, time: 0.006) nll: 0.494052 \n",
      "(GPU: 0, epoch: 17, iters: 41632, time: 0.005) nll: 0.795014 \n",
      "(GPU: 0, epoch: 17, iters: 42432, time: 0.006) nll: 0.718874 \n",
      "(GPU: 0, epoch: 17, iters: 43232, time: 0.005) nll: 0.782398 \n",
      "(GPU: 0, epoch: 17, iters: 44032, time: 0.006) nll: 0.642454 \n",
      "(GPU: 0, epoch: 17, iters: 44832, time: 0.005) nll: 0.933270 \n",
      "(GPU: 0, epoch: 17, iters: 45632, time: 0.006) nll: 0.662917 \n",
      "(GPU: 0, epoch: 17, iters: 46432, time: 0.005) nll: 0.810053 \n",
      "(GPU: 0, epoch: 17, iters: 47232, time: 0.006) nll: 0.660882 \n",
      "(GPU: 0, epoch: 17, iters: 48032, time: 0.005) nll: 0.649590 \n",
      "saving the latest model (epoch 17, total_steps 2440000)\n",
      "(GPU: 0, epoch: 17, iters: 48832, time: 0.006) nll: 0.780822 \n",
      "(GPU: 0, epoch: 17, iters: 49632, time: 0.005) nll: 0.902602 \n",
      "(GPU: 0, epoch: 17, iters: 50432, time: 0.006) nll: 0.753136 \n",
      "(GPU: 0, epoch: 17, iters: 51232, time: 0.006) nll: 0.931035 \n",
      "(GPU: 0, epoch: 17, iters: 52032, time: 0.006) nll: 0.621590 \n",
      "(GPU: 0, epoch: 17, iters: 52832, time: 0.006) nll: 0.863653 \n",
      "(GPU: 0, epoch: 17, iters: 53632, time: 0.006) nll: 0.589207 \n",
      "(GPU: 0, epoch: 17, iters: 54432, time: 0.005) nll: 0.645362 \n",
      "(GPU: 0, epoch: 17, iters: 55232, time: 0.006) nll: 0.644546 \n",
      "(GPU: 0, epoch: 17, iters: 56032, time: 0.005) nll: 0.762787 \n",
      "(GPU: 0, epoch: 17, iters: 56832, time: 0.006) nll: 0.699014 \n",
      "(GPU: 0, epoch: 17, iters: 57632, time: 0.005) nll: 0.732836 \n",
      "(GPU: 0, epoch: 17, iters: 58432, time: 0.006) nll: 0.757767 \n",
      "(GPU: 0, epoch: 17, iters: 59232, time: 0.005) nll: 0.668672 \n",
      "(GPU: 0, epoch: 17, iters: 60032, time: 0.006) nll: 1.061089 \n",
      "(GPU: 0, epoch: 17, iters: 60832, time: 0.005) nll: 0.935912 \n",
      "(GPU: 0, epoch: 17, iters: 61632, time: 0.006) nll: 0.607661 \n",
      "(GPU: 0, epoch: 17, iters: 62432, time: 0.005) nll: 0.834136 \n",
      "(GPU: 0, epoch: 17, iters: 63232, time: 0.006) nll: 0.918959 \n",
      "(GPU: 0, epoch: 17, iters: 64032, time: 0.005) nll: 0.807943 \n",
      "(GPU: 0, epoch: 17, iters: 64832, time: 0.006) nll: 0.771010 \n",
      "(GPU: 0, epoch: 17, iters: 65632, time: 0.005) nll: 0.917875 \n",
      "(GPU: 0, epoch: 17, iters: 66432, time: 0.006) nll: 1.102017 \n",
      "(GPU: 0, epoch: 17, iters: 67232, time: 0.005) nll: 0.842359 \n",
      "(GPU: 0, epoch: 17, iters: 68032, time: 0.006) nll: 0.609545 \n",
      "saving the latest model (epoch 17, total_steps 2460000)\n",
      "(GPU: 0, epoch: 17, iters: 68832, time: 0.005) nll: 0.682466 \n",
      "(GPU: 0, epoch: 17, iters: 69632, time: 0.006) nll: 0.850578 \n",
      "(GPU: 0, epoch: 17, iters: 70432, time: 0.005) nll: 0.726408 \n",
      "(GPU: 0, epoch: 17, iters: 71232, time: 0.006) nll: 0.627278 \n",
      "(GPU: 0, epoch: 17, iters: 72032, time: 0.005) nll: 0.585066 \n",
      "(GPU: 0, epoch: 17, iters: 72832, time: 0.006) nll: 0.761069 \n",
      "(GPU: 0, epoch: 17, iters: 73632, time: 0.005) nll: 0.782973 \n",
      "(GPU: 0, epoch: 17, iters: 74432, time: 0.006) nll: 0.846562 \n",
      "(GPU: 0, epoch: 17, iters: 75232, time: 0.005) nll: 0.728855 \n",
      "(GPU: 0, epoch: 17, iters: 76032, time: 0.006) nll: 0.636326 \n",
      "(GPU: 0, epoch: 17, iters: 76832, time: 0.005) nll: 0.800671 \n",
      "(GPU: 0, epoch: 17, iters: 77632, time: 0.006) nll: 0.564860 \n",
      "(GPU: 0, epoch: 17, iters: 78432, time: 0.006) nll: 0.707449 \n",
      "(GPU: 0, epoch: 17, iters: 79232, time: 0.006) nll: 0.655591 \n",
      "(GPU: 0, epoch: 17, iters: 80032, time: 0.005) nll: 0.643181 \n",
      "(GPU: 0, epoch: 17, iters: 80832, time: 0.006) nll: 0.905137 \n",
      "(GPU: 0, epoch: 17, iters: 81632, time: 0.005) nll: 0.654643 \n",
      "(GPU: 0, epoch: 17, iters: 82432, time: 0.006) nll: 0.635614 \n",
      "(GPU: 0, epoch: 17, iters: 83232, time: 0.006) nll: 0.693761 \n",
      "(GPU: 0, epoch: 17, iters: 84032, time: 0.006) nll: 0.782494 \n",
      "(GPU: 0, epoch: 17, iters: 84832, time: 0.005) nll: 0.808267 \n",
      "(GPU: 0, epoch: 17, iters: 85632, time: 0.006) nll: 0.760603 \n",
      "(GPU: 0, epoch: 17, iters: 86432, time: 0.006) nll: 0.856687 \n",
      "(GPU: 0, epoch: 17, iters: 87232, time: 0.006) nll: 0.716851 \n",
      "(GPU: 0, epoch: 17, iters: 88032, time: 0.005) nll: 1.031059 \n",
      "saving the latest model (epoch 17, total_steps 2480000)\n",
      "(GPU: 0, epoch: 17, iters: 88832, time: 0.006) nll: 0.697832 \n",
      "(GPU: 0, epoch: 17, iters: 89632, time: 0.005) nll: 0.666216 \n",
      "(GPU: 0, epoch: 17, iters: 90432, time: 0.006) nll: 0.964494 \n",
      "(GPU: 0, epoch: 17, iters: 91232, time: 0.005) nll: 0.637448 \n",
      "(GPU: 0, epoch: 17, iters: 92032, time: 0.006) nll: 0.881711 \n",
      "(GPU: 0, epoch: 17, iters: 92832, time: 0.005) nll: 0.633029 \n",
      "(GPU: 0, epoch: 17, iters: 93632, time: 0.006) nll: 0.574207 \n",
      "(GPU: 0, epoch: 17, iters: 94432, time: 0.005) nll: 0.824603 \n",
      "(GPU: 0, epoch: 17, iters: 95232, time: 0.006) nll: 0.836553 \n",
      "(GPU: 0, epoch: 17, iters: 96032, time: 0.005) nll: 0.719245 \n",
      "(GPU: 0, epoch: 17, iters: 96832, time: 0.006) nll: 0.857875 \n",
      "(GPU: 0, epoch: 17, iters: 97632, time: 0.005) nll: 0.809855 \n",
      "(GPU: 0, epoch: 17, iters: 98432, time: 0.006) nll: 0.733099 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 99232, time: 0.005) nll: 0.736058 \n",
      "(GPU: 0, epoch: 17, iters: 100032, time: 0.006) nll: 0.639917 \n",
      "(GPU: 0, epoch: 17, iters: 100832, time: 0.006) nll: 0.830319 \n",
      "(GPU: 0, epoch: 17, iters: 101632, time: 0.006) nll: 0.540273 \n",
      "(GPU: 0, epoch: 17, iters: 102432, time: 0.005) nll: 0.725792 \n",
      "(GPU: 0, epoch: 17, iters: 103232, time: 0.006) nll: 0.746596 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.006) nll: 0.623398 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.009) nll: 0.616281 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.009) nll: 0.797589 \n",
      "(GPU: 0, epoch: 17, iters: 104832, time: 0.006) nll: 0.691919 \n",
      "(GPU: 0, epoch: 17, iters: 105632, time: 0.006) nll: 0.755631 \n",
      "(GPU: 0, epoch: 17, iters: 106432, time: 0.006) nll: 0.756518 \n",
      "(GPU: 0, epoch: 17, iters: 107232, time: 0.005) nll: 0.893660 \n",
      "(GPU: 0, epoch: 17, iters: 108032, time: 0.006) nll: 0.793568 \n",
      "saving the latest model (epoch 17, total_steps 2500000)\n",
      "(GPU: 0, epoch: 17, iters: 108832, time: 0.005) nll: 0.807765 \n",
      "(GPU: 0, epoch: 17, iters: 109632, time: 0.006) nll: 0.633470 \n",
      "(GPU: 0, epoch: 17, iters: 110432, time: 0.005) nll: 0.482246 \n",
      "(GPU: 0, epoch: 17, iters: 111232, time: 0.006) nll: 0.791208 \n",
      "(GPU: 0, epoch: 17, iters: 112032, time: 0.005) nll: 0.718792 \n",
      "(GPU: 0, epoch: 17, iters: 112832, time: 0.006) nll: 0.892187 \n",
      "(GPU: 0, epoch: 17, iters: 113632, time: 0.005) nll: 0.787773 \n",
      "(GPU: 0, epoch: 17, iters: 114432, time: 0.006) nll: 0.490152 \n",
      "(GPU: 0, epoch: 17, iters: 115232, time: 0.005) nll: 0.700545 \n",
      "(GPU: 0, epoch: 17, iters: 116032, time: 0.006) nll: 0.724298 \n",
      "(GPU: 0, epoch: 17, iters: 116832, time: 0.005) nll: 0.994226 \n",
      "(GPU: 0, epoch: 17, iters: 117632, time: 0.006) nll: 0.725756 \n",
      "(GPU: 0, epoch: 17, iters: 118432, time: 0.006) nll: 0.529063 \n",
      "(GPU: 0, epoch: 17, iters: 119232, time: 0.006) nll: 0.779009 \n",
      "(GPU: 0, epoch: 17, iters: 120032, time: 0.006) nll: 0.755482 \n",
      "(GPU: 0, epoch: 17, iters: 120832, time: 0.006) nll: 0.875159 \n",
      "(GPU: 0, epoch: 17, iters: 121632, time: 0.005) nll: 0.805874 \n",
      "(GPU: 0, epoch: 17, iters: 122432, time: 0.006) nll: 0.691812 \n",
      "(GPU: 0, epoch: 17, iters: 123232, time: 0.005) nll: 0.991524 \n",
      "(GPU: 0, epoch: 17, iters: 124032, time: 0.006) nll: 1.046340 \n",
      "(GPU: 0, epoch: 17, iters: 124832, time: 0.005) nll: 0.678770 \n",
      "(GPU: 0, epoch: 17, iters: 125632, time: 0.006) nll: 1.000829 \n",
      "(GPU: 0, epoch: 17, iters: 126432, time: 0.005) nll: 0.586472 \n",
      "(GPU: 0, epoch: 17, iters: 127232, time: 0.006) nll: 0.832437 \n",
      "(GPU: 0, epoch: 17, iters: 128032, time: 0.005) nll: 0.728311 \n",
      "saving the latest model (epoch 17, total_steps 2520000)\n",
      "(GPU: 0, epoch: 17, iters: 128832, time: 0.006) nll: 0.668552 \n",
      "(GPU: 0, epoch: 17, iters: 129632, time: 0.005) nll: 0.831078 \n",
      "(GPU: 0, epoch: 17, iters: 130432, time: 0.006) nll: 0.848537 \n",
      "(GPU: 0, epoch: 17, iters: 131232, time: 0.005) nll: 0.747594 \n",
      "(GPU: 0, epoch: 17, iters: 132032, time: 0.006) nll: 0.601606 \n",
      "(GPU: 0, epoch: 17, iters: 132832, time: 0.006) nll: 0.694826 \n",
      "(GPU: 0, epoch: 17, iters: 133632, time: 0.006) nll: 0.807883 \n",
      "(GPU: 0, epoch: 17, iters: 134432, time: 0.005) nll: 0.624189 \n",
      "(GPU: 0, epoch: 17, iters: 135232, time: 0.006) nll: 0.790934 \n",
      "(GPU: 0, epoch: 17, iters: 136032, time: 0.005) nll: 0.887715 \n",
      "(GPU: 0, epoch: 17, iters: 136832, time: 0.006) nll: 0.829546 \n",
      "(GPU: 0, epoch: 17, iters: 137632, time: 0.005) nll: 0.588902 \n",
      "(GPU: 0, epoch: 17, iters: 138432, time: 0.006) nll: 0.792457 \n",
      "(GPU: 0, epoch: 17, iters: 139232, time: 0.005) nll: 0.650741 \n",
      "(GPU: 0, epoch: 17, iters: 140032, time: 0.006) nll: 0.751501 \n",
      "[*] End of epoch 17 / 25 \t Time Taken: 835 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000745\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3078/4397 [09:44<04:01,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 32, time: 0.003) nll: 0.585974 \n",
      "(GPU: 0, epoch: 18, iters: 32, time: 0.003) nll: 0.797162 \n",
      "(GPU: 0, epoch: 18, iters: 128, time: 0.006) nll: 0.833167 \n",
      "(GPU: 0, epoch: 18, iters: 928, time: 0.005) nll: 0.647301 \n",
      "(GPU: 0, epoch: 18, iters: 1728, time: 0.006) nll: 0.645764 \n",
      "(GPU: 0, epoch: 18, iters: 2528, time: 0.005) nll: 0.772798 \n",
      "(GPU: 0, epoch: 18, iters: 3328, time: 0.006) nll: 0.834807 \n",
      "(GPU: 0, epoch: 18, iters: 4128, time: 0.005) nll: 0.587981 \n",
      "(GPU: 0, epoch: 18, iters: 4928, time: 0.006) nll: 0.793413 \n",
      "(GPU: 0, epoch: 18, iters: 5728, time: 0.005) nll: 0.786561 \n",
      "(GPU: 0, epoch: 18, iters: 6528, time: 0.006) nll: 0.815077 \n",
      "(GPU: 0, epoch: 18, iters: 7328, time: 0.005) nll: 0.791185 \n",
      "saving the latest model (epoch 18, total_steps 2540000)\n",
      "(GPU: 0, epoch: 18, iters: 8128, time: 0.006) nll: 0.529616 \n",
      "(GPU: 0, epoch: 18, iters: 8928, time: 0.005) nll: 0.661303 \n",
      "(GPU: 0, epoch: 18, iters: 9728, time: 0.006) nll: 0.835437 \n",
      "(GPU: 0, epoch: 18, iters: 10528, time: 0.005) nll: 0.590953 \n",
      "(GPU: 0, epoch: 18, iters: 11328, time: 0.006) nll: 0.662979 \n",
      "(GPU: 0, epoch: 18, iters: 12128, time: 0.005) nll: 0.821941 \n",
      "(GPU: 0, epoch: 18, iters: 12928, time: 0.006) nll: 0.606968 \n",
      "(GPU: 0, epoch: 18, iters: 13728, time: 0.006) nll: 1.243347 \n",
      "(GPU: 0, epoch: 18, iters: 14528, time: 0.006) nll: 0.648562 \n",
      "(GPU: 0, epoch: 18, iters: 15328, time: 0.005) nll: 0.855008 \n",
      "(GPU: 0, epoch: 18, iters: 16128, time: 0.006) nll: 0.671969 \n",
      "(GPU: 0, epoch: 18, iters: 16928, time: 0.005) nll: 0.739126 \n",
      "(GPU: 0, epoch: 18, iters: 17728, time: 0.006) nll: 0.477961 \n",
      "(GPU: 0, epoch: 18, iters: 18528, time: 0.005) nll: 0.691582 \n",
      "(GPU: 0, epoch: 18, iters: 19328, time: 0.006) nll: 0.928045 \n",
      "(GPU: 0, epoch: 18, iters: 20128, time: 0.005) nll: 0.614003 \n",
      "(GPU: 0, epoch: 18, iters: 20928, time: 0.006) nll: 0.810038 \n",
      "(GPU: 0, epoch: 18, iters: 21728, time: 0.005) nll: 0.714971 \n",
      "(GPU: 0, epoch: 18, iters: 22528, time: 0.006) nll: 0.861718 \n",
      "(GPU: 0, epoch: 18, iters: 23328, time: 0.005) nll: 0.562070 \n",
      "(GPU: 0, epoch: 18, iters: 24128, time: 0.006) nll: 0.722737 \n",
      "(GPU: 0, epoch: 18, iters: 24928, time: 0.005) nll: 0.762641 \n",
      "(GPU: 0, epoch: 18, iters: 25728, time: 0.006) nll: 0.920119 \n",
      "(GPU: 0, epoch: 18, iters: 26528, time: 0.005) nll: 0.627751 \n",
      "(GPU: 0, epoch: 18, iters: 27328, time: 0.006) nll: 0.879020 \n",
      "saving the latest model (epoch 18, total_steps 2560000)\n",
      "(GPU: 0, epoch: 18, iters: 28128, time: 0.005) nll: 0.888984 \n",
      "(GPU: 0, epoch: 18, iters: 28928, time: 0.006) nll: 0.618120 \n",
      "(GPU: 0, epoch: 18, iters: 29728, time: 0.005) nll: 0.620386 \n",
      "(GPU: 0, epoch: 18, iters: 30528, time: 0.006) nll: 0.598770 \n",
      "(GPU: 0, epoch: 18, iters: 31328, time: 0.005) nll: 0.747581 \n",
      "(GPU: 0, epoch: 18, iters: 32128, time: 0.006) nll: 0.621557 \n",
      "(GPU: 0, epoch: 18, iters: 32928, time: 0.005) nll: 0.779293 \n",
      "(GPU: 0, epoch: 18, iters: 33728, time: 0.006) nll: 0.671676 \n",
      "(GPU: 0, epoch: 18, iters: 34528, time: 0.005) nll: 0.635913 \n",
      "(GPU: 0, epoch: 18, iters: 35328, time: 0.006) nll: 0.686715 \n",
      "(GPU: 0, epoch: 18, iters: 36128, time: 0.005) nll: 0.644217 \n",
      "(GPU: 0, epoch: 18, iters: 36928, time: 0.006) nll: 0.614802 \n",
      "(GPU: 0, epoch: 18, iters: 37728, time: 0.005) nll: 0.654751 \n",
      "(GPU: 0, epoch: 18, iters: 38528, time: 0.006) nll: 0.817307 \n",
      "(GPU: 0, epoch: 18, iters: 39328, time: 0.005) nll: 0.668530 \n",
      "(GPU: 0, epoch: 18, iters: 40128, time: 0.006) nll: 0.851780 \n",
      "(GPU: 0, epoch: 18, iters: 40928, time: 0.005) nll: 0.823302 \n",
      "(GPU: 0, epoch: 18, iters: 41728, time: 0.006) nll: 0.569410 \n",
      "(GPU: 0, epoch: 18, iters: 42528, time: 0.006) nll: 0.634838 \n",
      "(GPU: 0, epoch: 18, iters: 43328, time: 0.006) nll: 0.806297 \n",
      "(GPU: 0, epoch: 18, iters: 44128, time: 0.005) nll: 0.784144 \n",
      "(GPU: 0, epoch: 18, iters: 44928, time: 0.006) nll: 0.671973 \n",
      "(GPU: 0, epoch: 18, iters: 45728, time: 0.005) nll: 0.633986 \n",
      "(GPU: 0, epoch: 18, iters: 46528, time: 0.006) nll: 0.733108 \n",
      "(GPU: 0, epoch: 18, iters: 47328, time: 0.005) nll: 0.799936 \n",
      "saving the latest model (epoch 18, total_steps 2580000)\n",
      "(GPU: 0, epoch: 18, iters: 48128, time: 0.006) nll: 0.865146 \n",
      "(GPU: 0, epoch: 18, iters: 48928, time: 0.005) nll: 0.694648 \n",
      "(GPU: 0, epoch: 18, iters: 49728, time: 0.006) nll: 0.638509 \n",
      "(GPU: 0, epoch: 18, iters: 50528, time: 0.005) nll: 0.806574 \n",
      "(GPU: 0, epoch: 18, iters: 51328, time: 0.006) nll: 0.874348 \n",
      "(GPU: 0, epoch: 18, iters: 52128, time: 0.005) nll: 0.938475 \n",
      "(GPU: 0, epoch: 18, iters: 52928, time: 0.006) nll: 0.716632 \n",
      "(GPU: 0, epoch: 18, iters: 53728, time: 0.005) nll: 0.921826 \n",
      "(GPU: 0, epoch: 18, iters: 54528, time: 0.006) nll: 0.668333 \n",
      "(GPU: 0, epoch: 18, iters: 55328, time: 0.005) nll: 0.800072 \n",
      "(GPU: 0, epoch: 18, iters: 56128, time: 0.006) nll: 0.728967 \n",
      "(GPU: 0, epoch: 18, iters: 56928, time: 0.006) nll: 1.249127 \n",
      "(GPU: 0, epoch: 18, iters: 57728, time: 0.006) nll: 0.789348 \n",
      "(GPU: 0, epoch: 18, iters: 58528, time: 0.005) nll: 0.753332 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.006) nll: 0.793980 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.009) nll: 0.788068 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.009) nll: 0.627271 \n",
      "(GPU: 0, epoch: 18, iters: 60128, time: 0.005) nll: 0.845314 \n",
      "(GPU: 0, epoch: 18, iters: 60928, time: 0.006) nll: 0.759521 \n",
      "(GPU: 0, epoch: 18, iters: 61728, time: 0.005) nll: 0.700757 \n",
      "(GPU: 0, epoch: 18, iters: 62528, time: 0.006) nll: 0.800781 \n",
      "(GPU: 0, epoch: 18, iters: 63328, time: 0.006) nll: 0.696088 \n",
      "(GPU: 0, epoch: 18, iters: 64128, time: 0.006) nll: 0.926063 \n",
      "(GPU: 0, epoch: 18, iters: 64928, time: 0.005) nll: 0.689581 \n",
      "(GPU: 0, epoch: 18, iters: 65728, time: 0.006) nll: 0.527952 \n",
      "(GPU: 0, epoch: 18, iters: 66528, time: 0.005) nll: 0.769408 \n",
      "(GPU: 0, epoch: 18, iters: 67328, time: 0.006) nll: 0.645848 \n",
      "saving the latest model (epoch 18, total_steps 2600000)\n",
      "(GPU: 0, epoch: 18, iters: 68128, time: 0.005) nll: 0.749023 \n",
      "(GPU: 0, epoch: 18, iters: 68928, time: 0.006) nll: 0.694081 \n",
      "(GPU: 0, epoch: 18, iters: 69728, time: 0.006) nll: 0.741593 \n",
      "(GPU: 0, epoch: 18, iters: 70528, time: 0.006) nll: 0.557650 \n",
      "(GPU: 0, epoch: 18, iters: 71328, time: 0.005) nll: 0.701902 \n",
      "(GPU: 0, epoch: 18, iters: 72128, time: 0.006) nll: 0.567719 \n",
      "(GPU: 0, epoch: 18, iters: 72928, time: 0.006) nll: 0.659598 \n",
      "(GPU: 0, epoch: 18, iters: 73728, time: 0.006) nll: 0.675020 \n",
      "(GPU: 0, epoch: 18, iters: 74528, time: 0.005) nll: 0.687816 \n",
      "(GPU: 0, epoch: 18, iters: 75328, time: 0.006) nll: 0.690756 \n",
      "(GPU: 0, epoch: 18, iters: 76128, time: 0.005) nll: 0.616341 \n",
      "(GPU: 0, epoch: 18, iters: 76928, time: 0.006) nll: 0.583583 \n",
      "(GPU: 0, epoch: 18, iters: 77728, time: 0.005) nll: 0.764671 \n",
      "(GPU: 0, epoch: 18, iters: 78528, time: 0.006) nll: 0.899562 \n",
      "(GPU: 0, epoch: 18, iters: 79328, time: 0.006) nll: 0.646043 \n",
      "(GPU: 0, epoch: 18, iters: 80128, time: 0.006) nll: 0.667904 \n",
      "(GPU: 0, epoch: 18, iters: 80928, time: 0.005) nll: 0.608797 \n",
      "(GPU: 0, epoch: 18, iters: 81728, time: 0.006) nll: 0.592138 \n",
      "(GPU: 0, epoch: 18, iters: 82528, time: 0.005) nll: 0.987162 \n",
      "(GPU: 0, epoch: 18, iters: 83328, time: 0.006) nll: 0.616038 \n",
      "(GPU: 0, epoch: 18, iters: 84128, time: 0.005) nll: 0.523008 \n",
      "(GPU: 0, epoch: 18, iters: 84928, time: 0.006) nll: 0.832270 \n",
      "(GPU: 0, epoch: 18, iters: 85728, time: 0.005) nll: 0.842391 \n",
      "(GPU: 0, epoch: 18, iters: 86528, time: 0.006) nll: 0.848900 \n",
      "(GPU: 0, epoch: 18, iters: 87328, time: 0.005) nll: 0.740911 \n",
      "saving the latest model (epoch 18, total_steps 2620000)\n",
      "(GPU: 0, epoch: 18, iters: 88128, time: 0.006) nll: 0.923146 \n",
      "(GPU: 0, epoch: 18, iters: 88928, time: 0.005) nll: 0.627329 \n",
      "(GPU: 0, epoch: 18, iters: 89728, time: 0.006) nll: 0.744182 \n",
      "(GPU: 0, epoch: 18, iters: 90528, time: 0.005) nll: 0.716081 \n",
      "(GPU: 0, epoch: 18, iters: 91328, time: 0.006) nll: 0.656715 \n",
      "(GPU: 0, epoch: 18, iters: 92128, time: 0.005) nll: 0.918432 \n",
      "(GPU: 0, epoch: 18, iters: 92928, time: 0.006) nll: 0.770423 \n",
      "(GPU: 0, epoch: 18, iters: 93728, time: 0.005) nll: 0.714670 \n",
      "(GPU: 0, epoch: 18, iters: 94528, time: 0.006) nll: 0.641936 \n",
      "(GPU: 0, epoch: 18, iters: 95328, time: 0.005) nll: 0.736074 \n",
      "(GPU: 0, epoch: 18, iters: 96128, time: 0.006) nll: 0.724183 \n",
      "(GPU: 0, epoch: 18, iters: 96928, time: 0.005) nll: 0.704594 \n",
      "(GPU: 0, epoch: 18, iters: 97728, time: 0.006) nll: 0.456011 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 98528, time: 0.005) nll: 0.835403 \n",
      "(GPU: 0, epoch: 18, iters: 99328, time: 0.006) nll: 0.635074 \n",
      "(GPU: 0, epoch: 18, iters: 100128, time: 0.005) nll: 0.960831 \n",
      "(GPU: 0, epoch: 18, iters: 100928, time: 0.006) nll: 0.785588 \n",
      "(GPU: 0, epoch: 18, iters: 101728, time: 0.005) nll: 0.555952 \n",
      "(GPU: 0, epoch: 18, iters: 102528, time: 0.006) nll: 0.668185 \n",
      "(GPU: 0, epoch: 18, iters: 103328, time: 0.005) nll: 0.589176 \n",
      "(GPU: 0, epoch: 18, iters: 104128, time: 0.006) nll: 0.717101 \n",
      "(GPU: 0, epoch: 18, iters: 104928, time: 0.005) nll: 0.771369 \n",
      "(GPU: 0, epoch: 18, iters: 105728, time: 0.006) nll: 0.823899 \n",
      "(GPU: 0, epoch: 18, iters: 106528, time: 0.005) nll: 0.871633 \n",
      "(GPU: 0, epoch: 18, iters: 107328, time: 0.006) nll: 0.932793 \n",
      "saving the latest model (epoch 18, total_steps 2640000)\n",
      "(GPU: 0, epoch: 18, iters: 108128, time: 0.005) nll: 0.780770 \n",
      "(GPU: 0, epoch: 18, iters: 108928, time: 0.006) nll: 0.547430 \n",
      "(GPU: 0, epoch: 18, iters: 109728, time: 0.005) nll: 0.768528 \n",
      "(GPU: 0, epoch: 18, iters: 110528, time: 0.006) nll: 0.845604 \n",
      "(GPU: 0, epoch: 18, iters: 111328, time: 0.005) nll: 0.564631 \n",
      "(GPU: 0, epoch: 18, iters: 112128, time: 0.006) nll: 0.789633 \n",
      "(GPU: 0, epoch: 18, iters: 112928, time: 0.005) nll: 0.560623 \n",
      "(GPU: 0, epoch: 18, iters: 113728, time: 0.006) nll: 0.915108 \n",
      "(GPU: 0, epoch: 18, iters: 114528, time: 0.005) nll: 0.718405 \n",
      "(GPU: 0, epoch: 18, iters: 115328, time: 0.006) nll: 0.807435 \n",
      "(GPU: 0, epoch: 18, iters: 116128, time: 0.005) nll: 0.592136 \n",
      "(GPU: 0, epoch: 18, iters: 116928, time: 0.006) nll: 0.653777 \n",
      "(GPU: 0, epoch: 18, iters: 117728, time: 0.005) nll: 0.685234 \n",
      "(GPU: 0, epoch: 18, iters: 118528, time: 0.006) nll: 0.999729 \n",
      "(GPU: 0, epoch: 18, iters: 119328, time: 0.005) nll: 0.776608 \n",
      "(GPU: 0, epoch: 18, iters: 120128, time: 0.006) nll: 0.635438 \n",
      "(GPU: 0, epoch: 18, iters: 120928, time: 0.005) nll: 0.626751 \n",
      "(GPU: 0, epoch: 18, iters: 121728, time: 0.006) nll: 0.880762 \n",
      "(GPU: 0, epoch: 18, iters: 122528, time: 0.005) nll: 0.740990 \n",
      "(GPU: 0, epoch: 18, iters: 123328, time: 0.006) nll: 0.830206 \n",
      "(GPU: 0, epoch: 18, iters: 124128, time: 0.005) nll: 0.802006 \n",
      "(GPU: 0, epoch: 18, iters: 124928, time: 0.006) nll: 0.653556 \n",
      "(GPU: 0, epoch: 18, iters: 125728, time: 0.005) nll: 0.914891 \n",
      "(GPU: 0, epoch: 18, iters: 126528, time: 0.006) nll: 0.845941 \n",
      "(GPU: 0, epoch: 18, iters: 127328, time: 0.005) nll: 0.694458 \n",
      "saving the latest model (epoch 18, total_steps 2660000)\n",
      "(GPU: 0, epoch: 18, iters: 128128, time: 0.006) nll: 0.638979 \n",
      "(GPU: 0, epoch: 18, iters: 128928, time: 0.005) nll: 0.544121 \n",
      "(GPU: 0, epoch: 18, iters: 129728, time: 0.006) nll: 0.712147 \n",
      "(GPU: 0, epoch: 18, iters: 130528, time: 0.005) nll: 0.782741 \n",
      "(GPU: 0, epoch: 18, iters: 131328, time: 0.006) nll: 0.921447 \n",
      "(GPU: 0, epoch: 18, iters: 132128, time: 0.006) nll: 0.820463 \n",
      "(GPU: 0, epoch: 18, iters: 132928, time: 0.006) nll: 0.737191 \n",
      "(GPU: 0, epoch: 18, iters: 133728, time: 0.005) nll: 0.841861 \n",
      "(GPU: 0, epoch: 18, iters: 134528, time: 0.006) nll: 0.649675 \n",
      "(GPU: 0, epoch: 18, iters: 135328, time: 0.005) nll: 0.793135 \n",
      "(GPU: 0, epoch: 18, iters: 136128, time: 0.006) nll: 0.753963 \n",
      "(GPU: 0, epoch: 18, iters: 136928, time: 0.005) nll: 0.683907 \n",
      "(GPU: 0, epoch: 18, iters: 137728, time: 0.006) nll: 0.669615 \n",
      "(GPU: 0, epoch: 18, iters: 138528, time: 0.005) nll: 1.109290 \n",
      "(GPU: 0, epoch: 18, iters: 139328, time: 0.006) nll: 0.820402 \n",
      "(GPU: 0, epoch: 18, iters: 140128, time: 0.005) nll: 0.723113 \n",
      "saving the model at the end of epoch 18, iters 2673376\n",
      "([test] GPU: 0, epoch: 18) \n",
      "OrderedDict()\n",
      "[*] End of epoch 18 / 25 \t Time Taken: 840 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000725\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3081/4397 [09:43<04:00,  5.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 19, iters: 32, time: 0.003) nll: 0.679984 \n",
      "(GPU: 0, epoch: 19, iters: 32, time: 0.003) nll: 0.898139 \n",
      "(GPU: 0, epoch: 19, iters: 224, time: 0.005) nll: 0.497529 \n",
      "(GPU: 0, epoch: 19, iters: 1024, time: 0.006) nll: 0.608755 \n",
      "(GPU: 0, epoch: 19, iters: 1824, time: 0.005) nll: 0.599954 \n",
      "(GPU: 0, epoch: 19, iters: 2624, time: 0.006) nll: 0.916025 \n",
      "(GPU: 0, epoch: 19, iters: 3424, time: 0.005) nll: 0.769164 \n",
      "(GPU: 0, epoch: 19, iters: 4224, time: 0.006) nll: 0.788247 \n",
      "(GPU: 0, epoch: 19, iters: 5024, time: 0.005) nll: 0.762760 \n",
      "(GPU: 0, epoch: 19, iters: 5824, time: 0.006) nll: 0.801757 \n",
      "(GPU: 0, epoch: 19, iters: 6624, time: 0.005) nll: 0.621465 \n",
      "saving the latest model (epoch 19, total_steps 2680000)\n",
      "(GPU: 0, epoch: 19, iters: 7424, time: 0.006) nll: 0.819273 \n",
      "(GPU: 0, epoch: 19, iters: 8224, time: 0.005) nll: 0.824399 \n",
      "(GPU: 0, epoch: 19, iters: 9024, time: 0.006) nll: 0.740632 \n",
      "(GPU: 0, epoch: 19, iters: 9824, time: 0.005) nll: 0.789226 \n",
      "(GPU: 0, epoch: 19, iters: 10624, time: 0.006) nll: 0.634579 \n",
      "(GPU: 0, epoch: 19, iters: 11424, time: 0.006) nll: 0.831148 \n",
      "(GPU: 0, epoch: 19, iters: 12224, time: 0.006) nll: 0.885991 \n",
      "(GPU: 0, epoch: 19, iters: 13024, time: 0.005) nll: 0.527469 \n",
      "(GPU: 0, epoch: 19, iters: 13824, time: 0.006) nll: 0.741714 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.005) nll: 0.590617 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.008) nll: 0.583995 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.008) nll: 0.712663 \n",
      "(GPU: 0, epoch: 19, iters: 15424, time: 0.006) nll: 0.539831 \n",
      "(GPU: 0, epoch: 19, iters: 16224, time: 0.005) nll: 0.769506 \n",
      "(GPU: 0, epoch: 19, iters: 17024, time: 0.006) nll: 0.769345 \n",
      "(GPU: 0, epoch: 19, iters: 17824, time: 0.005) nll: 0.731749 \n",
      "(GPU: 0, epoch: 19, iters: 18624, time: 0.006) nll: 0.744010 \n",
      "(GPU: 0, epoch: 19, iters: 19424, time: 0.005) nll: 0.801981 \n",
      "(GPU: 0, epoch: 19, iters: 20224, time: 0.006) nll: 0.747686 \n",
      "(GPU: 0, epoch: 19, iters: 21024, time: 0.006) nll: 0.654373 \n",
      "(GPU: 0, epoch: 19, iters: 21824, time: 0.006) nll: 0.580369 \n",
      "(GPU: 0, epoch: 19, iters: 22624, time: 0.005) nll: 0.622604 \n",
      "(GPU: 0, epoch: 19, iters: 23424, time: 0.006) nll: 0.653583 \n",
      "(GPU: 0, epoch: 19, iters: 24224, time: 0.005) nll: 0.689572 \n",
      "(GPU: 0, epoch: 19, iters: 25024, time: 0.006) nll: 0.786859 \n",
      "(GPU: 0, epoch: 19, iters: 25824, time: 0.005) nll: 0.893297 \n",
      "(GPU: 0, epoch: 19, iters: 26624, time: 0.006) nll: 0.553080 \n",
      "saving the latest model (epoch 19, total_steps 2700000)\n",
      "(GPU: 0, epoch: 19, iters: 27424, time: 0.005) nll: 1.141249 \n",
      "(GPU: 0, epoch: 19, iters: 28224, time: 0.006) nll: 1.006782 \n",
      "(GPU: 0, epoch: 19, iters: 29024, time: 0.005) nll: 0.775002 \n",
      "(GPU: 0, epoch: 19, iters: 29824, time: 0.006) nll: 0.852902 \n",
      "(GPU: 0, epoch: 19, iters: 30624, time: 0.005) nll: 0.741369 \n",
      "(GPU: 0, epoch: 19, iters: 31424, time: 0.006) nll: 0.719195 \n",
      "(GPU: 0, epoch: 19, iters: 32224, time: 0.005) nll: 0.787276 \n",
      "(GPU: 0, epoch: 19, iters: 33024, time: 0.006) nll: 0.833835 \n",
      "(GPU: 0, epoch: 19, iters: 33824, time: 0.006) nll: 0.707173 \n",
      "(GPU: 0, epoch: 19, iters: 34624, time: 0.006) nll: 0.954785 \n",
      "(GPU: 0, epoch: 19, iters: 35424, time: 0.005) nll: 0.446605 \n",
      "(GPU: 0, epoch: 19, iters: 36224, time: 0.006) nll: 0.844233 \n",
      "(GPU: 0, epoch: 19, iters: 37024, time: 0.005) nll: 0.647195 \n",
      "(GPU: 0, epoch: 19, iters: 37824, time: 0.006) nll: 0.692393 \n",
      "(GPU: 0, epoch: 19, iters: 38624, time: 0.005) nll: 0.595562 \n",
      "(GPU: 0, epoch: 19, iters: 39424, time: 0.006) nll: 0.652231 \n",
      "(GPU: 0, epoch: 19, iters: 40224, time: 0.005) nll: 0.712542 \n",
      "(GPU: 0, epoch: 19, iters: 41024, time: 0.006) nll: 0.676025 \n",
      "(GPU: 0, epoch: 19, iters: 41824, time: 0.005) nll: 0.902844 \n",
      "(GPU: 0, epoch: 19, iters: 42624, time: 0.006) nll: 0.511373 \n",
      "(GPU: 0, epoch: 19, iters: 43424, time: 0.005) nll: 0.897143 \n",
      "(GPU: 0, epoch: 19, iters: 44224, time: 0.006) nll: 0.494950 \n",
      "(GPU: 0, epoch: 19, iters: 45024, time: 0.005) nll: 0.513855 \n",
      "(GPU: 0, epoch: 19, iters: 45824, time: 0.006) nll: 0.892173 \n",
      "(GPU: 0, epoch: 19, iters: 46624, time: 0.005) nll: 0.504337 \n",
      "saving the latest model (epoch 19, total_steps 2720000)\n",
      "(GPU: 0, epoch: 19, iters: 47424, time: 0.006) nll: 0.838864 \n",
      "(GPU: 0, epoch: 19, iters: 48224, time: 0.005) nll: 0.770550 \n",
      "(GPU: 0, epoch: 19, iters: 49024, time: 0.006) nll: 0.650826 \n",
      "(GPU: 0, epoch: 19, iters: 49824, time: 0.006) nll: 0.746809 \n",
      "(GPU: 0, epoch: 19, iters: 50624, time: 0.006) nll: 0.900392 \n",
      "(GPU: 0, epoch: 19, iters: 51424, time: 0.005) nll: 0.769167 \n",
      "(GPU: 0, epoch: 19, iters: 52224, time: 0.006) nll: 0.744772 \n",
      "(GPU: 0, epoch: 19, iters: 53024, time: 0.005) nll: 0.396798 \n",
      "(GPU: 0, epoch: 19, iters: 53824, time: 0.006) nll: 0.663260 \n",
      "(GPU: 0, epoch: 19, iters: 54624, time: 0.005) nll: 0.844152 \n",
      "(GPU: 0, epoch: 19, iters: 55424, time: 0.005) nll: 1.035857 \n",
      "(GPU: 0, epoch: 19, iters: 56224, time: 0.005) nll: 0.604312 \n",
      "(GPU: 0, epoch: 19, iters: 57024, time: 0.006) nll: 0.618264 \n",
      "(GPU: 0, epoch: 19, iters: 57824, time: 0.005) nll: 0.658470 \n",
      "(GPU: 0, epoch: 19, iters: 58624, time: 0.006) nll: 0.849226 \n",
      "(GPU: 0, epoch: 19, iters: 59424, time: 0.006) nll: 0.737678 \n",
      "(GPU: 0, epoch: 19, iters: 60224, time: 0.006) nll: 0.821953 \n",
      "(GPU: 0, epoch: 19, iters: 61024, time: 0.005) nll: 1.047192 \n",
      "(GPU: 0, epoch: 19, iters: 61824, time: 0.006) nll: 0.737581 \n",
      "(GPU: 0, epoch: 19, iters: 62624, time: 0.006) nll: 0.690063 \n",
      "(GPU: 0, epoch: 19, iters: 63424, time: 0.006) nll: 0.570603 \n",
      "(GPU: 0, epoch: 19, iters: 64224, time: 0.005) nll: 0.812232 \n",
      "(GPU: 0, epoch: 19, iters: 65024, time: 0.006) nll: 0.787459 \n",
      "(GPU: 0, epoch: 19, iters: 65824, time: 0.005) nll: 0.819506 \n",
      "(GPU: 0, epoch: 19, iters: 66624, time: 0.006) nll: 0.730474 \n",
      "saving the latest model (epoch 19, total_steps 2740000)\n",
      "(GPU: 0, epoch: 19, iters: 67424, time: 0.005) nll: 0.435851 \n",
      "(GPU: 0, epoch: 19, iters: 68224, time: 0.006) nll: 0.519845 \n",
      "(GPU: 0, epoch: 19, iters: 69024, time: 0.005) nll: 0.663940 \n",
      "(GPU: 0, epoch: 19, iters: 69824, time: 0.006) nll: 0.662153 \n",
      "(GPU: 0, epoch: 19, iters: 70624, time: 0.005) nll: 1.021224 \n",
      "(GPU: 0, epoch: 19, iters: 71424, time: 0.006) nll: 0.644558 \n",
      "(GPU: 0, epoch: 19, iters: 72224, time: 0.005) nll: 0.547550 \n",
      "(GPU: 0, epoch: 19, iters: 73024, time: 0.006) nll: 0.448434 \n",
      "(GPU: 0, epoch: 19, iters: 73824, time: 0.005) nll: 0.686446 \n",
      "(GPU: 0, epoch: 19, iters: 74624, time: 0.006) nll: 0.699445 \n",
      "(GPU: 0, epoch: 19, iters: 75424, time: 0.005) nll: 0.708943 \n",
      "(GPU: 0, epoch: 19, iters: 76224, time: 0.006) nll: 0.880328 \n",
      "(GPU: 0, epoch: 19, iters: 77024, time: 0.005) nll: 0.720971 \n",
      "(GPU: 0, epoch: 19, iters: 77824, time: 0.006) nll: 0.923219 \n",
      "(GPU: 0, epoch: 19, iters: 78624, time: 0.005) nll: 0.828248 \n",
      "(GPU: 0, epoch: 19, iters: 79424, time: 0.006) nll: 0.799109 \n",
      "(GPU: 0, epoch: 19, iters: 80224, time: 0.006) nll: 0.600419 \n",
      "(GPU: 0, epoch: 19, iters: 81024, time: 0.006) nll: 0.848922 \n",
      "(GPU: 0, epoch: 19, iters: 81824, time: 0.005) nll: 0.933071 \n",
      "(GPU: 0, epoch: 19, iters: 82624, time: 0.006) nll: 0.764628 \n",
      "(GPU: 0, epoch: 19, iters: 83424, time: 0.005) nll: 0.757225 \n",
      "(GPU: 0, epoch: 19, iters: 84224, time: 0.006) nll: 0.515400 \n",
      "(GPU: 0, epoch: 19, iters: 85024, time: 0.005) nll: 0.755109 \n",
      "(GPU: 0, epoch: 19, iters: 85824, time: 0.006) nll: 1.054922 \n",
      "(GPU: 0, epoch: 19, iters: 86624, time: 0.005) nll: 0.866080 \n",
      "saving the latest model (epoch 19, total_steps 2760000)\n",
      "(GPU: 0, epoch: 19, iters: 87424, time: 0.006) nll: 0.609907 \n",
      "(GPU: 0, epoch: 19, iters: 88224, time: 0.005) nll: 0.652713 \n",
      "(GPU: 0, epoch: 19, iters: 89024, time: 0.006) nll: 0.420447 \n",
      "(GPU: 0, epoch: 19, iters: 89824, time: 0.006) nll: 0.558936 \n",
      "(GPU: 0, epoch: 19, iters: 90624, time: 0.006) nll: 0.662772 \n",
      "(GPU: 0, epoch: 19, iters: 91424, time: 0.005) nll: 0.578324 \n",
      "(GPU: 0, epoch: 19, iters: 92224, time: 0.006) nll: 0.722627 \n",
      "(GPU: 0, epoch: 19, iters: 93024, time: 0.005) nll: 0.742911 \n",
      "(GPU: 0, epoch: 19, iters: 93824, time: 0.006) nll: 0.798742 \n",
      "(GPU: 0, epoch: 19, iters: 94624, time: 0.006) nll: 0.726180 \n",
      "(GPU: 0, epoch: 19, iters: 95424, time: 0.006) nll: 0.615925 \n",
      "(GPU: 0, epoch: 19, iters: 96224, time: 0.005) nll: 0.668071 \n",
      "(GPU: 0, epoch: 19, iters: 97024, time: 0.006) nll: 0.800968 \n",
      "(GPU: 0, epoch: 19, iters: 97824, time: 0.006) nll: 0.803719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:52<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 19, iters: 98624, time: 0.006) nll: 0.534527 \n",
      "(GPU: 0, epoch: 19, iters: 99424, time: 0.005) nll: 0.807896 \n",
      "(GPU: 0, epoch: 19, iters: 100224, time: 0.006) nll: 0.607708 \n",
      "(GPU: 0, epoch: 19, iters: 101024, time: 0.005) nll: 0.633470 \n",
      "(GPU: 0, epoch: 19, iters: 101824, time: 0.006) nll: 0.751700 \n",
      "(GPU: 0, epoch: 19, iters: 102624, time: 0.005) nll: 0.778089 \n",
      "(GPU: 0, epoch: 19, iters: 103424, time: 0.006) nll: 0.756980 \n",
      "(GPU: 0, epoch: 19, iters: 104224, time: 0.005) nll: 0.892104 \n",
      "(GPU: 0, epoch: 19, iters: 105024, time: 0.006) nll: 0.657083 \n",
      "(GPU: 0, epoch: 19, iters: 105824, time: 0.005) nll: 0.631288 \n",
      "(GPU: 0, epoch: 19, iters: 106624, time: 0.006) nll: 0.754442 \n",
      "saving the latest model (epoch 19, total_steps 2780000)\n",
      "(GPU: 0, epoch: 19, iters: 107424, time: 0.005) nll: 0.860413 \n",
      "(GPU: 0, epoch: 19, iters: 108224, time: 0.006) nll: 0.703983 \n",
      "(GPU: 0, epoch: 19, iters: 109024, time: 0.005) nll: 0.932005 \n",
      "(GPU: 0, epoch: 19, iters: 109824, time: 0.006) nll: 0.851688 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.005) nll: 0.892666 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.008) nll: 0.879779 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.008) nll: 0.960353 \n",
      "(GPU: 0, epoch: 19, iters: 111424, time: 0.006) nll: 0.639598 \n",
      "(GPU: 0, epoch: 19, iters: 112224, time: 0.005) nll: 0.770997 \n",
      "(GPU: 0, epoch: 19, iters: 113024, time: 0.006) nll: 0.800498 \n",
      "(GPU: 0, epoch: 19, iters: 113824, time: 0.005) nll: 0.773302 \n",
      "(GPU: 0, epoch: 19, iters: 114624, time: 0.006) nll: 0.902316 \n",
      "(GPU: 0, epoch: 19, iters: 115424, time: 0.005) nll: 0.579250 \n",
      "(GPU: 0, epoch: 19, iters: 116224, time: 0.006) nll: 0.733394 \n",
      "(GPU: 0, epoch: 19, iters: 117024, time: 0.005) nll: 0.851407 \n",
      "(GPU: 0, epoch: 19, iters: 117824, time: 0.006) nll: 0.649423 \n",
      "(GPU: 0, epoch: 19, iters: 118624, time: 0.005) nll: 0.720779 \n",
      "(GPU: 0, epoch: 19, iters: 119424, time: 0.006) nll: 0.619371 \n",
      "(GPU: 0, epoch: 19, iters: 120224, time: 0.005) nll: 0.582103 \n",
      "(GPU: 0, epoch: 19, iters: 121024, time: 0.006) nll: 0.954813 \n",
      "(GPU: 0, epoch: 19, iters: 121824, time: 0.005) nll: 0.772983 \n",
      "(GPU: 0, epoch: 19, iters: 122624, time: 0.006) nll: 0.756366 \n",
      "(GPU: 0, epoch: 19, iters: 123424, time: 0.005) nll: 0.769726 \n",
      "(GPU: 0, epoch: 19, iters: 124224, time: 0.006) nll: 0.788752 \n",
      "(GPU: 0, epoch: 19, iters: 125024, time: 0.005) nll: 0.722500 \n",
      "(GPU: 0, epoch: 19, iters: 125824, time: 0.006) nll: 0.749311 \n",
      "(GPU: 0, epoch: 19, iters: 126624, time: 0.005) nll: 0.873754 \n",
      "saving the latest model (epoch 19, total_steps 2800000)\n",
      "(GPU: 0, epoch: 19, iters: 127424, time: 0.006) nll: 0.538430 \n",
      "(GPU: 0, epoch: 19, iters: 128224, time: 0.005) nll: 0.725302 \n",
      "(GPU: 0, epoch: 19, iters: 129024, time: 0.006) nll: 0.936946 \n",
      "(GPU: 0, epoch: 19, iters: 129824, time: 0.005) nll: 0.656304 \n",
      "(GPU: 0, epoch: 19, iters: 130624, time: 0.006) nll: 0.522016 \n",
      "(GPU: 0, epoch: 19, iters: 131424, time: 0.005) nll: 0.630395 \n",
      "(GPU: 0, epoch: 19, iters: 132224, time: 0.006) nll: 0.548783 \n",
      "(GPU: 0, epoch: 19, iters: 133024, time: 0.005) nll: 0.883952 \n",
      "(GPU: 0, epoch: 19, iters: 133824, time: 0.006) nll: 0.624814 \n",
      "(GPU: 0, epoch: 19, iters: 134624, time: 0.005) nll: 0.785090 \n",
      "(GPU: 0, epoch: 19, iters: 135424, time: 0.006) nll: 0.603852 \n",
      "(GPU: 0, epoch: 19, iters: 136224, time: 0.005) nll: 0.571398 \n",
      "(GPU: 0, epoch: 19, iters: 137024, time: 0.006) nll: 0.631524 \n",
      "(GPU: 0, epoch: 19, iters: 137824, time: 0.005) nll: 0.860827 \n",
      "(GPU: 0, epoch: 19, iters: 138624, time: 0.006) nll: 0.697830 \n",
      "(GPU: 0, epoch: 19, iters: 139424, time: 0.006) nll: 0.756803 \n",
      "(GPU: 0, epoch: 19, iters: 140224, time: 0.006) nll: 0.665535 \n",
      "[*] End of epoch 19 / 25 \t Time Taken: 833 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000707\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3084/4397 [09:45<03:59,  5.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 20, iters: 32, time: 0.003) nll: 0.536134 \n",
      "(GPU: 0, epoch: 20, iters: 32, time: 0.003) nll: 0.753414 \n",
      "(GPU: 0, epoch: 20, iters: 320, time: 0.006) nll: 0.825714 \n",
      "(GPU: 0, epoch: 20, iters: 1120, time: 0.005) nll: 0.707980 \n",
      "(GPU: 0, epoch: 20, iters: 1920, time: 0.006) nll: 0.664594 \n",
      "(GPU: 0, epoch: 20, iters: 2720, time: 0.006) nll: 0.977883 \n",
      "(GPU: 0, epoch: 20, iters: 3520, time: 0.006) nll: 0.606874 \n",
      "(GPU: 0, epoch: 20, iters: 4320, time: 0.005) nll: 0.771263 \n",
      "(GPU: 0, epoch: 20, iters: 5120, time: 0.006) nll: 0.777077 \n",
      "(GPU: 0, epoch: 20, iters: 5920, time: 0.005) nll: 0.820469 \n",
      "saving the latest model (epoch 20, total_steps 2820000)\n",
      "(GPU: 0, epoch: 20, iters: 6720, time: 0.006) nll: 0.809880 \n",
      "(GPU: 0, epoch: 20, iters: 7520, time: 0.005) nll: 0.501626 \n",
      "(GPU: 0, epoch: 20, iters: 8320, time: 0.006) nll: 0.714099 \n",
      "(GPU: 0, epoch: 20, iters: 9120, time: 0.006) nll: 0.827637 \n",
      "(GPU: 0, epoch: 20, iters: 9920, time: 0.006) nll: 0.849619 \n",
      "(GPU: 0, epoch: 20, iters: 10720, time: 0.005) nll: 0.802392 \n",
      "(GPU: 0, epoch: 20, iters: 11520, time: 0.006) nll: 0.980326 \n",
      "(GPU: 0, epoch: 20, iters: 12320, time: 0.005) nll: 0.700872 \n",
      "(GPU: 0, epoch: 20, iters: 13120, time: 0.006) nll: 0.782280 \n",
      "(GPU: 0, epoch: 20, iters: 13920, time: 0.005) nll: 0.777973 \n",
      "(GPU: 0, epoch: 20, iters: 14720, time: 0.006) nll: 0.827255 \n",
      "(GPU: 0, epoch: 20, iters: 15520, time: 0.006) nll: 0.893515 \n",
      "(GPU: 0, epoch: 20, iters: 16320, time: 0.006) nll: 0.736625 \n",
      "(GPU: 0, epoch: 20, iters: 17120, time: 0.005) nll: 0.748223 \n",
      "(GPU: 0, epoch: 20, iters: 17920, time: 0.006) nll: 0.705670 \n",
      "(GPU: 0, epoch: 20, iters: 18720, time: 0.005) nll: 0.979179 \n",
      "(GPU: 0, epoch: 20, iters: 19520, time: 0.006) nll: 0.804104 \n",
      "(GPU: 0, epoch: 20, iters: 20320, time: 0.005) nll: 0.717772 \n",
      "(GPU: 0, epoch: 20, iters: 21120, time: 0.006) nll: 0.510864 \n",
      "(GPU: 0, epoch: 20, iters: 21920, time: 0.005) nll: 0.980447 \n",
      "(GPU: 0, epoch: 20, iters: 22720, time: 0.006) nll: 0.850222 \n",
      "(GPU: 0, epoch: 20, iters: 23520, time: 0.005) nll: 0.690400 \n",
      "(GPU: 0, epoch: 20, iters: 24320, time: 0.006) nll: 0.741022 \n",
      "(GPU: 0, epoch: 20, iters: 25120, time: 0.005) nll: 0.657611 \n",
      "(GPU: 0, epoch: 20, iters: 25920, time: 0.006) nll: 0.700190 \n",
      "saving the latest model (epoch 20, total_steps 2840000)\n",
      "(GPU: 0, epoch: 20, iters: 26720, time: 0.005) nll: 0.938927 \n",
      "(GPU: 0, epoch: 20, iters: 27520, time: 0.006) nll: 0.795470 \n",
      "(GPU: 0, epoch: 20, iters: 28320, time: 0.005) nll: 0.717134 \n",
      "(GPU: 0, epoch: 20, iters: 29120, time: 0.006) nll: 0.555132 \n",
      "(GPU: 0, epoch: 20, iters: 29920, time: 0.005) nll: 0.684143 \n",
      "(GPU: 0, epoch: 20, iters: 30720, time: 0.006) nll: 0.510429 \n",
      "(GPU: 0, epoch: 20, iters: 31520, time: 0.005) nll: 0.663270 \n",
      "(GPU: 0, epoch: 20, iters: 32320, time: 0.006) nll: 0.574199 \n",
      "(GPU: 0, epoch: 20, iters: 33120, time: 0.005) nll: 0.642072 \n",
      "(GPU: 0, epoch: 20, iters: 33920, time: 0.006) nll: 0.742545 \n",
      "(GPU: 0, epoch: 20, iters: 34720, time: 0.005) nll: 0.739248 \n",
      "(GPU: 0, epoch: 20, iters: 35520, time: 0.006) nll: 0.704585 \n",
      "(GPU: 0, epoch: 20, iters: 36320, time: 0.005) nll: 0.726046 \n",
      "(GPU: 0, epoch: 20, iters: 37120, time: 0.006) nll: 0.563451 \n",
      "(GPU: 0, epoch: 20, iters: 37920, time: 0.005) nll: 1.001758 \n",
      "(GPU: 0, epoch: 20, iters: 38720, time: 0.006) nll: 0.637591 \n",
      "(GPU: 0, epoch: 20, iters: 39520, time: 0.005) nll: 0.713948 \n",
      "(GPU: 0, epoch: 20, iters: 40320, time: 0.006) nll: 0.759159 \n",
      "(GPU: 0, epoch: 20, iters: 41120, time: 0.005) nll: 0.669486 \n",
      "(GPU: 0, epoch: 20, iters: 41920, time: 0.006) nll: 0.893988 \n",
      "(GPU: 0, epoch: 20, iters: 42720, time: 0.005) nll: 0.816918 \n",
      "(GPU: 0, epoch: 20, iters: 43520, time: 0.006) nll: 0.730370 \n",
      "(GPU: 0, epoch: 20, iters: 44320, time: 0.006) nll: 0.722228 \n",
      "(GPU: 0, epoch: 20, iters: 45120, time: 0.006) nll: 0.875903 \n",
      "(GPU: 0, epoch: 20, iters: 45920, time: 0.006) nll: 0.552509 \n",
      "saving the latest model (epoch 20, total_steps 2860000)\n",
      "(GPU: 0, epoch: 20, iters: 46720, time: 0.006) nll: 0.540644 \n",
      "(GPU: 0, epoch: 20, iters: 47520, time: 0.006) nll: 0.696069 \n",
      "(GPU: 0, epoch: 20, iters: 48320, time: 0.006) nll: 0.602899 \n",
      "(GPU: 0, epoch: 20, iters: 49120, time: 0.005) nll: 0.581487 \n",
      "(GPU: 0, epoch: 20, iters: 49920, time: 0.006) nll: 0.726120 \n",
      "(GPU: 0, epoch: 20, iters: 50720, time: 0.005) nll: 0.726445 \n",
      "(GPU: 0, epoch: 20, iters: 51520, time: 0.006) nll: 0.448341 \n",
      "(GPU: 0, epoch: 20, iters: 52320, time: 0.005) nll: 0.616130 \n",
      "(GPU: 0, epoch: 20, iters: 53120, time: 0.006) nll: 0.693785 \n",
      "(GPU: 0, epoch: 20, iters: 53920, time: 0.005) nll: 0.655065 \n",
      "(GPU: 0, epoch: 20, iters: 54720, time: 0.006) nll: 1.002001 \n",
      "(GPU: 0, epoch: 20, iters: 55520, time: 0.006) nll: 0.580479 \n",
      "(GPU: 0, epoch: 20, iters: 56320, time: 0.006) nll: 0.662432 \n",
      "(GPU: 0, epoch: 20, iters: 57120, time: 0.005) nll: 0.762448 \n",
      "(GPU: 0, epoch: 20, iters: 57920, time: 0.006) nll: 0.557214 \n",
      "(GPU: 0, epoch: 20, iters: 58720, time: 0.005) nll: 0.793529 \n",
      "(GPU: 0, epoch: 20, iters: 59520, time: 0.006) nll: 0.743360 \n",
      "(GPU: 0, epoch: 20, iters: 60320, time: 0.005) nll: 0.569684 \n",
      "(GPU: 0, epoch: 20, iters: 61120, time: 0.006) nll: 0.915572 \n",
      "(GPU: 0, epoch: 20, iters: 61920, time: 0.005) nll: 0.932083 \n",
      "(GPU: 0, epoch: 20, iters: 62720, time: 0.006) nll: 0.821582 \n",
      "(GPU: 0, epoch: 20, iters: 63520, time: 0.005) nll: 0.650088 \n",
      "(GPU: 0, epoch: 20, iters: 64320, time: 0.006) nll: 0.569119 \n",
      "(GPU: 0, epoch: 20, iters: 65120, time: 0.005) nll: 0.648736 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.006) nll: 0.678274 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.009) nll: 0.671397 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.009) nll: 0.736282 \n",
      "saving the latest model (epoch 20, total_steps 2880000)\n",
      "(GPU: 0, epoch: 20, iters: 66720, time: 0.005) nll: 0.528223 \n",
      "(GPU: 0, epoch: 20, iters: 67520, time: 0.006) nll: 0.979774 \n",
      "(GPU: 0, epoch: 20, iters: 68320, time: 0.005) nll: 0.948065 \n",
      "(GPU: 0, epoch: 20, iters: 69120, time: 0.006) nll: 0.737079 \n",
      "(GPU: 0, epoch: 20, iters: 69920, time: 0.005) nll: 0.666800 \n",
      "(GPU: 0, epoch: 20, iters: 70720, time: 0.006) nll: 0.839667 \n",
      "(GPU: 0, epoch: 20, iters: 71520, time: 0.005) nll: 0.767987 \n",
      "(GPU: 0, epoch: 20, iters: 72320, time: 0.006) nll: 0.764673 \n",
      "(GPU: 0, epoch: 20, iters: 73120, time: 0.005) nll: 0.529528 \n",
      "(GPU: 0, epoch: 20, iters: 73920, time: 0.006) nll: 0.803389 \n",
      "(GPU: 0, epoch: 20, iters: 74720, time: 0.005) nll: 0.591740 \n",
      "(GPU: 0, epoch: 20, iters: 75520, time: 0.006) nll: 0.593365 \n",
      "(GPU: 0, epoch: 20, iters: 76320, time: 0.005) nll: 0.729533 \n",
      "(GPU: 0, epoch: 20, iters: 77120, time: 0.006) nll: 0.736208 \n",
      "(GPU: 0, epoch: 20, iters: 77920, time: 0.005) nll: 0.702626 \n",
      "(GPU: 0, epoch: 20, iters: 78720, time: 0.006) nll: 0.774092 \n",
      "(GPU: 0, epoch: 20, iters: 79520, time: 0.005) nll: 0.665657 \n",
      "(GPU: 0, epoch: 20, iters: 80320, time: 0.006) nll: 0.711996 \n",
      "(GPU: 0, epoch: 20, iters: 81120, time: 0.005) nll: 0.565639 \n",
      "(GPU: 0, epoch: 20, iters: 81920, time: 0.006) nll: 0.828242 \n",
      "(GPU: 0, epoch: 20, iters: 82720, time: 0.006) nll: 0.771500 \n",
      "(GPU: 0, epoch: 20, iters: 83520, time: 0.006) nll: 1.191457 \n",
      "(GPU: 0, epoch: 20, iters: 84320, time: 0.006) nll: 0.655392 \n",
      "(GPU: 0, epoch: 20, iters: 85120, time: 0.006) nll: 0.700252 \n",
      "(GPU: 0, epoch: 20, iters: 85920, time: 0.005) nll: 0.768578 \n",
      "saving the latest model (epoch 20, total_steps 2900000)\n",
      "(GPU: 0, epoch: 20, iters: 86720, time: 0.006) nll: 0.763952 \n",
      "(GPU: 0, epoch: 20, iters: 87520, time: 0.005) nll: 0.912368 \n",
      "(GPU: 0, epoch: 20, iters: 88320, time: 0.006) nll: 0.643701 \n",
      "(GPU: 0, epoch: 20, iters: 89120, time: 0.006) nll: 0.653056 \n",
      "(GPU: 0, epoch: 20, iters: 89920, time: 0.006) nll: 0.669628 \n",
      "(GPU: 0, epoch: 20, iters: 90720, time: 0.006) nll: 0.610522 \n",
      "(GPU: 0, epoch: 20, iters: 91520, time: 0.006) nll: 0.563981 \n",
      "(GPU: 0, epoch: 20, iters: 92320, time: 0.005) nll: 0.860293 \n",
      "(GPU: 0, epoch: 20, iters: 93120, time: 0.006) nll: 1.015197 \n",
      "(GPU: 0, epoch: 20, iters: 93920, time: 0.005) nll: 0.538125 \n",
      "(GPU: 0, epoch: 20, iters: 94720, time: 0.006) nll: 0.843066 \n",
      "(GPU: 0, epoch: 20, iters: 95520, time: 0.005) nll: 0.633796 \n",
      "(GPU: 0, epoch: 20, iters: 96320, time: 0.006) nll: 0.621101 \n",
      "(GPU: 0, epoch: 20, iters: 97120, time: 0.005) nll: 0.754205 \n",
      "(GPU: 0, epoch: 20, iters: 97920, time: 0.006) nll: 0.650789 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 20, iters: 98720, time: 0.006) nll: 0.512444 \n",
      "(GPU: 0, epoch: 20, iters: 99520, time: 0.006) nll: 0.858560 \n",
      "(GPU: 0, epoch: 20, iters: 100320, time: 0.006) nll: 0.860097 \n",
      "(GPU: 0, epoch: 20, iters: 101120, time: 0.006) nll: 0.781104 \n",
      "(GPU: 0, epoch: 20, iters: 101920, time: 0.005) nll: 0.607672 \n",
      "(GPU: 0, epoch: 20, iters: 102720, time: 0.006) nll: 0.653103 \n",
      "(GPU: 0, epoch: 20, iters: 103520, time: 0.006) nll: 0.711180 \n",
      "(GPU: 0, epoch: 20, iters: 104320, time: 0.006) nll: 1.066366 \n",
      "(GPU: 0, epoch: 20, iters: 105120, time: 0.005) nll: 0.843277 \n",
      "(GPU: 0, epoch: 20, iters: 105920, time: 0.006) nll: 0.775135 \n",
      "saving the latest model (epoch 20, total_steps 2920000)\n",
      "(GPU: 0, epoch: 20, iters: 106720, time: 0.005) nll: 0.735176 \n",
      "(GPU: 0, epoch: 20, iters: 107520, time: 0.006) nll: 0.694456 \n",
      "(GPU: 0, epoch: 20, iters: 108320, time: 0.005) nll: 0.538573 \n",
      "(GPU: 0, epoch: 20, iters: 109120, time: 0.006) nll: 0.836472 \n",
      "(GPU: 0, epoch: 20, iters: 109920, time: 0.006) nll: 1.007032 \n",
      "(GPU: 0, epoch: 20, iters: 110720, time: 0.006) nll: 0.710997 \n",
      "(GPU: 0, epoch: 20, iters: 111520, time: 0.005) nll: 0.835653 \n",
      "(GPU: 0, epoch: 20, iters: 112320, time: 0.006) nll: 0.847295 \n",
      "(GPU: 0, epoch: 20, iters: 113120, time: 0.005) nll: 0.763990 \n",
      "(GPU: 0, epoch: 20, iters: 113920, time: 0.006) nll: 0.817528 \n",
      "(GPU: 0, epoch: 20, iters: 114720, time: 0.005) nll: 0.815478 \n",
      "(GPU: 0, epoch: 20, iters: 115520, time: 0.006) nll: 0.756506 \n",
      "(GPU: 0, epoch: 20, iters: 116320, time: 0.005) nll: 0.748195 \n",
      "(GPU: 0, epoch: 20, iters: 117120, time: 0.006) nll: 0.888728 \n",
      "(GPU: 0, epoch: 20, iters: 117920, time: 0.005) nll: 0.971143 \n",
      "(GPU: 0, epoch: 20, iters: 118720, time: 0.006) nll: 0.548440 \n",
      "(GPU: 0, epoch: 20, iters: 119520, time: 0.005) nll: 0.817840 \n",
      "(GPU: 0, epoch: 20, iters: 120320, time: 0.006) nll: 0.871151 \n",
      "(GPU: 0, epoch: 20, iters: 121120, time: 0.005) nll: 0.829705 \n",
      "(GPU: 0, epoch: 20, iters: 121920, time: 0.006) nll: 0.828938 \n",
      "(GPU: 0, epoch: 20, iters: 122720, time: 0.005) nll: 0.834483 \n",
      "(GPU: 0, epoch: 20, iters: 123520, time: 0.006) nll: 0.754999 \n",
      "(GPU: 0, epoch: 20, iters: 124320, time: 0.005) nll: 0.738297 \n",
      "(GPU: 0, epoch: 20, iters: 125120, time: 0.006) nll: 0.629910 \n",
      "(GPU: 0, epoch: 20, iters: 125920, time: 0.005) nll: 0.819984 \n",
      "saving the latest model (epoch 20, total_steps 2940000)\n",
      "(GPU: 0, epoch: 20, iters: 126720, time: 0.006) nll: 0.875117 \n",
      "(GPU: 0, epoch: 20, iters: 127520, time: 0.006) nll: 0.673752 \n",
      "(GPU: 0, epoch: 20, iters: 128320, time: 0.006) nll: 0.741824 \n",
      "(GPU: 0, epoch: 20, iters: 129120, time: 0.005) nll: 0.698097 \n",
      "(GPU: 0, epoch: 20, iters: 129920, time: 0.006) nll: 0.592961 \n",
      "(GPU: 0, epoch: 20, iters: 130720, time: 0.005) nll: 0.714799 \n",
      "(GPU: 0, epoch: 20, iters: 131520, time: 0.006) nll: 0.933675 \n",
      "(GPU: 0, epoch: 20, iters: 132320, time: 0.005) nll: 0.737324 \n",
      "(GPU: 0, epoch: 20, iters: 133120, time: 0.006) nll: 0.698456 \n",
      "(GPU: 0, epoch: 20, iters: 133920, time: 0.005) nll: 0.746123 \n",
      "(GPU: 0, epoch: 20, iters: 134720, time: 0.006) nll: 0.670461 \n",
      "(GPU: 0, epoch: 20, iters: 135520, time: 0.005) nll: 0.795149 \n",
      "(GPU: 0, epoch: 20, iters: 136320, time: 0.006) nll: 0.584592 \n",
      "(GPU: 0, epoch: 20, iters: 137120, time: 0.005) nll: 0.810454 \n",
      "(GPU: 0, epoch: 20, iters: 137920, time: 0.006) nll: 0.566837 \n",
      "(GPU: 0, epoch: 20, iters: 138720, time: 0.005) nll: 0.779146 \n",
      "(GPU: 0, epoch: 20, iters: 139520, time: 0.006) nll: 0.510215 \n",
      "(GPU: 0, epoch: 20, iters: 140320, time: 0.005) nll: 0.906620 \n",
      "[*] End of epoch 20 / 25 \t Time Taken: 834 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000690\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3087/4397 [09:46<04:01,  5.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 21, iters: 32, time: 0.003) nll: 0.689463 \n",
      "(GPU: 0, epoch: 21, iters: 32, time: 0.003) nll: 0.850872 \n",
      "(GPU: 0, epoch: 21, iters: 416, time: 0.005) nll: 0.515658 \n",
      "(GPU: 0, epoch: 21, iters: 1216, time: 0.006) nll: 0.683100 \n",
      "(GPU: 0, epoch: 21, iters: 2016, time: 0.005) nll: 0.854190 \n",
      "(GPU: 0, epoch: 21, iters: 2816, time: 0.006) nll: 0.794330 \n",
      "(GPU: 0, epoch: 21, iters: 3616, time: 0.005) nll: 0.624653 \n",
      "(GPU: 0, epoch: 21, iters: 4416, time: 0.006) nll: 0.734251 \n",
      "(GPU: 0, epoch: 21, iters: 5216, time: 0.005) nll: 0.753965 \n",
      "saving the latest model (epoch 21, total_steps 2960000)\n",
      "(GPU: 0, epoch: 21, iters: 6016, time: 0.006) nll: 0.833996 \n",
      "(GPU: 0, epoch: 21, iters: 6816, time: 0.006) nll: 0.735586 \n",
      "(GPU: 0, epoch: 21, iters: 7616, time: 0.006) nll: 0.729256 \n",
      "(GPU: 0, epoch: 21, iters: 8416, time: 0.005) nll: 0.608284 \n",
      "(GPU: 0, epoch: 21, iters: 9216, time: 0.006) nll: 0.710088 \n",
      "(GPU: 0, epoch: 21, iters: 10016, time: 0.006) nll: 0.993383 \n",
      "(GPU: 0, epoch: 21, iters: 10816, time: 0.006) nll: 0.596461 \n",
      "(GPU: 0, epoch: 21, iters: 11616, time: 0.005) nll: 0.579660 \n",
      "(GPU: 0, epoch: 21, iters: 12416, time: 0.006) nll: 0.729139 \n",
      "(GPU: 0, epoch: 21, iters: 13216, time: 0.005) nll: 0.784093 \n",
      "(GPU: 0, epoch: 21, iters: 14016, time: 0.006) nll: 0.815236 \n",
      "(GPU: 0, epoch: 21, iters: 14816, time: 0.005) nll: 0.701826 \n",
      "(GPU: 0, epoch: 21, iters: 15616, time: 0.006) nll: 0.834781 \n",
      "(GPU: 0, epoch: 21, iters: 16416, time: 0.005) nll: 0.827158 \n",
      "(GPU: 0, epoch: 21, iters: 17216, time: 0.006) nll: 0.695189 \n",
      "(GPU: 0, epoch: 21, iters: 18016, time: 0.005) nll: 0.760440 \n",
      "(GPU: 0, epoch: 21, iters: 18816, time: 0.006) nll: 0.655745 \n",
      "(GPU: 0, epoch: 21, iters: 19616, time: 0.006) nll: 0.840371 \n",
      "(GPU: 0, epoch: 21, iters: 20416, time: 0.006) nll: 0.684688 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.005) nll: 0.769742 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.008) nll: 0.754487 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.008) nll: 1.213831 \n",
      "(GPU: 0, epoch: 21, iters: 22016, time: 0.006) nll: 0.701893 \n",
      "(GPU: 0, epoch: 21, iters: 22816, time: 0.005) nll: 0.670907 \n",
      "(GPU: 0, epoch: 21, iters: 23616, time: 0.006) nll: 0.749694 \n",
      "(GPU: 0, epoch: 21, iters: 24416, time: 0.005) nll: 0.768574 \n",
      "(GPU: 0, epoch: 21, iters: 25216, time: 0.006) nll: 0.638413 \n",
      "saving the latest model (epoch 21, total_steps 2980000)\n",
      "(GPU: 0, epoch: 21, iters: 26016, time: 0.006) nll: 0.677103 \n",
      "(GPU: 0, epoch: 21, iters: 26816, time: 0.006) nll: 0.694159 \n",
      "(GPU: 0, epoch: 21, iters: 27616, time: 0.005) nll: 0.681906 \n",
      "(GPU: 0, epoch: 21, iters: 28416, time: 0.006) nll: 0.788902 \n",
      "(GPU: 0, epoch: 21, iters: 29216, time: 0.005) nll: 0.703665 \n",
      "(GPU: 0, epoch: 21, iters: 30016, time: 0.006) nll: 0.748792 \n",
      "(GPU: 0, epoch: 21, iters: 30816, time: 0.005) nll: 0.625496 \n",
      "(GPU: 0, epoch: 21, iters: 31616, time: 0.006) nll: 0.851798 \n",
      "(GPU: 0, epoch: 21, iters: 32416, time: 0.005) nll: 0.695915 \n",
      "(GPU: 0, epoch: 21, iters: 33216, time: 0.006) nll: 0.654917 \n",
      "(GPU: 0, epoch: 21, iters: 34016, time: 0.005) nll: 0.663020 \n",
      "(GPU: 0, epoch: 21, iters: 34816, time: 0.006) nll: 0.637540 \n",
      "(GPU: 0, epoch: 21, iters: 35616, time: 0.005) nll: 0.714884 \n",
      "(GPU: 0, epoch: 21, iters: 36416, time: 0.006) nll: 0.748468 \n",
      "(GPU: 0, epoch: 21, iters: 37216, time: 0.006) nll: 0.849112 \n",
      "(GPU: 0, epoch: 21, iters: 38016, time: 0.006) nll: 0.758323 \n",
      "(GPU: 0, epoch: 21, iters: 38816, time: 0.006) nll: 0.669678 \n",
      "(GPU: 0, epoch: 21, iters: 39616, time: 0.006) nll: 0.627238 \n",
      "(GPU: 0, epoch: 21, iters: 40416, time: 0.005) nll: 0.849587 \n",
      "(GPU: 0, epoch: 21, iters: 41216, time: 0.006) nll: 0.762041 \n",
      "(GPU: 0, epoch: 21, iters: 42016, time: 0.005) nll: 1.175992 \n",
      "(GPU: 0, epoch: 21, iters: 42816, time: 0.006) nll: 0.696261 \n",
      "(GPU: 0, epoch: 21, iters: 43616, time: 0.005) nll: 0.793662 \n",
      "(GPU: 0, epoch: 21, iters: 44416, time: 0.006) nll: 0.822775 \n",
      "(GPU: 0, epoch: 21, iters: 45216, time: 0.005) nll: 0.944852 \n",
      "saving the latest model (epoch 21, total_steps 3000000)\n",
      "(GPU: 0, epoch: 21, iters: 46016, time: 0.006) nll: 0.735283 \n",
      "(GPU: 0, epoch: 21, iters: 46816, time: 0.005) nll: 0.698989 \n",
      "(GPU: 0, epoch: 21, iters: 47616, time: 0.006) nll: 0.910305 \n",
      "(GPU: 0, epoch: 21, iters: 48416, time: 0.005) nll: 0.676492 \n",
      "(GPU: 0, epoch: 21, iters: 49216, time: 0.006) nll: 0.657251 \n",
      "(GPU: 0, epoch: 21, iters: 50016, time: 0.005) nll: 0.760959 \n",
      "(GPU: 0, epoch: 21, iters: 50816, time: 0.006) nll: 0.767912 \n",
      "(GPU: 0, epoch: 21, iters: 51616, time: 0.005) nll: 0.548394 \n",
      "(GPU: 0, epoch: 21, iters: 52416, time: 0.006) nll: 0.661172 \n",
      "(GPU: 0, epoch: 21, iters: 53216, time: 0.005) nll: 0.642465 \n",
      "(GPU: 0, epoch: 21, iters: 54016, time: 0.006) nll: 0.852481 \n",
      "(GPU: 0, epoch: 21, iters: 54816, time: 0.005) nll: 0.660119 \n",
      "(GPU: 0, epoch: 21, iters: 55616, time: 0.006) nll: 0.568648 \n",
      "(GPU: 0, epoch: 21, iters: 56416, time: 0.006) nll: 0.576356 \n",
      "(GPU: 0, epoch: 21, iters: 57216, time: 0.006) nll: 0.663853 \n",
      "(GPU: 0, epoch: 21, iters: 58016, time: 0.005) nll: 0.889786 \n",
      "(GPU: 0, epoch: 21, iters: 58816, time: 0.006) nll: 0.768360 \n",
      "(GPU: 0, epoch: 21, iters: 59616, time: 0.005) nll: 0.781237 \n",
      "(GPU: 0, epoch: 21, iters: 60416, time: 0.006) nll: 0.625799 \n",
      "(GPU: 0, epoch: 21, iters: 61216, time: 0.005) nll: 0.640315 \n",
      "(GPU: 0, epoch: 21, iters: 62016, time: 0.006) nll: 0.425278 \n",
      "(GPU: 0, epoch: 21, iters: 62816, time: 0.005) nll: 0.658140 \n",
      "(GPU: 0, epoch: 21, iters: 63616, time: 0.006) nll: 0.769388 \n",
      "(GPU: 0, epoch: 21, iters: 64416, time: 0.005) nll: 0.843120 \n",
      "(GPU: 0, epoch: 21, iters: 65216, time: 0.006) nll: 0.771909 \n",
      "saving the latest model (epoch 21, total_steps 3020000)\n",
      "(GPU: 0, epoch: 21, iters: 66016, time: 0.005) nll: 0.698961 \n",
      "(GPU: 0, epoch: 21, iters: 66816, time: 0.006) nll: 0.639986 \n",
      "(GPU: 0, epoch: 21, iters: 67616, time: 0.005) nll: 0.704531 \n",
      "(GPU: 0, epoch: 21, iters: 68416, time: 0.006) nll: 0.936595 \n",
      "(GPU: 0, epoch: 21, iters: 69216, time: 0.006) nll: 0.532915 \n",
      "(GPU: 0, epoch: 21, iters: 70016, time: 0.006) nll: 0.831671 \n",
      "(GPU: 0, epoch: 21, iters: 70816, time: 0.005) nll: 0.929213 \n",
      "(GPU: 0, epoch: 21, iters: 71616, time: 0.006) nll: 0.798759 \n",
      "(GPU: 0, epoch: 21, iters: 72416, time: 0.005) nll: 0.633472 \n",
      "(GPU: 0, epoch: 21, iters: 73216, time: 0.006) nll: 0.873147 \n",
      "(GPU: 0, epoch: 21, iters: 74016, time: 0.006) nll: 0.630076 \n",
      "(GPU: 0, epoch: 21, iters: 74816, time: 0.006) nll: 0.790928 \n",
      "(GPU: 0, epoch: 21, iters: 75616, time: 0.005) nll: 0.812439 \n",
      "(GPU: 0, epoch: 21, iters: 76416, time: 0.006) nll: 0.648544 \n",
      "(GPU: 0, epoch: 21, iters: 77216, time: 0.005) nll: 0.797182 \n",
      "(GPU: 0, epoch: 21, iters: 78016, time: 0.006) nll: 0.816474 \n",
      "(GPU: 0, epoch: 21, iters: 78816, time: 0.006) nll: 0.877846 \n",
      "(GPU: 0, epoch: 21, iters: 79616, time: 0.006) nll: 0.618052 \n",
      "(GPU: 0, epoch: 21, iters: 80416, time: 0.005) nll: 0.685020 \n",
      "(GPU: 0, epoch: 21, iters: 81216, time: 0.006) nll: 0.978323 \n",
      "(GPU: 0, epoch: 21, iters: 82016, time: 0.005) nll: 0.858222 \n",
      "(GPU: 0, epoch: 21, iters: 82816, time: 0.006) nll: 0.844564 \n",
      "(GPU: 0, epoch: 21, iters: 83616, time: 0.005) nll: 0.885994 \n",
      "(GPU: 0, epoch: 21, iters: 84416, time: 0.006) nll: 0.788098 \n",
      "(GPU: 0, epoch: 21, iters: 85216, time: 0.005) nll: 0.822704 \n",
      "saving the latest model (epoch 21, total_steps 3040000)\n",
      "(GPU: 0, epoch: 21, iters: 86016, time: 0.006) nll: 0.956153 \n",
      "(GPU: 0, epoch: 21, iters: 86816, time: 0.005) nll: 0.783869 \n",
      "(GPU: 0, epoch: 21, iters: 87616, time: 0.006) nll: 0.783930 \n",
      "(GPU: 0, epoch: 21, iters: 88416, time: 0.005) nll: 0.682468 \n",
      "(GPU: 0, epoch: 21, iters: 89216, time: 0.006) nll: 0.620779 \n",
      "(GPU: 0, epoch: 21, iters: 90016, time: 0.005) nll: 0.835836 \n",
      "(GPU: 0, epoch: 21, iters: 90816, time: 0.006) nll: 0.618041 \n",
      "(GPU: 0, epoch: 21, iters: 91616, time: 0.005) nll: 0.939363 \n",
      "(GPU: 0, epoch: 21, iters: 92416, time: 0.006) nll: 0.697534 \n",
      "(GPU: 0, epoch: 21, iters: 93216, time: 0.005) nll: 0.605780 \n",
      "(GPU: 0, epoch: 21, iters: 94016, time: 0.006) nll: 1.141539 \n",
      "(GPU: 0, epoch: 21, iters: 94816, time: 0.006) nll: 0.496029 \n",
      "(GPU: 0, epoch: 21, iters: 95616, time: 0.006) nll: 0.758550 \n",
      "(GPU: 0, epoch: 21, iters: 96416, time: 0.005) nll: 0.693229 \n",
      "(GPU: 0, epoch: 21, iters: 97216, time: 0.006) nll: 0.724856 \n",
      "(GPU: 0, epoch: 21, iters: 98016, time: 0.005) nll: 0.811542 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:54<00:00,  5.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 21, iters: 98816, time: 0.006) nll: 0.771355 \n",
      "(GPU: 0, epoch: 21, iters: 99616, time: 0.005) nll: 0.492618 \n",
      "(GPU: 0, epoch: 21, iters: 100416, time: 0.006) nll: 0.515966 \n",
      "(GPU: 0, epoch: 21, iters: 101216, time: 0.006) nll: 0.599596 \n",
      "(GPU: 0, epoch: 21, iters: 102016, time: 0.006) nll: 0.670731 \n",
      "(GPU: 0, epoch: 21, iters: 102816, time: 0.005) nll: 0.515861 \n",
      "(GPU: 0, epoch: 21, iters: 103616, time: 0.006) nll: 0.802581 \n",
      "(GPU: 0, epoch: 21, iters: 104416, time: 0.005) nll: 0.724890 \n",
      "(GPU: 0, epoch: 21, iters: 105216, time: 0.006) nll: 0.784215 \n",
      "saving the latest model (epoch 21, total_steps 3060000)\n",
      "(GPU: 0, epoch: 21, iters: 106016, time: 0.005) nll: 0.694588 \n",
      "(GPU: 0, epoch: 21, iters: 106816, time: 0.006) nll: 0.830300 \n",
      "(GPU: 0, epoch: 21, iters: 107616, time: 0.005) nll: 0.820572 \n",
      "(GPU: 0, epoch: 21, iters: 108416, time: 0.006) nll: 0.552806 \n",
      "(GPU: 0, epoch: 21, iters: 109216, time: 0.005) nll: 0.814358 \n",
      "(GPU: 0, epoch: 21, iters: 110016, time: 0.006) nll: 0.629856 \n",
      "(GPU: 0, epoch: 21, iters: 110816, time: 0.005) nll: 0.768418 \n",
      "(GPU: 0, epoch: 21, iters: 111616, time: 0.006) nll: 0.635447 \n",
      "(GPU: 0, epoch: 21, iters: 112416, time: 0.005) nll: 0.835545 \n",
      "(GPU: 0, epoch: 21, iters: 113216, time: 0.006) nll: 0.712724 \n",
      "(GPU: 0, epoch: 21, iters: 114016, time: 0.005) nll: 0.702959 \n",
      "(GPU: 0, epoch: 21, iters: 114816, time: 0.006) nll: 0.617074 \n",
      "(GPU: 0, epoch: 21, iters: 115616, time: 0.006) nll: 0.556198 \n",
      "(GPU: 0, epoch: 21, iters: 116416, time: 0.006) nll: 0.681007 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.005) nll: 0.983074 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.008) nll: 0.963388 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.008) nll: 0.618874 \n",
      "(GPU: 0, epoch: 21, iters: 118016, time: 0.006) nll: 0.596809 \n",
      "(GPU: 0, epoch: 21, iters: 118816, time: 0.005) nll: 0.729022 \n",
      "(GPU: 0, epoch: 21, iters: 119616, time: 0.006) nll: 0.873113 \n",
      "(GPU: 0, epoch: 21, iters: 120416, time: 0.005) nll: 0.726382 \n",
      "(GPU: 0, epoch: 21, iters: 121216, time: 0.006) nll: 0.606295 \n",
      "(GPU: 0, epoch: 21, iters: 122016, time: 0.006) nll: 0.687196 \n",
      "(GPU: 0, epoch: 21, iters: 122816, time: 0.006) nll: 0.667062 \n",
      "(GPU: 0, epoch: 21, iters: 123616, time: 0.005) nll: 0.552411 \n",
      "(GPU: 0, epoch: 21, iters: 124416, time: 0.006) nll: 0.754249 \n",
      "(GPU: 0, epoch: 21, iters: 125216, time: 0.005) nll: 0.580245 \n",
      "saving the latest model (epoch 21, total_steps 3080000)\n",
      "(GPU: 0, epoch: 21, iters: 126016, time: 0.006) nll: 0.573830 \n",
      "(GPU: 0, epoch: 21, iters: 126816, time: 0.005) nll: 0.967445 \n",
      "(GPU: 0, epoch: 21, iters: 127616, time: 0.006) nll: 0.647206 \n",
      "(GPU: 0, epoch: 21, iters: 128416, time: 0.005) nll: 0.904446 \n",
      "(GPU: 0, epoch: 21, iters: 129216, time: 0.006) nll: 0.893418 \n",
      "(GPU: 0, epoch: 21, iters: 130016, time: 0.005) nll: 0.605883 \n",
      "(GPU: 0, epoch: 21, iters: 130816, time: 0.006) nll: 0.736959 \n",
      "(GPU: 0, epoch: 21, iters: 131616, time: 0.005) nll: 0.736425 \n",
      "(GPU: 0, epoch: 21, iters: 132416, time: 0.006) nll: 0.663483 \n",
      "(GPU: 0, epoch: 21, iters: 133216, time: 0.005) nll: 0.850767 \n",
      "(GPU: 0, epoch: 21, iters: 134016, time: 0.006) nll: 0.688166 \n",
      "(GPU: 0, epoch: 21, iters: 134816, time: 0.005) nll: 0.650874 \n",
      "(GPU: 0, epoch: 21, iters: 135616, time: 0.006) nll: 0.936179 \n",
      "(GPU: 0, epoch: 21, iters: 136416, time: 0.005) nll: 0.556745 \n",
      "(GPU: 0, epoch: 21, iters: 137216, time: 0.006) nll: 0.661782 \n",
      "(GPU: 0, epoch: 21, iters: 138016, time: 0.005) nll: 0.702863 \n",
      "(GPU: 0, epoch: 21, iters: 138816, time: 0.006) nll: 0.651563 \n",
      "(GPU: 0, epoch: 21, iters: 139616, time: 0.005) nll: 0.747643 \n",
      "(GPU: 0, epoch: 21, iters: 140416, time: 0.006) nll: 0.653553 \n",
      "saving the model at the end of epoch 21, iters 3095488\n",
      "([test] GPU: 0, epoch: 21) \n",
      "OrderedDict()\n",
      "[*] End of epoch 21 / 25 \t Time Taken: 839 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000674\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3090/4397 [09:45<04:00,  5.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 22, iters: 32, time: 0.003) nll: 0.528680 \n",
      "(GPU: 0, epoch: 22, iters: 32, time: 0.003) nll: 0.633948 \n",
      "(GPU: 0, epoch: 22, iters: 512, time: 0.006) nll: 0.473999 \n",
      "(GPU: 0, epoch: 22, iters: 1312, time: 0.005) nll: 0.742129 \n",
      "(GPU: 0, epoch: 22, iters: 2112, time: 0.006) nll: 0.726472 \n",
      "(GPU: 0, epoch: 22, iters: 2912, time: 0.005) nll: 0.772527 \n",
      "(GPU: 0, epoch: 22, iters: 3712, time: 0.006) nll: 0.598654 \n",
      "(GPU: 0, epoch: 22, iters: 4512, time: 0.005) nll: 0.703703 \n",
      "saving the latest model (epoch 22, total_steps 3100000)\n",
      "(GPU: 0, epoch: 22, iters: 5312, time: 0.006) nll: 0.705267 \n",
      "(GPU: 0, epoch: 22, iters: 6112, time: 0.005) nll: 0.631603 \n",
      "(GPU: 0, epoch: 22, iters: 6912, time: 0.006) nll: 0.674535 \n",
      "(GPU: 0, epoch: 22, iters: 7712, time: 0.005) nll: 1.093189 \n",
      "(GPU: 0, epoch: 22, iters: 8512, time: 0.006) nll: 0.743715 \n",
      "(GPU: 0, epoch: 22, iters: 9312, time: 0.005) nll: 0.565014 \n",
      "(GPU: 0, epoch: 22, iters: 10112, time: 0.006) nll: 0.667743 \n",
      "(GPU: 0, epoch: 22, iters: 10912, time: 0.005) nll: 0.726123 \n",
      "(GPU: 0, epoch: 22, iters: 11712, time: 0.006) nll: 0.719779 \n",
      "(GPU: 0, epoch: 22, iters: 12512, time: 0.005) nll: 0.721039 \n",
      "(GPU: 0, epoch: 22, iters: 13312, time: 0.006) nll: 0.722984 \n",
      "(GPU: 0, epoch: 22, iters: 14112, time: 0.005) nll: 0.955011 \n",
      "(GPU: 0, epoch: 22, iters: 14912, time: 0.006) nll: 0.449574 \n",
      "(GPU: 0, epoch: 22, iters: 15712, time: 0.006) nll: 0.759732 \n",
      "(GPU: 0, epoch: 22, iters: 16512, time: 0.006) nll: 0.845698 \n",
      "(GPU: 0, epoch: 22, iters: 17312, time: 0.005) nll: 0.731321 \n",
      "(GPU: 0, epoch: 22, iters: 18112, time: 0.006) nll: 0.470941 \n",
      "(GPU: 0, epoch: 22, iters: 18912, time: 0.005) nll: 0.497156 \n",
      "(GPU: 0, epoch: 22, iters: 19712, time: 0.006) nll: 1.085142 \n",
      "(GPU: 0, epoch: 22, iters: 20512, time: 0.005) nll: 0.649591 \n",
      "(GPU: 0, epoch: 22, iters: 21312, time: 0.006) nll: 0.610617 \n",
      "(GPU: 0, epoch: 22, iters: 22112, time: 0.005) nll: 0.453997 \n",
      "(GPU: 0, epoch: 22, iters: 22912, time: 0.006) nll: 0.685376 \n",
      "(GPU: 0, epoch: 22, iters: 23712, time: 0.006) nll: 1.189935 \n",
      "(GPU: 0, epoch: 22, iters: 24512, time: 0.006) nll: 0.722212 \n",
      "saving the latest model (epoch 22, total_steps 3120000)\n",
      "(GPU: 0, epoch: 22, iters: 25312, time: 0.005) nll: 0.688330 \n",
      "(GPU: 0, epoch: 22, iters: 26112, time: 0.006) nll: 0.678741 \n",
      "(GPU: 0, epoch: 22, iters: 26912, time: 0.005) nll: 0.678414 \n",
      "(GPU: 0, epoch: 22, iters: 27712, time: 0.006) nll: 0.784992 \n",
      "(GPU: 0, epoch: 22, iters: 28512, time: 0.005) nll: 0.652848 \n",
      "(GPU: 0, epoch: 22, iters: 29312, time: 0.006) nll: 0.820419 \n",
      "(GPU: 0, epoch: 22, iters: 30112, time: 0.005) nll: 0.505562 \n",
      "(GPU: 0, epoch: 22, iters: 30912, time: 0.006) nll: 0.781428 \n",
      "(GPU: 0, epoch: 22, iters: 31712, time: 0.005) nll: 0.709083 \n",
      "(GPU: 0, epoch: 22, iters: 32512, time: 0.006) nll: 0.798213 \n",
      "(GPU: 0, epoch: 22, iters: 33312, time: 0.005) nll: 0.655876 \n",
      "(GPU: 0, epoch: 22, iters: 34112, time: 0.006) nll: 0.707314 \n",
      "(GPU: 0, epoch: 22, iters: 34912, time: 0.005) nll: 0.814990 \n",
      "(GPU: 0, epoch: 22, iters: 35712, time: 0.006) nll: 0.585563 \n",
      "(GPU: 0, epoch: 22, iters: 36512, time: 0.005) nll: 0.615292 \n",
      "(GPU: 0, epoch: 22, iters: 37312, time: 0.006) nll: 0.717475 \n",
      "(GPU: 0, epoch: 22, iters: 38112, time: 0.005) nll: 0.530969 \n",
      "(GPU: 0, epoch: 22, iters: 38912, time: 0.006) nll: 0.528596 \n",
      "(GPU: 0, epoch: 22, iters: 39712, time: 0.006) nll: 0.775267 \n",
      "(GPU: 0, epoch: 22, iters: 40512, time: 0.006) nll: 0.573928 \n",
      "(GPU: 0, epoch: 22, iters: 41312, time: 0.005) nll: 0.870248 \n",
      "(GPU: 0, epoch: 22, iters: 42112, time: 0.006) nll: 0.914603 \n",
      "(GPU: 0, epoch: 22, iters: 42912, time: 0.005) nll: 0.593711 \n",
      "(GPU: 0, epoch: 22, iters: 43712, time: 0.006) nll: 0.638360 \n",
      "(GPU: 0, epoch: 22, iters: 44512, time: 0.005) nll: 0.809186 \n",
      "saving the latest model (epoch 22, total_steps 3140000)\n",
      "(GPU: 0, epoch: 22, iters: 45312, time: 0.006) nll: 0.578537 \n",
      "(GPU: 0, epoch: 22, iters: 46112, time: 0.005) nll: 0.757984 \n",
      "(GPU: 0, epoch: 22, iters: 46912, time: 0.006) nll: 0.671420 \n",
      "(GPU: 0, epoch: 22, iters: 47712, time: 0.005) nll: 0.616635 \n",
      "(GPU: 0, epoch: 22, iters: 48512, time: 0.006) nll: 0.404678 \n",
      "(GPU: 0, epoch: 22, iters: 49312, time: 0.005) nll: 0.690036 \n",
      "(GPU: 0, epoch: 22, iters: 50112, time: 0.006) nll: 0.725343 \n",
      "(GPU: 0, epoch: 22, iters: 50912, time: 0.005) nll: 0.711261 \n",
      "(GPU: 0, epoch: 22, iters: 51712, time: 0.006) nll: 0.527766 \n",
      "(GPU: 0, epoch: 22, iters: 52512, time: 0.005) nll: 0.788343 \n",
      "(GPU: 0, epoch: 22, iters: 53312, time: 0.006) nll: 0.834107 \n",
      "(GPU: 0, epoch: 22, iters: 54112, time: 0.005) nll: 0.531784 \n",
      "(GPU: 0, epoch: 22, iters: 54912, time: 0.006) nll: 0.801531 \n",
      "(GPU: 0, epoch: 22, iters: 55712, time: 0.005) nll: 0.766460 \n",
      "(GPU: 0, epoch: 22, iters: 56512, time: 0.006) nll: 0.671508 \n",
      "(GPU: 0, epoch: 22, iters: 57312, time: 0.005) nll: 0.991765 \n",
      "(GPU: 0, epoch: 22, iters: 58112, time: 0.006) nll: 0.759071 \n",
      "(GPU: 0, epoch: 22, iters: 58912, time: 0.005) nll: 0.650354 \n",
      "(GPU: 0, epoch: 22, iters: 59712, time: 0.006) nll: 0.646105 \n",
      "(GPU: 0, epoch: 22, iters: 60512, time: 0.005) nll: 0.910655 \n",
      "(GPU: 0, epoch: 22, iters: 61312, time: 0.006) nll: 0.746843 \n",
      "(GPU: 0, epoch: 22, iters: 62112, time: 0.006) nll: 0.733284 \n",
      "(GPU: 0, epoch: 22, iters: 62912, time: 0.006) nll: 0.679917 \n",
      "(GPU: 0, epoch: 22, iters: 63712, time: 0.005) nll: 0.652502 \n",
      "(GPU: 0, epoch: 22, iters: 64512, time: 0.006) nll: 0.712019 \n",
      "saving the latest model (epoch 22, total_steps 3160000)\n",
      "(GPU: 0, epoch: 22, iters: 65312, time: 0.005) nll: 0.524354 \n",
      "(GPU: 0, epoch: 22, iters: 66112, time: 0.006) nll: 0.745240 \n",
      "(GPU: 0, epoch: 22, iters: 66912, time: 0.005) nll: 1.093614 \n",
      "(GPU: 0, epoch: 22, iters: 67712, time: 0.006) nll: 0.541187 \n",
      "(GPU: 0, epoch: 22, iters: 68512, time: 0.005) nll: 0.732586 \n",
      "(GPU: 0, epoch: 22, iters: 69312, time: 0.006) nll: 0.748849 \n",
      "(GPU: 0, epoch: 22, iters: 70112, time: 0.005) nll: 0.653352 \n",
      "(GPU: 0, epoch: 22, iters: 70912, time: 0.006) nll: 0.643757 \n",
      "(GPU: 0, epoch: 22, iters: 71712, time: 0.005) nll: 0.748482 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.006) nll: 0.827109 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.009) nll: 0.817581 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.009) nll: 0.725036 \n",
      "(GPU: 0, epoch: 22, iters: 73312, time: 0.005) nll: 0.900053 \n",
      "(GPU: 0, epoch: 22, iters: 74112, time: 0.006) nll: 0.607677 \n",
      "(GPU: 0, epoch: 22, iters: 74912, time: 0.005) nll: 0.545882 \n",
      "(GPU: 0, epoch: 22, iters: 75712, time: 0.006) nll: 0.760390 \n",
      "(GPU: 0, epoch: 22, iters: 76512, time: 0.006) nll: 0.881557 \n",
      "(GPU: 0, epoch: 22, iters: 77312, time: 0.006) nll: 0.510181 \n",
      "(GPU: 0, epoch: 22, iters: 78112, time: 0.005) nll: 0.587934 \n",
      "(GPU: 0, epoch: 22, iters: 78912, time: 0.006) nll: 0.663977 \n",
      "(GPU: 0, epoch: 22, iters: 79712, time: 0.005) nll: 0.786456 \n",
      "(GPU: 0, epoch: 22, iters: 80512, time: 0.006) nll: 0.570377 \n",
      "(GPU: 0, epoch: 22, iters: 81312, time: 0.005) nll: 0.784059 \n",
      "(GPU: 0, epoch: 22, iters: 82112, time: 0.006) nll: 0.732532 \n",
      "(GPU: 0, epoch: 22, iters: 82912, time: 0.005) nll: 0.959497 \n",
      "(GPU: 0, epoch: 22, iters: 83712, time: 0.006) nll: 0.616040 \n",
      "(GPU: 0, epoch: 22, iters: 84512, time: 0.005) nll: 0.862222 \n",
      "saving the latest model (epoch 22, total_steps 3180000)\n",
      "(GPU: 0, epoch: 22, iters: 85312, time: 0.006) nll: 0.535272 \n",
      "(GPU: 0, epoch: 22, iters: 86112, time: 0.005) nll: 0.788359 \n",
      "(GPU: 0, epoch: 22, iters: 86912, time: 0.006) nll: 0.858261 \n",
      "(GPU: 0, epoch: 22, iters: 87712, time: 0.005) nll: 0.476432 \n",
      "(GPU: 0, epoch: 22, iters: 88512, time: 0.006) nll: 0.754876 \n",
      "(GPU: 0, epoch: 22, iters: 89312, time: 0.005) nll: 0.479007 \n",
      "(GPU: 0, epoch: 22, iters: 90112, time: 0.006) nll: 0.643394 \n",
      "(GPU: 0, epoch: 22, iters: 90912, time: 0.006) nll: 0.693329 \n",
      "(GPU: 0, epoch: 22, iters: 91712, time: 0.006) nll: 0.693725 \n",
      "(GPU: 0, epoch: 22, iters: 92512, time: 0.005) nll: 0.669309 \n",
      "(GPU: 0, epoch: 22, iters: 93312, time: 0.006) nll: 0.697088 \n",
      "(GPU: 0, epoch: 22, iters: 94112, time: 0.005) nll: 0.852303 \n",
      "(GPU: 0, epoch: 22, iters: 94912, time: 0.006) nll: 0.622855 \n",
      "(GPU: 0, epoch: 22, iters: 95712, time: 0.005) nll: 0.622203 \n",
      "(GPU: 0, epoch: 22, iters: 96512, time: 0.006) nll: 0.587125 \n",
      "(GPU: 0, epoch: 22, iters: 97312, time: 0.005) nll: 0.713708 \n",
      "(GPU: 0, epoch: 22, iters: 98112, time: 0.006) nll: 0.560598 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:53<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 22, iters: 98912, time: 0.005) nll: 0.844588 \n",
      "(GPU: 0, epoch: 22, iters: 99712, time: 0.006) nll: 0.880802 \n",
      "(GPU: 0, epoch: 22, iters: 100512, time: 0.006) nll: 0.789153 \n",
      "(GPU: 0, epoch: 22, iters: 101312, time: 0.006) nll: 0.540889 \n",
      "(GPU: 0, epoch: 22, iters: 102112, time: 0.005) nll: 0.770774 \n",
      "(GPU: 0, epoch: 22, iters: 102912, time: 0.006) nll: 0.745691 \n",
      "(GPU: 0, epoch: 22, iters: 103712, time: 0.005) nll: 0.770354 \n",
      "(GPU: 0, epoch: 22, iters: 104512, time: 0.006) nll: 0.688042 \n",
      "saving the latest model (epoch 22, total_steps 3200000)\n",
      "(GPU: 0, epoch: 22, iters: 105312, time: 0.005) nll: 0.714821 \n",
      "(GPU: 0, epoch: 22, iters: 106112, time: 0.006) nll: 0.633342 \n",
      "(GPU: 0, epoch: 22, iters: 106912, time: 0.005) nll: 0.918040 \n",
      "(GPU: 0, epoch: 22, iters: 107712, time: 0.006) nll: 0.949263 \n",
      "(GPU: 0, epoch: 22, iters: 108512, time: 0.005) nll: 1.162943 \n",
      "(GPU: 0, epoch: 22, iters: 109312, time: 0.006) nll: 0.760035 \n",
      "(GPU: 0, epoch: 22, iters: 110112, time: 0.005) nll: 0.812662 \n",
      "(GPU: 0, epoch: 22, iters: 110912, time: 0.006) nll: 0.775706 \n",
      "(GPU: 0, epoch: 22, iters: 111712, time: 0.005) nll: 0.763401 \n",
      "(GPU: 0, epoch: 22, iters: 112512, time: 0.006) nll: 0.731154 \n",
      "(GPU: 0, epoch: 22, iters: 113312, time: 0.006) nll: 0.734113 \n",
      "(GPU: 0, epoch: 22, iters: 114112, time: 0.006) nll: 0.699294 \n",
      "(GPU: 0, epoch: 22, iters: 114912, time: 0.005) nll: 0.647314 \n",
      "(GPU: 0, epoch: 22, iters: 115712, time: 0.006) nll: 0.706686 \n",
      "(GPU: 0, epoch: 22, iters: 116512, time: 0.005) nll: 0.486882 \n",
      "(GPU: 0, epoch: 22, iters: 117312, time: 0.006) nll: 0.634368 \n",
      "(GPU: 0, epoch: 22, iters: 118112, time: 0.005) nll: 0.590896 \n",
      "(GPU: 0, epoch: 22, iters: 118912, time: 0.006) nll: 1.000579 \n",
      "(GPU: 0, epoch: 22, iters: 119712, time: 0.005) nll: 0.669051 \n",
      "(GPU: 0, epoch: 22, iters: 120512, time: 0.006) nll: 0.778452 \n",
      "(GPU: 0, epoch: 22, iters: 121312, time: 0.006) nll: 0.435071 \n",
      "(GPU: 0, epoch: 22, iters: 122112, time: 0.006) nll: 0.575292 \n",
      "(GPU: 0, epoch: 22, iters: 122912, time: 0.005) nll: 0.762585 \n",
      "(GPU: 0, epoch: 22, iters: 123712, time: 0.006) nll: 0.722681 \n",
      "(GPU: 0, epoch: 22, iters: 124512, time: 0.005) nll: 0.731136 \n",
      "saving the latest model (epoch 22, total_steps 3220000)\n",
      "(GPU: 0, epoch: 22, iters: 125312, time: 0.006) nll: 0.825282 \n",
      "(GPU: 0, epoch: 22, iters: 126112, time: 0.005) nll: 0.936128 \n",
      "(GPU: 0, epoch: 22, iters: 126912, time: 0.006) nll: 0.621740 \n",
      "(GPU: 0, epoch: 22, iters: 127712, time: 0.006) nll: 0.804548 \n",
      "(GPU: 0, epoch: 22, iters: 128512, time: 0.006) nll: 0.740196 \n",
      "(GPU: 0, epoch: 22, iters: 129312, time: 0.005) nll: 0.730710 \n",
      "(GPU: 0, epoch: 22, iters: 130112, time: 0.006) nll: 0.655215 \n",
      "(GPU: 0, epoch: 22, iters: 130912, time: 0.005) nll: 0.675307 \n",
      "(GPU: 0, epoch: 22, iters: 131712, time: 0.006) nll: 0.668778 \n",
      "(GPU: 0, epoch: 22, iters: 132512, time: 0.005) nll: 0.797280 \n",
      "(GPU: 0, epoch: 22, iters: 133312, time: 0.006) nll: 0.569363 \n",
      "(GPU: 0, epoch: 22, iters: 134112, time: 0.005) nll: 0.568512 \n",
      "(GPU: 0, epoch: 22, iters: 134912, time: 0.006) nll: 0.678926 \n",
      "(GPU: 0, epoch: 22, iters: 135712, time: 0.006) nll: 0.748927 \n",
      "(GPU: 0, epoch: 22, iters: 136512, time: 0.006) nll: 0.689580 \n",
      "(GPU: 0, epoch: 22, iters: 137312, time: 0.005) nll: 0.598785 \n",
      "(GPU: 0, epoch: 22, iters: 138112, time: 0.006) nll: 0.731085 \n",
      "(GPU: 0, epoch: 22, iters: 138912, time: 0.006) nll: 0.801167 \n",
      "(GPU: 0, epoch: 22, iters: 139712, time: 0.006) nll: 0.733837 \n",
      "(GPU: 0, epoch: 22, iters: 140512, time: 0.005) nll: 0.629796 \n",
      "[*] End of epoch 22 / 25 \t Time Taken: 833 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000659\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3093/4397 [09:45<03:58,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 23, iters: 32, time: 0.003) nll: 0.722185 \n",
      "(GPU: 0, epoch: 23, iters: 32, time: 0.003) nll: 0.777708 \n",
      "(GPU: 0, epoch: 23, iters: 608, time: 0.005) nll: 0.529681 \n",
      "(GPU: 0, epoch: 23, iters: 1408, time: 0.006) nll: 0.598726 \n",
      "(GPU: 0, epoch: 23, iters: 2208, time: 0.006) nll: 0.593549 \n",
      "(GPU: 0, epoch: 23, iters: 3008, time: 0.006) nll: 0.702862 \n",
      "(GPU: 0, epoch: 23, iters: 3808, time: 0.005) nll: 0.720503 \n",
      "saving the latest model (epoch 23, total_steps 3240000)\n",
      "(GPU: 0, epoch: 23, iters: 4608, time: 0.006) nll: 0.588743 \n",
      "(GPU: 0, epoch: 23, iters: 5408, time: 0.005) nll: 0.763669 \n",
      "(GPU: 0, epoch: 23, iters: 6208, time: 0.006) nll: 0.526995 \n",
      "(GPU: 0, epoch: 23, iters: 7008, time: 0.006) nll: 0.966953 \n",
      "(GPU: 0, epoch: 23, iters: 7808, time: 0.006) nll: 0.882347 \n",
      "(GPU: 0, epoch: 23, iters: 8608, time: 0.005) nll: 0.722677 \n",
      "(GPU: 0, epoch: 23, iters: 9408, time: 0.006) nll: 0.548015 \n",
      "(GPU: 0, epoch: 23, iters: 10208, time: 0.005) nll: 0.482900 \n",
      "(GPU: 0, epoch: 23, iters: 11008, time: 0.006) nll: 0.659550 \n",
      "(GPU: 0, epoch: 23, iters: 11808, time: 0.005) nll: 0.616689 \n",
      "(GPU: 0, epoch: 23, iters: 12608, time: 0.006) nll: 0.733972 \n",
      "(GPU: 0, epoch: 23, iters: 13408, time: 0.005) nll: 0.731465 \n",
      "(GPU: 0, epoch: 23, iters: 14208, time: 0.006) nll: 0.635058 \n",
      "(GPU: 0, epoch: 23, iters: 15008, time: 0.006) nll: 0.679574 \n",
      "(GPU: 0, epoch: 23, iters: 15808, time: 0.006) nll: 0.949462 \n",
      "(GPU: 0, epoch: 23, iters: 16608, time: 0.005) nll: 0.640852 \n",
      "(GPU: 0, epoch: 23, iters: 17408, time: 0.006) nll: 0.609528 \n",
      "(GPU: 0, epoch: 23, iters: 18208, time: 0.006) nll: 0.599608 \n",
      "(GPU: 0, epoch: 23, iters: 19008, time: 0.006) nll: 0.702504 \n",
      "(GPU: 0, epoch: 23, iters: 19808, time: 0.005) nll: 0.614880 \n",
      "(GPU: 0, epoch: 23, iters: 20608, time: 0.006) nll: 1.045626 \n",
      "(GPU: 0, epoch: 23, iters: 21408, time: 0.005) nll: 0.684011 \n",
      "(GPU: 0, epoch: 23, iters: 22208, time: 0.006) nll: 0.740615 \n",
      "(GPU: 0, epoch: 23, iters: 23008, time: 0.005) nll: 0.774001 \n",
      "(GPU: 0, epoch: 23, iters: 23808, time: 0.006) nll: 0.671348 \n",
      "saving the latest model (epoch 23, total_steps 3260000)\n",
      "(GPU: 0, epoch: 23, iters: 24608, time: 0.005) nll: 0.912545 \n",
      "(GPU: 0, epoch: 23, iters: 25408, time: 0.006) nll: 0.627825 \n",
      "(GPU: 0, epoch: 23, iters: 26208, time: 0.005) nll: 0.527787 \n",
      "(GPU: 0, epoch: 23, iters: 27008, time: 0.006) nll: 0.640786 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.005) nll: 0.704920 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.008) nll: 0.699759 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.008) nll: 0.892546 \n",
      "(GPU: 0, epoch: 23, iters: 28608, time: 0.006) nll: 0.773565 \n",
      "(GPU: 0, epoch: 23, iters: 29408, time: 0.005) nll: 0.775875 \n",
      "(GPU: 0, epoch: 23, iters: 30208, time: 0.006) nll: 0.547095 \n",
      "(GPU: 0, epoch: 23, iters: 31008, time: 0.006) nll: 0.693819 \n",
      "(GPU: 0, epoch: 23, iters: 31808, time: 0.006) nll: 0.609442 \n",
      "(GPU: 0, epoch: 23, iters: 32608, time: 0.005) nll: 0.716682 \n",
      "(GPU: 0, epoch: 23, iters: 33408, time: 0.006) nll: 0.745061 \n",
      "(GPU: 0, epoch: 23, iters: 34208, time: 0.005) nll: 0.590183 \n",
      "(GPU: 0, epoch: 23, iters: 35008, time: 0.006) nll: 0.683341 \n",
      "(GPU: 0, epoch: 23, iters: 35808, time: 0.005) nll: 0.663831 \n",
      "(GPU: 0, epoch: 23, iters: 36608, time: 0.006) nll: 0.551596 \n",
      "(GPU: 0, epoch: 23, iters: 37408, time: 0.005) nll: 0.773651 \n",
      "(GPU: 0, epoch: 23, iters: 38208, time: 0.006) nll: 0.595656 \n",
      "(GPU: 0, epoch: 23, iters: 39008, time: 0.006) nll: 0.717190 \n",
      "(GPU: 0, epoch: 23, iters: 39808, time: 0.006) nll: 0.735488 \n",
      "(GPU: 0, epoch: 23, iters: 40608, time: 0.005) nll: 0.679732 \n",
      "(GPU: 0, epoch: 23, iters: 41408, time: 0.006) nll: 0.539167 \n",
      "(GPU: 0, epoch: 23, iters: 42208, time: 0.006) nll: 0.837561 \n",
      "(GPU: 0, epoch: 23, iters: 43008, time: 0.006) nll: 1.003688 \n",
      "(GPU: 0, epoch: 23, iters: 43808, time: 0.005) nll: 0.620029 \n",
      "saving the latest model (epoch 23, total_steps 3280000)\n",
      "(GPU: 0, epoch: 23, iters: 44608, time: 0.006) nll: 0.739900 \n",
      "(GPU: 0, epoch: 23, iters: 45408, time: 0.005) nll: 0.730401 \n",
      "(GPU: 0, epoch: 23, iters: 46208, time: 0.006) nll: 0.580857 \n",
      "(GPU: 0, epoch: 23, iters: 47008, time: 0.005) nll: 0.656610 \n",
      "(GPU: 0, epoch: 23, iters: 47808, time: 0.006) nll: 0.543749 \n",
      "(GPU: 0, epoch: 23, iters: 48608, time: 0.005) nll: 0.720280 \n",
      "(GPU: 0, epoch: 23, iters: 49408, time: 0.006) nll: 0.685728 \n",
      "(GPU: 0, epoch: 23, iters: 50208, time: 0.005) nll: 0.687848 \n",
      "(GPU: 0, epoch: 23, iters: 51008, time: 0.006) nll: 0.656412 \n",
      "(GPU: 0, epoch: 23, iters: 51808, time: 0.005) nll: 0.555825 \n",
      "(GPU: 0, epoch: 23, iters: 52608, time: 0.006) nll: 0.820624 \n",
      "(GPU: 0, epoch: 23, iters: 53408, time: 0.005) nll: 0.770469 \n",
      "(GPU: 0, epoch: 23, iters: 54208, time: 0.006) nll: 0.761384 \n",
      "(GPU: 0, epoch: 23, iters: 55008, time: 0.005) nll: 0.720415 \n",
      "(GPU: 0, epoch: 23, iters: 55808, time: 0.006) nll: 0.815872 \n",
      "(GPU: 0, epoch: 23, iters: 56608, time: 0.005) nll: 0.888086 \n",
      "(GPU: 0, epoch: 23, iters: 57408, time: 0.006) nll: 0.945553 \n",
      "(GPU: 0, epoch: 23, iters: 58208, time: 0.005) nll: 0.762924 \n",
      "(GPU: 0, epoch: 23, iters: 59008, time: 0.006) nll: 0.698573 \n",
      "(GPU: 0, epoch: 23, iters: 59808, time: 0.005) nll: 0.639896 \n",
      "(GPU: 0, epoch: 23, iters: 60608, time: 0.006) nll: 0.906272 \n",
      "(GPU: 0, epoch: 23, iters: 61408, time: 0.005) nll: 0.852192 \n",
      "(GPU: 0, epoch: 23, iters: 62208, time: 0.006) nll: 0.725729 \n",
      "(GPU: 0, epoch: 23, iters: 63008, time: 0.005) nll: 0.790726 \n",
      "(GPU: 0, epoch: 23, iters: 63808, time: 0.006) nll: 0.708627 \n",
      "saving the latest model (epoch 23, total_steps 3300000)\n",
      "(GPU: 0, epoch: 23, iters: 64608, time: 0.006) nll: 0.729845 \n",
      "(GPU: 0, epoch: 23, iters: 65408, time: 0.006) nll: 0.915862 \n",
      "(GPU: 0, epoch: 23, iters: 66208, time: 0.005) nll: 0.649460 \n",
      "(GPU: 0, epoch: 23, iters: 67008, time: 0.006) nll: 0.632319 \n",
      "(GPU: 0, epoch: 23, iters: 67808, time: 0.005) nll: 0.618599 \n",
      "(GPU: 0, epoch: 23, iters: 68608, time: 0.006) nll: 0.643021 \n",
      "(GPU: 0, epoch: 23, iters: 69408, time: 0.005) nll: 0.682944 \n",
      "(GPU: 0, epoch: 23, iters: 70208, time: 0.006) nll: 0.786654 \n",
      "(GPU: 0, epoch: 23, iters: 71008, time: 0.005) nll: 0.711378 \n",
      "(GPU: 0, epoch: 23, iters: 71808, time: 0.006) nll: 0.797550 \n",
      "(GPU: 0, epoch: 23, iters: 72608, time: 0.005) nll: 0.653405 \n",
      "(GPU: 0, epoch: 23, iters: 73408, time: 0.006) nll: 0.574179 \n",
      "(GPU: 0, epoch: 23, iters: 74208, time: 0.005) nll: 0.573595 \n",
      "(GPU: 0, epoch: 23, iters: 75008, time: 0.006) nll: 1.014915 \n",
      "(GPU: 0, epoch: 23, iters: 75808, time: 0.005) nll: 0.992725 \n",
      "(GPU: 0, epoch: 23, iters: 76608, time: 0.006) nll: 0.790306 \n",
      "(GPU: 0, epoch: 23, iters: 77408, time: 0.005) nll: 0.452524 \n",
      "(GPU: 0, epoch: 23, iters: 78208, time: 0.006) nll: 0.673557 \n",
      "(GPU: 0, epoch: 23, iters: 79008, time: 0.005) nll: 0.784575 \n",
      "(GPU: 0, epoch: 23, iters: 79808, time: 0.006) nll: 0.516877 \n",
      "(GPU: 0, epoch: 23, iters: 80608, time: 0.006) nll: 0.549324 \n",
      "(GPU: 0, epoch: 23, iters: 81408, time: 0.006) nll: 0.718779 \n",
      "(GPU: 0, epoch: 23, iters: 82208, time: 0.005) nll: 0.669434 \n",
      "(GPU: 0, epoch: 23, iters: 83008, time: 0.006) nll: 0.788374 \n",
      "(GPU: 0, epoch: 23, iters: 83808, time: 0.006) nll: 0.782697 \n",
      "saving the latest model (epoch 23, total_steps 3320000)\n",
      "(GPU: 0, epoch: 23, iters: 84608, time: 0.006) nll: 0.855443 \n",
      "(GPU: 0, epoch: 23, iters: 85408, time: 0.005) nll: 1.102243 \n",
      "(GPU: 0, epoch: 23, iters: 86208, time: 0.006) nll: 0.921894 \n",
      "(GPU: 0, epoch: 23, iters: 87008, time: 0.005) nll: 0.649919 \n",
      "(GPU: 0, epoch: 23, iters: 87808, time: 0.006) nll: 0.863734 \n",
      "(GPU: 0, epoch: 23, iters: 88608, time: 0.005) nll: 0.735782 \n",
      "(GPU: 0, epoch: 23, iters: 89408, time: 0.006) nll: 0.857393 \n",
      "(GPU: 0, epoch: 23, iters: 90208, time: 0.005) nll: 0.657960 \n",
      "(GPU: 0, epoch: 23, iters: 91008, time: 0.006) nll: 0.623322 \n",
      "(GPU: 0, epoch: 23, iters: 91808, time: 0.005) nll: 0.610815 \n",
      "(GPU: 0, epoch: 23, iters: 92608, time: 0.006) nll: 0.743334 \n",
      "(GPU: 0, epoch: 23, iters: 93408, time: 0.005) nll: 0.678340 \n",
      "(GPU: 0, epoch: 23, iters: 94208, time: 0.006) nll: 0.792758 \n",
      "(GPU: 0, epoch: 23, iters: 95008, time: 0.005) nll: 0.458881 \n",
      "(GPU: 0, epoch: 23, iters: 95808, time: 0.006) nll: 0.636198 \n",
      "(GPU: 0, epoch: 23, iters: 96608, time: 0.005) nll: 0.544284 \n",
      "(GPU: 0, epoch: 23, iters: 97408, time: 0.006) nll: 0.831833 \n",
      "(GPU: 0, epoch: 23, iters: 98208, time: 0.006) nll: 0.646640 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:52<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 23, iters: 99008, time: 0.006) nll: 1.025612 \n",
      "(GPU: 0, epoch: 23, iters: 99808, time: 0.005) nll: 0.563829 \n",
      "(GPU: 0, epoch: 23, iters: 100608, time: 0.006) nll: 0.561737 \n",
      "(GPU: 0, epoch: 23, iters: 101408, time: 0.005) nll: 0.853919 \n",
      "(GPU: 0, epoch: 23, iters: 102208, time: 0.006) nll: 0.884680 \n",
      "(GPU: 0, epoch: 23, iters: 103008, time: 0.005) nll: 0.741015 \n",
      "(GPU: 0, epoch: 23, iters: 103808, time: 0.006) nll: 0.735703 \n",
      "saving the latest model (epoch 23, total_steps 3340000)\n",
      "(GPU: 0, epoch: 23, iters: 104608, time: 0.005) nll: 0.674207 \n",
      "(GPU: 0, epoch: 23, iters: 105408, time: 0.006) nll: 0.751772 \n",
      "(GPU: 0, epoch: 23, iters: 106208, time: 0.005) nll: 0.916744 \n",
      "(GPU: 0, epoch: 23, iters: 107008, time: 0.006) nll: 0.647909 \n",
      "(GPU: 0, epoch: 23, iters: 107808, time: 0.005) nll: 0.593060 \n",
      "(GPU: 0, epoch: 23, iters: 108608, time: 0.006) nll: 0.739992 \n",
      "(GPU: 0, epoch: 23, iters: 109408, time: 0.005) nll: 0.670910 \n",
      "(GPU: 0, epoch: 23, iters: 110208, time: 0.006) nll: 0.762217 \n",
      "(GPU: 0, epoch: 23, iters: 111008, time: 0.005) nll: 0.625081 \n",
      "(GPU: 0, epoch: 23, iters: 111808, time: 0.006) nll: 0.670058 \n",
      "(GPU: 0, epoch: 23, iters: 112608, time: 0.006) nll: 0.713167 \n",
      "(GPU: 0, epoch: 23, iters: 113408, time: 0.006) nll: 0.568496 \n",
      "(GPU: 0, epoch: 23, iters: 114208, time: 0.006) nll: 0.713323 \n",
      "(GPU: 0, epoch: 23, iters: 115008, time: 0.006) nll: 0.810044 \n",
      "(GPU: 0, epoch: 23, iters: 115808, time: 0.005) nll: 0.747520 \n",
      "(GPU: 0, epoch: 23, iters: 116608, time: 0.006) nll: 0.831829 \n",
      "(GPU: 0, epoch: 23, iters: 117408, time: 0.005) nll: 1.150154 \n",
      "(GPU: 0, epoch: 23, iters: 118208, time: 0.006) nll: 0.611860 \n",
      "(GPU: 0, epoch: 23, iters: 119008, time: 0.005) nll: 0.793464 \n",
      "(GPU: 0, epoch: 23, iters: 119808, time: 0.006) nll: 0.708618 \n",
      "(GPU: 0, epoch: 23, iters: 120608, time: 0.005) nll: 0.894855 \n",
      "(GPU: 0, epoch: 23, iters: 121408, time: 0.006) nll: 0.879653 \n",
      "(GPU: 0, epoch: 23, iters: 122208, time: 0.005) nll: 0.725236 \n",
      "(GPU: 0, epoch: 23, iters: 123008, time: 0.006) nll: 0.674020 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.006) nll: 0.570237 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.009) nll: 0.564831 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.009) nll: 1.373082 \n",
      "saving the latest model (epoch 23, total_steps 3360000)\n",
      "(GPU: 0, epoch: 23, iters: 124608, time: 0.006) nll: 0.519673 \n",
      "(GPU: 0, epoch: 23, iters: 125408, time: 0.005) nll: 0.870446 \n",
      "(GPU: 0, epoch: 23, iters: 126208, time: 0.006) nll: 0.716747 \n",
      "(GPU: 0, epoch: 23, iters: 127008, time: 0.005) nll: 0.643786 \n",
      "(GPU: 0, epoch: 23, iters: 127808, time: 0.006) nll: 0.511605 \n",
      "(GPU: 0, epoch: 23, iters: 128608, time: 0.005) nll: 0.615107 \n",
      "(GPU: 0, epoch: 23, iters: 129408, time: 0.006) nll: 0.588571 \n",
      "(GPU: 0, epoch: 23, iters: 130208, time: 0.005) nll: 0.979442 \n",
      "(GPU: 0, epoch: 23, iters: 131008, time: 0.006) nll: 0.553718 \n",
      "(GPU: 0, epoch: 23, iters: 131808, time: 0.005) nll: 0.586731 \n",
      "(GPU: 0, epoch: 23, iters: 132608, time: 0.006) nll: 0.658743 \n",
      "(GPU: 0, epoch: 23, iters: 133408, time: 0.005) nll: 0.773408 \n",
      "(GPU: 0, epoch: 23, iters: 134208, time: 0.006) nll: 0.755718 \n",
      "(GPU: 0, epoch: 23, iters: 135008, time: 0.006) nll: 0.745766 \n",
      "(GPU: 0, epoch: 23, iters: 135808, time: 0.006) nll: 0.572215 \n",
      "(GPU: 0, epoch: 23, iters: 136608, time: 0.005) nll: 0.666756 \n",
      "(GPU: 0, epoch: 23, iters: 137408, time: 0.006) nll: 0.789511 \n",
      "(GPU: 0, epoch: 23, iters: 138208, time: 0.006) nll: 0.783245 \n",
      "(GPU: 0, epoch: 23, iters: 139008, time: 0.006) nll: 0.737419 \n",
      "(GPU: 0, epoch: 23, iters: 139808, time: 0.005) nll: 0.641546 \n",
      "(GPU: 0, epoch: 23, iters: 140608, time: 0.006) nll: 0.532638 \n",
      "[*] End of epoch 23 / 25 \t Time Taken: 832 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000645\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3096/4397 [09:46<03:58,  5.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 24, iters: 32, time: 0.003) nll: 0.882932 \n",
      "(GPU: 0, epoch: 24, iters: 32, time: 0.003) nll: 0.926898 \n",
      "(GPU: 0, epoch: 24, iters: 704, time: 0.006) nll: 0.901887 \n",
      "(GPU: 0, epoch: 24, iters: 1504, time: 0.005) nll: 0.868711 \n",
      "(GPU: 0, epoch: 24, iters: 2304, time: 0.006) nll: 0.742234 \n",
      "(GPU: 0, epoch: 24, iters: 3104, time: 0.005) nll: 0.841291 \n",
      "saving the latest model (epoch 24, total_steps 3380000)\n",
      "(GPU: 0, epoch: 24, iters: 3904, time: 0.006) nll: 0.578995 \n",
      "(GPU: 0, epoch: 24, iters: 4704, time: 0.006) nll: 0.881329 \n",
      "(GPU: 0, epoch: 24, iters: 5504, time: 0.006) nll: 0.624928 \n",
      "(GPU: 0, epoch: 24, iters: 6304, time: 0.005) nll: 1.094883 \n",
      "(GPU: 0, epoch: 24, iters: 7104, time: 0.006) nll: 0.578469 \n",
      "(GPU: 0, epoch: 24, iters: 7904, time: 0.005) nll: 0.809418 \n",
      "(GPU: 0, epoch: 24, iters: 8704, time: 0.006) nll: 0.734972 \n",
      "(GPU: 0, epoch: 24, iters: 9504, time: 0.005) nll: 0.794869 \n",
      "(GPU: 0, epoch: 24, iters: 10304, time: 0.006) nll: 0.922576 \n",
      "(GPU: 0, epoch: 24, iters: 11104, time: 0.005) nll: 0.876738 \n",
      "(GPU: 0, epoch: 24, iters: 11904, time: 0.006) nll: 0.756542 \n",
      "(GPU: 0, epoch: 24, iters: 12704, time: 0.005) nll: 0.602044 \n",
      "(GPU: 0, epoch: 24, iters: 13504, time: 0.006) nll: 1.110726 \n",
      "(GPU: 0, epoch: 24, iters: 14304, time: 0.005) nll: 0.803779 \n",
      "(GPU: 0, epoch: 24, iters: 15104, time: 0.006) nll: 0.600642 \n",
      "(GPU: 0, epoch: 24, iters: 15904, time: 0.005) nll: 0.722497 \n",
      "(GPU: 0, epoch: 24, iters: 16704, time: 0.006) nll: 0.697708 \n",
      "(GPU: 0, epoch: 24, iters: 17504, time: 0.005) nll: 0.675211 \n",
      "(GPU: 0, epoch: 24, iters: 18304, time: 0.006) nll: 0.551482 \n",
      "(GPU: 0, epoch: 24, iters: 19104, time: 0.005) nll: 0.755847 \n",
      "(GPU: 0, epoch: 24, iters: 19904, time: 0.006) nll: 0.725775 \n",
      "(GPU: 0, epoch: 24, iters: 20704, time: 0.005) nll: 0.775147 \n",
      "(GPU: 0, epoch: 24, iters: 21504, time: 0.006) nll: 0.769210 \n",
      "(GPU: 0, epoch: 24, iters: 22304, time: 0.005) nll: 0.768208 \n",
      "(GPU: 0, epoch: 24, iters: 23104, time: 0.006) nll: 0.559922 \n",
      "saving the latest model (epoch 24, total_steps 3400000)\n",
      "(GPU: 0, epoch: 24, iters: 23904, time: 0.005) nll: 0.806531 \n",
      "(GPU: 0, epoch: 24, iters: 24704, time: 0.006) nll: 0.594316 \n",
      "(GPU: 0, epoch: 24, iters: 25504, time: 0.005) nll: 0.598498 \n",
      "(GPU: 0, epoch: 24, iters: 26304, time: 0.006) nll: 0.640500 \n",
      "(GPU: 0, epoch: 24, iters: 27104, time: 0.005) nll: 0.490595 \n",
      "(GPU: 0, epoch: 24, iters: 27904, time: 0.006) nll: 1.110179 \n",
      "(GPU: 0, epoch: 24, iters: 28704, time: 0.005) nll: 0.928249 \n",
      "(GPU: 0, epoch: 24, iters: 29504, time: 0.006) nll: 0.783825 \n",
      "(GPU: 0, epoch: 24, iters: 30304, time: 0.005) nll: 0.654419 \n",
      "(GPU: 0, epoch: 24, iters: 31104, time: 0.006) nll: 0.765022 \n",
      "(GPU: 0, epoch: 24, iters: 31904, time: 0.005) nll: 0.696939 \n",
      "(GPU: 0, epoch: 24, iters: 32704, time: 0.006) nll: 0.581935 \n",
      "(GPU: 0, epoch: 24, iters: 33504, time: 0.005) nll: 0.785419 \n",
      "(GPU: 0, epoch: 24, iters: 34304, time: 0.006) nll: 0.466088 \n",
      "(GPU: 0, epoch: 24, iters: 35104, time: 0.005) nll: 0.792351 \n",
      "(GPU: 0, epoch: 24, iters: 35904, time: 0.006) nll: 0.629413 \n",
      "(GPU: 0, epoch: 24, iters: 36704, time: 0.005) nll: 0.712280 \n",
      "(GPU: 0, epoch: 24, iters: 37504, time: 0.006) nll: 0.608885 \n",
      "(GPU: 0, epoch: 24, iters: 38304, time: 0.005) nll: 0.603287 \n",
      "(GPU: 0, epoch: 24, iters: 39104, time: 0.006) nll: 0.507436 \n",
      "(GPU: 0, epoch: 24, iters: 39904, time: 0.005) nll: 0.736821 \n",
      "(GPU: 0, epoch: 24, iters: 40704, time: 0.006) nll: 0.823280 \n",
      "(GPU: 0, epoch: 24, iters: 41504, time: 0.005) nll: 0.657284 \n",
      "(GPU: 0, epoch: 24, iters: 42304, time: 0.006) nll: 0.702673 \n",
      "(GPU: 0, epoch: 24, iters: 43104, time: 0.005) nll: 0.768739 \n",
      "saving the latest model (epoch 24, total_steps 3420000)\n",
      "(GPU: 0, epoch: 24, iters: 43904, time: 0.006) nll: 0.844627 \n",
      "(GPU: 0, epoch: 24, iters: 44704, time: 0.005) nll: 0.831320 \n",
      "(GPU: 0, epoch: 24, iters: 45504, time: 0.006) nll: 0.791357 \n",
      "(GPU: 0, epoch: 24, iters: 46304, time: 0.005) nll: 0.547985 \n",
      "(GPU: 0, epoch: 24, iters: 47104, time: 0.006) nll: 0.555940 \n",
      "(GPU: 0, epoch: 24, iters: 47904, time: 0.005) nll: 0.702164 \n",
      "(GPU: 0, epoch: 24, iters: 48704, time: 0.006) nll: 0.657464 \n",
      "(GPU: 0, epoch: 24, iters: 49504, time: 0.005) nll: 0.491505 \n",
      "(GPU: 0, epoch: 24, iters: 50304, time: 0.006) nll: 0.802985 \n",
      "(GPU: 0, epoch: 24, iters: 51104, time: 0.005) nll: 0.747386 \n",
      "(GPU: 0, epoch: 24, iters: 51904, time: 0.006) nll: 0.904222 \n",
      "(GPU: 0, epoch: 24, iters: 52704, time: 0.005) nll: 0.727556 \n",
      "(GPU: 0, epoch: 24, iters: 53504, time: 0.006) nll: 0.699238 \n",
      "(GPU: 0, epoch: 24, iters: 54304, time: 0.005) nll: 0.699630 \n",
      "(GPU: 0, epoch: 24, iters: 55104, time: 0.006) nll: 0.498068 \n",
      "(GPU: 0, epoch: 24, iters: 55904, time: 0.005) nll: 0.500425 \n",
      "(GPU: 0, epoch: 24, iters: 56704, time: 0.006) nll: 0.897976 \n",
      "(GPU: 0, epoch: 24, iters: 57504, time: 0.006) nll: 0.676686 \n",
      "(GPU: 0, epoch: 24, iters: 58304, time: 0.006) nll: 0.667615 \n",
      "(GPU: 0, epoch: 24, iters: 59104, time: 0.005) nll: 0.719414 \n",
      "(GPU: 0, epoch: 24, iters: 59904, time: 0.006) nll: 0.769413 \n",
      "(GPU: 0, epoch: 24, iters: 60704, time: 0.005) nll: 0.788870 \n",
      "(GPU: 0, epoch: 24, iters: 61504, time: 0.006) nll: 0.678778 \n",
      "(GPU: 0, epoch: 24, iters: 62304, time: 0.006) nll: 0.653814 \n",
      "(GPU: 0, epoch: 24, iters: 63104, time: 0.006) nll: 0.698780 \n",
      "saving the latest model (epoch 24, total_steps 3440000)\n",
      "(GPU: 0, epoch: 24, iters: 63904, time: 0.005) nll: 0.548549 \n",
      "(GPU: 0, epoch: 24, iters: 64704, time: 0.006) nll: 0.842239 \n",
      "(GPU: 0, epoch: 24, iters: 65504, time: 0.005) nll: 0.747773 \n",
      "(GPU: 0, epoch: 24, iters: 66304, time: 0.006) nll: 0.717749 \n",
      "(GPU: 0, epoch: 24, iters: 67104, time: 0.005) nll: 0.723118 \n",
      "(GPU: 0, epoch: 24, iters: 67904, time: 0.006) nll: 0.517455 \n",
      "(GPU: 0, epoch: 24, iters: 68704, time: 0.005) nll: 0.441546 \n",
      "(GPU: 0, epoch: 24, iters: 69504, time: 0.006) nll: 0.702293 \n",
      "(GPU: 0, epoch: 24, iters: 70304, time: 0.005) nll: 0.508145 \n",
      "(GPU: 0, epoch: 24, iters: 71104, time: 0.006) nll: 0.769577 \n",
      "(GPU: 0, epoch: 24, iters: 71904, time: 0.005) nll: 0.872151 \n",
      "(GPU: 0, epoch: 24, iters: 72704, time: 0.006) nll: 0.875117 \n",
      "(GPU: 0, epoch: 24, iters: 73504, time: 0.005) nll: 0.698183 \n",
      "(GPU: 0, epoch: 24, iters: 74304, time: 0.006) nll: 0.758559 \n",
      "(GPU: 0, epoch: 24, iters: 75104, time: 0.005) nll: 0.627259 \n",
      "(GPU: 0, epoch: 24, iters: 75904, time: 0.006) nll: 0.604714 \n",
      "(GPU: 0, epoch: 24, iters: 76704, time: 0.005) nll: 0.732253 \n",
      "(GPU: 0, epoch: 24, iters: 77504, time: 0.006) nll: 0.783241 \n",
      "(GPU: 0, epoch: 24, iters: 78304, time: 0.005) nll: 0.602802 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.006) nll: 0.714281 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.009) nll: 0.709209 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.009) nll: 0.788997 \n",
      "(GPU: 0, epoch: 24, iters: 79904, time: 0.005) nll: 0.710376 \n",
      "(GPU: 0, epoch: 24, iters: 80704, time: 0.006) nll: 0.650300 \n",
      "(GPU: 0, epoch: 24, iters: 81504, time: 0.006) nll: 0.815784 \n",
      "(GPU: 0, epoch: 24, iters: 82304, time: 0.006) nll: 0.822582 \n",
      "(GPU: 0, epoch: 24, iters: 83104, time: 0.005) nll: 0.595942 \n",
      "saving the latest model (epoch 24, total_steps 3460000)\n",
      "(GPU: 0, epoch: 24, iters: 83904, time: 0.006) nll: 0.814990 \n",
      "(GPU: 0, epoch: 24, iters: 84704, time: 0.005) nll: 0.597581 \n",
      "(GPU: 0, epoch: 24, iters: 85504, time: 0.006) nll: 0.778732 \n",
      "(GPU: 0, epoch: 24, iters: 86304, time: 0.005) nll: 0.857308 \n",
      "(GPU: 0, epoch: 24, iters: 87104, time: 0.006) nll: 0.626757 \n",
      "(GPU: 0, epoch: 24, iters: 87904, time: 0.006) nll: 0.953528 \n",
      "(GPU: 0, epoch: 24, iters: 88704, time: 0.006) nll: 1.084928 \n",
      "(GPU: 0, epoch: 24, iters: 89504, time: 0.005) nll: 0.360181 \n",
      "(GPU: 0, epoch: 24, iters: 90304, time: 0.006) nll: 0.800727 \n",
      "(GPU: 0, epoch: 24, iters: 91104, time: 0.005) nll: 0.479208 \n",
      "(GPU: 0, epoch: 24, iters: 91904, time: 0.006) nll: 0.754773 \n",
      "(GPU: 0, epoch: 24, iters: 92704, time: 0.005) nll: 0.796259 \n",
      "(GPU: 0, epoch: 24, iters: 93504, time: 0.006) nll: 0.701752 \n",
      "(GPU: 0, epoch: 24, iters: 94304, time: 0.005) nll: 0.768282 \n",
      "(GPU: 0, epoch: 24, iters: 95104, time: 0.006) nll: 0.662232 \n",
      "(GPU: 0, epoch: 24, iters: 95904, time: 0.005) nll: 0.938780 \n",
      "(GPU: 0, epoch: 24, iters: 96704, time: 0.006) nll: 0.773062 \n",
      "(GPU: 0, epoch: 24, iters: 97504, time: 0.006) nll: 0.600606 \n",
      "(GPU: 0, epoch: 24, iters: 98304, time: 0.006) nll: 0.713579 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:52<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 24, iters: 99104, time: 0.005) nll: 0.632760 \n",
      "(GPU: 0, epoch: 24, iters: 99904, time: 0.006) nll: 0.813894 \n",
      "(GPU: 0, epoch: 24, iters: 100704, time: 0.005) nll: 0.787334 \n",
      "(GPU: 0, epoch: 24, iters: 101504, time: 0.006) nll: 0.640497 \n",
      "(GPU: 0, epoch: 24, iters: 102304, time: 0.005) nll: 0.794609 \n",
      "(GPU: 0, epoch: 24, iters: 103104, time: 0.006) nll: 0.697490 \n",
      "saving the latest model (epoch 24, total_steps 3480000)\n",
      "(GPU: 0, epoch: 24, iters: 103904, time: 0.005) nll: 0.801019 \n",
      "(GPU: 0, epoch: 24, iters: 104704, time: 0.006) nll: 0.753589 \n",
      "(GPU: 0, epoch: 24, iters: 105504, time: 0.005) nll: 0.668472 \n",
      "(GPU: 0, epoch: 24, iters: 106304, time: 0.006) nll: 0.631875 \n",
      "(GPU: 0, epoch: 24, iters: 107104, time: 0.005) nll: 0.731518 \n",
      "(GPU: 0, epoch: 24, iters: 107904, time: 0.006) nll: 0.793501 \n",
      "(GPU: 0, epoch: 24, iters: 108704, time: 0.005) nll: 0.663747 \n",
      "(GPU: 0, epoch: 24, iters: 109504, time: 0.006) nll: 0.729981 \n",
      "(GPU: 0, epoch: 24, iters: 110304, time: 0.005) nll: 0.538759 \n",
      "(GPU: 0, epoch: 24, iters: 111104, time: 0.006) nll: 0.643498 \n",
      "(GPU: 0, epoch: 24, iters: 111904, time: 0.005) nll: 0.697070 \n",
      "(GPU: 0, epoch: 24, iters: 112704, time: 0.006) nll: 0.571199 \n",
      "(GPU: 0, epoch: 24, iters: 113504, time: 0.005) nll: 0.666679 \n",
      "(GPU: 0, epoch: 24, iters: 114304, time: 0.006) nll: 0.641780 \n",
      "(GPU: 0, epoch: 24, iters: 115104, time: 0.005) nll: 0.822287 \n",
      "(GPU: 0, epoch: 24, iters: 115904, time: 0.006) nll: 0.758044 \n",
      "(GPU: 0, epoch: 24, iters: 116704, time: 0.005) nll: 0.813796 \n",
      "(GPU: 0, epoch: 24, iters: 117504, time: 0.006) nll: 0.535286 \n",
      "(GPU: 0, epoch: 24, iters: 118304, time: 0.005) nll: 0.613944 \n",
      "(GPU: 0, epoch: 24, iters: 119104, time: 0.006) nll: 0.687954 \n",
      "(GPU: 0, epoch: 24, iters: 119904, time: 0.005) nll: 0.836385 \n",
      "(GPU: 0, epoch: 24, iters: 120704, time: 0.006) nll: 0.856519 \n",
      "(GPU: 0, epoch: 24, iters: 121504, time: 0.006) nll: 0.684494 \n",
      "(GPU: 0, epoch: 24, iters: 122304, time: 0.006) nll: 0.730739 \n",
      "(GPU: 0, epoch: 24, iters: 123104, time: 0.005) nll: 0.838318 \n",
      "saving the latest model (epoch 24, total_steps 3500000)\n",
      "(GPU: 0, epoch: 24, iters: 123904, time: 0.006) nll: 0.745713 \n",
      "(GPU: 0, epoch: 24, iters: 124704, time: 0.005) nll: 0.621550 \n",
      "(GPU: 0, epoch: 24, iters: 125504, time: 0.006) nll: 0.954229 \n",
      "(GPU: 0, epoch: 24, iters: 126304, time: 0.005) nll: 0.712750 \n",
      "(GPU: 0, epoch: 24, iters: 127104, time: 0.006) nll: 0.493107 \n",
      "(GPU: 0, epoch: 24, iters: 127904, time: 0.006) nll: 0.554565 \n",
      "(GPU: 0, epoch: 24, iters: 128704, time: 0.006) nll: 0.665310 \n",
      "(GPU: 0, epoch: 24, iters: 129504, time: 0.005) nll: 1.022788 \n",
      "(GPU: 0, epoch: 24, iters: 130304, time: 0.006) nll: 0.664210 \n",
      "(GPU: 0, epoch: 24, iters: 131104, time: 0.006) nll: 0.589452 \n",
      "(GPU: 0, epoch: 24, iters: 131904, time: 0.006) nll: 0.554975 \n",
      "(GPU: 0, epoch: 24, iters: 132704, time: 0.005) nll: 0.805610 \n",
      "(GPU: 0, epoch: 24, iters: 133504, time: 0.006) nll: 0.752345 \n",
      "(GPU: 0, epoch: 24, iters: 134304, time: 0.005) nll: 0.754315 \n",
      "(GPU: 0, epoch: 24, iters: 135104, time: 0.006) nll: 0.606692 \n",
      "(GPU: 0, epoch: 24, iters: 135904, time: 0.005) nll: 0.642433 \n",
      "(GPU: 0, epoch: 24, iters: 136704, time: 0.006) nll: 0.848420 \n",
      "(GPU: 0, epoch: 24, iters: 137504, time: 0.005) nll: 0.588900 \n",
      "(GPU: 0, epoch: 24, iters: 138304, time: 0.006) nll: 0.666901 \n",
      "(GPU: 0, epoch: 24, iters: 139104, time: 0.005) nll: 0.769854 \n",
      "(GPU: 0, epoch: 24, iters: 139904, time: 0.006) nll: 0.685838 \n",
      "(GPU: 0, epoch: 24, iters: 140704, time: 0.005) nll: 0.730169 \n",
      "saving the model at the end of epoch 24, iters 3517600\n",
      "([test] GPU: 0, epoch: 24) \n",
      "OrderedDict()\n",
      "[*] End of epoch 24 / 25 \t Time Taken: 837 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert-concat-cross-entropy\n",
      "[*] learning rate = 0.0000632\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_rand_tf_snet_code.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf46647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
