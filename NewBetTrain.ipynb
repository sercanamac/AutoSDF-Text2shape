{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ddad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ./launchers/train_new_bert.sh: Permission denied\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_new_bert.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9b0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autosdf.yaml\t\t      filelists\t\t      README.md\r\n",
      "Compare.ipynb\t\t      info-shapenet.json      results\r\n",
      "configs\t\t\t      launchers\t\t      shape_set_paths.json\r\n",
      "datasets\t\t      logs\t\t      Test-Reproduce.ipynb\r\n",
      "demo_data\t\t      logs2\t\t      test_samples_paper.txt\r\n",
      "demo-lang-conditional.ipynb   models\t\t      text2ShapePP.json\r\n",
      "demo_shape_comp.ipynb\t      New-Bert-Sandbox.ipynb  train.py\r\n",
      "demo_single_view_recon.ipynb  NewBetTrain.ipynb       utils\r\n",
      "extract_code.py\t\t      options\r\n",
      "file.json\t\t      preprocess\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f6cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 32\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: text2shape-seq\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: ./logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 100000000000\n",
      "model: bert2vqsc_v4\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "ndf: 64\n",
      "nepochs: 20\n",
      "nepochs_decay: 5\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: Text2Shape\n",
      "[*] # training images = 140707\n",
      "[*] # testing images = 16000\n",
      "---------- Networks initialized -------------\n",
      "-----------------------------------------------\n",
      "[*] Model has been created: BERT2VQSC-Model\n",
      "[*] \"bert2vqsc_v4\" initialized.\n",
      "[*] create image directory:\n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert/images...\n",
      "[*] saving model and dataset files: /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py, /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/datasets/text2shape.py\n",
      "140707 Length train dataset\n",
      "16000 Length test dataset\n",
      "4397 Length train_dl\n",
      "500 Length test_dl\n",
      "[*] Start training. name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.013) nll: 6.197304 \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3199/4397 [06:10<02:05,  9.57it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.013) nll: 6.192618 \n",
      "(GPU: 0, epoch: 0, iters: 800, time: 0.003) nll: 4.484746 \n",
      "(GPU: 0, epoch: 0, iters: 1600, time: 0.003) nll: 2.922876 \n",
      "(GPU: 0, epoch: 0, iters: 2400, time: 0.003) nll: 2.105350 \n",
      "(GPU: 0, epoch: 0, iters: 3200, time: 0.003) nll: 1.594635 \n",
      "(GPU: 0, epoch: 0, iters: 4000, time: 0.003) nll: 1.427794 \n",
      "(GPU: 0, epoch: 0, iters: 4800, time: 0.003) nll: 1.249756 \n",
      "(GPU: 0, epoch: 0, iters: 5600, time: 0.003) nll: 1.278447 \n",
      "(GPU: 0, epoch: 0, iters: 6400, time: 0.003) nll: 1.076914 \n",
      "(GPU: 0, epoch: 0, iters: 7200, time: 0.003) nll: 1.236006 \n",
      "(GPU: 0, epoch: 0, iters: 8000, time: 0.003) nll: 1.443759 \n",
      "(GPU: 0, epoch: 0, iters: 8800, time: 0.003) nll: 1.254671 \n",
      "(GPU: 0, epoch: 0, iters: 9600, time: 0.003) nll: 1.169444 \n",
      "(GPU: 0, epoch: 0, iters: 10400, time: 0.003) nll: 1.181535 \n",
      "(GPU: 0, epoch: 0, iters: 11200, time: 0.003) nll: 1.089167 \n",
      "(GPU: 0, epoch: 0, iters: 12000, time: 0.003) nll: 1.097767 \n",
      "(GPU: 0, epoch: 0, iters: 12800, time: 0.003) nll: 1.151091 \n",
      "(GPU: 0, epoch: 0, iters: 13600, time: 0.003) nll: 1.027288 \n",
      "(GPU: 0, epoch: 0, iters: 14400, time: 0.003) nll: 1.134346 \n",
      "(GPU: 0, epoch: 0, iters: 15200, time: 0.003) nll: 1.292534 \n",
      "(GPU: 0, epoch: 0, iters: 16000, time: 0.003) nll: 1.355514 \n",
      "(GPU: 0, epoch: 0, iters: 16800, time: 0.003) nll: 1.193142 \n",
      "(GPU: 0, epoch: 0, iters: 17600, time: 0.003) nll: 1.128079 \n",
      "(GPU: 0, epoch: 0, iters: 18400, time: 0.003) nll: 1.119886 \n",
      "(GPU: 0, epoch: 0, iters: 19200, time: 0.003) nll: 0.990524 \n",
      "(GPU: 0, epoch: 0, iters: 20000, time: 0.003) nll: 1.177026 \n",
      "saving the latest model (epoch 0, total_steps 20000)\n",
      "(GPU: 0, epoch: 0, iters: 20800, time: 0.003) nll: 1.019749 \n",
      "(GPU: 0, epoch: 0, iters: 21600, time: 0.003) nll: 1.010064 \n",
      "(GPU: 0, epoch: 0, iters: 22400, time: 0.003) nll: 1.060305 \n",
      "(GPU: 0, epoch: 0, iters: 23200, time: 0.003) nll: 1.035172 \n",
      "(GPU: 0, epoch: 0, iters: 24000, time: 0.003) nll: 0.917360 \n",
      "(GPU: 0, epoch: 0, iters: 24800, time: 0.003) nll: 0.977323 \n",
      "(GPU: 0, epoch: 0, iters: 25600, time: 0.003) nll: 1.145302 \n",
      "(GPU: 0, epoch: 0, iters: 26400, time: 0.003) nll: 0.873323 \n",
      "(GPU: 0, epoch: 0, iters: 27200, time: 0.003) nll: 0.995048 \n",
      "(GPU: 0, epoch: 0, iters: 28000, time: 0.003) nll: 1.172407 \n",
      "(GPU: 0, epoch: 0, iters: 28800, time: 0.003) nll: 1.008996 \n",
      "(GPU: 0, epoch: 0, iters: 29600, time: 0.003) nll: 1.212114 \n",
      "(GPU: 0, epoch: 0, iters: 30400, time: 0.003) nll: 1.027342 \n",
      "(GPU: 0, epoch: 0, iters: 31200, time: 0.003) nll: 1.055711 \n",
      "(GPU: 0, epoch: 0, iters: 32000, time: 0.003) nll: 0.913875 \n",
      "(GPU: 0, epoch: 0, iters: 32800, time: 0.003) nll: 0.867838 \n",
      "(GPU: 0, epoch: 0, iters: 33600, time: 0.003) nll: 1.012258 \n",
      "(GPU: 0, epoch: 0, iters: 34400, time: 0.003) nll: 1.076438 \n",
      "(GPU: 0, epoch: 0, iters: 35200, time: 0.003) nll: 1.093900 \n",
      "(GPU: 0, epoch: 0, iters: 36000, time: 0.003) nll: 0.935365 \n",
      "(GPU: 0, epoch: 0, iters: 36800, time: 0.003) nll: 0.872672 \n",
      "(GPU: 0, epoch: 0, iters: 37600, time: 0.003) nll: 1.049298 \n",
      "(GPU: 0, epoch: 0, iters: 38400, time: 0.003) nll: 0.958103 \n",
      "(GPU: 0, epoch: 0, iters: 39200, time: 0.003) nll: 0.934550 \n",
      "(GPU: 0, epoch: 0, iters: 40000, time: 0.003) nll: 0.899880 \n",
      "saving the latest model (epoch 0, total_steps 40000)\n",
      "(GPU: 0, epoch: 0, iters: 40800, time: 0.003) nll: 0.894805 \n",
      "(GPU: 0, epoch: 0, iters: 41600, time: 0.003) nll: 0.928805 \n",
      "(GPU: 0, epoch: 0, iters: 42400, time: 0.003) nll: 0.948510 \n",
      "(GPU: 0, epoch: 0, iters: 43200, time: 0.003) nll: 1.017230 \n",
      "(GPU: 0, epoch: 0, iters: 44000, time: 0.003) nll: 1.041762 \n",
      "(GPU: 0, epoch: 0, iters: 44800, time: 0.003) nll: 1.346196 \n",
      "(GPU: 0, epoch: 0, iters: 45600, time: 0.003) nll: 1.492079 \n",
      "(GPU: 0, epoch: 0, iters: 46400, time: 0.003) nll: 1.147355 \n",
      "(GPU: 0, epoch: 0, iters: 47200, time: 0.003) nll: 0.903700 \n",
      "(GPU: 0, epoch: 0, iters: 48000, time: 0.003) nll: 0.940366 \n",
      "(GPU: 0, epoch: 0, iters: 48800, time: 0.003) nll: 0.982857 \n",
      "(GPU: 0, epoch: 0, iters: 49600, time: 0.003) nll: 0.952314 \n",
      "(GPU: 0, epoch: 0, iters: 50400, time: 0.003) nll: 0.853504 \n",
      "(GPU: 0, epoch: 0, iters: 51200, time: 0.003) nll: 1.075976 \n",
      "(GPU: 0, epoch: 0, iters: 52000, time: 0.003) nll: 0.792471 \n",
      "(GPU: 0, epoch: 0, iters: 52800, time: 0.003) nll: 0.967118 \n",
      "(GPU: 0, epoch: 0, iters: 53600, time: 0.003) nll: 0.947367 \n",
      "(GPU: 0, epoch: 0, iters: 54400, time: 0.003) nll: 1.002826 \n",
      "(GPU: 0, epoch: 0, iters: 55200, time: 0.003) nll: 0.962317 \n",
      "(GPU: 0, epoch: 0, iters: 56000, time: 0.003) nll: 0.878868 \n",
      "(GPU: 0, epoch: 0, iters: 56800, time: 0.003) nll: 0.920478 \n",
      "(GPU: 0, epoch: 0, iters: 57600, time: 0.003) nll: 1.070568 \n",
      "(GPU: 0, epoch: 0, iters: 58400, time: 0.003) nll: 1.004321 \n",
      "(GPU: 0, epoch: 0, iters: 59200, time: 0.003) nll: 0.923106 \n",
      "(GPU: 0, epoch: 0, iters: 60000, time: 0.003) nll: 0.958873 \n",
      "saving the latest model (epoch 0, total_steps 60000)\n",
      "(GPU: 0, epoch: 0, iters: 60800, time: 0.003) nll: 0.852020 \n",
      "(GPU: 0, epoch: 0, iters: 61600, time: 0.003) nll: 1.049261 \n",
      "(GPU: 0, epoch: 0, iters: 62400, time: 0.003) nll: 0.842060 \n",
      "(GPU: 0, epoch: 0, iters: 63200, time: 0.003) nll: 1.019082 \n",
      "(GPU: 0, epoch: 0, iters: 64000, time: 0.003) nll: 1.106026 \n",
      "(GPU: 0, epoch: 0, iters: 64800, time: 0.003) nll: 0.879743 \n",
      "(GPU: 0, epoch: 0, iters: 65600, time: 0.003) nll: 1.102120 \n",
      "(GPU: 0, epoch: 0, iters: 66400, time: 0.003) nll: 0.983633 \n",
      "(GPU: 0, epoch: 0, iters: 67200, time: 0.003) nll: 0.944631 \n",
      "(GPU: 0, epoch: 0, iters: 68000, time: 0.003) nll: 0.967272 \n",
      "(GPU: 0, epoch: 0, iters: 68800, time: 0.003) nll: 0.829858 \n",
      "(GPU: 0, epoch: 0, iters: 69600, time: 0.003) nll: 1.195973 \n",
      "(GPU: 0, epoch: 0, iters: 70400, time: 0.003) nll: 0.948654 \n",
      "(GPU: 0, epoch: 0, iters: 71200, time: 0.003) nll: 0.918973 \n",
      "(GPU: 0, epoch: 0, iters: 72000, time: 0.003) nll: 1.053998 \n",
      "(GPU: 0, epoch: 0, iters: 72800, time: 0.003) nll: 0.908832 \n",
      "(GPU: 0, epoch: 0, iters: 73600, time: 0.003) nll: 1.003840 \n",
      "(GPU: 0, epoch: 0, iters: 74400, time: 0.003) nll: 0.797889 \n",
      "(GPU: 0, epoch: 0, iters: 75200, time: 0.003) nll: 0.802550 \n",
      "(GPU: 0, epoch: 0, iters: 76000, time: 0.003) nll: 1.171358 \n",
      "(GPU: 0, epoch: 0, iters: 76800, time: 0.003) nll: 0.961899 \n",
      "(GPU: 0, epoch: 0, iters: 77600, time: 0.003) nll: 0.911420 \n",
      "(GPU: 0, epoch: 0, iters: 78400, time: 0.003) nll: 1.093091 \n",
      "(GPU: 0, epoch: 0, iters: 79200, time: 0.003) nll: 1.010767 \n",
      "(GPU: 0, epoch: 0, iters: 80000, time: 0.003) nll: 0.881413 \n",
      "saving the latest model (epoch 0, total_steps 80000)\n",
      "(GPU: 0, epoch: 0, iters: 80800, time: 0.003) nll: 0.797954 \n",
      "(GPU: 0, epoch: 0, iters: 81600, time: 0.003) nll: 0.967722 \n",
      "(GPU: 0, epoch: 0, iters: 82400, time: 0.003) nll: 0.972075 \n",
      "(GPU: 0, epoch: 0, iters: 83200, time: 0.003) nll: 1.049921 \n",
      "(GPU: 0, epoch: 0, iters: 84000, time: 0.003) nll: 1.314642 \n",
      "(GPU: 0, epoch: 0, iters: 84800, time: 0.003) nll: 1.172688 \n",
      "(GPU: 0, epoch: 0, iters: 85600, time: 0.003) nll: 0.900067 \n",
      "(GPU: 0, epoch: 0, iters: 86400, time: 0.003) nll: 0.982667 \n",
      "(GPU: 0, epoch: 0, iters: 87200, time: 0.003) nll: 0.848366 \n",
      "(GPU: 0, epoch: 0, iters: 88000, time: 0.003) nll: 0.852298 \n",
      "(GPU: 0, epoch: 0, iters: 88800, time: 0.003) nll: 0.894102 \n",
      "(GPU: 0, epoch: 0, iters: 89600, time: 0.003) nll: 1.027297 \n",
      "(GPU: 0, epoch: 0, iters: 90400, time: 0.003) nll: 0.832628 \n",
      "(GPU: 0, epoch: 0, iters: 91200, time: 0.003) nll: 1.118266 \n",
      "(GPU: 0, epoch: 0, iters: 92000, time: 0.003) nll: 1.242756 \n",
      "(GPU: 0, epoch: 0, iters: 92800, time: 0.003) nll: 0.771146 \n",
      "(GPU: 0, epoch: 0, iters: 93600, time: 0.003) nll: 1.050417 \n",
      "(GPU: 0, epoch: 0, iters: 94400, time: 0.003) nll: 0.982408 \n",
      "(GPU: 0, epoch: 0, iters: 95200, time: 0.003) nll: 0.932478 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.003) nll: 0.725361 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.005) nll: 0.710216 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.005) nll: 1.025698 \n",
      "(GPU: 0, epoch: 0, iters: 96800, time: 0.003) nll: 0.882241 \n",
      "(GPU: 0, epoch: 0, iters: 97600, time: 0.003) nll: 1.044138 \n",
      "(GPU: 0, epoch: 0, iters: 98400, time: 0.003) nll: 0.825437 \n",
      "(GPU: 0, epoch: 0, iters: 99200, time: 0.003) nll: 0.854949 \n",
      "(GPU: 0, epoch: 0, iters: 100000, time: 0.003) nll: 0.883305 \n",
      "saving the latest model (epoch 0, total_steps 100000)\n",
      "(GPU: 0, epoch: 0, iters: 100800, time: 0.003) nll: 1.059894 \n",
      "(GPU: 0, epoch: 0, iters: 101600, time: 0.003) nll: 0.695505 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 102400, time: 0.003) nll: 0.918161 \n",
      "(GPU: 0, epoch: 0, iters: 103200, time: 0.003) nll: 1.065499 \n",
      "(GPU: 0, epoch: 0, iters: 104000, time: 0.003) nll: 0.770254 \n",
      "(GPU: 0, epoch: 0, iters: 104800, time: 0.003) nll: 0.963216 \n",
      "(GPU: 0, epoch: 0, iters: 105600, time: 0.003) nll: 1.248263 \n",
      "(GPU: 0, epoch: 0, iters: 106400, time: 0.003) nll: 1.281891 \n",
      "(GPU: 0, epoch: 0, iters: 107200, time: 0.003) nll: 0.742215 \n",
      "(GPU: 0, epoch: 0, iters: 108000, time: 0.003) nll: 1.171782 \n",
      "(GPU: 0, epoch: 0, iters: 108800, time: 0.003) nll: 0.926965 \n",
      "(GPU: 0, epoch: 0, iters: 109600, time: 0.003) nll: 1.131079 \n",
      "(GPU: 0, epoch: 0, iters: 110400, time: 0.003) nll: 0.941555 \n",
      "(GPU: 0, epoch: 0, iters: 111200, time: 0.003) nll: 0.839637 \n",
      "(GPU: 0, epoch: 0, iters: 112000, time: 0.003) nll: 0.895498 \n",
      "(GPU: 0, epoch: 0, iters: 112800, time: 0.003) nll: 0.958390 \n",
      "(GPU: 0, epoch: 0, iters: 113600, time: 0.003) nll: 0.830217 \n",
      "(GPU: 0, epoch: 0, iters: 114400, time: 0.003) nll: 1.109693 \n",
      "(GPU: 0, epoch: 0, iters: 115200, time: 0.003) nll: 1.315063 \n",
      "(GPU: 0, epoch: 0, iters: 116000, time: 0.003) nll: 1.132705 \n",
      "(GPU: 0, epoch: 0, iters: 116800, time: 0.003) nll: 0.961574 \n",
      "(GPU: 0, epoch: 0, iters: 117600, time: 0.003) nll: 1.061064 \n",
      "(GPU: 0, epoch: 0, iters: 118400, time: 0.003) nll: 1.024280 \n",
      "(GPU: 0, epoch: 0, iters: 119200, time: 0.003) nll: 0.956299 \n",
      "(GPU: 0, epoch: 0, iters: 120000, time: 0.003) nll: 1.340401 \n",
      "saving the latest model (epoch 0, total_steps 120000)\n",
      "(GPU: 0, epoch: 0, iters: 120800, time: 0.003) nll: 0.999860 \n",
      "(GPU: 0, epoch: 0, iters: 121600, time: 0.003) nll: 0.998186 \n",
      "(GPU: 0, epoch: 0, iters: 122400, time: 0.003) nll: 0.979695 \n",
      "(GPU: 0, epoch: 0, iters: 123200, time: 0.003) nll: 0.968762 \n",
      "(GPU: 0, epoch: 0, iters: 124000, time: 0.003) nll: 1.255928 \n",
      "(GPU: 0, epoch: 0, iters: 124800, time: 0.003) nll: 0.860040 \n",
      "(GPU: 0, epoch: 0, iters: 125600, time: 0.003) nll: 0.871827 \n",
      "(GPU: 0, epoch: 0, iters: 126400, time: 0.003) nll: 1.118401 \n",
      "(GPU: 0, epoch: 0, iters: 127200, time: 0.003) nll: 0.842219 \n",
      "(GPU: 0, epoch: 0, iters: 128000, time: 0.003) nll: 0.743143 \n",
      "(GPU: 0, epoch: 0, iters: 128800, time: 0.003) nll: 0.929696 \n",
      "(GPU: 0, epoch: 0, iters: 129600, time: 0.003) nll: 0.916067 \n",
      "(GPU: 0, epoch: 0, iters: 130400, time: 0.003) nll: 1.139901 \n",
      "(GPU: 0, epoch: 0, iters: 131200, time: 0.003) nll: 0.970933 \n",
      "(GPU: 0, epoch: 0, iters: 132000, time: 0.003) nll: 0.775682 \n",
      "(GPU: 0, epoch: 0, iters: 132800, time: 0.003) nll: 0.761816 \n",
      "(GPU: 0, epoch: 0, iters: 133600, time: 0.003) nll: 1.068642 \n",
      "(GPU: 0, epoch: 0, iters: 134400, time: 0.003) nll: 0.928124 \n",
      "(GPU: 0, epoch: 0, iters: 135200, time: 0.003) nll: 0.939095 \n",
      "(GPU: 0, epoch: 0, iters: 136000, time: 0.003) nll: 0.791641 \n",
      "(GPU: 0, epoch: 0, iters: 136800, time: 0.003) nll: 0.833909 \n",
      "(GPU: 0, epoch: 0, iters: 137600, time: 0.003) nll: 1.046566 \n",
      "(GPU: 0, epoch: 0, iters: 138400, time: 0.003) nll: 0.859911 \n",
      "(GPU: 0, epoch: 0, iters: 139200, time: 0.003) nll: 0.997682 \n",
      "(GPU: 0, epoch: 0, iters: 140000, time: 0.003) nll: 1.478633 \n",
      "saving the latest model (epoch 0, total_steps 140000)\n",
      "saving the model at the end of epoch 0, iters 140704\n",
      "([test] GPU: 0, epoch: 0) \n",
      "OrderedDict()\n",
      "[*] End of epoch 0 / 25 \t Time Taken: 523 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000100\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3152/4397 [06:04<02:10,  9.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 32, time: 0.002) nll: 0.908842 \n",
      "(GPU: 0, epoch: 1, iters: 32, time: 0.002) nll: 0.983379 \n",
      "(GPU: 0, epoch: 1, iters: 96, time: 0.003) nll: 0.984390 \n",
      "(GPU: 0, epoch: 1, iters: 896, time: 0.003) nll: 0.967643 \n",
      "(GPU: 0, epoch: 1, iters: 1696, time: 0.003) nll: 0.934804 \n",
      "(GPU: 0, epoch: 1, iters: 2496, time: 0.003) nll: 0.875927 \n",
      "(GPU: 0, epoch: 1, iters: 3296, time: 0.003) nll: 0.810842 \n",
      "(GPU: 0, epoch: 1, iters: 4096, time: 0.003) nll: 1.070840 \n",
      "(GPU: 0, epoch: 1, iters: 4896, time: 0.003) nll: 1.093577 \n",
      "(GPU: 0, epoch: 1, iters: 5696, time: 0.003) nll: 0.881346 \n",
      "(GPU: 0, epoch: 1, iters: 6496, time: 0.003) nll: 0.912343 \n",
      "(GPU: 0, epoch: 1, iters: 7296, time: 0.003) nll: 0.993656 \n",
      "(GPU: 0, epoch: 1, iters: 8096, time: 0.003) nll: 0.786638 \n",
      "(GPU: 0, epoch: 1, iters: 8896, time: 0.003) nll: 0.938615 \n",
      "(GPU: 0, epoch: 1, iters: 9696, time: 0.003) nll: 0.854471 \n",
      "(GPU: 0, epoch: 1, iters: 10496, time: 0.003) nll: 0.913480 \n",
      "(GPU: 0, epoch: 1, iters: 11296, time: 0.003) nll: 1.313035 \n",
      "(GPU: 0, epoch: 1, iters: 12096, time: 0.003) nll: 0.919524 \n",
      "(GPU: 0, epoch: 1, iters: 12896, time: 0.003) nll: 0.903585 \n",
      "(GPU: 0, epoch: 1, iters: 13696, time: 0.003) nll: 0.971028 \n",
      "(GPU: 0, epoch: 1, iters: 14496, time: 0.003) nll: 0.779590 \n",
      "(GPU: 0, epoch: 1, iters: 15296, time: 0.003) nll: 0.815210 \n",
      "(GPU: 0, epoch: 1, iters: 16096, time: 0.003) nll: 0.869084 \n",
      "(GPU: 0, epoch: 1, iters: 16896, time: 0.003) nll: 1.534583 \n",
      "(GPU: 0, epoch: 1, iters: 17696, time: 0.003) nll: 0.801239 \n",
      "(GPU: 0, epoch: 1, iters: 18496, time: 0.003) nll: 0.693854 \n",
      "(GPU: 0, epoch: 1, iters: 19296, time: 0.003) nll: 0.907484 \n",
      "saving the latest model (epoch 1, total_steps 160000)\n",
      "(GPU: 0, epoch: 1, iters: 20096, time: 0.003) nll: 0.762606 \n",
      "(GPU: 0, epoch: 1, iters: 20896, time: 0.003) nll: 0.991943 \n",
      "(GPU: 0, epoch: 1, iters: 21696, time: 0.003) nll: 0.830345 \n",
      "(GPU: 0, epoch: 1, iters: 22496, time: 0.003) nll: 0.914007 \n",
      "(GPU: 0, epoch: 1, iters: 23296, time: 0.003) nll: 0.759201 \n",
      "(GPU: 0, epoch: 1, iters: 24096, time: 0.003) nll: 0.713354 \n",
      "(GPU: 0, epoch: 1, iters: 24896, time: 0.003) nll: 0.989721 \n",
      "(GPU: 0, epoch: 1, iters: 25696, time: 0.003) nll: 0.816863 \n",
      "(GPU: 0, epoch: 1, iters: 26496, time: 0.003) nll: 0.841548 \n",
      "(GPU: 0, epoch: 1, iters: 27296, time: 0.003) nll: 0.908569 \n",
      "(GPU: 0, epoch: 1, iters: 28096, time: 0.003) nll: 0.939952 \n",
      "(GPU: 0, epoch: 1, iters: 28896, time: 0.003) nll: 0.766349 \n",
      "(GPU: 0, epoch: 1, iters: 29696, time: 0.003) nll: 0.919790 \n",
      "(GPU: 0, epoch: 1, iters: 30496, time: 0.003) nll: 0.956856 \n",
      "(GPU: 0, epoch: 1, iters: 31296, time: 0.003) nll: 0.839922 \n",
      "(GPU: 0, epoch: 1, iters: 32096, time: 0.003) nll: 1.445140 \n",
      "(GPU: 0, epoch: 1, iters: 32896, time: 0.003) nll: 0.974819 \n",
      "(GPU: 0, epoch: 1, iters: 33696, time: 0.003) nll: 0.849986 \n",
      "(GPU: 0, epoch: 1, iters: 34496, time: 0.003) nll: 1.061362 \n",
      "(GPU: 0, epoch: 1, iters: 35296, time: 0.003) nll: 0.994933 \n",
      "(GPU: 0, epoch: 1, iters: 36096, time: 0.003) nll: 0.696131 \n",
      "(GPU: 0, epoch: 1, iters: 36896, time: 0.003) nll: 0.787893 \n",
      "(GPU: 0, epoch: 1, iters: 37696, time: 0.003) nll: 0.935540 \n",
      "(GPU: 0, epoch: 1, iters: 38496, time: 0.003) nll: 0.982103 \n",
      "(GPU: 0, epoch: 1, iters: 39296, time: 0.003) nll: 1.004823 \n",
      "saving the latest model (epoch 1, total_steps 180000)\n",
      "(GPU: 0, epoch: 1, iters: 40096, time: 0.003) nll: 0.758446 \n",
      "(GPU: 0, epoch: 1, iters: 40896, time: 0.003) nll: 0.747865 \n",
      "(GPU: 0, epoch: 1, iters: 41696, time: 0.003) nll: 1.153899 \n",
      "(GPU: 0, epoch: 1, iters: 42496, time: 0.003) nll: 1.013232 \n",
      "(GPU: 0, epoch: 1, iters: 43296, time: 0.003) nll: 0.922424 \n",
      "(GPU: 0, epoch: 1, iters: 44096, time: 0.003) nll: 1.090823 \n",
      "(GPU: 0, epoch: 1, iters: 44896, time: 0.003) nll: 0.985106 \n",
      "(GPU: 0, epoch: 1, iters: 45696, time: 0.003) nll: 0.805407 \n",
      "(GPU: 0, epoch: 1, iters: 46496, time: 0.003) nll: 0.805841 \n",
      "(GPU: 0, epoch: 1, iters: 47296, time: 0.003) nll: 0.922520 \n",
      "(GPU: 0, epoch: 1, iters: 48096, time: 0.003) nll: 0.817993 \n",
      "(GPU: 0, epoch: 1, iters: 48896, time: 0.003) nll: 1.151106 \n",
      "(GPU: 0, epoch: 1, iters: 49696, time: 0.003) nll: 0.959341 \n",
      "(GPU: 0, epoch: 1, iters: 50496, time: 0.003) nll: 0.745106 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.003) nll: 0.865442 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.005) nll: 0.856014 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.005) nll: 0.806968 \n",
      "(GPU: 0, epoch: 1, iters: 52096, time: 0.003) nll: 1.262228 \n",
      "(GPU: 0, epoch: 1, iters: 52896, time: 0.003) nll: 0.993160 \n",
      "(GPU: 0, epoch: 1, iters: 53696, time: 0.003) nll: 0.899681 \n",
      "(GPU: 0, epoch: 1, iters: 54496, time: 0.003) nll: 0.971401 \n",
      "(GPU: 0, epoch: 1, iters: 55296, time: 0.003) nll: 0.774152 \n",
      "(GPU: 0, epoch: 1, iters: 56096, time: 0.003) nll: 0.861176 \n",
      "(GPU: 0, epoch: 1, iters: 56896, time: 0.003) nll: 0.934036 \n",
      "(GPU: 0, epoch: 1, iters: 57696, time: 0.003) nll: 0.854274 \n",
      "(GPU: 0, epoch: 1, iters: 58496, time: 0.003) nll: 0.877478 \n",
      "(GPU: 0, epoch: 1, iters: 59296, time: 0.003) nll: 1.086345 \n",
      "saving the latest model (epoch 1, total_steps 200000)\n",
      "(GPU: 0, epoch: 1, iters: 60096, time: 0.003) nll: 0.705335 \n",
      "(GPU: 0, epoch: 1, iters: 60896, time: 0.003) nll: 1.298159 \n",
      "(GPU: 0, epoch: 1, iters: 61696, time: 0.003) nll: 0.976471 \n",
      "(GPU: 0, epoch: 1, iters: 62496, time: 0.003) nll: 0.789223 \n",
      "(GPU: 0, epoch: 1, iters: 63296, time: 0.003) nll: 1.069163 \n",
      "(GPU: 0, epoch: 1, iters: 64096, time: 0.003) nll: 1.007933 \n",
      "(GPU: 0, epoch: 1, iters: 64896, time: 0.003) nll: 1.036977 \n",
      "(GPU: 0, epoch: 1, iters: 65696, time: 0.003) nll: 0.788280 \n",
      "(GPU: 0, epoch: 1, iters: 66496, time: 0.003) nll: 1.075876 \n",
      "(GPU: 0, epoch: 1, iters: 67296, time: 0.003) nll: 0.917184 \n",
      "(GPU: 0, epoch: 1, iters: 68096, time: 0.003) nll: 0.814961 \n",
      "(GPU: 0, epoch: 1, iters: 68896, time: 0.003) nll: 0.976044 \n",
      "(GPU: 0, epoch: 1, iters: 69696, time: 0.003) nll: 1.006016 \n",
      "(GPU: 0, epoch: 1, iters: 70496, time: 0.003) nll: 0.835361 \n",
      "(GPU: 0, epoch: 1, iters: 71296, time: 0.003) nll: 1.026004 \n",
      "(GPU: 0, epoch: 1, iters: 72096, time: 0.003) nll: 0.784285 \n",
      "(GPU: 0, epoch: 1, iters: 72896, time: 0.003) nll: 0.938560 \n",
      "(GPU: 0, epoch: 1, iters: 73696, time: 0.003) nll: 0.688112 \n",
      "(GPU: 0, epoch: 1, iters: 74496, time: 0.003) nll: 0.973392 \n",
      "(GPU: 0, epoch: 1, iters: 75296, time: 0.003) nll: 0.838978 \n",
      "(GPU: 0, epoch: 1, iters: 76096, time: 0.003) nll: 0.912020 \n",
      "(GPU: 0, epoch: 1, iters: 76896, time: 0.003) nll: 0.689074 \n",
      "(GPU: 0, epoch: 1, iters: 77696, time: 0.003) nll: 0.881825 \n",
      "(GPU: 0, epoch: 1, iters: 78496, time: 0.003) nll: 0.988992 \n",
      "(GPU: 0, epoch: 1, iters: 79296, time: 0.003) nll: 0.950582 \n",
      "saving the latest model (epoch 1, total_steps 220000)\n",
      "(GPU: 0, epoch: 1, iters: 80096, time: 0.003) nll: 0.746653 \n",
      "(GPU: 0, epoch: 1, iters: 80896, time: 0.003) nll: 1.206552 \n",
      "(GPU: 0, epoch: 1, iters: 81696, time: 0.003) nll: 0.993374 \n",
      "(GPU: 0, epoch: 1, iters: 82496, time: 0.003) nll: 1.002082 \n",
      "(GPU: 0, epoch: 1, iters: 83296, time: 0.003) nll: 0.962420 \n",
      "(GPU: 0, epoch: 1, iters: 84096, time: 0.003) nll: 0.894731 \n",
      "(GPU: 0, epoch: 1, iters: 84896, time: 0.003) nll: 0.822985 \n",
      "(GPU: 0, epoch: 1, iters: 85696, time: 0.003) nll: 0.831292 \n",
      "(GPU: 0, epoch: 1, iters: 86496, time: 0.003) nll: 0.691579 \n",
      "(GPU: 0, epoch: 1, iters: 87296, time: 0.003) nll: 0.773240 \n",
      "(GPU: 0, epoch: 1, iters: 88096, time: 0.003) nll: 1.074297 \n",
      "(GPU: 0, epoch: 1, iters: 88896, time: 0.003) nll: 1.086270 \n",
      "(GPU: 0, epoch: 1, iters: 89696, time: 0.003) nll: 0.883788 \n",
      "(GPU: 0, epoch: 1, iters: 90496, time: 0.003) nll: 1.009990 \n",
      "(GPU: 0, epoch: 1, iters: 91296, time: 0.003) nll: 0.849390 \n",
      "(GPU: 0, epoch: 1, iters: 92096, time: 0.003) nll: 0.765679 \n",
      "(GPU: 0, epoch: 1, iters: 92896, time: 0.003) nll: 1.148780 \n",
      "(GPU: 0, epoch: 1, iters: 93696, time: 0.003) nll: 0.961783 \n",
      "(GPU: 0, epoch: 1, iters: 94496, time: 0.003) nll: 1.112485 \n",
      "(GPU: 0, epoch: 1, iters: 95296, time: 0.003) nll: 0.704769 \n",
      "(GPU: 0, epoch: 1, iters: 96096, time: 0.003) nll: 1.236913 \n",
      "(GPU: 0, epoch: 1, iters: 96896, time: 0.003) nll: 0.956947 \n",
      "(GPU: 0, epoch: 1, iters: 97696, time: 0.003) nll: 1.020038 \n",
      "(GPU: 0, epoch: 1, iters: 98496, time: 0.003) nll: 0.812171 \n",
      "(GPU: 0, epoch: 1, iters: 99296, time: 0.003) nll: 0.661045 \n",
      "saving the latest model (epoch 1, total_steps 240000)\n",
      "(GPU: 0, epoch: 1, iters: 100096, time: 0.003) nll: 1.484892 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 100896, time: 0.003) nll: 0.819457 \n",
      "(GPU: 0, epoch: 1, iters: 101696, time: 0.003) nll: 0.872397 \n",
      "(GPU: 0, epoch: 1, iters: 102496, time: 0.003) nll: 0.730967 \n",
      "(GPU: 0, epoch: 1, iters: 103296, time: 0.003) nll: 0.829992 \n",
      "(GPU: 0, epoch: 1, iters: 104096, time: 0.003) nll: 1.039900 \n",
      "(GPU: 0, epoch: 1, iters: 104896, time: 0.003) nll: 0.985211 \n",
      "(GPU: 0, epoch: 1, iters: 105696, time: 0.003) nll: 0.889369 \n",
      "(GPU: 0, epoch: 1, iters: 106496, time: 0.003) nll: 0.934719 \n",
      "(GPU: 0, epoch: 1, iters: 107296, time: 0.003) nll: 0.997504 \n",
      "(GPU: 0, epoch: 1, iters: 108096, time: 0.003) nll: 1.063014 \n",
      "(GPU: 0, epoch: 1, iters: 108896, time: 0.003) nll: 0.788992 \n",
      "(GPU: 0, epoch: 1, iters: 109696, time: 0.003) nll: 0.739177 \n",
      "(GPU: 0, epoch: 1, iters: 110496, time: 0.003) nll: 1.022586 \n",
      "(GPU: 0, epoch: 1, iters: 111296, time: 0.003) nll: 0.955223 \n",
      "(GPU: 0, epoch: 1, iters: 112096, time: 0.003) nll: 0.988020 \n",
      "(GPU: 0, epoch: 1, iters: 112896, time: 0.003) nll: 1.272373 \n",
      "(GPU: 0, epoch: 1, iters: 113696, time: 0.003) nll: 1.184783 \n",
      "(GPU: 0, epoch: 1, iters: 114496, time: 0.003) nll: 0.719551 \n",
      "(GPU: 0, epoch: 1, iters: 115296, time: 0.003) nll: 0.721455 \n",
      "(GPU: 0, epoch: 1, iters: 116096, time: 0.003) nll: 0.755402 \n",
      "(GPU: 0, epoch: 1, iters: 116896, time: 0.003) nll: 0.985114 \n",
      "(GPU: 0, epoch: 1, iters: 117696, time: 0.003) nll: 0.714735 \n",
      "(GPU: 0, epoch: 1, iters: 118496, time: 0.003) nll: 1.158703 \n",
      "(GPU: 0, epoch: 1, iters: 119296, time: 0.003) nll: 1.074790 \n",
      "saving the latest model (epoch 1, total_steps 260000)\n",
      "(GPU: 0, epoch: 1, iters: 120096, time: 0.003) nll: 1.023661 \n",
      "(GPU: 0, epoch: 1, iters: 120896, time: 0.003) nll: 0.898489 \n",
      "(GPU: 0, epoch: 1, iters: 121696, time: 0.003) nll: 0.785129 \n",
      "(GPU: 0, epoch: 1, iters: 122496, time: 0.003) nll: 1.513509 \n",
      "(GPU: 0, epoch: 1, iters: 123296, time: 0.003) nll: 1.028976 \n",
      "(GPU: 0, epoch: 1, iters: 124096, time: 0.003) nll: 1.059719 \n",
      "(GPU: 0, epoch: 1, iters: 124896, time: 0.003) nll: 0.718991 \n",
      "(GPU: 0, epoch: 1, iters: 125696, time: 0.003) nll: 0.947233 \n",
      "(GPU: 0, epoch: 1, iters: 126496, time: 0.003) nll: 0.685515 \n",
      "(GPU: 0, epoch: 1, iters: 127296, time: 0.003) nll: 0.979346 \n",
      "(GPU: 0, epoch: 1, iters: 128096, time: 0.003) nll: 1.083675 \n",
      "(GPU: 0, epoch: 1, iters: 128896, time: 0.003) nll: 1.634807 \n",
      "(GPU: 0, epoch: 1, iters: 129696, time: 0.003) nll: 1.362397 \n",
      "(GPU: 0, epoch: 1, iters: 130496, time: 0.003) nll: 1.103230 \n",
      "(GPU: 0, epoch: 1, iters: 131296, time: 0.003) nll: 0.874696 \n",
      "(GPU: 0, epoch: 1, iters: 132096, time: 0.003) nll: 0.946107 \n",
      "(GPU: 0, epoch: 1, iters: 132896, time: 0.003) nll: 1.423579 \n",
      "(GPU: 0, epoch: 1, iters: 133696, time: 0.003) nll: 0.928235 \n",
      "(GPU: 0, epoch: 1, iters: 134496, time: 0.003) nll: 0.836975 \n",
      "(GPU: 0, epoch: 1, iters: 135296, time: 0.003) nll: 0.783863 \n",
      "(GPU: 0, epoch: 1, iters: 136096, time: 0.003) nll: 0.962893 \n",
      "(GPU: 0, epoch: 1, iters: 136896, time: 0.003) nll: 0.930254 \n",
      "(GPU: 0, epoch: 1, iters: 137696, time: 0.003) nll: 1.029038 \n",
      "(GPU: 0, epoch: 1, iters: 138496, time: 0.003) nll: 0.723031 \n",
      "(GPU: 0, epoch: 1, iters: 139296, time: 0.003) nll: 0.960295 \n",
      "saving the latest model (epoch 1, total_steps 280000)\n",
      "(GPU: 0, epoch: 1, iters: 140096, time: 0.003) nll: 1.155448 \n",
      "[*] End of epoch 1 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000200\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3155/4397 [06:06<02:10,  9.52it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 32, time: 0.002) nll: 0.994215 \n",
      "(GPU: 0, epoch: 2, iters: 32, time: 0.002) nll: 0.699330 \n",
      "(GPU: 0, epoch: 2, iters: 192, time: 0.003) nll: 0.913931 \n",
      "(GPU: 0, epoch: 2, iters: 992, time: 0.003) nll: 0.875719 \n",
      "(GPU: 0, epoch: 2, iters: 1792, time: 0.003) nll: 0.805397 \n",
      "(GPU: 0, epoch: 2, iters: 2592, time: 0.003) nll: 0.891033 \n",
      "(GPU: 0, epoch: 2, iters: 3392, time: 0.003) nll: 1.085461 \n",
      "(GPU: 0, epoch: 2, iters: 4192, time: 0.003) nll: 0.737924 \n",
      "(GPU: 0, epoch: 2, iters: 4992, time: 0.003) nll: 0.837152 \n",
      "(GPU: 0, epoch: 2, iters: 5792, time: 0.003) nll: 0.784634 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.003) nll: 0.826292 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.005) nll: 0.822726 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.005) nll: 0.695436 \n",
      "(GPU: 0, epoch: 2, iters: 7392, time: 0.003) nll: 0.791281 \n",
      "(GPU: 0, epoch: 2, iters: 8192, time: 0.003) nll: 1.176112 \n",
      "(GPU: 0, epoch: 2, iters: 8992, time: 0.003) nll: 0.872843 \n",
      "(GPU: 0, epoch: 2, iters: 9792, time: 0.003) nll: 1.064499 \n",
      "(GPU: 0, epoch: 2, iters: 10592, time: 0.003) nll: 0.834947 \n",
      "(GPU: 0, epoch: 2, iters: 11392, time: 0.003) nll: 0.873134 \n",
      "(GPU: 0, epoch: 2, iters: 12192, time: 0.003) nll: 0.813198 \n",
      "(GPU: 0, epoch: 2, iters: 12992, time: 0.003) nll: 0.861190 \n",
      "(GPU: 0, epoch: 2, iters: 13792, time: 0.003) nll: 0.908061 \n",
      "(GPU: 0, epoch: 2, iters: 14592, time: 0.003) nll: 0.915284 \n",
      "(GPU: 0, epoch: 2, iters: 15392, time: 0.003) nll: 0.956135 \n",
      "(GPU: 0, epoch: 2, iters: 16192, time: 0.003) nll: 1.377610 \n",
      "(GPU: 0, epoch: 2, iters: 16992, time: 0.003) nll: 0.858449 \n",
      "(GPU: 0, epoch: 2, iters: 17792, time: 0.003) nll: 0.783278 \n",
      "(GPU: 0, epoch: 2, iters: 18592, time: 0.003) nll: 1.085360 \n",
      "saving the latest model (epoch 2, total_steps 300000)\n",
      "(GPU: 0, epoch: 2, iters: 19392, time: 0.003) nll: 0.828742 \n",
      "(GPU: 0, epoch: 2, iters: 20192, time: 0.003) nll: 1.016737 \n",
      "(GPU: 0, epoch: 2, iters: 20992, time: 0.003) nll: 1.227821 \n",
      "(GPU: 0, epoch: 2, iters: 21792, time: 0.003) nll: 0.814564 \n",
      "(GPU: 0, epoch: 2, iters: 22592, time: 0.003) nll: 0.786578 \n",
      "(GPU: 0, epoch: 2, iters: 23392, time: 0.003) nll: 0.867906 \n",
      "(GPU: 0, epoch: 2, iters: 24192, time: 0.003) nll: 0.924035 \n",
      "(GPU: 0, epoch: 2, iters: 24992, time: 0.003) nll: 0.993704 \n",
      "(GPU: 0, epoch: 2, iters: 25792, time: 0.003) nll: 0.896105 \n",
      "(GPU: 0, epoch: 2, iters: 26592, time: 0.003) nll: 0.954344 \n",
      "(GPU: 0, epoch: 2, iters: 27392, time: 0.003) nll: 0.929255 \n",
      "(GPU: 0, epoch: 2, iters: 28192, time: 0.003) nll: 0.678258 \n",
      "(GPU: 0, epoch: 2, iters: 28992, time: 0.003) nll: 0.850640 \n",
      "(GPU: 0, epoch: 2, iters: 29792, time: 0.003) nll: 1.232965 \n",
      "(GPU: 0, epoch: 2, iters: 30592, time: 0.003) nll: 0.747468 \n",
      "(GPU: 0, epoch: 2, iters: 31392, time: 0.003) nll: 1.020331 \n",
      "(GPU: 0, epoch: 2, iters: 32192, time: 0.003) nll: 0.918110 \n",
      "(GPU: 0, epoch: 2, iters: 32992, time: 0.003) nll: 0.948393 \n",
      "(GPU: 0, epoch: 2, iters: 33792, time: 0.003) nll: 0.866767 \n",
      "(GPU: 0, epoch: 2, iters: 34592, time: 0.003) nll: 0.756381 \n",
      "(GPU: 0, epoch: 2, iters: 35392, time: 0.003) nll: 1.051929 \n",
      "(GPU: 0, epoch: 2, iters: 36192, time: 0.003) nll: 0.780333 \n",
      "(GPU: 0, epoch: 2, iters: 36992, time: 0.003) nll: 0.717543 \n",
      "(GPU: 0, epoch: 2, iters: 37792, time: 0.003) nll: 0.810631 \n",
      "(GPU: 0, epoch: 2, iters: 38592, time: 0.003) nll: 0.857312 \n",
      "saving the latest model (epoch 2, total_steps 320000)\n",
      "(GPU: 0, epoch: 2, iters: 39392, time: 0.003) nll: 1.062742 \n",
      "(GPU: 0, epoch: 2, iters: 40192, time: 0.003) nll: 1.004230 \n",
      "(GPU: 0, epoch: 2, iters: 40992, time: 0.003) nll: 0.788173 \n",
      "(GPU: 0, epoch: 2, iters: 41792, time: 0.003) nll: 0.900078 \n",
      "(GPU: 0, epoch: 2, iters: 42592, time: 0.003) nll: 0.865550 \n",
      "(GPU: 0, epoch: 2, iters: 43392, time: 0.003) nll: 0.993223 \n",
      "(GPU: 0, epoch: 2, iters: 44192, time: 0.003) nll: 0.998522 \n",
      "(GPU: 0, epoch: 2, iters: 44992, time: 0.003) nll: 0.871163 \n",
      "(GPU: 0, epoch: 2, iters: 45792, time: 0.003) nll: 1.190906 \n",
      "(GPU: 0, epoch: 2, iters: 46592, time: 0.003) nll: 0.717465 \n",
      "(GPU: 0, epoch: 2, iters: 47392, time: 0.003) nll: 0.773410 \n",
      "(GPU: 0, epoch: 2, iters: 48192, time: 0.003) nll: 0.850533 \n",
      "(GPU: 0, epoch: 2, iters: 48992, time: 0.003) nll: 1.127251 \n",
      "(GPU: 0, epoch: 2, iters: 49792, time: 0.003) nll: 1.102960 \n",
      "(GPU: 0, epoch: 2, iters: 50592, time: 0.003) nll: 1.086829 \n",
      "(GPU: 0, epoch: 2, iters: 51392, time: 0.003) nll: 0.971824 \n",
      "(GPU: 0, epoch: 2, iters: 52192, time: 0.003) nll: 0.963832 \n",
      "(GPU: 0, epoch: 2, iters: 52992, time: 0.003) nll: 0.799029 \n",
      "(GPU: 0, epoch: 2, iters: 53792, time: 0.003) nll: 0.948049 \n",
      "(GPU: 0, epoch: 2, iters: 54592, time: 0.003) nll: 0.839965 \n",
      "(GPU: 0, epoch: 2, iters: 55392, time: 0.003) nll: 0.706713 \n",
      "(GPU: 0, epoch: 2, iters: 56192, time: 0.003) nll: 0.864715 \n",
      "(GPU: 0, epoch: 2, iters: 56992, time: 0.003) nll: 0.893538 \n",
      "(GPU: 0, epoch: 2, iters: 57792, time: 0.003) nll: 0.922036 \n",
      "(GPU: 0, epoch: 2, iters: 58592, time: 0.003) nll: 0.758775 \n",
      "saving the latest model (epoch 2, total_steps 340000)\n",
      "(GPU: 0, epoch: 2, iters: 59392, time: 0.003) nll: 0.761683 \n",
      "(GPU: 0, epoch: 2, iters: 60192, time: 0.003) nll: 0.885083 \n",
      "(GPU: 0, epoch: 2, iters: 60992, time: 0.003) nll: 0.996773 \n",
      "(GPU: 0, epoch: 2, iters: 61792, time: 0.003) nll: 0.736609 \n",
      "(GPU: 0, epoch: 2, iters: 62592, time: 0.003) nll: 1.054273 \n",
      "(GPU: 0, epoch: 2, iters: 63392, time: 0.003) nll: 0.703756 \n",
      "(GPU: 0, epoch: 2, iters: 64192, time: 0.003) nll: 0.782490 \n",
      "(GPU: 0, epoch: 2, iters: 64992, time: 0.003) nll: 0.893943 \n",
      "(GPU: 0, epoch: 2, iters: 65792, time: 0.003) nll: 0.989446 \n",
      "(GPU: 0, epoch: 2, iters: 66592, time: 0.003) nll: 1.341478 \n",
      "(GPU: 0, epoch: 2, iters: 67392, time: 0.003) nll: 0.897433 \n",
      "(GPU: 0, epoch: 2, iters: 68192, time: 0.003) nll: 1.001233 \n",
      "(GPU: 0, epoch: 2, iters: 68992, time: 0.003) nll: 0.819412 \n",
      "(GPU: 0, epoch: 2, iters: 69792, time: 0.003) nll: 0.792529 \n",
      "(GPU: 0, epoch: 2, iters: 70592, time: 0.003) nll: 0.875908 \n",
      "(GPU: 0, epoch: 2, iters: 71392, time: 0.003) nll: 0.898371 \n",
      "(GPU: 0, epoch: 2, iters: 72192, time: 0.003) nll: 0.956450 \n",
      "(GPU: 0, epoch: 2, iters: 72992, time: 0.003) nll: 0.741063 \n",
      "(GPU: 0, epoch: 2, iters: 73792, time: 0.003) nll: 1.023981 \n",
      "(GPU: 0, epoch: 2, iters: 74592, time: 0.003) nll: 0.985810 \n",
      "(GPU: 0, epoch: 2, iters: 75392, time: 0.003) nll: 0.838869 \n",
      "(GPU: 0, epoch: 2, iters: 76192, time: 0.003) nll: 1.223446 \n",
      "(GPU: 0, epoch: 2, iters: 76992, time: 0.003) nll: 0.882037 \n",
      "(GPU: 0, epoch: 2, iters: 77792, time: 0.003) nll: 0.911742 \n",
      "(GPU: 0, epoch: 2, iters: 78592, time: 0.003) nll: 0.736891 \n",
      "saving the latest model (epoch 2, total_steps 360000)\n",
      "(GPU: 0, epoch: 2, iters: 79392, time: 0.003) nll: 0.651940 \n",
      "(GPU: 0, epoch: 2, iters: 80192, time: 0.003) nll: 1.155441 \n",
      "(GPU: 0, epoch: 2, iters: 80992, time: 0.003) nll: 0.837736 \n",
      "(GPU: 0, epoch: 2, iters: 81792, time: 0.003) nll: 0.601296 \n",
      "(GPU: 0, epoch: 2, iters: 82592, time: 0.003) nll: 0.914791 \n",
      "(GPU: 0, epoch: 2, iters: 83392, time: 0.003) nll: 0.705685 \n",
      "(GPU: 0, epoch: 2, iters: 84192, time: 0.003) nll: 0.873967 \n",
      "(GPU: 0, epoch: 2, iters: 84992, time: 0.003) nll: 1.100079 \n",
      "(GPU: 0, epoch: 2, iters: 85792, time: 0.003) nll: 0.913890 \n",
      "(GPU: 0, epoch: 2, iters: 86592, time: 0.003) nll: 0.828859 \n",
      "(GPU: 0, epoch: 2, iters: 87392, time: 0.003) nll: 0.899458 \n",
      "(GPU: 0, epoch: 2, iters: 88192, time: 0.003) nll: 1.157582 \n",
      "(GPU: 0, epoch: 2, iters: 88992, time: 0.003) nll: 0.917046 \n",
      "(GPU: 0, epoch: 2, iters: 89792, time: 0.003) nll: 0.681735 \n",
      "(GPU: 0, epoch: 2, iters: 90592, time: 0.003) nll: 0.858753 \n",
      "(GPU: 0, epoch: 2, iters: 91392, time: 0.003) nll: 0.799281 \n",
      "(GPU: 0, epoch: 2, iters: 92192, time: 0.003) nll: 0.924247 \n",
      "(GPU: 0, epoch: 2, iters: 92992, time: 0.003) nll: 0.545113 \n",
      "(GPU: 0, epoch: 2, iters: 93792, time: 0.003) nll: 0.858004 \n",
      "(GPU: 0, epoch: 2, iters: 94592, time: 0.003) nll: 0.937293 \n",
      "(GPU: 0, epoch: 2, iters: 95392, time: 0.003) nll: 0.796277 \n",
      "(GPU: 0, epoch: 2, iters: 96192, time: 0.003) nll: 0.907961 \n",
      "(GPU: 0, epoch: 2, iters: 96992, time: 0.003) nll: 0.789357 \n",
      "(GPU: 0, epoch: 2, iters: 97792, time: 0.003) nll: 0.753674 \n",
      "(GPU: 0, epoch: 2, iters: 98592, time: 0.003) nll: 0.955053 \n",
      "saving the latest model (epoch 2, total_steps 380000)\n",
      "(GPU: 0, epoch: 2, iters: 99392, time: 0.003) nll: 0.671241 \n",
      "(GPU: 0, epoch: 2, iters: 100192, time: 0.003) nll: 0.776848 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 100992, time: 0.003) nll: 0.871732 \n",
      "(GPU: 0, epoch: 2, iters: 101792, time: 0.003) nll: 1.021769 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.003) nll: 0.906720 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.005) nll: 0.907648 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.005) nll: 0.926452 \n",
      "(GPU: 0, epoch: 2, iters: 103392, time: 0.003) nll: 1.027992 \n",
      "(GPU: 0, epoch: 2, iters: 104192, time: 0.003) nll: 0.833086 \n",
      "(GPU: 0, epoch: 2, iters: 104992, time: 0.003) nll: 0.883318 \n",
      "(GPU: 0, epoch: 2, iters: 105792, time: 0.003) nll: 0.780548 \n",
      "(GPU: 0, epoch: 2, iters: 106592, time: 0.003) nll: 0.864402 \n",
      "(GPU: 0, epoch: 2, iters: 107392, time: 0.003) nll: 0.822900 \n",
      "(GPU: 0, epoch: 2, iters: 108192, time: 0.003) nll: 0.840549 \n",
      "(GPU: 0, epoch: 2, iters: 108992, time: 0.003) nll: 1.046713 \n",
      "(GPU: 0, epoch: 2, iters: 109792, time: 0.003) nll: 0.804873 \n",
      "(GPU: 0, epoch: 2, iters: 110592, time: 0.003) nll: 0.631314 \n",
      "(GPU: 0, epoch: 2, iters: 111392, time: 0.003) nll: 0.717382 \n",
      "(GPU: 0, epoch: 2, iters: 112192, time: 0.003) nll: 0.726280 \n",
      "(GPU: 0, epoch: 2, iters: 112992, time: 0.003) nll: 0.981293 \n",
      "(GPU: 0, epoch: 2, iters: 113792, time: 0.003) nll: 0.990987 \n",
      "(GPU: 0, epoch: 2, iters: 114592, time: 0.003) nll: 0.927978 \n",
      "(GPU: 0, epoch: 2, iters: 115392, time: 0.003) nll: 0.914436 \n",
      "(GPU: 0, epoch: 2, iters: 116192, time: 0.003) nll: 0.975337 \n",
      "(GPU: 0, epoch: 2, iters: 116992, time: 0.003) nll: 1.355030 \n",
      "(GPU: 0, epoch: 2, iters: 117792, time: 0.003) nll: 0.814687 \n",
      "(GPU: 0, epoch: 2, iters: 118592, time: 0.003) nll: 0.787244 \n",
      "saving the latest model (epoch 2, total_steps 400000)\n",
      "(GPU: 0, epoch: 2, iters: 119392, time: 0.003) nll: 0.933760 \n",
      "(GPU: 0, epoch: 2, iters: 120192, time: 0.003) nll: 0.890026 \n",
      "(GPU: 0, epoch: 2, iters: 120992, time: 0.003) nll: 1.074370 \n",
      "(GPU: 0, epoch: 2, iters: 121792, time: 0.003) nll: 0.917870 \n",
      "(GPU: 0, epoch: 2, iters: 122592, time: 0.003) nll: 1.162609 \n",
      "(GPU: 0, epoch: 2, iters: 123392, time: 0.003) nll: 0.923488 \n",
      "(GPU: 0, epoch: 2, iters: 124192, time: 0.003) nll: 0.930533 \n",
      "(GPU: 0, epoch: 2, iters: 124992, time: 0.003) nll: 0.950555 \n",
      "(GPU: 0, epoch: 2, iters: 125792, time: 0.003) nll: 0.833000 \n",
      "(GPU: 0, epoch: 2, iters: 126592, time: 0.003) nll: 0.986790 \n",
      "(GPU: 0, epoch: 2, iters: 127392, time: 0.003) nll: 0.815869 \n",
      "(GPU: 0, epoch: 2, iters: 128192, time: 0.003) nll: 0.796735 \n",
      "(GPU: 0, epoch: 2, iters: 128992, time: 0.003) nll: 0.865556 \n",
      "(GPU: 0, epoch: 2, iters: 129792, time: 0.003) nll: 0.850242 \n",
      "(GPU: 0, epoch: 2, iters: 130592, time: 0.003) nll: 0.918144 \n",
      "(GPU: 0, epoch: 2, iters: 131392, time: 0.003) nll: 0.910368 \n",
      "(GPU: 0, epoch: 2, iters: 132192, time: 0.003) nll: 0.961934 \n",
      "(GPU: 0, epoch: 2, iters: 132992, time: 0.003) nll: 0.838051 \n",
      "(GPU: 0, epoch: 2, iters: 133792, time: 0.003) nll: 0.939233 \n",
      "(GPU: 0, epoch: 2, iters: 134592, time: 0.003) nll: 0.815799 \n",
      "(GPU: 0, epoch: 2, iters: 135392, time: 0.003) nll: 0.923330 \n",
      "(GPU: 0, epoch: 2, iters: 136192, time: 0.003) nll: 0.668150 \n",
      "(GPU: 0, epoch: 2, iters: 136992, time: 0.003) nll: 0.966068 \n",
      "(GPU: 0, epoch: 2, iters: 137792, time: 0.003) nll: 0.770915 \n",
      "(GPU: 0, epoch: 2, iters: 138592, time: 0.003) nll: 0.841787 \n",
      "saving the latest model (epoch 2, total_steps 420000)\n",
      "(GPU: 0, epoch: 2, iters: 139392, time: 0.003) nll: 0.959953 \n",
      "(GPU: 0, epoch: 2, iters: 140192, time: 0.003) nll: 0.763535 \n",
      "[*] End of epoch 2 / 25 \t Time Taken: 511 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000300\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3158/4397 [06:05<02:11,  9.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 32, time: 0.002) nll: 0.851436 \n",
      "(GPU: 0, epoch: 3, iters: 32, time: 0.002) nll: 0.895475 \n",
      "(GPU: 0, epoch: 3, iters: 288, time: 0.003) nll: 0.936407 \n",
      "(GPU: 0, epoch: 3, iters: 1088, time: 0.003) nll: 0.957185 \n",
      "(GPU: 0, epoch: 3, iters: 1888, time: 0.003) nll: 0.960963 \n",
      "(GPU: 0, epoch: 3, iters: 2688, time: 0.003) nll: 0.761003 \n",
      "(GPU: 0, epoch: 3, iters: 3488, time: 0.003) nll: 0.944615 \n",
      "(GPU: 0, epoch: 3, iters: 4288, time: 0.003) nll: 0.933810 \n",
      "(GPU: 0, epoch: 3, iters: 5088, time: 0.003) nll: 0.721976 \n",
      "(GPU: 0, epoch: 3, iters: 5888, time: 0.003) nll: 1.152391 \n",
      "(GPU: 0, epoch: 3, iters: 6688, time: 0.003) nll: 1.032294 \n",
      "(GPU: 0, epoch: 3, iters: 7488, time: 0.003) nll: 1.303758 \n",
      "(GPU: 0, epoch: 3, iters: 8288, time: 0.003) nll: 0.980551 \n",
      "(GPU: 0, epoch: 3, iters: 9088, time: 0.003) nll: 0.865233 \n",
      "(GPU: 0, epoch: 3, iters: 9888, time: 0.003) nll: 0.933948 \n",
      "(GPU: 0, epoch: 3, iters: 10688, time: 0.003) nll: 0.831854 \n",
      "(GPU: 0, epoch: 3, iters: 11488, time: 0.003) nll: 0.842173 \n",
      "(GPU: 0, epoch: 3, iters: 12288, time: 0.003) nll: 1.182753 \n",
      "(GPU: 0, epoch: 3, iters: 13088, time: 0.003) nll: 0.824164 \n",
      "(GPU: 0, epoch: 3, iters: 13888, time: 0.003) nll: 1.073411 \n",
      "(GPU: 0, epoch: 3, iters: 14688, time: 0.003) nll: 1.036122 \n",
      "(GPU: 0, epoch: 3, iters: 15488, time: 0.003) nll: 0.806124 \n",
      "(GPU: 0, epoch: 3, iters: 16288, time: 0.003) nll: 0.907357 \n",
      "(GPU: 0, epoch: 3, iters: 17088, time: 0.003) nll: 0.861566 \n",
      "(GPU: 0, epoch: 3, iters: 17888, time: 0.003) nll: 0.745137 \n",
      "saving the latest model (epoch 3, total_steps 440000)\n",
      "(GPU: 0, epoch: 3, iters: 18688, time: 0.003) nll: 0.786527 \n",
      "(GPU: 0, epoch: 3, iters: 19488, time: 0.003) nll: 0.774275 \n",
      "(GPU: 0, epoch: 3, iters: 20288, time: 0.003) nll: 0.701569 \n",
      "(GPU: 0, epoch: 3, iters: 21088, time: 0.003) nll: 0.847341 \n",
      "(GPU: 0, epoch: 3, iters: 21888, time: 0.003) nll: 0.848666 \n",
      "(GPU: 0, epoch: 3, iters: 22688, time: 0.003) nll: 0.757403 \n",
      "(GPU: 0, epoch: 3, iters: 23488, time: 0.003) nll: 0.713268 \n",
      "(GPU: 0, epoch: 3, iters: 24288, time: 0.003) nll: 1.145219 \n",
      "(GPU: 0, epoch: 3, iters: 25088, time: 0.003) nll: 1.178810 \n",
      "(GPU: 0, epoch: 3, iters: 25888, time: 0.003) nll: 0.824942 \n",
      "(GPU: 0, epoch: 3, iters: 26688, time: 0.003) nll: 0.886841 \n",
      "(GPU: 0, epoch: 3, iters: 27488, time: 0.003) nll: 0.761803 \n",
      "(GPU: 0, epoch: 3, iters: 28288, time: 0.003) nll: 0.856651 \n",
      "(GPU: 0, epoch: 3, iters: 29088, time: 0.003) nll: 0.827290 \n",
      "(GPU: 0, epoch: 3, iters: 29888, time: 0.003) nll: 0.617598 \n",
      "(GPU: 0, epoch: 3, iters: 30688, time: 0.003) nll: 0.778824 \n",
      "(GPU: 0, epoch: 3, iters: 31488, time: 0.003) nll: 0.971231 \n",
      "(GPU: 0, epoch: 3, iters: 32288, time: 0.003) nll: 0.656998 \n",
      "(GPU: 0, epoch: 3, iters: 33088, time: 0.003) nll: 0.843846 \n",
      "(GPU: 0, epoch: 3, iters: 33888, time: 0.003) nll: 0.761695 \n",
      "(GPU: 0, epoch: 3, iters: 34688, time: 0.003) nll: 0.826198 \n",
      "(GPU: 0, epoch: 3, iters: 35488, time: 0.003) nll: 0.701826 \n",
      "(GPU: 0, epoch: 3, iters: 36288, time: 0.003) nll: 0.850029 \n",
      "(GPU: 0, epoch: 3, iters: 37088, time: 0.003) nll: 1.179874 \n",
      "(GPU: 0, epoch: 3, iters: 37888, time: 0.003) nll: 1.079790 \n",
      "saving the latest model (epoch 3, total_steps 460000)\n",
      "(GPU: 0, epoch: 3, iters: 38688, time: 0.003) nll: 0.898919 \n",
      "(GPU: 0, epoch: 3, iters: 39488, time: 0.003) nll: 1.025732 \n",
      "(GPU: 0, epoch: 3, iters: 40288, time: 0.003) nll: 1.123388 \n",
      "(GPU: 0, epoch: 3, iters: 41088, time: 0.003) nll: 0.928741 \n",
      "(GPU: 0, epoch: 3, iters: 41888, time: 0.003) nll: 1.099885 \n",
      "(GPU: 0, epoch: 3, iters: 42688, time: 0.003) nll: 0.940177 \n",
      "(GPU: 0, epoch: 3, iters: 43488, time: 0.003) nll: 0.748794 \n",
      "(GPU: 0, epoch: 3, iters: 44288, time: 0.003) nll: 1.367643 \n",
      "(GPU: 0, epoch: 3, iters: 45088, time: 0.003) nll: 0.889141 \n",
      "(GPU: 0, epoch: 3, iters: 45888, time: 0.003) nll: 0.764402 \n",
      "(GPU: 0, epoch: 3, iters: 46688, time: 0.003) nll: 0.717401 \n",
      "(GPU: 0, epoch: 3, iters: 47488, time: 0.003) nll: 0.720234 \n",
      "(GPU: 0, epoch: 3, iters: 48288, time: 0.003) nll: 0.797088 \n",
      "(GPU: 0, epoch: 3, iters: 49088, time: 0.003) nll: 0.754532 \n",
      "(GPU: 0, epoch: 3, iters: 49888, time: 0.003) nll: 0.698974 \n",
      "(GPU: 0, epoch: 3, iters: 50688, time: 0.003) nll: 0.859051 \n",
      "(GPU: 0, epoch: 3, iters: 51488, time: 0.003) nll: 0.919505 \n",
      "(GPU: 0, epoch: 3, iters: 52288, time: 0.003) nll: 0.549227 \n",
      "(GPU: 0, epoch: 3, iters: 53088, time: 0.003) nll: 0.886337 \n",
      "(GPU: 0, epoch: 3, iters: 53888, time: 0.003) nll: 0.934912 \n",
      "(GPU: 0, epoch: 3, iters: 54688, time: 0.003) nll: 0.849039 \n",
      "(GPU: 0, epoch: 3, iters: 55488, time: 0.003) nll: 0.909344 \n",
      "(GPU: 0, epoch: 3, iters: 56288, time: 0.003) nll: 0.539300 \n",
      "(GPU: 0, epoch: 3, iters: 57088, time: 0.003) nll: 0.985798 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.003) nll: 0.874484 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.005) nll: 0.854494 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.005) nll: 0.817374 \n",
      "saving the latest model (epoch 3, total_steps 480000)\n",
      "(GPU: 0, epoch: 3, iters: 58688, time: 0.003) nll: 1.115190 \n",
      "(GPU: 0, epoch: 3, iters: 59488, time: 0.003) nll: 0.953924 \n",
      "(GPU: 0, epoch: 3, iters: 60288, time: 0.003) nll: 0.864214 \n",
      "(GPU: 0, epoch: 3, iters: 61088, time: 0.003) nll: 0.903129 \n",
      "(GPU: 0, epoch: 3, iters: 61888, time: 0.003) nll: 0.958495 \n",
      "(GPU: 0, epoch: 3, iters: 62688, time: 0.003) nll: 0.924075 \n",
      "(GPU: 0, epoch: 3, iters: 63488, time: 0.003) nll: 0.867804 \n",
      "(GPU: 0, epoch: 3, iters: 64288, time: 0.003) nll: 0.930244 \n",
      "(GPU: 0, epoch: 3, iters: 65088, time: 0.003) nll: 0.819313 \n",
      "(GPU: 0, epoch: 3, iters: 65888, time: 0.003) nll: 1.081249 \n",
      "(GPU: 0, epoch: 3, iters: 66688, time: 0.003) nll: 0.884033 \n",
      "(GPU: 0, epoch: 3, iters: 67488, time: 0.003) nll: 0.737365 \n",
      "(GPU: 0, epoch: 3, iters: 68288, time: 0.003) nll: 0.830767 \n",
      "(GPU: 0, epoch: 3, iters: 69088, time: 0.003) nll: 0.523032 \n",
      "(GPU: 0, epoch: 3, iters: 69888, time: 0.003) nll: 0.945154 \n",
      "(GPU: 0, epoch: 3, iters: 70688, time: 0.003) nll: 0.878789 \n",
      "(GPU: 0, epoch: 3, iters: 71488, time: 0.003) nll: 1.192790 \n",
      "(GPU: 0, epoch: 3, iters: 72288, time: 0.003) nll: 0.599769 \n",
      "(GPU: 0, epoch: 3, iters: 73088, time: 0.003) nll: 0.793448 \n",
      "(GPU: 0, epoch: 3, iters: 73888, time: 0.003) nll: 0.766487 \n",
      "(GPU: 0, epoch: 3, iters: 74688, time: 0.003) nll: 0.818599 \n",
      "(GPU: 0, epoch: 3, iters: 75488, time: 0.003) nll: 0.750768 \n",
      "(GPU: 0, epoch: 3, iters: 76288, time: 0.003) nll: 0.998716 \n",
      "(GPU: 0, epoch: 3, iters: 77088, time: 0.003) nll: 0.736029 \n",
      "(GPU: 0, epoch: 3, iters: 77888, time: 0.003) nll: 0.799278 \n",
      "saving the latest model (epoch 3, total_steps 500000)\n",
      "(GPU: 0, epoch: 3, iters: 78688, time: 0.003) nll: 1.061181 \n",
      "(GPU: 0, epoch: 3, iters: 79488, time: 0.003) nll: 0.866970 \n",
      "(GPU: 0, epoch: 3, iters: 80288, time: 0.003) nll: 0.684076 \n",
      "(GPU: 0, epoch: 3, iters: 81088, time: 0.003) nll: 0.734775 \n",
      "(GPU: 0, epoch: 3, iters: 81888, time: 0.003) nll: 0.892428 \n",
      "(GPU: 0, epoch: 3, iters: 82688, time: 0.003) nll: 0.787554 \n",
      "(GPU: 0, epoch: 3, iters: 83488, time: 0.003) nll: 0.777311 \n",
      "(GPU: 0, epoch: 3, iters: 84288, time: 0.003) nll: 1.228289 \n",
      "(GPU: 0, epoch: 3, iters: 85088, time: 0.003) nll: 0.770196 \n",
      "(GPU: 0, epoch: 3, iters: 85888, time: 0.003) nll: 0.945615 \n",
      "(GPU: 0, epoch: 3, iters: 86688, time: 0.003) nll: 0.952012 \n",
      "(GPU: 0, epoch: 3, iters: 87488, time: 0.003) nll: 0.743552 \n",
      "(GPU: 0, epoch: 3, iters: 88288, time: 0.003) nll: 0.649773 \n",
      "(GPU: 0, epoch: 3, iters: 89088, time: 0.003) nll: 0.909365 \n",
      "(GPU: 0, epoch: 3, iters: 89888, time: 0.003) nll: 0.850907 \n",
      "(GPU: 0, epoch: 3, iters: 90688, time: 0.003) nll: 1.460604 \n",
      "(GPU: 0, epoch: 3, iters: 91488, time: 0.003) nll: 1.230666 \n",
      "(GPU: 0, epoch: 3, iters: 92288, time: 0.003) nll: 0.933519 \n",
      "(GPU: 0, epoch: 3, iters: 93088, time: 0.003) nll: 0.874443 \n",
      "(GPU: 0, epoch: 3, iters: 93888, time: 0.003) nll: 0.888863 \n",
      "(GPU: 0, epoch: 3, iters: 94688, time: 0.003) nll: 0.851392 \n",
      "(GPU: 0, epoch: 3, iters: 95488, time: 0.003) nll: 1.040830 \n",
      "(GPU: 0, epoch: 3, iters: 96288, time: 0.003) nll: 1.174723 \n",
      "(GPU: 0, epoch: 3, iters: 97088, time: 0.003) nll: 0.984456 \n",
      "(GPU: 0, epoch: 3, iters: 97888, time: 0.003) nll: 0.707828 \n",
      "saving the latest model (epoch 3, total_steps 520000)\n",
      "(GPU: 0, epoch: 3, iters: 98688, time: 0.003) nll: 0.995824 \n",
      "(GPU: 0, epoch: 3, iters: 99488, time: 0.003) nll: 1.009660 \n",
      "(GPU: 0, epoch: 3, iters: 100288, time: 0.003) nll: 0.913626 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 101088, time: 0.003) nll: 1.108787 \n",
      "(GPU: 0, epoch: 3, iters: 101888, time: 0.003) nll: 0.514348 \n",
      "(GPU: 0, epoch: 3, iters: 102688, time: 0.003) nll: 1.384587 \n",
      "(GPU: 0, epoch: 3, iters: 103488, time: 0.003) nll: 0.867827 \n",
      "(GPU: 0, epoch: 3, iters: 104288, time: 0.003) nll: 0.894023 \n",
      "(GPU: 0, epoch: 3, iters: 105088, time: 0.003) nll: 0.882192 \n",
      "(GPU: 0, epoch: 3, iters: 105888, time: 0.003) nll: 1.134511 \n",
      "(GPU: 0, epoch: 3, iters: 106688, time: 0.003) nll: 0.797792 \n",
      "(GPU: 0, epoch: 3, iters: 107488, time: 0.003) nll: 0.856871 \n",
      "(GPU: 0, epoch: 3, iters: 108288, time: 0.003) nll: 0.819122 \n",
      "(GPU: 0, epoch: 3, iters: 109088, time: 0.003) nll: 1.090133 \n",
      "(GPU: 0, epoch: 3, iters: 109888, time: 0.003) nll: 0.721512 \n",
      "(GPU: 0, epoch: 3, iters: 110688, time: 0.003) nll: 1.161422 \n",
      "(GPU: 0, epoch: 3, iters: 111488, time: 0.003) nll: 0.930230 \n",
      "(GPU: 0, epoch: 3, iters: 112288, time: 0.003) nll: 0.849083 \n",
      "(GPU: 0, epoch: 3, iters: 113088, time: 0.003) nll: 0.792984 \n",
      "(GPU: 0, epoch: 3, iters: 113888, time: 0.003) nll: 0.839825 \n",
      "(GPU: 0, epoch: 3, iters: 114688, time: 0.003) nll: 0.977603 \n",
      "(GPU: 0, epoch: 3, iters: 115488, time: 0.003) nll: 0.898308 \n",
      "(GPU: 0, epoch: 3, iters: 116288, time: 0.003) nll: 0.736585 \n",
      "(GPU: 0, epoch: 3, iters: 117088, time: 0.003) nll: 0.811164 \n",
      "(GPU: 0, epoch: 3, iters: 117888, time: 0.003) nll: 1.213326 \n",
      "saving the latest model (epoch 3, total_steps 540000)\n",
      "(GPU: 0, epoch: 3, iters: 118688, time: 0.003) nll: 0.860470 \n",
      "(GPU: 0, epoch: 3, iters: 119488, time: 0.003) nll: 1.445416 \n",
      "(GPU: 0, epoch: 3, iters: 120288, time: 0.003) nll: 0.691013 \n",
      "(GPU: 0, epoch: 3, iters: 121088, time: 0.003) nll: 0.878174 \n",
      "(GPU: 0, epoch: 3, iters: 121888, time: 0.003) nll: 0.965064 \n",
      "(GPU: 0, epoch: 3, iters: 122688, time: 0.003) nll: 1.060891 \n",
      "(GPU: 0, epoch: 3, iters: 123488, time: 0.003) nll: 0.799911 \n",
      "(GPU: 0, epoch: 3, iters: 124288, time: 0.003) nll: 0.968443 \n",
      "(GPU: 0, epoch: 3, iters: 125088, time: 0.003) nll: 1.422904 \n",
      "(GPU: 0, epoch: 3, iters: 125888, time: 0.003) nll: 0.838058 \n",
      "(GPU: 0, epoch: 3, iters: 126688, time: 0.003) nll: 1.026650 \n",
      "(GPU: 0, epoch: 3, iters: 127488, time: 0.003) nll: 0.894067 \n",
      "(GPU: 0, epoch: 3, iters: 128288, time: 0.003) nll: 0.823660 \n",
      "(GPU: 0, epoch: 3, iters: 129088, time: 0.003) nll: 1.258129 \n",
      "(GPU: 0, epoch: 3, iters: 129888, time: 0.003) nll: 0.636608 \n",
      "(GPU: 0, epoch: 3, iters: 130688, time: 0.003) nll: 1.015324 \n",
      "(GPU: 0, epoch: 3, iters: 131488, time: 0.003) nll: 0.891363 \n",
      "(GPU: 0, epoch: 3, iters: 132288, time: 0.003) nll: 0.984339 \n",
      "(GPU: 0, epoch: 3, iters: 133088, time: 0.003) nll: 0.961609 \n",
      "(GPU: 0, epoch: 3, iters: 133888, time: 0.003) nll: 0.833986 \n",
      "(GPU: 0, epoch: 3, iters: 134688, time: 0.003) nll: 1.099383 \n",
      "(GPU: 0, epoch: 3, iters: 135488, time: 0.003) nll: 0.851002 \n",
      "(GPU: 0, epoch: 3, iters: 136288, time: 0.003) nll: 0.780911 \n",
      "(GPU: 0, epoch: 3, iters: 137088, time: 0.003) nll: 0.817315 \n",
      "(GPU: 0, epoch: 3, iters: 137888, time: 0.003) nll: 0.854167 \n",
      "saving the latest model (epoch 3, total_steps 560000)\n",
      "(GPU: 0, epoch: 3, iters: 138688, time: 0.003) nll: 1.027198 \n",
      "(GPU: 0, epoch: 3, iters: 139488, time: 0.003) nll: 0.800429 \n",
      "(GPU: 0, epoch: 3, iters: 140288, time: 0.003) nll: 1.045506 \n",
      "saving the model at the end of epoch 3, iters 562816\n",
      "([test] GPU: 0, epoch: 3) \n",
      "OrderedDict()\n",
      "[*] End of epoch 3 / 25 \t Time Taken: 523 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000400\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3161/4397 [06:09<02:10,  9.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 32, time: 0.002) nll: 0.821753 \n",
      "(GPU: 0, epoch: 4, iters: 32, time: 0.002) nll: 0.983299 \n",
      "(GPU: 0, epoch: 4, iters: 384, time: 0.003) nll: 0.701554 \n",
      "(GPU: 0, epoch: 4, iters: 1184, time: 0.003) nll: 0.700069 \n",
      "(GPU: 0, epoch: 4, iters: 1984, time: 0.003) nll: 0.828333 \n",
      "(GPU: 0, epoch: 4, iters: 2784, time: 0.003) nll: 0.966506 \n",
      "(GPU: 0, epoch: 4, iters: 3584, time: 0.003) nll: 0.825833 \n",
      "(GPU: 0, epoch: 4, iters: 4384, time: 0.003) nll: 0.840189 \n",
      "(GPU: 0, epoch: 4, iters: 5184, time: 0.003) nll: 1.009315 \n",
      "(GPU: 0, epoch: 4, iters: 5984, time: 0.003) nll: 0.886553 \n",
      "(GPU: 0, epoch: 4, iters: 6784, time: 0.003) nll: 0.918867 \n",
      "(GPU: 0, epoch: 4, iters: 7584, time: 0.003) nll: 1.000763 \n",
      "(GPU: 0, epoch: 4, iters: 8384, time: 0.003) nll: 1.122841 \n",
      "(GPU: 0, epoch: 4, iters: 9184, time: 0.003) nll: 0.976595 \n",
      "(GPU: 0, epoch: 4, iters: 9984, time: 0.003) nll: 0.781421 \n",
      "(GPU: 0, epoch: 4, iters: 10784, time: 0.003) nll: 0.744251 \n",
      "(GPU: 0, epoch: 4, iters: 11584, time: 0.003) nll: 1.218330 \n",
      "(GPU: 0, epoch: 4, iters: 12384, time: 0.003) nll: 0.609039 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.003) nll: 0.893371 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.005) nll: 0.890763 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.005) nll: 0.733465 \n",
      "(GPU: 0, epoch: 4, iters: 13984, time: 0.003) nll: 0.847245 \n",
      "(GPU: 0, epoch: 4, iters: 14784, time: 0.003) nll: 0.820980 \n",
      "(GPU: 0, epoch: 4, iters: 15584, time: 0.003) nll: 0.832723 \n",
      "(GPU: 0, epoch: 4, iters: 16384, time: 0.003) nll: 1.131863 \n",
      "(GPU: 0, epoch: 4, iters: 17184, time: 0.003) nll: 0.924949 \n",
      "saving the latest model (epoch 4, total_steps 580000)\n",
      "(GPU: 0, epoch: 4, iters: 17984, time: 0.003) nll: 0.949516 \n",
      "(GPU: 0, epoch: 4, iters: 18784, time: 0.003) nll: 0.848558 \n",
      "(GPU: 0, epoch: 4, iters: 19584, time: 0.003) nll: 0.831088 \n",
      "(GPU: 0, epoch: 4, iters: 20384, time: 0.003) nll: 0.768132 \n",
      "(GPU: 0, epoch: 4, iters: 21184, time: 0.003) nll: 0.893495 \n",
      "(GPU: 0, epoch: 4, iters: 21984, time: 0.003) nll: 0.842217 \n",
      "(GPU: 0, epoch: 4, iters: 22784, time: 0.003) nll: 1.069052 \n",
      "(GPU: 0, epoch: 4, iters: 23584, time: 0.003) nll: 0.988557 \n",
      "(GPU: 0, epoch: 4, iters: 24384, time: 0.003) nll: 0.916000 \n",
      "(GPU: 0, epoch: 4, iters: 25184, time: 0.003) nll: 0.869944 \n",
      "(GPU: 0, epoch: 4, iters: 25984, time: 0.003) nll: 0.684692 \n",
      "(GPU: 0, epoch: 4, iters: 26784, time: 0.003) nll: 0.801247 \n",
      "(GPU: 0, epoch: 4, iters: 27584, time: 0.003) nll: 0.920664 \n",
      "(GPU: 0, epoch: 4, iters: 28384, time: 0.003) nll: 0.806468 \n",
      "(GPU: 0, epoch: 4, iters: 29184, time: 0.003) nll: 0.788867 \n",
      "(GPU: 0, epoch: 4, iters: 29984, time: 0.003) nll: 0.996836 \n",
      "(GPU: 0, epoch: 4, iters: 30784, time: 0.003) nll: 0.912728 \n",
      "(GPU: 0, epoch: 4, iters: 31584, time: 0.003) nll: 0.819082 \n",
      "(GPU: 0, epoch: 4, iters: 32384, time: 0.003) nll: 0.876861 \n",
      "(GPU: 0, epoch: 4, iters: 33184, time: 0.003) nll: 1.001091 \n",
      "(GPU: 0, epoch: 4, iters: 33984, time: 0.003) nll: 0.892125 \n",
      "(GPU: 0, epoch: 4, iters: 34784, time: 0.003) nll: 0.891446 \n",
      "(GPU: 0, epoch: 4, iters: 35584, time: 0.003) nll: 0.784244 \n",
      "(GPU: 0, epoch: 4, iters: 36384, time: 0.003) nll: 0.871398 \n",
      "(GPU: 0, epoch: 4, iters: 37184, time: 0.003) nll: 0.545891 \n",
      "saving the latest model (epoch 4, total_steps 600000)\n",
      "(GPU: 0, epoch: 4, iters: 37984, time: 0.003) nll: 0.928185 \n",
      "(GPU: 0, epoch: 4, iters: 38784, time: 0.003) nll: 0.679305 \n",
      "(GPU: 0, epoch: 4, iters: 39584, time: 0.003) nll: 0.792389 \n",
      "(GPU: 0, epoch: 4, iters: 40384, time: 0.003) nll: 0.926484 \n",
      "(GPU: 0, epoch: 4, iters: 41184, time: 0.003) nll: 0.785256 \n",
      "(GPU: 0, epoch: 4, iters: 41984, time: 0.003) nll: 0.593236 \n",
      "(GPU: 0, epoch: 4, iters: 42784, time: 0.003) nll: 1.139123 \n",
      "(GPU: 0, epoch: 4, iters: 43584, time: 0.003) nll: 1.077595 \n",
      "(GPU: 0, epoch: 4, iters: 44384, time: 0.003) nll: 0.825197 \n",
      "(GPU: 0, epoch: 4, iters: 45184, time: 0.003) nll: 0.779499 \n",
      "(GPU: 0, epoch: 4, iters: 45984, time: 0.003) nll: 0.970282 \n",
      "(GPU: 0, epoch: 4, iters: 46784, time: 0.003) nll: 0.862491 \n",
      "(GPU: 0, epoch: 4, iters: 47584, time: 0.003) nll: 1.054509 \n",
      "(GPU: 0, epoch: 4, iters: 48384, time: 0.003) nll: 0.890661 \n",
      "(GPU: 0, epoch: 4, iters: 49184, time: 0.003) nll: 0.861950 \n",
      "(GPU: 0, epoch: 4, iters: 49984, time: 0.003) nll: 0.611602 \n",
      "(GPU: 0, epoch: 4, iters: 50784, time: 0.003) nll: 0.769219 \n",
      "(GPU: 0, epoch: 4, iters: 51584, time: 0.003) nll: 1.026430 \n",
      "(GPU: 0, epoch: 4, iters: 52384, time: 0.003) nll: 0.758952 \n",
      "(GPU: 0, epoch: 4, iters: 53184, time: 0.003) nll: 0.818342 \n",
      "(GPU: 0, epoch: 4, iters: 53984, time: 0.003) nll: 0.881079 \n",
      "(GPU: 0, epoch: 4, iters: 54784, time: 0.003) nll: 1.043662 \n",
      "(GPU: 0, epoch: 4, iters: 55584, time: 0.003) nll: 0.809884 \n",
      "(GPU: 0, epoch: 4, iters: 56384, time: 0.003) nll: 0.816479 \n",
      "(GPU: 0, epoch: 4, iters: 57184, time: 0.003) nll: 0.794170 \n",
      "saving the latest model (epoch 4, total_steps 620000)\n",
      "(GPU: 0, epoch: 4, iters: 57984, time: 0.003) nll: 0.724551 \n",
      "(GPU: 0, epoch: 4, iters: 58784, time: 0.003) nll: 0.755852 \n",
      "(GPU: 0, epoch: 4, iters: 59584, time: 0.003) nll: 0.924543 \n",
      "(GPU: 0, epoch: 4, iters: 60384, time: 0.003) nll: 1.015544 \n",
      "(GPU: 0, epoch: 4, iters: 61184, time: 0.003) nll: 0.759854 \n",
      "(GPU: 0, epoch: 4, iters: 61984, time: 0.003) nll: 0.797092 \n",
      "(GPU: 0, epoch: 4, iters: 62784, time: 0.003) nll: 1.038040 \n",
      "(GPU: 0, epoch: 4, iters: 63584, time: 0.003) nll: 0.752716 \n",
      "(GPU: 0, epoch: 4, iters: 64384, time: 0.003) nll: 0.799388 \n",
      "(GPU: 0, epoch: 4, iters: 65184, time: 0.003) nll: 0.610490 \n",
      "(GPU: 0, epoch: 4, iters: 65984, time: 0.003) nll: 0.723302 \n",
      "(GPU: 0, epoch: 4, iters: 66784, time: 0.003) nll: 0.989308 \n",
      "(GPU: 0, epoch: 4, iters: 67584, time: 0.003) nll: 0.721541 \n",
      "(GPU: 0, epoch: 4, iters: 68384, time: 0.003) nll: 0.669461 \n",
      "(GPU: 0, epoch: 4, iters: 69184, time: 0.003) nll: 1.006499 \n",
      "(GPU: 0, epoch: 4, iters: 69984, time: 0.003) nll: 0.685239 \n",
      "(GPU: 0, epoch: 4, iters: 70784, time: 0.003) nll: 0.890207 \n",
      "(GPU: 0, epoch: 4, iters: 71584, time: 0.003) nll: 0.737766 \n",
      "(GPU: 0, epoch: 4, iters: 72384, time: 0.003) nll: 0.757730 \n",
      "(GPU: 0, epoch: 4, iters: 73184, time: 0.003) nll: 1.112275 \n",
      "(GPU: 0, epoch: 4, iters: 73984, time: 0.003) nll: 0.728986 \n",
      "(GPU: 0, epoch: 4, iters: 74784, time: 0.003) nll: 0.833717 \n",
      "(GPU: 0, epoch: 4, iters: 75584, time: 0.003) nll: 0.752264 \n",
      "(GPU: 0, epoch: 4, iters: 76384, time: 0.003) nll: 0.951104 \n",
      "(GPU: 0, epoch: 4, iters: 77184, time: 0.003) nll: 0.656407 \n",
      "saving the latest model (epoch 4, total_steps 640000)\n",
      "(GPU: 0, epoch: 4, iters: 77984, time: 0.003) nll: 0.713799 \n",
      "(GPU: 0, epoch: 4, iters: 78784, time: 0.003) nll: 0.889046 \n",
      "(GPU: 0, epoch: 4, iters: 79584, time: 0.003) nll: 0.858852 \n",
      "(GPU: 0, epoch: 4, iters: 80384, time: 0.003) nll: 0.894950 \n",
      "(GPU: 0, epoch: 4, iters: 81184, time: 0.003) nll: 0.752914 \n",
      "(GPU: 0, epoch: 4, iters: 81984, time: 0.003) nll: 0.805063 \n",
      "(GPU: 0, epoch: 4, iters: 82784, time: 0.003) nll: 0.878855 \n",
      "(GPU: 0, epoch: 4, iters: 83584, time: 0.003) nll: 0.737968 \n",
      "(GPU: 0, epoch: 4, iters: 84384, time: 0.003) nll: 0.784354 \n",
      "(GPU: 0, epoch: 4, iters: 85184, time: 0.003) nll: 0.907341 \n",
      "(GPU: 0, epoch: 4, iters: 85984, time: 0.003) nll: 0.659478 \n",
      "(GPU: 0, epoch: 4, iters: 86784, time: 0.003) nll: 0.924515 \n",
      "(GPU: 0, epoch: 4, iters: 87584, time: 0.003) nll: 0.942623 \n",
      "(GPU: 0, epoch: 4, iters: 88384, time: 0.003) nll: 1.001669 \n",
      "(GPU: 0, epoch: 4, iters: 89184, time: 0.003) nll: 1.130288 \n",
      "(GPU: 0, epoch: 4, iters: 89984, time: 0.003) nll: 1.245971 \n",
      "(GPU: 0, epoch: 4, iters: 90784, time: 0.003) nll: 0.912529 \n",
      "(GPU: 0, epoch: 4, iters: 91584, time: 0.003) nll: 0.904770 \n",
      "(GPU: 0, epoch: 4, iters: 92384, time: 0.003) nll: 1.054496 \n",
      "(GPU: 0, epoch: 4, iters: 93184, time: 0.003) nll: 1.140676 \n",
      "(GPU: 0, epoch: 4, iters: 93984, time: 0.003) nll: 0.882667 \n",
      "(GPU: 0, epoch: 4, iters: 94784, time: 0.003) nll: 1.049596 \n",
      "(GPU: 0, epoch: 4, iters: 95584, time: 0.003) nll: 0.941877 \n",
      "(GPU: 0, epoch: 4, iters: 96384, time: 0.003) nll: 0.804427 \n",
      "(GPU: 0, epoch: 4, iters: 97184, time: 0.003) nll: 0.687088 \n",
      "saving the latest model (epoch 4, total_steps 660000)\n",
      "(GPU: 0, epoch: 4, iters: 97984, time: 0.003) nll: 0.794054 \n",
      "(GPU: 0, epoch: 4, iters: 98784, time: 0.003) nll: 0.735342 \n",
      "(GPU: 0, epoch: 4, iters: 99584, time: 0.003) nll: 1.282571 \n",
      "(GPU: 0, epoch: 4, iters: 100384, time: 0.003) nll: 0.943659 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:34<00:00,  8.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 101184, time: 0.003) nll: 0.876938 \n",
      "(GPU: 0, epoch: 4, iters: 101984, time: 0.003) nll: 0.944832 \n",
      "(GPU: 0, epoch: 4, iters: 102784, time: 0.003) nll: 0.966570 \n",
      "(GPU: 0, epoch: 4, iters: 103584, time: 0.003) nll: 0.804179 \n",
      "(GPU: 0, epoch: 4, iters: 104384, time: 0.003) nll: 0.965714 \n",
      "(GPU: 0, epoch: 4, iters: 105184, time: 0.003) nll: 0.985782 \n",
      "(GPU: 0, epoch: 4, iters: 105984, time: 0.003) nll: 1.155694 \n",
      "(GPU: 0, epoch: 4, iters: 106784, time: 0.003) nll: 0.963819 \n",
      "(GPU: 0, epoch: 4, iters: 107584, time: 0.003) nll: 0.792343 \n",
      "(GPU: 0, epoch: 4, iters: 108384, time: 0.003) nll: 1.119161 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.003) nll: 0.924527 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.005) nll: 0.936265 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.005) nll: 0.980385 \n",
      "(GPU: 0, epoch: 4, iters: 109984, time: 0.003) nll: 0.745985 \n",
      "(GPU: 0, epoch: 4, iters: 110784, time: 0.003) nll: 0.622819 \n",
      "(GPU: 0, epoch: 4, iters: 111584, time: 0.003) nll: 0.676250 \n",
      "(GPU: 0, epoch: 4, iters: 112384, time: 0.003) nll: 0.838495 \n",
      "(GPU: 0, epoch: 4, iters: 113184, time: 0.003) nll: 0.727815 \n",
      "(GPU: 0, epoch: 4, iters: 113984, time: 0.003) nll: 0.914231 \n",
      "(GPU: 0, epoch: 4, iters: 114784, time: 0.003) nll: 1.006560 \n",
      "(GPU: 0, epoch: 4, iters: 115584, time: 0.003) nll: 0.711951 \n",
      "(GPU: 0, epoch: 4, iters: 116384, time: 0.003) nll: 0.864125 \n",
      "(GPU: 0, epoch: 4, iters: 117184, time: 0.003) nll: 0.622055 \n",
      "saving the latest model (epoch 4, total_steps 680000)\n",
      "(GPU: 0, epoch: 4, iters: 117984, time: 0.003) nll: 0.741086 \n",
      "(GPU: 0, epoch: 4, iters: 118784, time: 0.003) nll: 0.855844 \n",
      "(GPU: 0, epoch: 4, iters: 119584, time: 0.003) nll: 1.033036 \n",
      "(GPU: 0, epoch: 4, iters: 120384, time: 0.003) nll: 0.891804 \n",
      "(GPU: 0, epoch: 4, iters: 121184, time: 0.003) nll: 0.911062 \n",
      "(GPU: 0, epoch: 4, iters: 121984, time: 0.003) nll: 0.894729 \n",
      "(GPU: 0, epoch: 4, iters: 122784, time: 0.003) nll: 0.694051 \n",
      "(GPU: 0, epoch: 4, iters: 123584, time: 0.003) nll: 0.732433 \n",
      "(GPU: 0, epoch: 4, iters: 124384, time: 0.003) nll: 0.947628 \n",
      "(GPU: 0, epoch: 4, iters: 125184, time: 0.003) nll: 1.269431 \n",
      "(GPU: 0, epoch: 4, iters: 125984, time: 0.003) nll: 0.793611 \n",
      "(GPU: 0, epoch: 4, iters: 126784, time: 0.003) nll: 0.989787 \n",
      "(GPU: 0, epoch: 4, iters: 127584, time: 0.003) nll: 0.822221 \n",
      "(GPU: 0, epoch: 4, iters: 128384, time: 0.003) nll: 0.857171 \n",
      "(GPU: 0, epoch: 4, iters: 129184, time: 0.003) nll: 0.776090 \n",
      "(GPU: 0, epoch: 4, iters: 129984, time: 0.003) nll: 0.886006 \n",
      "(GPU: 0, epoch: 4, iters: 130784, time: 0.003) nll: 0.936448 \n",
      "(GPU: 0, epoch: 4, iters: 131584, time: 0.003) nll: 0.957143 \n",
      "(GPU: 0, epoch: 4, iters: 132384, time: 0.003) nll: 0.679897 \n",
      "(GPU: 0, epoch: 4, iters: 133184, time: 0.003) nll: 0.887007 \n",
      "(GPU: 0, epoch: 4, iters: 133984, time: 0.003) nll: 0.669275 \n",
      "(GPU: 0, epoch: 4, iters: 134784, time: 0.003) nll: 0.730830 \n",
      "(GPU: 0, epoch: 4, iters: 135584, time: 0.003) nll: 0.755937 \n",
      "(GPU: 0, epoch: 4, iters: 136384, time: 0.003) nll: 0.947552 \n",
      "(GPU: 0, epoch: 4, iters: 137184, time: 0.003) nll: 0.987496 \n",
      "saving the latest model (epoch 4, total_steps 700000)\n",
      "(GPU: 0, epoch: 4, iters: 137984, time: 0.003) nll: 0.706327 \n",
      "(GPU: 0, epoch: 4, iters: 138784, time: 0.003) nll: 1.029235 \n",
      "(GPU: 0, epoch: 4, iters: 139584, time: 0.003) nll: 0.915933 \n",
      "(GPU: 0, epoch: 4, iters: 140384, time: 0.003) nll: 0.642315 \n",
      "[*] End of epoch 4 / 25 \t Time Taken: 514 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000500\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3164/4397 [06:06<02:10,  9.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 32, time: 0.002) nll: 0.826697 \n",
      "(GPU: 0, epoch: 5, iters: 32, time: 0.002) nll: 0.666479 \n",
      "(GPU: 0, epoch: 5, iters: 480, time: 0.003) nll: 0.679524 \n",
      "(GPU: 0, epoch: 5, iters: 1280, time: 0.003) nll: 0.661826 \n",
      "(GPU: 0, epoch: 5, iters: 2080, time: 0.003) nll: 0.990067 \n",
      "(GPU: 0, epoch: 5, iters: 2880, time: 0.003) nll: 1.000229 \n",
      "(GPU: 0, epoch: 5, iters: 3680, time: 0.003) nll: 0.899598 \n",
      "(GPU: 0, epoch: 5, iters: 4480, time: 0.003) nll: 0.735113 \n",
      "(GPU: 0, epoch: 5, iters: 5280, time: 0.003) nll: 0.833689 \n",
      "(GPU: 0, epoch: 5, iters: 6080, time: 0.003) nll: 0.879365 \n",
      "(GPU: 0, epoch: 5, iters: 6880, time: 0.003) nll: 0.980371 \n",
      "(GPU: 0, epoch: 5, iters: 7680, time: 0.003) nll: 1.002258 \n",
      "(GPU: 0, epoch: 5, iters: 8480, time: 0.003) nll: 0.842305 \n",
      "(GPU: 0, epoch: 5, iters: 9280, time: 0.003) nll: 0.797124 \n",
      "(GPU: 0, epoch: 5, iters: 10080, time: 0.003) nll: 0.526745 \n",
      "(GPU: 0, epoch: 5, iters: 10880, time: 0.003) nll: 0.835981 \n",
      "(GPU: 0, epoch: 5, iters: 11680, time: 0.003) nll: 1.001480 \n",
      "(GPU: 0, epoch: 5, iters: 12480, time: 0.003) nll: 0.922548 \n",
      "(GPU: 0, epoch: 5, iters: 13280, time: 0.003) nll: 0.930139 \n",
      "(GPU: 0, epoch: 5, iters: 14080, time: 0.003) nll: 0.835048 \n",
      "(GPU: 0, epoch: 5, iters: 14880, time: 0.003) nll: 0.831578 \n",
      "(GPU: 0, epoch: 5, iters: 15680, time: 0.003) nll: 0.937039 \n",
      "(GPU: 0, epoch: 5, iters: 16480, time: 0.003) nll: 0.906703 \n",
      "saving the latest model (epoch 5, total_steps 720000)\n",
      "(GPU: 0, epoch: 5, iters: 17280, time: 0.003) nll: 1.094105 \n",
      "(GPU: 0, epoch: 5, iters: 18080, time: 0.003) nll: 0.926734 \n",
      "(GPU: 0, epoch: 5, iters: 18880, time: 0.003) nll: 0.718146 \n",
      "(GPU: 0, epoch: 5, iters: 19680, time: 0.003) nll: 0.718058 \n",
      "(GPU: 0, epoch: 5, iters: 20480, time: 0.003) nll: 1.073764 \n",
      "(GPU: 0, epoch: 5, iters: 21280, time: 0.003) nll: 0.827004 \n",
      "(GPU: 0, epoch: 5, iters: 22080, time: 0.003) nll: 0.732876 \n",
      "(GPU: 0, epoch: 5, iters: 22880, time: 0.003) nll: 0.803768 \n",
      "(GPU: 0, epoch: 5, iters: 23680, time: 0.003) nll: 1.085199 \n",
      "(GPU: 0, epoch: 5, iters: 24480, time: 0.003) nll: 0.748306 \n",
      "(GPU: 0, epoch: 5, iters: 25280, time: 0.003) nll: 0.945515 \n",
      "(GPU: 0, epoch: 5, iters: 26080, time: 0.003) nll: 0.882098 \n",
      "(GPU: 0, epoch: 5, iters: 26880, time: 0.003) nll: 0.943356 \n",
      "(GPU: 0, epoch: 5, iters: 27680, time: 0.003) nll: 0.925596 \n",
      "(GPU: 0, epoch: 5, iters: 28480, time: 0.003) nll: 0.826084 \n",
      "(GPU: 0, epoch: 5, iters: 29280, time: 0.003) nll: 0.771095 \n",
      "(GPU: 0, epoch: 5, iters: 30080, time: 0.003) nll: 0.775750 \n",
      "(GPU: 0, epoch: 5, iters: 30880, time: 0.003) nll: 0.901929 \n",
      "(GPU: 0, epoch: 5, iters: 31680, time: 0.003) nll: 0.894215 \n",
      "(GPU: 0, epoch: 5, iters: 32480, time: 0.003) nll: 0.864980 \n",
      "(GPU: 0, epoch: 5, iters: 33280, time: 0.003) nll: 0.832903 \n",
      "(GPU: 0, epoch: 5, iters: 34080, time: 0.003) nll: 1.004282 \n",
      "(GPU: 0, epoch: 5, iters: 34880, time: 0.003) nll: 0.970686 \n",
      "(GPU: 0, epoch: 5, iters: 35680, time: 0.003) nll: 0.797253 \n",
      "(GPU: 0, epoch: 5, iters: 36480, time: 0.003) nll: 0.616474 \n",
      "saving the latest model (epoch 5, total_steps 740000)\n",
      "(GPU: 0, epoch: 5, iters: 37280, time: 0.003) nll: 0.926982 \n",
      "(GPU: 0, epoch: 5, iters: 38080, time: 0.003) nll: 0.758102 \n",
      "(GPU: 0, epoch: 5, iters: 38880, time: 0.003) nll: 0.886568 \n",
      "(GPU: 0, epoch: 5, iters: 39680, time: 0.003) nll: 1.299178 \n",
      "(GPU: 0, epoch: 5, iters: 40480, time: 0.003) nll: 0.791760 \n",
      "(GPU: 0, epoch: 5, iters: 41280, time: 0.003) nll: 0.753240 \n",
      "(GPU: 0, epoch: 5, iters: 42080, time: 0.003) nll: 0.743354 \n",
      "(GPU: 0, epoch: 5, iters: 42880, time: 0.003) nll: 0.594919 \n",
      "(GPU: 0, epoch: 5, iters: 43680, time: 0.003) nll: 0.593293 \n",
      "(GPU: 0, epoch: 5, iters: 44480, time: 0.003) nll: 0.711995 \n",
      "(GPU: 0, epoch: 5, iters: 45280, time: 0.003) nll: 0.828557 \n",
      "(GPU: 0, epoch: 5, iters: 46080, time: 0.003) nll: 0.876748 \n",
      "(GPU: 0, epoch: 5, iters: 46880, time: 0.003) nll: 0.787485 \n",
      "(GPU: 0, epoch: 5, iters: 47680, time: 0.003) nll: 0.773032 \n",
      "(GPU: 0, epoch: 5, iters: 48480, time: 0.003) nll: 0.816806 \n",
      "(GPU: 0, epoch: 5, iters: 49280, time: 0.003) nll: 1.048604 \n",
      "(GPU: 0, epoch: 5, iters: 50080, time: 0.003) nll: 0.777428 \n",
      "(GPU: 0, epoch: 5, iters: 50880, time: 0.003) nll: 0.906662 \n",
      "(GPU: 0, epoch: 5, iters: 51680, time: 0.003) nll: 0.904597 \n",
      "(GPU: 0, epoch: 5, iters: 52480, time: 0.003) nll: 1.247906 \n",
      "(GPU: 0, epoch: 5, iters: 53280, time: 0.003) nll: 0.817348 \n",
      "(GPU: 0, epoch: 5, iters: 54080, time: 0.003) nll: 0.935027 \n",
      "(GPU: 0, epoch: 5, iters: 54880, time: 0.003) nll: 0.850961 \n",
      "(GPU: 0, epoch: 5, iters: 55680, time: 0.003) nll: 0.613646 \n",
      "(GPU: 0, epoch: 5, iters: 56480, time: 0.003) nll: 0.975707 \n",
      "saving the latest model (epoch 5, total_steps 760000)\n",
      "(GPU: 0, epoch: 5, iters: 57280, time: 0.003) nll: 0.803910 \n",
      "(GPU: 0, epoch: 5, iters: 58080, time: 0.003) nll: 0.967766 \n",
      "(GPU: 0, epoch: 5, iters: 58880, time: 0.003) nll: 0.869694 \n",
      "(GPU: 0, epoch: 5, iters: 59680, time: 0.003) nll: 0.641009 \n",
      "(GPU: 0, epoch: 5, iters: 60480, time: 0.003) nll: 0.783894 \n",
      "(GPU: 0, epoch: 5, iters: 61280, time: 0.003) nll: 1.106258 \n",
      "(GPU: 0, epoch: 5, iters: 62080, time: 0.003) nll: 0.892166 \n",
      "(GPU: 0, epoch: 5, iters: 62880, time: 0.003) nll: 0.912626 \n",
      "(GPU: 0, epoch: 5, iters: 63680, time: 0.003) nll: 0.725129 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.003) nll: 0.661926 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.005) nll: 0.659387 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.005) nll: 0.763280 \n",
      "(GPU: 0, epoch: 5, iters: 65280, time: 0.003) nll: 0.664458 \n",
      "(GPU: 0, epoch: 5, iters: 66080, time: 0.003) nll: 0.994024 \n",
      "(GPU: 0, epoch: 5, iters: 66880, time: 0.003) nll: 0.846558 \n",
      "(GPU: 0, epoch: 5, iters: 67680, time: 0.003) nll: 0.618758 \n",
      "(GPU: 0, epoch: 5, iters: 68480, time: 0.003) nll: 0.950589 \n",
      "(GPU: 0, epoch: 5, iters: 69280, time: 0.003) nll: 0.943792 \n",
      "(GPU: 0, epoch: 5, iters: 70080, time: 0.003) nll: 0.816336 \n",
      "(GPU: 0, epoch: 5, iters: 70880, time: 0.003) nll: 0.787152 \n",
      "(GPU: 0, epoch: 5, iters: 71680, time: 0.003) nll: 0.888295 \n",
      "(GPU: 0, epoch: 5, iters: 72480, time: 0.003) nll: 0.629759 \n",
      "(GPU: 0, epoch: 5, iters: 73280, time: 0.003) nll: 1.016275 \n",
      "(GPU: 0, epoch: 5, iters: 74080, time: 0.003) nll: 0.884160 \n",
      "(GPU: 0, epoch: 5, iters: 74880, time: 0.003) nll: 0.842788 \n",
      "(GPU: 0, epoch: 5, iters: 75680, time: 0.003) nll: 0.875224 \n",
      "(GPU: 0, epoch: 5, iters: 76480, time: 0.003) nll: 0.751827 \n",
      "saving the latest model (epoch 5, total_steps 780000)\n",
      "(GPU: 0, epoch: 5, iters: 77280, time: 0.003) nll: 0.997142 \n",
      "(GPU: 0, epoch: 5, iters: 78080, time: 0.003) nll: 1.472078 \n",
      "(GPU: 0, epoch: 5, iters: 78880, time: 0.003) nll: 0.765192 \n",
      "(GPU: 0, epoch: 5, iters: 79680, time: 0.003) nll: 1.003432 \n",
      "(GPU: 0, epoch: 5, iters: 80480, time: 0.003) nll: 0.870725 \n",
      "(GPU: 0, epoch: 5, iters: 81280, time: 0.003) nll: 0.827804 \n",
      "(GPU: 0, epoch: 5, iters: 82080, time: 0.003) nll: 0.810128 \n",
      "(GPU: 0, epoch: 5, iters: 82880, time: 0.003) nll: 0.951839 \n",
      "(GPU: 0, epoch: 5, iters: 83680, time: 0.003) nll: 0.874956 \n",
      "(GPU: 0, epoch: 5, iters: 84480, time: 0.003) nll: 0.746118 \n",
      "(GPU: 0, epoch: 5, iters: 85280, time: 0.003) nll: 0.672992 \n",
      "(GPU: 0, epoch: 5, iters: 86080, time: 0.003) nll: 0.747505 \n",
      "(GPU: 0, epoch: 5, iters: 86880, time: 0.003) nll: 1.044273 \n",
      "(GPU: 0, epoch: 5, iters: 87680, time: 0.003) nll: 1.144271 \n",
      "(GPU: 0, epoch: 5, iters: 88480, time: 0.003) nll: 0.974635 \n",
      "(GPU: 0, epoch: 5, iters: 89280, time: 0.003) nll: 0.770973 \n",
      "(GPU: 0, epoch: 5, iters: 90080, time: 0.003) nll: 0.631505 \n",
      "(GPU: 0, epoch: 5, iters: 90880, time: 0.003) nll: 0.787498 \n",
      "(GPU: 0, epoch: 5, iters: 91680, time: 0.003) nll: 0.720278 \n",
      "(GPU: 0, epoch: 5, iters: 92480, time: 0.003) nll: 0.831276 \n",
      "(GPU: 0, epoch: 5, iters: 93280, time: 0.003) nll: 0.833160 \n",
      "(GPU: 0, epoch: 5, iters: 94080, time: 0.003) nll: 0.936022 \n",
      "(GPU: 0, epoch: 5, iters: 94880, time: 0.003) nll: 0.735883 \n",
      "(GPU: 0, epoch: 5, iters: 95680, time: 0.003) nll: 0.820377 \n",
      "(GPU: 0, epoch: 5, iters: 96480, time: 0.003) nll: 0.859882 \n",
      "saving the latest model (epoch 5, total_steps 800000)\n",
      "(GPU: 0, epoch: 5, iters: 97280, time: 0.003) nll: 1.039634 \n",
      "(GPU: 0, epoch: 5, iters: 98080, time: 0.003) nll: 1.058607 \n",
      "(GPU: 0, epoch: 5, iters: 98880, time: 0.003) nll: 0.879137 \n",
      "(GPU: 0, epoch: 5, iters: 99680, time: 0.003) nll: 0.754174 \n",
      "(GPU: 0, epoch: 5, iters: 100480, time: 0.003) nll: 1.067214 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 101280, time: 0.003) nll: 0.917946 \n",
      "(GPU: 0, epoch: 5, iters: 102080, time: 0.003) nll: 1.190158 \n",
      "(GPU: 0, epoch: 5, iters: 102880, time: 0.003) nll: 0.749191 \n",
      "(GPU: 0, epoch: 5, iters: 103680, time: 0.003) nll: 0.803459 \n",
      "(GPU: 0, epoch: 5, iters: 104480, time: 0.003) nll: 0.887736 \n",
      "(GPU: 0, epoch: 5, iters: 105280, time: 0.003) nll: 0.934700 \n",
      "(GPU: 0, epoch: 5, iters: 106080, time: 0.003) nll: 0.795764 \n",
      "(GPU: 0, epoch: 5, iters: 106880, time: 0.003) nll: 0.916597 \n",
      "(GPU: 0, epoch: 5, iters: 107680, time: 0.003) nll: 0.718044 \n",
      "(GPU: 0, epoch: 5, iters: 108480, time: 0.003) nll: 1.061913 \n",
      "(GPU: 0, epoch: 5, iters: 109280, time: 0.003) nll: 0.911739 \n",
      "(GPU: 0, epoch: 5, iters: 110080, time: 0.003) nll: 0.809031 \n",
      "(GPU: 0, epoch: 5, iters: 110880, time: 0.003) nll: 0.663282 \n",
      "(GPU: 0, epoch: 5, iters: 111680, time: 0.003) nll: 0.878273 \n",
      "(GPU: 0, epoch: 5, iters: 112480, time: 0.003) nll: 0.823344 \n",
      "(GPU: 0, epoch: 5, iters: 113280, time: 0.003) nll: 0.871856 \n",
      "(GPU: 0, epoch: 5, iters: 114080, time: 0.003) nll: 0.940023 \n",
      "(GPU: 0, epoch: 5, iters: 114880, time: 0.003) nll: 0.720555 \n",
      "(GPU: 0, epoch: 5, iters: 115680, time: 0.003) nll: 1.363233 \n",
      "(GPU: 0, epoch: 5, iters: 116480, time: 0.003) nll: 0.949011 \n",
      "saving the latest model (epoch 5, total_steps 820000)\n",
      "(GPU: 0, epoch: 5, iters: 117280, time: 0.003) nll: 0.894178 \n",
      "(GPU: 0, epoch: 5, iters: 118080, time: 0.003) nll: 0.975202 \n",
      "(GPU: 0, epoch: 5, iters: 118880, time: 0.003) nll: 0.868248 \n",
      "(GPU: 0, epoch: 5, iters: 119680, time: 0.003) nll: 0.787854 \n",
      "(GPU: 0, epoch: 5, iters: 120480, time: 0.003) nll: 0.915281 \n",
      "(GPU: 0, epoch: 5, iters: 121280, time: 0.003) nll: 0.619260 \n",
      "(GPU: 0, epoch: 5, iters: 122080, time: 0.003) nll: 0.743120 \n",
      "(GPU: 0, epoch: 5, iters: 122880, time: 0.003) nll: 0.864359 \n",
      "(GPU: 0, epoch: 5, iters: 123680, time: 0.003) nll: 0.906596 \n",
      "(GPU: 0, epoch: 5, iters: 124480, time: 0.003) nll: 0.862988 \n",
      "(GPU: 0, epoch: 5, iters: 125280, time: 0.003) nll: 0.966179 \n",
      "(GPU: 0, epoch: 5, iters: 126080, time: 0.003) nll: 0.736186 \n",
      "(GPU: 0, epoch: 5, iters: 126880, time: 0.003) nll: 0.984931 \n",
      "(GPU: 0, epoch: 5, iters: 127680, time: 0.003) nll: 0.710863 \n",
      "(GPU: 0, epoch: 5, iters: 128480, time: 0.003) nll: 0.729140 \n",
      "(GPU: 0, epoch: 5, iters: 129280, time: 0.003) nll: 0.860625 \n",
      "(GPU: 0, epoch: 5, iters: 130080, time: 0.003) nll: 0.837935 \n",
      "(GPU: 0, epoch: 5, iters: 130880, time: 0.003) nll: 0.810243 \n",
      "(GPU: 0, epoch: 5, iters: 131680, time: 0.003) nll: 0.677710 \n",
      "(GPU: 0, epoch: 5, iters: 132480, time: 0.003) nll: 0.788584 \n",
      "(GPU: 0, epoch: 5, iters: 133280, time: 0.003) nll: 0.819929 \n",
      "(GPU: 0, epoch: 5, iters: 134080, time: 0.003) nll: 1.123258 \n",
      "(GPU: 0, epoch: 5, iters: 134880, time: 0.003) nll: 1.592199 \n",
      "(GPU: 0, epoch: 5, iters: 135680, time: 0.003) nll: 0.754530 \n",
      "(GPU: 0, epoch: 5, iters: 136480, time: 0.003) nll: 0.669232 \n",
      "saving the latest model (epoch 5, total_steps 840000)\n",
      "(GPU: 0, epoch: 5, iters: 137280, time: 0.003) nll: 0.805416 \n",
      "(GPU: 0, epoch: 5, iters: 138080, time: 0.003) nll: 0.779102 \n",
      "(GPU: 0, epoch: 5, iters: 138880, time: 0.003) nll: 0.810232 \n",
      "(GPU: 0, epoch: 5, iters: 139680, time: 0.003) nll: 0.837214 \n",
      "(GPU: 0, epoch: 5, iters: 140480, time: 0.003) nll: 0.766217 \n",
      "[*] End of epoch 5 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000600\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3168/4397 [06:06<02:33,  8.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 32, time: 0.002) nll: 0.650898 \n",
      "(GPU: 0, epoch: 6, iters: 32, time: 0.002) nll: 0.843892 \n",
      "(GPU: 0, epoch: 6, iters: 576, time: 0.003) nll: 0.780030 \n",
      "(GPU: 0, epoch: 6, iters: 1376, time: 0.003) nll: 0.680274 \n",
      "(GPU: 0, epoch: 6, iters: 2176, time: 0.003) nll: 1.004419 \n",
      "(GPU: 0, epoch: 6, iters: 2976, time: 0.003) nll: 0.654727 \n",
      "(GPU: 0, epoch: 6, iters: 3776, time: 0.003) nll: 0.908706 \n",
      "(GPU: 0, epoch: 6, iters: 4576, time: 0.003) nll: 0.821849 \n",
      "(GPU: 0, epoch: 6, iters: 5376, time: 0.003) nll: 0.986734 \n",
      "(GPU: 0, epoch: 6, iters: 6176, time: 0.003) nll: 0.833770 \n",
      "(GPU: 0, epoch: 6, iters: 6976, time: 0.003) nll: 0.826964 \n",
      "(GPU: 0, epoch: 6, iters: 7776, time: 0.003) nll: 0.728793 \n",
      "(GPU: 0, epoch: 6, iters: 8576, time: 0.003) nll: 0.886403 \n",
      "(GPU: 0, epoch: 6, iters: 9376, time: 0.003) nll: 0.838160 \n",
      "(GPU: 0, epoch: 6, iters: 10176, time: 0.003) nll: 0.805860 \n",
      "(GPU: 0, epoch: 6, iters: 10976, time: 0.003) nll: 0.977623 \n",
      "(GPU: 0, epoch: 6, iters: 11776, time: 0.003) nll: 0.827566 \n",
      "(GPU: 0, epoch: 6, iters: 12576, time: 0.003) nll: 0.665933 \n",
      "(GPU: 0, epoch: 6, iters: 13376, time: 0.003) nll: 1.077696 \n",
      "(GPU: 0, epoch: 6, iters: 14176, time: 0.003) nll: 0.866393 \n",
      "(GPU: 0, epoch: 6, iters: 14976, time: 0.003) nll: 0.770515 \n",
      "(GPU: 0, epoch: 6, iters: 15776, time: 0.003) nll: 0.742355 \n",
      "saving the latest model (epoch 6, total_steps 860000)\n",
      "(GPU: 0, epoch: 6, iters: 16576, time: 0.003) nll: 0.790935 \n",
      "(GPU: 0, epoch: 6, iters: 17376, time: 0.003) nll: 0.710882 \n",
      "(GPU: 0, epoch: 6, iters: 18176, time: 0.003) nll: 0.922685 \n",
      "(GPU: 0, epoch: 6, iters: 18976, time: 0.003) nll: 0.786506 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.003) nll: 0.860656 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.005) nll: 0.857635 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.005) nll: 0.843276 \n",
      "(GPU: 0, epoch: 6, iters: 20576, time: 0.003) nll: 0.768089 \n",
      "(GPU: 0, epoch: 6, iters: 21376, time: 0.003) nll: 0.682823 \n",
      "(GPU: 0, epoch: 6, iters: 22176, time: 0.003) nll: 0.872298 \n",
      "(GPU: 0, epoch: 6, iters: 22976, time: 0.003) nll: 0.938174 \n",
      "(GPU: 0, epoch: 6, iters: 23776, time: 0.003) nll: 0.814754 \n",
      "(GPU: 0, epoch: 6, iters: 24576, time: 0.003) nll: 0.755946 \n",
      "(GPU: 0, epoch: 6, iters: 25376, time: 0.003) nll: 0.911003 \n",
      "(GPU: 0, epoch: 6, iters: 26176, time: 0.003) nll: 0.769574 \n",
      "(GPU: 0, epoch: 6, iters: 26976, time: 0.003) nll: 0.914179 \n",
      "(GPU: 0, epoch: 6, iters: 27776, time: 0.003) nll: 1.113331 \n",
      "(GPU: 0, epoch: 6, iters: 28576, time: 0.003) nll: 0.869780 \n",
      "(GPU: 0, epoch: 6, iters: 29376, time: 0.003) nll: 0.691288 \n",
      "(GPU: 0, epoch: 6, iters: 30176, time: 0.003) nll: 1.141605 \n",
      "(GPU: 0, epoch: 6, iters: 30976, time: 0.003) nll: 0.731379 \n",
      "(GPU: 0, epoch: 6, iters: 31776, time: 0.003) nll: 0.753920 \n",
      "(GPU: 0, epoch: 6, iters: 32576, time: 0.003) nll: 0.894419 \n",
      "(GPU: 0, epoch: 6, iters: 33376, time: 0.003) nll: 0.765701 \n",
      "(GPU: 0, epoch: 6, iters: 34176, time: 0.003) nll: 1.016952 \n",
      "(GPU: 0, epoch: 6, iters: 34976, time: 0.003) nll: 0.804935 \n",
      "(GPU: 0, epoch: 6, iters: 35776, time: 0.003) nll: 0.786065 \n",
      "saving the latest model (epoch 6, total_steps 880000)\n",
      "(GPU: 0, epoch: 6, iters: 36576, time: 0.003) nll: 1.086927 \n",
      "(GPU: 0, epoch: 6, iters: 37376, time: 0.003) nll: 0.925945 \n",
      "(GPU: 0, epoch: 6, iters: 38176, time: 0.003) nll: 1.035632 \n",
      "(GPU: 0, epoch: 6, iters: 38976, time: 0.003) nll: 0.778590 \n",
      "(GPU: 0, epoch: 6, iters: 39776, time: 0.003) nll: 1.137895 \n",
      "(GPU: 0, epoch: 6, iters: 40576, time: 0.003) nll: 0.833001 \n",
      "(GPU: 0, epoch: 6, iters: 41376, time: 0.003) nll: 0.778402 \n",
      "(GPU: 0, epoch: 6, iters: 42176, time: 0.003) nll: 0.993034 \n",
      "(GPU: 0, epoch: 6, iters: 42976, time: 0.003) nll: 0.666677 \n",
      "(GPU: 0, epoch: 6, iters: 43776, time: 0.003) nll: 0.904139 \n",
      "(GPU: 0, epoch: 6, iters: 44576, time: 0.003) nll: 0.959674 \n",
      "(GPU: 0, epoch: 6, iters: 45376, time: 0.003) nll: 0.991465 \n",
      "(GPU: 0, epoch: 6, iters: 46176, time: 0.003) nll: 0.836172 \n",
      "(GPU: 0, epoch: 6, iters: 46976, time: 0.003) nll: 0.957540 \n",
      "(GPU: 0, epoch: 6, iters: 47776, time: 0.003) nll: 0.724391 \n",
      "(GPU: 0, epoch: 6, iters: 48576, time: 0.003) nll: 0.594673 \n",
      "(GPU: 0, epoch: 6, iters: 49376, time: 0.003) nll: 0.839950 \n",
      "(GPU: 0, epoch: 6, iters: 50176, time: 0.003) nll: 0.593497 \n",
      "(GPU: 0, epoch: 6, iters: 50976, time: 0.003) nll: 1.258121 \n",
      "(GPU: 0, epoch: 6, iters: 51776, time: 0.003) nll: 0.905850 \n",
      "(GPU: 0, epoch: 6, iters: 52576, time: 0.003) nll: 0.964606 \n",
      "(GPU: 0, epoch: 6, iters: 53376, time: 0.003) nll: 0.923750 \n",
      "(GPU: 0, epoch: 6, iters: 54176, time: 0.003) nll: 0.876725 \n",
      "(GPU: 0, epoch: 6, iters: 54976, time: 0.003) nll: 1.033902 \n",
      "(GPU: 0, epoch: 6, iters: 55776, time: 0.003) nll: 0.893446 \n",
      "saving the latest model (epoch 6, total_steps 900000)\n",
      "(GPU: 0, epoch: 6, iters: 56576, time: 0.003) nll: 0.926496 \n",
      "(GPU: 0, epoch: 6, iters: 57376, time: 0.003) nll: 0.964043 \n",
      "(GPU: 0, epoch: 6, iters: 58176, time: 0.003) nll: 0.628234 \n",
      "(GPU: 0, epoch: 6, iters: 58976, time: 0.003) nll: 0.709731 \n",
      "(GPU: 0, epoch: 6, iters: 59776, time: 0.003) nll: 0.875960 \n",
      "(GPU: 0, epoch: 6, iters: 60576, time: 0.003) nll: 0.899758 \n",
      "(GPU: 0, epoch: 6, iters: 61376, time: 0.003) nll: 0.777643 \n",
      "(GPU: 0, epoch: 6, iters: 62176, time: 0.003) nll: 0.937859 \n",
      "(GPU: 0, epoch: 6, iters: 62976, time: 0.003) nll: 0.840209 \n",
      "(GPU: 0, epoch: 6, iters: 63776, time: 0.003) nll: 0.641039 \n",
      "(GPU: 0, epoch: 6, iters: 64576, time: 0.003) nll: 1.124900 \n",
      "(GPU: 0, epoch: 6, iters: 65376, time: 0.003) nll: 0.792962 \n",
      "(GPU: 0, epoch: 6, iters: 66176, time: 0.003) nll: 0.773907 \n",
      "(GPU: 0, epoch: 6, iters: 66976, time: 0.003) nll: 0.741563 \n",
      "(GPU: 0, epoch: 6, iters: 67776, time: 0.003) nll: 0.808115 \n",
      "(GPU: 0, epoch: 6, iters: 68576, time: 0.003) nll: 0.670357 \n",
      "(GPU: 0, epoch: 6, iters: 69376, time: 0.003) nll: 0.700128 \n",
      "(GPU: 0, epoch: 6, iters: 70176, time: 0.003) nll: 0.778083 \n",
      "(GPU: 0, epoch: 6, iters: 70976, time: 0.003) nll: 1.113766 \n",
      "(GPU: 0, epoch: 6, iters: 71776, time: 0.003) nll: 0.682443 \n",
      "(GPU: 0, epoch: 6, iters: 72576, time: 0.003) nll: 1.128898 \n",
      "(GPU: 0, epoch: 6, iters: 73376, time: 0.003) nll: 0.942521 \n",
      "(GPU: 0, epoch: 6, iters: 74176, time: 0.003) nll: 1.015289 \n",
      "(GPU: 0, epoch: 6, iters: 74976, time: 0.003) nll: 0.930655 \n",
      "(GPU: 0, epoch: 6, iters: 75776, time: 0.003) nll: 0.846936 \n",
      "saving the latest model (epoch 6, total_steps 920000)\n",
      "(GPU: 0, epoch: 6, iters: 76576, time: 0.003) nll: 0.838477 \n",
      "(GPU: 0, epoch: 6, iters: 77376, time: 0.003) nll: 1.207840 \n",
      "(GPU: 0, epoch: 6, iters: 78176, time: 0.003) nll: 0.750275 \n",
      "(GPU: 0, epoch: 6, iters: 78976, time: 0.003) nll: 0.811770 \n",
      "(GPU: 0, epoch: 6, iters: 79776, time: 0.003) nll: 1.151626 \n",
      "(GPU: 0, epoch: 6, iters: 80576, time: 0.003) nll: 1.184235 \n",
      "(GPU: 0, epoch: 6, iters: 81376, time: 0.003) nll: 0.833092 \n",
      "(GPU: 0, epoch: 6, iters: 82176, time: 0.003) nll: 0.890385 \n",
      "(GPU: 0, epoch: 6, iters: 82976, time: 0.003) nll: 0.573082 \n",
      "(GPU: 0, epoch: 6, iters: 83776, time: 0.003) nll: 0.891014 \n",
      "(GPU: 0, epoch: 6, iters: 84576, time: 0.003) nll: 0.853618 \n",
      "(GPU: 0, epoch: 6, iters: 85376, time: 0.003) nll: 0.805164 \n",
      "(GPU: 0, epoch: 6, iters: 86176, time: 0.003) nll: 1.043436 \n",
      "(GPU: 0, epoch: 6, iters: 86976, time: 0.003) nll: 0.789462 \n",
      "(GPU: 0, epoch: 6, iters: 87776, time: 0.003) nll: 0.892036 \n",
      "(GPU: 0, epoch: 6, iters: 88576, time: 0.003) nll: 0.766045 \n",
      "(GPU: 0, epoch: 6, iters: 89376, time: 0.003) nll: 0.850689 \n",
      "(GPU: 0, epoch: 6, iters: 90176, time: 0.003) nll: 0.984073 \n",
      "(GPU: 0, epoch: 6, iters: 90976, time: 0.003) nll: 0.669466 \n",
      "(GPU: 0, epoch: 6, iters: 91776, time: 0.003) nll: 0.887444 \n",
      "(GPU: 0, epoch: 6, iters: 92576, time: 0.003) nll: 0.741836 \n",
      "(GPU: 0, epoch: 6, iters: 93376, time: 0.003) nll: 0.880942 \n",
      "(GPU: 0, epoch: 6, iters: 94176, time: 0.003) nll: 0.782956 \n",
      "(GPU: 0, epoch: 6, iters: 94976, time: 0.003) nll: 0.742269 \n",
      "(GPU: 0, epoch: 6, iters: 95776, time: 0.003) nll: 0.856890 \n",
      "saving the latest model (epoch 6, total_steps 940000)\n",
      "(GPU: 0, epoch: 6, iters: 96576, time: 0.003) nll: 0.935752 \n",
      "(GPU: 0, epoch: 6, iters: 97376, time: 0.003) nll: 1.145842 \n",
      "(GPU: 0, epoch: 6, iters: 98176, time: 0.003) nll: 0.933952 \n",
      "(GPU: 0, epoch: 6, iters: 98976, time: 0.003) nll: 1.105408 \n",
      "(GPU: 0, epoch: 6, iters: 99776, time: 0.003) nll: 1.167055 \n",
      "(GPU: 0, epoch: 6, iters: 100576, time: 0.003) nll: 0.762683 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 101376, time: 0.003) nll: 1.137754 \n",
      "(GPU: 0, epoch: 6, iters: 102176, time: 0.003) nll: 0.630385 \n",
      "(GPU: 0, epoch: 6, iters: 102976, time: 0.003) nll: 0.806670 \n",
      "(GPU: 0, epoch: 6, iters: 103776, time: 0.003) nll: 0.736165 \n",
      "(GPU: 0, epoch: 6, iters: 104576, time: 0.003) nll: 0.970907 \n",
      "(GPU: 0, epoch: 6, iters: 105376, time: 0.003) nll: 0.730985 \n",
      "(GPU: 0, epoch: 6, iters: 106176, time: 0.003) nll: 0.730533 \n",
      "(GPU: 0, epoch: 6, iters: 106976, time: 0.003) nll: 0.788410 \n",
      "(GPU: 0, epoch: 6, iters: 107776, time: 0.003) nll: 0.725004 \n",
      "(GPU: 0, epoch: 6, iters: 108576, time: 0.003) nll: 0.893759 \n",
      "(GPU: 0, epoch: 6, iters: 109376, time: 0.003) nll: 0.923524 \n",
      "(GPU: 0, epoch: 6, iters: 110176, time: 0.003) nll: 0.882115 \n",
      "(GPU: 0, epoch: 6, iters: 110976, time: 0.003) nll: 0.789236 \n",
      "(GPU: 0, epoch: 6, iters: 111776, time: 0.003) nll: 0.676931 \n",
      "(GPU: 0, epoch: 6, iters: 112576, time: 0.003) nll: 0.841351 \n",
      "(GPU: 0, epoch: 6, iters: 113376, time: 0.003) nll: 0.734478 \n",
      "(GPU: 0, epoch: 6, iters: 114176, time: 0.003) nll: 0.867870 \n",
      "(GPU: 0, epoch: 6, iters: 114976, time: 0.003) nll: 0.849585 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.003) nll: 0.800838 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.005) nll: 0.783413 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.005) nll: 0.766828 \n",
      "saving the latest model (epoch 6, total_steps 960000)\n",
      "(GPU: 0, epoch: 6, iters: 116576, time: 0.003) nll: 0.785741 \n",
      "(GPU: 0, epoch: 6, iters: 117376, time: 0.003) nll: 0.906431 \n",
      "(GPU: 0, epoch: 6, iters: 118176, time: 0.003) nll: 0.797526 \n",
      "(GPU: 0, epoch: 6, iters: 118976, time: 0.003) nll: 0.767392 \n",
      "(GPU: 0, epoch: 6, iters: 119776, time: 0.003) nll: 0.803553 \n",
      "(GPU: 0, epoch: 6, iters: 120576, time: 0.003) nll: 0.531941 \n",
      "(GPU: 0, epoch: 6, iters: 121376, time: 0.003) nll: 0.879063 \n",
      "(GPU: 0, epoch: 6, iters: 122176, time: 0.003) nll: 1.148475 \n",
      "(GPU: 0, epoch: 6, iters: 122976, time: 0.003) nll: 1.080911 \n",
      "(GPU: 0, epoch: 6, iters: 123776, time: 0.003) nll: 0.843367 \n",
      "(GPU: 0, epoch: 6, iters: 124576, time: 0.003) nll: 0.936833 \n",
      "(GPU: 0, epoch: 6, iters: 125376, time: 0.003) nll: 0.991463 \n",
      "(GPU: 0, epoch: 6, iters: 126176, time: 0.003) nll: 0.810047 \n",
      "(GPU: 0, epoch: 6, iters: 126976, time: 0.003) nll: 0.820515 \n",
      "(GPU: 0, epoch: 6, iters: 127776, time: 0.003) nll: 0.920771 \n",
      "(GPU: 0, epoch: 6, iters: 128576, time: 0.003) nll: 0.802955 \n",
      "(GPU: 0, epoch: 6, iters: 129376, time: 0.003) nll: 0.656862 \n",
      "(GPU: 0, epoch: 6, iters: 130176, time: 0.003) nll: 0.660841 \n",
      "(GPU: 0, epoch: 6, iters: 130976, time: 0.003) nll: 0.901680 \n",
      "(GPU: 0, epoch: 6, iters: 131776, time: 0.003) nll: 0.809991 \n",
      "(GPU: 0, epoch: 6, iters: 132576, time: 0.003) nll: 0.873403 \n",
      "(GPU: 0, epoch: 6, iters: 133376, time: 0.003) nll: 0.743917 \n",
      "(GPU: 0, epoch: 6, iters: 134176, time: 0.003) nll: 1.126704 \n",
      "(GPU: 0, epoch: 6, iters: 134976, time: 0.003) nll: 0.990026 \n",
      "(GPU: 0, epoch: 6, iters: 135776, time: 0.003) nll: 0.947168 \n",
      "saving the latest model (epoch 6, total_steps 980000)\n",
      "(GPU: 0, epoch: 6, iters: 136576, time: 0.003) nll: 0.935302 \n",
      "(GPU: 0, epoch: 6, iters: 137376, time: 0.003) nll: 0.673029 \n",
      "(GPU: 0, epoch: 6, iters: 138176, time: 0.003) nll: 0.985437 \n",
      "(GPU: 0, epoch: 6, iters: 138976, time: 0.003) nll: 0.880802 \n",
      "(GPU: 0, epoch: 6, iters: 139776, time: 0.003) nll: 0.950861 \n",
      "(GPU: 0, epoch: 6, iters: 140576, time: 0.003) nll: 0.849950 \n",
      "saving the model at the end of epoch 6, iters 984928\n",
      "([test] GPU: 0, epoch: 6) \n",
      "OrderedDict()\n",
      "[*] End of epoch 6 / 25 \t Time Taken: 521 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000700\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3170/4397 [06:06<02:09,  9.45it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 32, time: 0.002) nll: 0.771302 \n",
      "(GPU: 0, epoch: 7, iters: 32, time: 0.002) nll: 0.877406 \n",
      "(GPU: 0, epoch: 7, iters: 672, time: 0.003) nll: 0.805442 \n",
      "(GPU: 0, epoch: 7, iters: 1472, time: 0.003) nll: 0.887074 \n",
      "(GPU: 0, epoch: 7, iters: 2272, time: 0.003) nll: 0.785557 \n",
      "(GPU: 0, epoch: 7, iters: 3072, time: 0.003) nll: 0.994865 \n",
      "(GPU: 0, epoch: 7, iters: 3872, time: 0.003) nll: 0.766501 \n",
      "(GPU: 0, epoch: 7, iters: 4672, time: 0.003) nll: 1.021117 \n",
      "(GPU: 0, epoch: 7, iters: 5472, time: 0.003) nll: 0.694921 \n",
      "(GPU: 0, epoch: 7, iters: 6272, time: 0.003) nll: 0.634064 \n",
      "(GPU: 0, epoch: 7, iters: 7072, time: 0.003) nll: 0.779894 \n",
      "(GPU: 0, epoch: 7, iters: 7872, time: 0.003) nll: 0.841690 \n",
      "(GPU: 0, epoch: 7, iters: 8672, time: 0.003) nll: 0.764442 \n",
      "(GPU: 0, epoch: 7, iters: 9472, time: 0.003) nll: 0.828133 \n",
      "(GPU: 0, epoch: 7, iters: 10272, time: 0.003) nll: 1.236364 \n",
      "(GPU: 0, epoch: 7, iters: 11072, time: 0.003) nll: 0.654434 \n",
      "(GPU: 0, epoch: 7, iters: 11872, time: 0.003) nll: 0.546657 \n",
      "(GPU: 0, epoch: 7, iters: 12672, time: 0.003) nll: 0.898717 \n",
      "(GPU: 0, epoch: 7, iters: 13472, time: 0.003) nll: 1.038973 \n",
      "(GPU: 0, epoch: 7, iters: 14272, time: 0.003) nll: 1.208727 \n",
      "(GPU: 0, epoch: 7, iters: 15072, time: 0.003) nll: 0.922324 \n",
      "saving the latest model (epoch 7, total_steps 1000000)\n",
      "(GPU: 0, epoch: 7, iters: 15872, time: 0.003) nll: 0.809243 \n",
      "(GPU: 0, epoch: 7, iters: 16672, time: 0.003) nll: 1.024067 \n",
      "(GPU: 0, epoch: 7, iters: 17472, time: 0.003) nll: 0.666113 \n",
      "(GPU: 0, epoch: 7, iters: 18272, time: 0.003) nll: 0.905078 \n",
      "(GPU: 0, epoch: 7, iters: 19072, time: 0.003) nll: 0.727253 \n",
      "(GPU: 0, epoch: 7, iters: 19872, time: 0.003) nll: 0.870569 \n",
      "(GPU: 0, epoch: 7, iters: 20672, time: 0.003) nll: 0.878501 \n",
      "(GPU: 0, epoch: 7, iters: 21472, time: 0.003) nll: 0.820486 \n",
      "(GPU: 0, epoch: 7, iters: 22272, time: 0.003) nll: 0.800400 \n",
      "(GPU: 0, epoch: 7, iters: 23072, time: 0.003) nll: 0.831098 \n",
      "(GPU: 0, epoch: 7, iters: 23872, time: 0.003) nll: 0.769361 \n",
      "(GPU: 0, epoch: 7, iters: 24672, time: 0.003) nll: 0.848695 \n",
      "(GPU: 0, epoch: 7, iters: 25472, time: 0.003) nll: 0.930142 \n",
      "(GPU: 0, epoch: 7, iters: 26272, time: 0.003) nll: 0.933868 \n",
      "(GPU: 0, epoch: 7, iters: 27072, time: 0.003) nll: 0.800593 \n",
      "(GPU: 0, epoch: 7, iters: 27872, time: 0.003) nll: 0.900027 \n",
      "(GPU: 0, epoch: 7, iters: 28672, time: 0.003) nll: 0.693886 \n",
      "(GPU: 0, epoch: 7, iters: 29472, time: 0.003) nll: 0.924491 \n",
      "(GPU: 0, epoch: 7, iters: 30272, time: 0.003) nll: 0.863235 \n",
      "(GPU: 0, epoch: 7, iters: 31072, time: 0.003) nll: 0.816098 \n",
      "(GPU: 0, epoch: 7, iters: 31872, time: 0.003) nll: 1.029698 \n",
      "(GPU: 0, epoch: 7, iters: 32672, time: 0.003) nll: 0.836933 \n",
      "(GPU: 0, epoch: 7, iters: 33472, time: 0.003) nll: 0.975977 \n",
      "(GPU: 0, epoch: 7, iters: 34272, time: 0.003) nll: 0.761823 \n",
      "(GPU: 0, epoch: 7, iters: 35072, time: 0.003) nll: 0.772249 \n",
      "saving the latest model (epoch 7, total_steps 1020000)\n",
      "(GPU: 0, epoch: 7, iters: 35872, time: 0.003) nll: 0.777541 \n",
      "(GPU: 0, epoch: 7, iters: 36672, time: 0.003) nll: 0.687249 \n",
      "(GPU: 0, epoch: 7, iters: 37472, time: 0.003) nll: 0.924239 \n",
      "(GPU: 0, epoch: 7, iters: 38272, time: 0.003) nll: 0.740049 \n",
      "(GPU: 0, epoch: 7, iters: 39072, time: 0.003) nll: 1.342849 \n",
      "(GPU: 0, epoch: 7, iters: 39872, time: 0.003) nll: 0.697336 \n",
      "(GPU: 0, epoch: 7, iters: 40672, time: 0.003) nll: 0.797122 \n",
      "(GPU: 0, epoch: 7, iters: 41472, time: 0.003) nll: 0.714912 \n",
      "(GPU: 0, epoch: 7, iters: 42272, time: 0.003) nll: 0.951158 \n",
      "(GPU: 0, epoch: 7, iters: 43072, time: 0.003) nll: 0.867146 \n",
      "(GPU: 0, epoch: 7, iters: 43872, time: 0.003) nll: 0.691539 \n",
      "(GPU: 0, epoch: 7, iters: 44672, time: 0.003) nll: 0.729329 \n",
      "(GPU: 0, epoch: 7, iters: 45472, time: 0.003) nll: 0.958277 \n",
      "(GPU: 0, epoch: 7, iters: 46272, time: 0.003) nll: 0.579679 \n",
      "(GPU: 0, epoch: 7, iters: 47072, time: 0.003) nll: 0.755390 \n",
      "(GPU: 0, epoch: 7, iters: 47872, time: 0.003) nll: 0.788466 \n",
      "(GPU: 0, epoch: 7, iters: 48672, time: 0.003) nll: 0.645082 \n",
      "(GPU: 0, epoch: 7, iters: 49472, time: 0.003) nll: 1.164260 \n",
      "(GPU: 0, epoch: 7, iters: 50272, time: 0.003) nll: 0.723731 \n",
      "(GPU: 0, epoch: 7, iters: 51072, time: 0.003) nll: 0.746687 \n",
      "(GPU: 0, epoch: 7, iters: 51872, time: 0.003) nll: 0.593623 \n",
      "(GPU: 0, epoch: 7, iters: 52672, time: 0.003) nll: 1.079953 \n",
      "(GPU: 0, epoch: 7, iters: 53472, time: 0.003) nll: 0.750901 \n",
      "(GPU: 0, epoch: 7, iters: 54272, time: 0.003) nll: 0.853316 \n",
      "(GPU: 0, epoch: 7, iters: 55072, time: 0.003) nll: 0.780064 \n",
      "saving the latest model (epoch 7, total_steps 1040000)\n",
      "(GPU: 0, epoch: 7, iters: 55872, time: 0.003) nll: 0.893270 \n",
      "(GPU: 0, epoch: 7, iters: 56672, time: 0.003) nll: 1.039415 \n",
      "(GPU: 0, epoch: 7, iters: 57472, time: 0.003) nll: 0.872636 \n",
      "(GPU: 0, epoch: 7, iters: 58272, time: 0.003) nll: 0.901909 \n",
      "(GPU: 0, epoch: 7, iters: 59072, time: 0.003) nll: 1.305782 \n",
      "(GPU: 0, epoch: 7, iters: 59872, time: 0.003) nll: 0.724263 \n",
      "(GPU: 0, epoch: 7, iters: 60672, time: 0.003) nll: 0.762132 \n",
      "(GPU: 0, epoch: 7, iters: 61472, time: 0.003) nll: 0.795050 \n",
      "(GPU: 0, epoch: 7, iters: 62272, time: 0.003) nll: 0.928087 \n",
      "(GPU: 0, epoch: 7, iters: 63072, time: 0.003) nll: 0.860628 \n",
      "(GPU: 0, epoch: 7, iters: 63872, time: 0.003) nll: 1.036456 \n",
      "(GPU: 0, epoch: 7, iters: 64672, time: 0.003) nll: 0.960004 \n",
      "(GPU: 0, epoch: 7, iters: 65472, time: 0.003) nll: 0.708099 \n",
      "(GPU: 0, epoch: 7, iters: 66272, time: 0.003) nll: 0.866913 \n",
      "(GPU: 0, epoch: 7, iters: 67072, time: 0.003) nll: 0.618516 \n",
      "(GPU: 0, epoch: 7, iters: 67872, time: 0.003) nll: 0.796009 \n",
      "(GPU: 0, epoch: 7, iters: 68672, time: 0.003) nll: 1.230791 \n",
      "(GPU: 0, epoch: 7, iters: 69472, time: 0.003) nll: 0.594743 \n",
      "(GPU: 0, epoch: 7, iters: 70272, time: 0.003) nll: 0.909943 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.003) nll: 1.078296 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.005) nll: 1.074275 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.005) nll: 1.023036 \n",
      "(GPU: 0, epoch: 7, iters: 71872, time: 0.003) nll: 0.978858 \n",
      "(GPU: 0, epoch: 7, iters: 72672, time: 0.003) nll: 0.758872 \n",
      "(GPU: 0, epoch: 7, iters: 73472, time: 0.003) nll: 0.783255 \n",
      "(GPU: 0, epoch: 7, iters: 74272, time: 0.003) nll: 1.020520 \n",
      "(GPU: 0, epoch: 7, iters: 75072, time: 0.003) nll: 0.725350 \n",
      "saving the latest model (epoch 7, total_steps 1060000)\n",
      "(GPU: 0, epoch: 7, iters: 75872, time: 0.003) nll: 0.903676 \n",
      "(GPU: 0, epoch: 7, iters: 76672, time: 0.003) nll: 0.833200 \n",
      "(GPU: 0, epoch: 7, iters: 77472, time: 0.003) nll: 1.106073 \n",
      "(GPU: 0, epoch: 7, iters: 78272, time: 0.003) nll: 0.748964 \n",
      "(GPU: 0, epoch: 7, iters: 79072, time: 0.003) nll: 0.898613 \n",
      "(GPU: 0, epoch: 7, iters: 79872, time: 0.003) nll: 1.166691 \n",
      "(GPU: 0, epoch: 7, iters: 80672, time: 0.003) nll: 0.870263 \n",
      "(GPU: 0, epoch: 7, iters: 81472, time: 0.003) nll: 0.808476 \n",
      "(GPU: 0, epoch: 7, iters: 82272, time: 0.003) nll: 0.749497 \n",
      "(GPU: 0, epoch: 7, iters: 83072, time: 0.003) nll: 0.898417 \n",
      "(GPU: 0, epoch: 7, iters: 83872, time: 0.003) nll: 0.847220 \n",
      "(GPU: 0, epoch: 7, iters: 84672, time: 0.003) nll: 0.873590 \n",
      "(GPU: 0, epoch: 7, iters: 85472, time: 0.003) nll: 1.010849 \n",
      "(GPU: 0, epoch: 7, iters: 86272, time: 0.003) nll: 0.852303 \n",
      "(GPU: 0, epoch: 7, iters: 87072, time: 0.003) nll: 0.831323 \n",
      "(GPU: 0, epoch: 7, iters: 87872, time: 0.003) nll: 0.758668 \n",
      "(GPU: 0, epoch: 7, iters: 88672, time: 0.003) nll: 0.793650 \n",
      "(GPU: 0, epoch: 7, iters: 89472, time: 0.003) nll: 1.013998 \n",
      "(GPU: 0, epoch: 7, iters: 90272, time: 0.003) nll: 0.915062 \n",
      "(GPU: 0, epoch: 7, iters: 91072, time: 0.003) nll: 0.817131 \n",
      "(GPU: 0, epoch: 7, iters: 91872, time: 0.003) nll: 0.993943 \n",
      "(GPU: 0, epoch: 7, iters: 92672, time: 0.003) nll: 0.988400 \n",
      "(GPU: 0, epoch: 7, iters: 93472, time: 0.003) nll: 0.809177 \n",
      "(GPU: 0, epoch: 7, iters: 94272, time: 0.003) nll: 0.750184 \n",
      "(GPU: 0, epoch: 7, iters: 95072, time: 0.003) nll: 1.056906 \n",
      "saving the latest model (epoch 7, total_steps 1080000)\n",
      "(GPU: 0, epoch: 7, iters: 95872, time: 0.003) nll: 1.030968 \n",
      "(GPU: 0, epoch: 7, iters: 96672, time: 0.003) nll: 0.953999 \n",
      "(GPU: 0, epoch: 7, iters: 97472, time: 0.003) nll: 0.922734 \n",
      "(GPU: 0, epoch: 7, iters: 98272, time: 0.003) nll: 0.684697 \n",
      "(GPU: 0, epoch: 7, iters: 99072, time: 0.003) nll: 0.832207 \n",
      "(GPU: 0, epoch: 7, iters: 99872, time: 0.003) nll: 0.617647 \n",
      "(GPU: 0, epoch: 7, iters: 100672, time: 0.003) nll: 0.823303 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 101472, time: 0.003) nll: 1.000906 \n",
      "(GPU: 0, epoch: 7, iters: 102272, time: 0.003) nll: 0.683742 \n",
      "(GPU: 0, epoch: 7, iters: 103072, time: 0.003) nll: 0.729860 \n",
      "(GPU: 0, epoch: 7, iters: 103872, time: 0.003) nll: 0.623594 \n",
      "(GPU: 0, epoch: 7, iters: 104672, time: 0.003) nll: 0.832024 \n",
      "(GPU: 0, epoch: 7, iters: 105472, time: 0.003) nll: 0.842626 \n",
      "(GPU: 0, epoch: 7, iters: 106272, time: 0.003) nll: 0.948862 \n",
      "(GPU: 0, epoch: 7, iters: 107072, time: 0.003) nll: 0.858434 \n",
      "(GPU: 0, epoch: 7, iters: 107872, time: 0.003) nll: 0.655273 \n",
      "(GPU: 0, epoch: 7, iters: 108672, time: 0.003) nll: 0.924535 \n",
      "(GPU: 0, epoch: 7, iters: 109472, time: 0.003) nll: 0.828868 \n",
      "(GPU: 0, epoch: 7, iters: 110272, time: 0.003) nll: 1.078557 \n",
      "(GPU: 0, epoch: 7, iters: 111072, time: 0.003) nll: 0.807521 \n",
      "(GPU: 0, epoch: 7, iters: 111872, time: 0.003) nll: 0.846991 \n",
      "(GPU: 0, epoch: 7, iters: 112672, time: 0.003) nll: 0.759381 \n",
      "(GPU: 0, epoch: 7, iters: 113472, time: 0.003) nll: 0.741040 \n",
      "(GPU: 0, epoch: 7, iters: 114272, time: 0.003) nll: 1.033911 \n",
      "(GPU: 0, epoch: 7, iters: 115072, time: 0.003) nll: 0.727375 \n",
      "saving the latest model (epoch 7, total_steps 1100000)\n",
      "(GPU: 0, epoch: 7, iters: 115872, time: 0.003) nll: 0.732299 \n",
      "(GPU: 0, epoch: 7, iters: 116672, time: 0.003) nll: 0.802466 \n",
      "(GPU: 0, epoch: 7, iters: 117472, time: 0.003) nll: 0.926245 \n",
      "(GPU: 0, epoch: 7, iters: 118272, time: 0.003) nll: 1.180414 \n",
      "(GPU: 0, epoch: 7, iters: 119072, time: 0.003) nll: 0.960094 \n",
      "(GPU: 0, epoch: 7, iters: 119872, time: 0.003) nll: 0.768511 \n",
      "(GPU: 0, epoch: 7, iters: 120672, time: 0.003) nll: 0.775061 \n",
      "(GPU: 0, epoch: 7, iters: 121472, time: 0.003) nll: 0.787933 \n",
      "(GPU: 0, epoch: 7, iters: 122272, time: 0.003) nll: 0.748801 \n",
      "(GPU: 0, epoch: 7, iters: 123072, time: 0.003) nll: 0.669377 \n",
      "(GPU: 0, epoch: 7, iters: 123872, time: 0.003) nll: 0.753617 \n",
      "(GPU: 0, epoch: 7, iters: 124672, time: 0.003) nll: 0.828574 \n",
      "(GPU: 0, epoch: 7, iters: 125472, time: 0.003) nll: 1.113814 \n",
      "(GPU: 0, epoch: 7, iters: 126272, time: 0.003) nll: 0.836970 \n",
      "(GPU: 0, epoch: 7, iters: 127072, time: 0.003) nll: 0.935876 \n",
      "(GPU: 0, epoch: 7, iters: 127872, time: 0.003) nll: 0.798013 \n",
      "(GPU: 0, epoch: 7, iters: 128672, time: 0.003) nll: 0.886479 \n",
      "(GPU: 0, epoch: 7, iters: 129472, time: 0.003) nll: 0.844696 \n",
      "(GPU: 0, epoch: 7, iters: 130272, time: 0.003) nll: 0.735487 \n",
      "(GPU: 0, epoch: 7, iters: 131072, time: 0.003) nll: 0.765625 \n",
      "(GPU: 0, epoch: 7, iters: 131872, time: 0.003) nll: 0.752397 \n",
      "(GPU: 0, epoch: 7, iters: 132672, time: 0.003) nll: 0.741542 \n",
      "(GPU: 0, epoch: 7, iters: 133472, time: 0.003) nll: 0.801935 \n",
      "(GPU: 0, epoch: 7, iters: 134272, time: 0.003) nll: 0.821658 \n",
      "(GPU: 0, epoch: 7, iters: 135072, time: 0.003) nll: 0.790471 \n",
      "saving the latest model (epoch 7, total_steps 1120000)\n",
      "(GPU: 0, epoch: 7, iters: 135872, time: 0.003) nll: 0.767867 \n",
      "(GPU: 0, epoch: 7, iters: 136672, time: 0.003) nll: 0.785051 \n",
      "(GPU: 0, epoch: 7, iters: 137472, time: 0.003) nll: 0.987251 \n",
      "(GPU: 0, epoch: 7, iters: 138272, time: 0.003) nll: 0.792250 \n",
      "(GPU: 0, epoch: 7, iters: 139072, time: 0.003) nll: 0.705004 \n",
      "(GPU: 0, epoch: 7, iters: 139872, time: 0.003) nll: 0.855539 \n",
      "(GPU: 0, epoch: 7, iters: 140672, time: 0.003) nll: 0.645503 \n",
      "[*] End of epoch 7 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000800\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3174/4397 [06:06<02:33,  7.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 32, time: 0.002) nll: 0.973917 \n",
      "(GPU: 0, epoch: 8, iters: 32, time: 0.002) nll: 0.620879 \n",
      "(GPU: 0, epoch: 8, iters: 768, time: 0.003) nll: 0.740583 \n",
      "(GPU: 0, epoch: 8, iters: 1568, time: 0.003) nll: 0.903572 \n",
      "(GPU: 0, epoch: 8, iters: 2368, time: 0.003) nll: 0.991454 \n",
      "(GPU: 0, epoch: 8, iters: 3168, time: 0.003) nll: 0.700836 \n",
      "(GPU: 0, epoch: 8, iters: 3968, time: 0.003) nll: 0.607399 \n",
      "(GPU: 0, epoch: 8, iters: 4768, time: 0.003) nll: 0.688804 \n",
      "(GPU: 0, epoch: 8, iters: 5568, time: 0.003) nll: 0.763069 \n",
      "(GPU: 0, epoch: 8, iters: 6368, time: 0.003) nll: 0.790410 \n",
      "(GPU: 0, epoch: 8, iters: 7168, time: 0.003) nll: 0.999686 \n",
      "(GPU: 0, epoch: 8, iters: 7968, time: 0.003) nll: 0.709301 \n",
      "(GPU: 0, epoch: 8, iters: 8768, time: 0.003) nll: 0.890924 \n",
      "(GPU: 0, epoch: 8, iters: 9568, time: 0.003) nll: 0.945263 \n",
      "(GPU: 0, epoch: 8, iters: 10368, time: 0.003) nll: 1.163161 \n",
      "(GPU: 0, epoch: 8, iters: 11168, time: 0.003) nll: 0.746355 \n",
      "(GPU: 0, epoch: 8, iters: 11968, time: 0.003) nll: 0.842615 \n",
      "(GPU: 0, epoch: 8, iters: 12768, time: 0.003) nll: 0.970969 \n",
      "(GPU: 0, epoch: 8, iters: 13568, time: 0.003) nll: 0.693333 \n",
      "(GPU: 0, epoch: 8, iters: 14368, time: 0.003) nll: 0.635592 \n",
      "saving the latest model (epoch 8, total_steps 1140000)\n",
      "(GPU: 0, epoch: 8, iters: 15168, time: 0.003) nll: 0.875847 \n",
      "(GPU: 0, epoch: 8, iters: 15968, time: 0.003) nll: 0.746530 \n",
      "(GPU: 0, epoch: 8, iters: 16768, time: 0.003) nll: 0.990700 \n",
      "(GPU: 0, epoch: 8, iters: 17568, time: 0.003) nll: 0.768729 \n",
      "(GPU: 0, epoch: 8, iters: 18368, time: 0.003) nll: 0.833986 \n",
      "(GPU: 0, epoch: 8, iters: 19168, time: 0.003) nll: 0.670175 \n",
      "(GPU: 0, epoch: 8, iters: 19968, time: 0.003) nll: 1.024796 \n",
      "(GPU: 0, epoch: 8, iters: 20768, time: 0.003) nll: 0.770398 \n",
      "(GPU: 0, epoch: 8, iters: 21568, time: 0.003) nll: 0.753026 \n",
      "(GPU: 0, epoch: 8, iters: 22368, time: 0.003) nll: 0.978727 \n",
      "(GPU: 0, epoch: 8, iters: 23168, time: 0.003) nll: 0.808381 \n",
      "(GPU: 0, epoch: 8, iters: 23968, time: 0.003) nll: 1.595382 \n",
      "(GPU: 0, epoch: 8, iters: 24768, time: 0.003) nll: 0.623165 \n",
      "(GPU: 0, epoch: 8, iters: 25568, time: 0.003) nll: 0.740295 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.003) nll: 0.854464 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.005) nll: 0.836031 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.005) nll: 0.934930 \n",
      "(GPU: 0, epoch: 8, iters: 27168, time: 0.003) nll: 0.599470 \n",
      "(GPU: 0, epoch: 8, iters: 27968, time: 0.003) nll: 1.111375 \n",
      "(GPU: 0, epoch: 8, iters: 28768, time: 0.003) nll: 0.674155 \n",
      "(GPU: 0, epoch: 8, iters: 29568, time: 0.003) nll: 0.796417 \n",
      "(GPU: 0, epoch: 8, iters: 30368, time: 0.003) nll: 0.702073 \n",
      "(GPU: 0, epoch: 8, iters: 31168, time: 0.003) nll: 0.890351 \n",
      "(GPU: 0, epoch: 8, iters: 31968, time: 0.003) nll: 0.841091 \n",
      "(GPU: 0, epoch: 8, iters: 32768, time: 0.003) nll: 0.933847 \n",
      "(GPU: 0, epoch: 8, iters: 33568, time: 0.003) nll: 0.945323 \n",
      "(GPU: 0, epoch: 8, iters: 34368, time: 0.003) nll: 0.745917 \n",
      "saving the latest model (epoch 8, total_steps 1160000)\n",
      "(GPU: 0, epoch: 8, iters: 35168, time: 0.003) nll: 0.858271 \n",
      "(GPU: 0, epoch: 8, iters: 35968, time: 0.003) nll: 0.724514 \n",
      "(GPU: 0, epoch: 8, iters: 36768, time: 0.003) nll: 0.739335 \n",
      "(GPU: 0, epoch: 8, iters: 37568, time: 0.003) nll: 0.805505 \n",
      "(GPU: 0, epoch: 8, iters: 38368, time: 0.003) nll: 0.856897 \n",
      "(GPU: 0, epoch: 8, iters: 39168, time: 0.003) nll: 1.294907 \n",
      "(GPU: 0, epoch: 8, iters: 39968, time: 0.003) nll: 0.735247 \n",
      "(GPU: 0, epoch: 8, iters: 40768, time: 0.003) nll: 0.567638 \n",
      "(GPU: 0, epoch: 8, iters: 41568, time: 0.003) nll: 0.913354 \n",
      "(GPU: 0, epoch: 8, iters: 42368, time: 0.003) nll: 0.821837 \n",
      "(GPU: 0, epoch: 8, iters: 43168, time: 0.003) nll: 0.763404 \n",
      "(GPU: 0, epoch: 8, iters: 43968, time: 0.003) nll: 0.788791 \n",
      "(GPU: 0, epoch: 8, iters: 44768, time: 0.003) nll: 0.946264 \n",
      "(GPU: 0, epoch: 8, iters: 45568, time: 0.003) nll: 0.721241 \n",
      "(GPU: 0, epoch: 8, iters: 46368, time: 0.003) nll: 0.993415 \n",
      "(GPU: 0, epoch: 8, iters: 47168, time: 0.003) nll: 0.929044 \n",
      "(GPU: 0, epoch: 8, iters: 47968, time: 0.003) nll: 0.838060 \n",
      "(GPU: 0, epoch: 8, iters: 48768, time: 0.003) nll: 0.687267 \n",
      "(GPU: 0, epoch: 8, iters: 49568, time: 0.003) nll: 0.885098 \n",
      "(GPU: 0, epoch: 8, iters: 50368, time: 0.003) nll: 0.627391 \n",
      "(GPU: 0, epoch: 8, iters: 51168, time: 0.003) nll: 1.167549 \n",
      "(GPU: 0, epoch: 8, iters: 51968, time: 0.003) nll: 0.838424 \n",
      "(GPU: 0, epoch: 8, iters: 52768, time: 0.003) nll: 0.850562 \n",
      "(GPU: 0, epoch: 8, iters: 53568, time: 0.003) nll: 0.920949 \n",
      "(GPU: 0, epoch: 8, iters: 54368, time: 0.003) nll: 0.626806 \n",
      "saving the latest model (epoch 8, total_steps 1180000)\n",
      "(GPU: 0, epoch: 8, iters: 55168, time: 0.003) nll: 0.901482 \n",
      "(GPU: 0, epoch: 8, iters: 55968, time: 0.003) nll: 1.314251 \n",
      "(GPU: 0, epoch: 8, iters: 56768, time: 0.003) nll: 0.822707 \n",
      "(GPU: 0, epoch: 8, iters: 57568, time: 0.003) nll: 0.836470 \n",
      "(GPU: 0, epoch: 8, iters: 58368, time: 0.003) nll: 0.931047 \n",
      "(GPU: 0, epoch: 8, iters: 59168, time: 0.003) nll: 0.759147 \n",
      "(GPU: 0, epoch: 8, iters: 59968, time: 0.003) nll: 0.752526 \n",
      "(GPU: 0, epoch: 8, iters: 60768, time: 0.003) nll: 0.767115 \n",
      "(GPU: 0, epoch: 8, iters: 61568, time: 0.003) nll: 0.742571 \n",
      "(GPU: 0, epoch: 8, iters: 62368, time: 0.003) nll: 0.889109 \n",
      "(GPU: 0, epoch: 8, iters: 63168, time: 0.003) nll: 0.853900 \n",
      "(GPU: 0, epoch: 8, iters: 63968, time: 0.003) nll: 0.723211 \n",
      "(GPU: 0, epoch: 8, iters: 64768, time: 0.003) nll: 1.040630 \n",
      "(GPU: 0, epoch: 8, iters: 65568, time: 0.003) nll: 0.822604 \n",
      "(GPU: 0, epoch: 8, iters: 66368, time: 0.003) nll: 0.728129 \n",
      "(GPU: 0, epoch: 8, iters: 67168, time: 0.003) nll: 0.833737 \n",
      "(GPU: 0, epoch: 8, iters: 67968, time: 0.003) nll: 0.777404 \n",
      "(GPU: 0, epoch: 8, iters: 68768, time: 0.003) nll: 0.925699 \n",
      "(GPU: 0, epoch: 8, iters: 69568, time: 0.003) nll: 0.850529 \n",
      "(GPU: 0, epoch: 8, iters: 70368, time: 0.003) nll: 0.827649 \n",
      "(GPU: 0, epoch: 8, iters: 71168, time: 0.003) nll: 0.792024 \n",
      "(GPU: 0, epoch: 8, iters: 71968, time: 0.003) nll: 0.994078 \n",
      "(GPU: 0, epoch: 8, iters: 72768, time: 0.003) nll: 0.639850 \n",
      "(GPU: 0, epoch: 8, iters: 73568, time: 0.003) nll: 0.774713 \n",
      "(GPU: 0, epoch: 8, iters: 74368, time: 0.003) nll: 0.880123 \n",
      "saving the latest model (epoch 8, total_steps 1200000)\n",
      "(GPU: 0, epoch: 8, iters: 75168, time: 0.003) nll: 0.720296 \n",
      "(GPU: 0, epoch: 8, iters: 75968, time: 0.003) nll: 1.012150 \n",
      "(GPU: 0, epoch: 8, iters: 76768, time: 0.003) nll: 0.868118 \n",
      "(GPU: 0, epoch: 8, iters: 77568, time: 0.003) nll: 0.891466 \n",
      "(GPU: 0, epoch: 8, iters: 78368, time: 0.003) nll: 1.059241 \n",
      "(GPU: 0, epoch: 8, iters: 79168, time: 0.003) nll: 0.758523 \n",
      "(GPU: 0, epoch: 8, iters: 79968, time: 0.003) nll: 0.766206 \n",
      "(GPU: 0, epoch: 8, iters: 80768, time: 0.003) nll: 0.816761 \n",
      "(GPU: 0, epoch: 8, iters: 81568, time: 0.003) nll: 0.795900 \n",
      "(GPU: 0, epoch: 8, iters: 82368, time: 0.003) nll: 0.911053 \n",
      "(GPU: 0, epoch: 8, iters: 83168, time: 0.003) nll: 1.332848 \n",
      "(GPU: 0, epoch: 8, iters: 83968, time: 0.003) nll: 0.798475 \n",
      "(GPU: 0, epoch: 8, iters: 84768, time: 0.003) nll: 0.750697 \n",
      "(GPU: 0, epoch: 8, iters: 85568, time: 0.003) nll: 0.589909 \n",
      "(GPU: 0, epoch: 8, iters: 86368, time: 0.003) nll: 0.908216 \n",
      "(GPU: 0, epoch: 8, iters: 87168, time: 0.003) nll: 0.735544 \n",
      "(GPU: 0, epoch: 8, iters: 87968, time: 0.003) nll: 0.995934 \n",
      "(GPU: 0, epoch: 8, iters: 88768, time: 0.003) nll: 1.050320 \n",
      "(GPU: 0, epoch: 8, iters: 89568, time: 0.003) nll: 1.098724 \n",
      "(GPU: 0, epoch: 8, iters: 90368, time: 0.003) nll: 0.943234 \n",
      "(GPU: 0, epoch: 8, iters: 91168, time: 0.003) nll: 0.801624 \n",
      "(GPU: 0, epoch: 8, iters: 91968, time: 0.003) nll: 1.093806 \n",
      "(GPU: 0, epoch: 8, iters: 92768, time: 0.003) nll: 1.477023 \n",
      "(GPU: 0, epoch: 8, iters: 93568, time: 0.003) nll: 0.708950 \n",
      "(GPU: 0, epoch: 8, iters: 94368, time: 0.003) nll: 0.705934 \n",
      "saving the latest model (epoch 8, total_steps 1220000)\n",
      "(GPU: 0, epoch: 8, iters: 95168, time: 0.003) nll: 0.679082 \n",
      "(GPU: 0, epoch: 8, iters: 95968, time: 0.003) nll: 1.007281 \n",
      "(GPU: 0, epoch: 8, iters: 96768, time: 0.003) nll: 0.814141 \n",
      "(GPU: 0, epoch: 8, iters: 97568, time: 0.003) nll: 0.711611 \n",
      "(GPU: 0, epoch: 8, iters: 98368, time: 0.003) nll: 0.882210 \n",
      "(GPU: 0, epoch: 8, iters: 99168, time: 0.003) nll: 0.965674 \n",
      "(GPU: 0, epoch: 8, iters: 99968, time: 0.003) nll: 0.723876 \n",
      "(GPU: 0, epoch: 8, iters: 100768, time: 0.003) nll: 0.964099 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:28<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 101568, time: 0.003) nll: 0.690636 \n",
      "(GPU: 0, epoch: 8, iters: 102368, time: 0.003) nll: 0.966784 \n",
      "(GPU: 0, epoch: 8, iters: 103168, time: 0.003) nll: 0.694995 \n",
      "(GPU: 0, epoch: 8, iters: 103968, time: 0.003) nll: 0.943456 \n",
      "(GPU: 0, epoch: 8, iters: 104768, time: 0.003) nll: 0.845968 \n",
      "(GPU: 0, epoch: 8, iters: 105568, time: 0.003) nll: 0.960324 \n",
      "(GPU: 0, epoch: 8, iters: 106368, time: 0.003) nll: 0.903989 \n",
      "(GPU: 0, epoch: 8, iters: 107168, time: 0.003) nll: 0.552253 \n",
      "(GPU: 0, epoch: 8, iters: 107968, time: 0.003) nll: 0.581206 \n",
      "(GPU: 0, epoch: 8, iters: 108768, time: 0.003) nll: 0.762282 \n",
      "(GPU: 0, epoch: 8, iters: 109568, time: 0.003) nll: 1.004611 \n",
      "(GPU: 0, epoch: 8, iters: 110368, time: 0.003) nll: 0.730160 \n",
      "(GPU: 0, epoch: 8, iters: 111168, time: 0.003) nll: 0.828247 \n",
      "(GPU: 0, epoch: 8, iters: 111968, time: 0.003) nll: 0.838471 \n",
      "(GPU: 0, epoch: 8, iters: 112768, time: 0.003) nll: 0.748680 \n",
      "(GPU: 0, epoch: 8, iters: 113568, time: 0.003) nll: 0.782783 \n",
      "(GPU: 0, epoch: 8, iters: 114368, time: 0.003) nll: 1.060333 \n",
      "saving the latest model (epoch 8, total_steps 1240000)\n",
      "(GPU: 0, epoch: 8, iters: 115168, time: 0.003) nll: 0.708376 \n",
      "(GPU: 0, epoch: 8, iters: 115968, time: 0.003) nll: 0.860355 \n",
      "(GPU: 0, epoch: 8, iters: 116768, time: 0.003) nll: 0.819575 \n",
      "(GPU: 0, epoch: 8, iters: 117568, time: 0.003) nll: 0.671785 \n",
      "(GPU: 0, epoch: 8, iters: 118368, time: 0.003) nll: 0.904013 \n",
      "(GPU: 0, epoch: 8, iters: 119168, time: 0.003) nll: 0.865992 \n",
      "(GPU: 0, epoch: 8, iters: 119968, time: 0.003) nll: 0.809429 \n",
      "(GPU: 0, epoch: 8, iters: 120768, time: 0.003) nll: 0.702278 \n",
      "(GPU: 0, epoch: 8, iters: 121568, time: 0.003) nll: 1.069250 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.003) nll: 0.865910 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.005) nll: 0.865743 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.005) nll: 0.848810 \n",
      "(GPU: 0, epoch: 8, iters: 123168, time: 0.003) nll: 0.949672 \n",
      "(GPU: 0, epoch: 8, iters: 123968, time: 0.003) nll: 0.798641 \n",
      "(GPU: 0, epoch: 8, iters: 124768, time: 0.003) nll: 0.584524 \n",
      "(GPU: 0, epoch: 8, iters: 125568, time: 0.003) nll: 0.775686 \n",
      "(GPU: 0, epoch: 8, iters: 126368, time: 0.003) nll: 0.819411 \n",
      "(GPU: 0, epoch: 8, iters: 127168, time: 0.003) nll: 0.675408 \n",
      "(GPU: 0, epoch: 8, iters: 127968, time: 0.003) nll: 0.868613 \n",
      "(GPU: 0, epoch: 8, iters: 128768, time: 0.003) nll: 0.771236 \n",
      "(GPU: 0, epoch: 8, iters: 129568, time: 0.003) nll: 0.669178 \n",
      "(GPU: 0, epoch: 8, iters: 130368, time: 0.003) nll: 0.794404 \n",
      "(GPU: 0, epoch: 8, iters: 131168, time: 0.003) nll: 1.068967 \n",
      "(GPU: 0, epoch: 8, iters: 131968, time: 0.003) nll: 0.986259 \n",
      "(GPU: 0, epoch: 8, iters: 132768, time: 0.003) nll: 0.899447 \n",
      "(GPU: 0, epoch: 8, iters: 133568, time: 0.003) nll: 0.881213 \n",
      "(GPU: 0, epoch: 8, iters: 134368, time: 0.003) nll: 0.941404 \n",
      "saving the latest model (epoch 8, total_steps 1260000)\n",
      "(GPU: 0, epoch: 8, iters: 135168, time: 0.003) nll: 0.783630 \n",
      "(GPU: 0, epoch: 8, iters: 135968, time: 0.003) nll: 0.988279 \n",
      "(GPU: 0, epoch: 8, iters: 136768, time: 0.003) nll: 0.948334 \n",
      "(GPU: 0, epoch: 8, iters: 137568, time: 0.003) nll: 0.656228 \n",
      "(GPU: 0, epoch: 8, iters: 138368, time: 0.003) nll: 0.856970 \n",
      "(GPU: 0, epoch: 8, iters: 139168, time: 0.003) nll: 0.772854 \n",
      "(GPU: 0, epoch: 8, iters: 139968, time: 0.003) nll: 0.678020 \n",
      "[*] End of epoch 8 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000900\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3152/4397 [06:04<02:35,  8.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 32, time: 0.002) nll: 0.940670 \n",
      "(GPU: 0, epoch: 9, iters: 32, time: 0.002) nll: 0.926684 \n",
      "(GPU: 0, epoch: 9, iters: 64, time: 0.002) nll: 0.897867 \n",
      "(GPU: 0, epoch: 9, iters: 864, time: 0.003) nll: 0.792564 \n",
      "(GPU: 0, epoch: 9, iters: 1664, time: 0.003) nll: 0.982916 \n",
      "(GPU: 0, epoch: 9, iters: 2464, time: 0.003) nll: 0.884587 \n",
      "(GPU: 0, epoch: 9, iters: 3264, time: 0.003) nll: 0.689603 \n",
      "(GPU: 0, epoch: 9, iters: 4064, time: 0.003) nll: 0.612720 \n",
      "(GPU: 0, epoch: 9, iters: 4864, time: 0.003) nll: 0.899003 \n",
      "(GPU: 0, epoch: 9, iters: 5664, time: 0.003) nll: 0.970956 \n",
      "(GPU: 0, epoch: 9, iters: 6464, time: 0.003) nll: 0.901188 \n",
      "(GPU: 0, epoch: 9, iters: 7264, time: 0.003) nll: 0.941810 \n",
      "(GPU: 0, epoch: 9, iters: 8064, time: 0.003) nll: 0.863581 \n",
      "(GPU: 0, epoch: 9, iters: 8864, time: 0.003) nll: 0.952039 \n",
      "(GPU: 0, epoch: 9, iters: 9664, time: 0.003) nll: 1.104469 \n",
      "(GPU: 0, epoch: 9, iters: 10464, time: 0.003) nll: 0.774015 \n",
      "(GPU: 0, epoch: 9, iters: 11264, time: 0.003) nll: 0.837586 \n",
      "(GPU: 0, epoch: 9, iters: 12064, time: 0.003) nll: 0.778757 \n",
      "(GPU: 0, epoch: 9, iters: 12864, time: 0.003) nll: 0.895156 \n",
      "(GPU: 0, epoch: 9, iters: 13664, time: 0.003) nll: 0.954910 \n",
      "saving the latest model (epoch 9, total_steps 1280000)\n",
      "(GPU: 0, epoch: 9, iters: 14464, time: 0.003) nll: 0.691787 \n",
      "(GPU: 0, epoch: 9, iters: 15264, time: 0.003) nll: 0.920392 \n",
      "(GPU: 0, epoch: 9, iters: 16064, time: 0.003) nll: 0.907317 \n",
      "(GPU: 0, epoch: 9, iters: 16864, time: 0.003) nll: 0.939950 \n",
      "(GPU: 0, epoch: 9, iters: 17664, time: 0.003) nll: 0.965642 \n",
      "(GPU: 0, epoch: 9, iters: 18464, time: 0.003) nll: 0.818858 \n",
      "(GPU: 0, epoch: 9, iters: 19264, time: 0.003) nll: 0.759750 \n",
      "(GPU: 0, epoch: 9, iters: 20064, time: 0.003) nll: 1.106114 \n",
      "(GPU: 0, epoch: 9, iters: 20864, time: 0.003) nll: 1.145572 \n",
      "(GPU: 0, epoch: 9, iters: 21664, time: 0.003) nll: 0.655672 \n",
      "(GPU: 0, epoch: 9, iters: 22464, time: 0.003) nll: 0.783715 \n",
      "(GPU: 0, epoch: 9, iters: 23264, time: 0.003) nll: 1.052194 \n",
      "(GPU: 0, epoch: 9, iters: 24064, time: 0.003) nll: 0.518353 \n",
      "(GPU: 0, epoch: 9, iters: 24864, time: 0.003) nll: 0.884287 \n",
      "(GPU: 0, epoch: 9, iters: 25664, time: 0.003) nll: 0.672285 \n",
      "(GPU: 0, epoch: 9, iters: 26464, time: 0.003) nll: 0.976212 \n",
      "(GPU: 0, epoch: 9, iters: 27264, time: 0.003) nll: 0.715457 \n",
      "(GPU: 0, epoch: 9, iters: 28064, time: 0.003) nll: 0.770685 \n",
      "(GPU: 0, epoch: 9, iters: 28864, time: 0.003) nll: 0.787244 \n",
      "(GPU: 0, epoch: 9, iters: 29664, time: 0.003) nll: 0.777499 \n",
      "(GPU: 0, epoch: 9, iters: 30464, time: 0.003) nll: 0.759142 \n",
      "(GPU: 0, epoch: 9, iters: 31264, time: 0.003) nll: 1.020307 \n",
      "(GPU: 0, epoch: 9, iters: 32064, time: 0.003) nll: 0.791491 \n",
      "(GPU: 0, epoch: 9, iters: 32864, time: 0.003) nll: 0.663190 \n",
      "(GPU: 0, epoch: 9, iters: 33664, time: 0.003) nll: 0.772555 \n",
      "saving the latest model (epoch 9, total_steps 1300000)\n",
      "(GPU: 0, epoch: 9, iters: 34464, time: 0.003) nll: 0.960707 \n",
      "(GPU: 0, epoch: 9, iters: 35264, time: 0.003) nll: 1.006433 \n",
      "(GPU: 0, epoch: 9, iters: 36064, time: 0.003) nll: 0.730151 \n",
      "(GPU: 0, epoch: 9, iters: 36864, time: 0.003) nll: 0.849129 \n",
      "(GPU: 0, epoch: 9, iters: 37664, time: 0.003) nll: 0.774676 \n",
      "(GPU: 0, epoch: 9, iters: 38464, time: 0.003) nll: 0.715350 \n",
      "(GPU: 0, epoch: 9, iters: 39264, time: 0.003) nll: 0.637403 \n",
      "(GPU: 0, epoch: 9, iters: 40064, time: 0.003) nll: 0.799852 \n",
      "(GPU: 0, epoch: 9, iters: 40864, time: 0.003) nll: 0.556631 \n",
      "(GPU: 0, epoch: 9, iters: 41664, time: 0.003) nll: 0.907459 \n",
      "(GPU: 0, epoch: 9, iters: 42464, time: 0.003) nll: 0.935292 \n",
      "(GPU: 0, epoch: 9, iters: 43264, time: 0.003) nll: 0.807042 \n",
      "(GPU: 0, epoch: 9, iters: 44064, time: 0.003) nll: 0.809257 \n",
      "(GPU: 0, epoch: 9, iters: 44864, time: 0.003) nll: 0.688308 \n",
      "(GPU: 0, epoch: 9, iters: 45664, time: 0.003) nll: 0.948467 \n",
      "(GPU: 0, epoch: 9, iters: 46464, time: 0.003) nll: 0.930415 \n",
      "(GPU: 0, epoch: 9, iters: 47264, time: 0.003) nll: 0.725265 \n",
      "(GPU: 0, epoch: 9, iters: 48064, time: 0.003) nll: 0.622366 \n",
      "(GPU: 0, epoch: 9, iters: 48864, time: 0.003) nll: 0.972810 \n",
      "(GPU: 0, epoch: 9, iters: 49664, time: 0.003) nll: 0.862948 \n",
      "(GPU: 0, epoch: 9, iters: 50464, time: 0.003) nll: 0.815283 \n",
      "(GPU: 0, epoch: 9, iters: 51264, time: 0.003) nll: 0.949640 \n",
      "(GPU: 0, epoch: 9, iters: 52064, time: 0.003) nll: 0.903803 \n",
      "(GPU: 0, epoch: 9, iters: 52864, time: 0.003) nll: 0.924985 \n",
      "(GPU: 0, epoch: 9, iters: 53664, time: 0.003) nll: 1.074032 \n",
      "saving the latest model (epoch 9, total_steps 1320000)\n",
      "(GPU: 0, epoch: 9, iters: 54464, time: 0.003) nll: 0.859782 \n",
      "(GPU: 0, epoch: 9, iters: 55264, time: 0.003) nll: 0.932852 \n",
      "(GPU: 0, epoch: 9, iters: 56064, time: 0.003) nll: 0.763989 \n",
      "(GPU: 0, epoch: 9, iters: 56864, time: 0.003) nll: 0.857885 \n",
      "(GPU: 0, epoch: 9, iters: 57664, time: 0.003) nll: 0.840271 \n",
      "(GPU: 0, epoch: 9, iters: 58464, time: 0.003) nll: 0.898623 \n",
      "(GPU: 0, epoch: 9, iters: 59264, time: 0.003) nll: 0.734789 \n",
      "(GPU: 0, epoch: 9, iters: 60064, time: 0.003) nll: 0.895147 \n",
      "(GPU: 0, epoch: 9, iters: 60864, time: 0.003) nll: 0.928474 \n",
      "(GPU: 0, epoch: 9, iters: 61664, time: 0.003) nll: 0.951564 \n",
      "(GPU: 0, epoch: 9, iters: 62464, time: 0.003) nll: 0.855542 \n",
      "(GPU: 0, epoch: 9, iters: 63264, time: 0.003) nll: 1.080310 \n",
      "(GPU: 0, epoch: 9, iters: 64064, time: 0.003) nll: 0.944984 \n",
      "(GPU: 0, epoch: 9, iters: 64864, time: 0.003) nll: 0.834645 \n",
      "(GPU: 0, epoch: 9, iters: 65664, time: 0.003) nll: 1.007355 \n",
      "(GPU: 0, epoch: 9, iters: 66464, time: 0.003) nll: 0.737554 \n",
      "(GPU: 0, epoch: 9, iters: 67264, time: 0.003) nll: 0.785478 \n",
      "(GPU: 0, epoch: 9, iters: 68064, time: 0.003) nll: 0.661906 \n",
      "(GPU: 0, epoch: 9, iters: 68864, time: 0.003) nll: 0.785847 \n",
      "(GPU: 0, epoch: 9, iters: 69664, time: 0.003) nll: 0.838161 \n",
      "(GPU: 0, epoch: 9, iters: 70464, time: 0.003) nll: 0.738759 \n",
      "(GPU: 0, epoch: 9, iters: 71264, time: 0.003) nll: 0.603509 \n",
      "(GPU: 0, epoch: 9, iters: 72064, time: 0.003) nll: 0.761291 \n",
      "(GPU: 0, epoch: 9, iters: 72864, time: 0.003) nll: 1.000048 \n",
      "(GPU: 0, epoch: 9, iters: 73664, time: 0.003) nll: 0.814212 \n",
      "saving the latest model (epoch 9, total_steps 1340000)\n",
      "(GPU: 0, epoch: 9, iters: 74464, time: 0.003) nll: 1.153503 \n",
      "(GPU: 0, epoch: 9, iters: 75264, time: 0.003) nll: 0.608046 \n",
      "(GPU: 0, epoch: 9, iters: 76064, time: 0.003) nll: 0.814413 \n",
      "(GPU: 0, epoch: 9, iters: 76864, time: 0.003) nll: 0.818976 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.003) nll: 1.039888 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.005) nll: 1.035118 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.005) nll: 0.708657 \n",
      "(GPU: 0, epoch: 9, iters: 78464, time: 0.003) nll: 0.814024 \n",
      "(GPU: 0, epoch: 9, iters: 79264, time: 0.003) nll: 0.892901 \n",
      "(GPU: 0, epoch: 9, iters: 80064, time: 0.003) nll: 0.879394 \n",
      "(GPU: 0, epoch: 9, iters: 80864, time: 0.003) nll: 0.747628 \n",
      "(GPU: 0, epoch: 9, iters: 81664, time: 0.003) nll: 0.790455 \n",
      "(GPU: 0, epoch: 9, iters: 82464, time: 0.003) nll: 0.658963 \n",
      "(GPU: 0, epoch: 9, iters: 83264, time: 0.003) nll: 0.631354 \n",
      "(GPU: 0, epoch: 9, iters: 84064, time: 0.003) nll: 1.004269 \n",
      "(GPU: 0, epoch: 9, iters: 84864, time: 0.003) nll: 0.930675 \n",
      "(GPU: 0, epoch: 9, iters: 85664, time: 0.003) nll: 1.109678 \n",
      "(GPU: 0, epoch: 9, iters: 86464, time: 0.003) nll: 0.907245 \n",
      "(GPU: 0, epoch: 9, iters: 87264, time: 0.003) nll: 0.847502 \n",
      "(GPU: 0, epoch: 9, iters: 88064, time: 0.003) nll: 0.689790 \n",
      "(GPU: 0, epoch: 9, iters: 88864, time: 0.003) nll: 1.030146 \n",
      "(GPU: 0, epoch: 9, iters: 89664, time: 0.003) nll: 0.773032 \n",
      "(GPU: 0, epoch: 9, iters: 90464, time: 0.003) nll: 1.025335 \n",
      "(GPU: 0, epoch: 9, iters: 91264, time: 0.003) nll: 0.816548 \n",
      "(GPU: 0, epoch: 9, iters: 92064, time: 0.003) nll: 1.045870 \n",
      "(GPU: 0, epoch: 9, iters: 92864, time: 0.003) nll: 0.805234 \n",
      "(GPU: 0, epoch: 9, iters: 93664, time: 0.003) nll: 0.855530 \n",
      "saving the latest model (epoch 9, total_steps 1360000)\n",
      "(GPU: 0, epoch: 9, iters: 94464, time: 0.003) nll: 0.776383 \n",
      "(GPU: 0, epoch: 9, iters: 95264, time: 0.003) nll: 0.926467 \n",
      "(GPU: 0, epoch: 9, iters: 96064, time: 0.003) nll: 1.039083 \n",
      "(GPU: 0, epoch: 9, iters: 96864, time: 0.003) nll: 0.767289 \n",
      "(GPU: 0, epoch: 9, iters: 97664, time: 0.003) nll: 0.617624 \n",
      "(GPU: 0, epoch: 9, iters: 98464, time: 0.003) nll: 0.726095 \n",
      "(GPU: 0, epoch: 9, iters: 99264, time: 0.003) nll: 0.804920 \n",
      "(GPU: 0, epoch: 9, iters: 100064, time: 0.003) nll: 0.996402 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 100864, time: 0.003) nll: 0.669283 \n",
      "(GPU: 0, epoch: 9, iters: 101664, time: 0.003) nll: 0.991609 \n",
      "(GPU: 0, epoch: 9, iters: 102464, time: 0.003) nll: 0.682534 \n",
      "(GPU: 0, epoch: 9, iters: 103264, time: 0.003) nll: 0.943430 \n",
      "(GPU: 0, epoch: 9, iters: 104064, time: 0.003) nll: 0.812421 \n",
      "(GPU: 0, epoch: 9, iters: 104864, time: 0.003) nll: 0.995107 \n",
      "(GPU: 0, epoch: 9, iters: 105664, time: 0.003) nll: 0.811597 \n",
      "(GPU: 0, epoch: 9, iters: 106464, time: 0.003) nll: 0.762313 \n",
      "(GPU: 0, epoch: 9, iters: 107264, time: 0.003) nll: 0.721220 \n",
      "(GPU: 0, epoch: 9, iters: 108064, time: 0.003) nll: 0.841334 \n",
      "(GPU: 0, epoch: 9, iters: 108864, time: 0.003) nll: 0.752178 \n",
      "(GPU: 0, epoch: 9, iters: 109664, time: 0.003) nll: 0.832100 \n",
      "(GPU: 0, epoch: 9, iters: 110464, time: 0.003) nll: 0.808243 \n",
      "(GPU: 0, epoch: 9, iters: 111264, time: 0.003) nll: 0.823141 \n",
      "(GPU: 0, epoch: 9, iters: 112064, time: 0.003) nll: 0.625885 \n",
      "(GPU: 0, epoch: 9, iters: 112864, time: 0.003) nll: 0.745258 \n",
      "(GPU: 0, epoch: 9, iters: 113664, time: 0.003) nll: 0.912717 \n",
      "saving the latest model (epoch 9, total_steps 1380000)\n",
      "(GPU: 0, epoch: 9, iters: 114464, time: 0.003) nll: 0.928390 \n",
      "(GPU: 0, epoch: 9, iters: 115264, time: 0.003) nll: 1.258606 \n",
      "(GPU: 0, epoch: 9, iters: 116064, time: 0.003) nll: 0.745885 \n",
      "(GPU: 0, epoch: 9, iters: 116864, time: 0.003) nll: 0.706987 \n",
      "(GPU: 0, epoch: 9, iters: 117664, time: 0.003) nll: 0.787319 \n",
      "(GPU: 0, epoch: 9, iters: 118464, time: 0.003) nll: 0.785747 \n",
      "(GPU: 0, epoch: 9, iters: 119264, time: 0.003) nll: 0.740920 \n",
      "(GPU: 0, epoch: 9, iters: 120064, time: 0.003) nll: 0.674246 \n",
      "(GPU: 0, epoch: 9, iters: 120864, time: 0.003) nll: 0.823456 \n",
      "(GPU: 0, epoch: 9, iters: 121664, time: 0.003) nll: 0.880299 \n",
      "(GPU: 0, epoch: 9, iters: 122464, time: 0.003) nll: 0.683777 \n",
      "(GPU: 0, epoch: 9, iters: 123264, time: 0.003) nll: 1.055693 \n",
      "(GPU: 0, epoch: 9, iters: 124064, time: 0.003) nll: 0.890729 \n",
      "(GPU: 0, epoch: 9, iters: 124864, time: 0.003) nll: 0.957001 \n",
      "(GPU: 0, epoch: 9, iters: 125664, time: 0.003) nll: 0.839325 \n",
      "(GPU: 0, epoch: 9, iters: 126464, time: 0.003) nll: 0.804564 \n",
      "(GPU: 0, epoch: 9, iters: 127264, time: 0.003) nll: 0.659164 \n",
      "(GPU: 0, epoch: 9, iters: 128064, time: 0.003) nll: 0.722777 \n",
      "(GPU: 0, epoch: 9, iters: 128864, time: 0.003) nll: 0.822255 \n",
      "(GPU: 0, epoch: 9, iters: 129664, time: 0.003) nll: 0.820376 \n",
      "(GPU: 0, epoch: 9, iters: 130464, time: 0.003) nll: 0.701301 \n",
      "(GPU: 0, epoch: 9, iters: 131264, time: 0.003) nll: 0.674785 \n",
      "(GPU: 0, epoch: 9, iters: 132064, time: 0.003) nll: 1.021860 \n",
      "(GPU: 0, epoch: 9, iters: 132864, time: 0.003) nll: 0.926559 \n",
      "(GPU: 0, epoch: 9, iters: 133664, time: 0.003) nll: 1.063149 \n",
      "saving the latest model (epoch 9, total_steps 1400000)\n",
      "(GPU: 0, epoch: 9, iters: 134464, time: 0.003) nll: 0.754264 \n",
      "(GPU: 0, epoch: 9, iters: 135264, time: 0.003) nll: 0.799181 \n",
      "(GPU: 0, epoch: 9, iters: 136064, time: 0.003) nll: 0.786131 \n",
      "(GPU: 0, epoch: 9, iters: 136864, time: 0.003) nll: 0.720276 \n",
      "(GPU: 0, epoch: 9, iters: 137664, time: 0.003) nll: 0.945519 \n",
      "(GPU: 0, epoch: 9, iters: 138464, time: 0.003) nll: 0.675714 \n",
      "(GPU: 0, epoch: 9, iters: 139264, time: 0.003) nll: 0.764646 \n",
      "(GPU: 0, epoch: 9, iters: 140064, time: 0.003) nll: 1.075778 \n",
      "saving the model at the end of epoch 9, iters 1407040\n",
      "([test] GPU: 0, epoch: 9) \n",
      "OrderedDict()\n",
      "[*] End of epoch 9 / 25 \t Time Taken: 522 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0001000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3080/4397 [05:57<02:45,  7.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 32, time: 0.002) nll: 0.748130 \n",
      "(GPU: 0, epoch: 10, iters: 32, time: 0.002) nll: 0.915795 \n",
      "(GPU: 0, epoch: 10, iters: 160, time: 0.003) nll: 0.790892 \n",
      "(GPU: 0, epoch: 10, iters: 960, time: 0.003) nll: 0.915349 \n",
      "(GPU: 0, epoch: 10, iters: 1760, time: 0.003) nll: 0.918529 \n",
      "(GPU: 0, epoch: 10, iters: 2560, time: 0.003) nll: 0.763452 \n",
      "(GPU: 0, epoch: 10, iters: 3360, time: 0.003) nll: 0.781397 \n",
      "(GPU: 0, epoch: 10, iters: 4160, time: 0.003) nll: 0.743299 \n",
      "(GPU: 0, epoch: 10, iters: 4960, time: 0.003) nll: 0.777682 \n",
      "(GPU: 0, epoch: 10, iters: 5760, time: 0.003) nll: 0.903720 \n",
      "(GPU: 0, epoch: 10, iters: 6560, time: 0.003) nll: 0.796541 \n",
      "(GPU: 0, epoch: 10, iters: 7360, time: 0.003) nll: 0.884533 \n",
      "(GPU: 0, epoch: 10, iters: 8160, time: 0.003) nll: 1.227302 \n",
      "(GPU: 0, epoch: 10, iters: 8960, time: 0.003) nll: 0.818519 \n",
      "(GPU: 0, epoch: 10, iters: 9760, time: 0.003) nll: 0.921339 \n",
      "(GPU: 0, epoch: 10, iters: 10560, time: 0.003) nll: 0.836662 \n",
      "(GPU: 0, epoch: 10, iters: 11360, time: 0.003) nll: 0.755735 \n",
      "(GPU: 0, epoch: 10, iters: 12160, time: 0.003) nll: 0.752372 \n",
      "(GPU: 0, epoch: 10, iters: 12960, time: 0.003) nll: 0.605284 \n",
      "saving the latest model (epoch 10, total_steps 1420000)\n",
      "(GPU: 0, epoch: 10, iters: 13760, time: 0.003) nll: 0.841143 \n",
      "(GPU: 0, epoch: 10, iters: 14560, time: 0.003) nll: 0.598074 \n",
      "(GPU: 0, epoch: 10, iters: 15360, time: 0.003) nll: 0.612859 \n",
      "(GPU: 0, epoch: 10, iters: 16160, time: 0.003) nll: 0.927143 \n",
      "(GPU: 0, epoch: 10, iters: 16960, time: 0.003) nll: 1.057867 \n",
      "(GPU: 0, epoch: 10, iters: 17760, time: 0.003) nll: 0.627363 \n",
      "(GPU: 0, epoch: 10, iters: 18560, time: 0.003) nll: 0.816945 \n",
      "(GPU: 0, epoch: 10, iters: 19360, time: 0.003) nll: 0.710914 \n",
      "(GPU: 0, epoch: 10, iters: 20160, time: 0.003) nll: 0.812712 \n",
      "(GPU: 0, epoch: 10, iters: 20960, time: 0.003) nll: 0.681663 \n",
      "(GPU: 0, epoch: 10, iters: 21760, time: 0.003) nll: 0.809694 \n",
      "(GPU: 0, epoch: 10, iters: 22560, time: 0.003) nll: 0.666834 \n",
      "(GPU: 0, epoch: 10, iters: 23360, time: 0.003) nll: 0.531000 \n",
      "(GPU: 0, epoch: 10, iters: 24160, time: 0.003) nll: 0.845392 \n",
      "(GPU: 0, epoch: 10, iters: 24960, time: 0.003) nll: 0.859632 \n",
      "(GPU: 0, epoch: 10, iters: 25760, time: 0.003) nll: 1.211009 \n",
      "(GPU: 0, epoch: 10, iters: 26560, time: 0.003) nll: 1.005535 \n",
      "(GPU: 0, epoch: 10, iters: 27360, time: 0.003) nll: 0.917394 \n",
      "(GPU: 0, epoch: 10, iters: 28160, time: 0.003) nll: 0.638980 \n",
      "(GPU: 0, epoch: 10, iters: 28960, time: 0.003) nll: 0.678567 \n",
      "(GPU: 0, epoch: 10, iters: 29760, time: 0.003) nll: 0.751020 \n",
      "(GPU: 0, epoch: 10, iters: 30560, time: 0.003) nll: 0.683967 \n",
      "(GPU: 0, epoch: 10, iters: 31360, time: 0.003) nll: 0.844829 \n",
      "(GPU: 0, epoch: 10, iters: 32160, time: 0.003) nll: 0.796078 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.003) nll: 0.582308 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.005) nll: 0.662798 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.005) nll: 0.483771 \n",
      "saving the latest model (epoch 10, total_steps 1440000)\n",
      "(GPU: 0, epoch: 10, iters: 33760, time: 0.003) nll: 0.757699 \n",
      "(GPU: 0, epoch: 10, iters: 34560, time: 0.003) nll: 0.773833 \n",
      "(GPU: 0, epoch: 10, iters: 35360, time: 0.003) nll: 0.815447 \n",
      "(GPU: 0, epoch: 10, iters: 36160, time: 0.003) nll: 0.599723 \n",
      "(GPU: 0, epoch: 10, iters: 36960, time: 0.003) nll: 0.888635 \n",
      "(GPU: 0, epoch: 10, iters: 37760, time: 0.003) nll: 0.692837 \n",
      "(GPU: 0, epoch: 10, iters: 38560, time: 0.003) nll: 0.834308 \n",
      "(GPU: 0, epoch: 10, iters: 39360, time: 0.003) nll: 0.751330 \n",
      "(GPU: 0, epoch: 10, iters: 40160, time: 0.003) nll: 0.952989 \n",
      "(GPU: 0, epoch: 10, iters: 40960, time: 0.003) nll: 0.800944 \n",
      "(GPU: 0, epoch: 10, iters: 41760, time: 0.003) nll: 0.652479 \n",
      "(GPU: 0, epoch: 10, iters: 42560, time: 0.003) nll: 0.797391 \n",
      "(GPU: 0, epoch: 10, iters: 43360, time: 0.003) nll: 0.657753 \n",
      "(GPU: 0, epoch: 10, iters: 44160, time: 0.003) nll: 0.699195 \n",
      "(GPU: 0, epoch: 10, iters: 44960, time: 0.003) nll: 0.773753 \n",
      "(GPU: 0, epoch: 10, iters: 45760, time: 0.003) nll: 1.233816 \n",
      "(GPU: 0, epoch: 10, iters: 46560, time: 0.003) nll: 0.962979 \n",
      "(GPU: 0, epoch: 10, iters: 47360, time: 0.003) nll: 0.948967 \n",
      "(GPU: 0, epoch: 10, iters: 48160, time: 0.003) nll: 0.893901 \n",
      "(GPU: 0, epoch: 10, iters: 48960, time: 0.003) nll: 0.877840 \n",
      "(GPU: 0, epoch: 10, iters: 49760, time: 0.003) nll: 0.874765 \n",
      "(GPU: 0, epoch: 10, iters: 50560, time: 0.003) nll: 0.902959 \n",
      "(GPU: 0, epoch: 10, iters: 51360, time: 0.003) nll: 0.811957 \n",
      "(GPU: 0, epoch: 10, iters: 52160, time: 0.003) nll: 0.627166 \n",
      "(GPU: 0, epoch: 10, iters: 52960, time: 0.003) nll: 0.738495 \n",
      "saving the latest model (epoch 10, total_steps 1460000)\n",
      "(GPU: 0, epoch: 10, iters: 53760, time: 0.003) nll: 0.808667 \n",
      "(GPU: 0, epoch: 10, iters: 54560, time: 0.003) nll: 0.727622 \n",
      "(GPU: 0, epoch: 10, iters: 55360, time: 0.003) nll: 0.879500 \n",
      "(GPU: 0, epoch: 10, iters: 56160, time: 0.003) nll: 0.739871 \n",
      "(GPU: 0, epoch: 10, iters: 56960, time: 0.003) nll: 0.766491 \n",
      "(GPU: 0, epoch: 10, iters: 57760, time: 0.003) nll: 0.922293 \n",
      "(GPU: 0, epoch: 10, iters: 58560, time: 0.003) nll: 0.689376 \n",
      "(GPU: 0, epoch: 10, iters: 59360, time: 0.003) nll: 0.797216 \n",
      "(GPU: 0, epoch: 10, iters: 60160, time: 0.003) nll: 0.574081 \n",
      "(GPU: 0, epoch: 10, iters: 60960, time: 0.003) nll: 0.627783 \n",
      "(GPU: 0, epoch: 10, iters: 61760, time: 0.003) nll: 0.967315 \n",
      "(GPU: 0, epoch: 10, iters: 62560, time: 0.003) nll: 0.858926 \n",
      "(GPU: 0, epoch: 10, iters: 63360, time: 0.003) nll: 1.040305 \n",
      "(GPU: 0, epoch: 10, iters: 64160, time: 0.003) nll: 0.642767 \n",
      "(GPU: 0, epoch: 10, iters: 64960, time: 0.003) nll: 1.330093 \n",
      "(GPU: 0, epoch: 10, iters: 65760, time: 0.003) nll: 0.720825 \n",
      "(GPU: 0, epoch: 10, iters: 66560, time: 0.003) nll: 0.852872 \n",
      "(GPU: 0, epoch: 10, iters: 67360, time: 0.003) nll: 0.935648 \n",
      "(GPU: 0, epoch: 10, iters: 68160, time: 0.003) nll: 0.771741 \n",
      "(GPU: 0, epoch: 10, iters: 68960, time: 0.003) nll: 0.926308 \n",
      "(GPU: 0, epoch: 10, iters: 69760, time: 0.003) nll: 1.018170 \n",
      "(GPU: 0, epoch: 10, iters: 70560, time: 0.003) nll: 0.677160 \n",
      "(GPU: 0, epoch: 10, iters: 71360, time: 0.003) nll: 0.788991 \n",
      "(GPU: 0, epoch: 10, iters: 72160, time: 0.003) nll: 0.811509 \n",
      "(GPU: 0, epoch: 10, iters: 72960, time: 0.003) nll: 0.810323 \n",
      "saving the latest model (epoch 10, total_steps 1480000)\n",
      "(GPU: 0, epoch: 10, iters: 73760, time: 0.003) nll: 0.861065 \n",
      "(GPU: 0, epoch: 10, iters: 74560, time: 0.003) nll: 0.856470 \n",
      "(GPU: 0, epoch: 10, iters: 75360, time: 0.003) nll: 0.894709 \n",
      "(GPU: 0, epoch: 10, iters: 76160, time: 0.003) nll: 0.885975 \n",
      "(GPU: 0, epoch: 10, iters: 76960, time: 0.003) nll: 0.749763 \n",
      "(GPU: 0, epoch: 10, iters: 77760, time: 0.003) nll: 0.927206 \n",
      "(GPU: 0, epoch: 10, iters: 78560, time: 0.003) nll: 0.657022 \n",
      "(GPU: 0, epoch: 10, iters: 79360, time: 0.003) nll: 0.851598 \n",
      "(GPU: 0, epoch: 10, iters: 80160, time: 0.003) nll: 0.881659 \n",
      "(GPU: 0, epoch: 10, iters: 80960, time: 0.003) nll: 0.857060 \n",
      "(GPU: 0, epoch: 10, iters: 81760, time: 0.003) nll: 0.751502 \n",
      "(GPU: 0, epoch: 10, iters: 82560, time: 0.003) nll: 0.638514 \n",
      "(GPU: 0, epoch: 10, iters: 83360, time: 0.003) nll: 0.769298 \n",
      "(GPU: 0, epoch: 10, iters: 84160, time: 0.003) nll: 0.712632 \n",
      "(GPU: 0, epoch: 10, iters: 84960, time: 0.003) nll: 0.938727 \n",
      "(GPU: 0, epoch: 10, iters: 85760, time: 0.003) nll: 0.689680 \n",
      "(GPU: 0, epoch: 10, iters: 86560, time: 0.003) nll: 0.643747 \n",
      "(GPU: 0, epoch: 10, iters: 87360, time: 0.003) nll: 0.847459 \n",
      "(GPU: 0, epoch: 10, iters: 88160, time: 0.003) nll: 0.965699 \n",
      "(GPU: 0, epoch: 10, iters: 88960, time: 0.003) nll: 0.952129 \n",
      "(GPU: 0, epoch: 10, iters: 89760, time: 0.003) nll: 1.095502 \n",
      "(GPU: 0, epoch: 10, iters: 90560, time: 0.003) nll: 1.116260 \n",
      "(GPU: 0, epoch: 10, iters: 91360, time: 0.003) nll: 0.739705 \n",
      "(GPU: 0, epoch: 10, iters: 92160, time: 0.003) nll: 0.805375 \n",
      "(GPU: 0, epoch: 10, iters: 92960, time: 0.003) nll: 0.995977 \n",
      "saving the latest model (epoch 10, total_steps 1500000)\n",
      "(GPU: 0, epoch: 10, iters: 93760, time: 0.003) nll: 1.038221 \n",
      "(GPU: 0, epoch: 10, iters: 94560, time: 0.003) nll: 0.959047 \n",
      "(GPU: 0, epoch: 10, iters: 95360, time: 0.003) nll: 0.705676 \n",
      "(GPU: 0, epoch: 10, iters: 96160, time: 0.003) nll: 0.770187 \n",
      "(GPU: 0, epoch: 10, iters: 96960, time: 0.003) nll: 0.870806 \n",
      "(GPU: 0, epoch: 10, iters: 97760, time: 0.003) nll: 0.656179 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 98560, time: 0.003) nll: 0.653082 \n",
      "(GPU: 0, epoch: 10, iters: 99360, time: 0.003) nll: 0.861121 \n",
      "(GPU: 0, epoch: 10, iters: 100160, time: 0.003) nll: 0.887944 \n",
      "(GPU: 0, epoch: 10, iters: 100960, time: 0.003) nll: 0.762877 \n",
      "(GPU: 0, epoch: 10, iters: 101760, time: 0.003) nll: 0.941957 \n",
      "(GPU: 0, epoch: 10, iters: 102560, time: 0.003) nll: 0.840045 \n",
      "(GPU: 0, epoch: 10, iters: 103360, time: 0.003) nll: 0.583216 \n",
      "(GPU: 0, epoch: 10, iters: 104160, time: 0.003) nll: 0.835343 \n",
      "(GPU: 0, epoch: 10, iters: 104960, time: 0.003) nll: 0.843054 \n",
      "(GPU: 0, epoch: 10, iters: 105760, time: 0.003) nll: 0.823230 \n",
      "(GPU: 0, epoch: 10, iters: 106560, time: 0.003) nll: 0.973440 \n",
      "(GPU: 0, epoch: 10, iters: 107360, time: 0.003) nll: 0.839925 \n",
      "(GPU: 0, epoch: 10, iters: 108160, time: 0.003) nll: 0.603112 \n",
      "(GPU: 0, epoch: 10, iters: 108960, time: 0.003) nll: 0.729526 \n",
      "(GPU: 0, epoch: 10, iters: 109760, time: 0.003) nll: 1.172637 \n",
      "(GPU: 0, epoch: 10, iters: 110560, time: 0.003) nll: 0.684821 \n",
      "(GPU: 0, epoch: 10, iters: 111360, time: 0.003) nll: 0.857403 \n",
      "(GPU: 0, epoch: 10, iters: 112160, time: 0.003) nll: 0.730041 \n",
      "(GPU: 0, epoch: 10, iters: 112960, time: 0.003) nll: 0.793706 \n",
      "saving the latest model (epoch 10, total_steps 1520000)\n",
      "(GPU: 0, epoch: 10, iters: 113760, time: 0.003) nll: 0.635768 \n",
      "(GPU: 0, epoch: 10, iters: 114560, time: 0.003) nll: 0.773665 \n",
      "(GPU: 0, epoch: 10, iters: 115360, time: 0.003) nll: 0.926938 \n",
      "(GPU: 0, epoch: 10, iters: 116160, time: 0.003) nll: 0.907121 \n",
      "(GPU: 0, epoch: 10, iters: 116960, time: 0.003) nll: 1.152102 \n",
      "(GPU: 0, epoch: 10, iters: 117760, time: 0.003) nll: 0.733473 \n",
      "(GPU: 0, epoch: 10, iters: 118560, time: 0.003) nll: 0.808566 \n",
      "(GPU: 0, epoch: 10, iters: 119360, time: 0.003) nll: 1.069824 \n",
      "(GPU: 0, epoch: 10, iters: 120160, time: 0.003) nll: 0.720312 \n",
      "(GPU: 0, epoch: 10, iters: 120960, time: 0.003) nll: 1.282465 \n",
      "(GPU: 0, epoch: 10, iters: 121760, time: 0.003) nll: 0.606002 \n",
      "(GPU: 0, epoch: 10, iters: 122560, time: 0.003) nll: 0.820864 \n",
      "(GPU: 0, epoch: 10, iters: 123360, time: 0.003) nll: 0.619794 \n",
      "(GPU: 0, epoch: 10, iters: 124160, time: 0.003) nll: 1.260219 \n",
      "(GPU: 0, epoch: 10, iters: 124960, time: 0.003) nll: 1.019364 \n",
      "(GPU: 0, epoch: 10, iters: 125760, time: 0.003) nll: 1.191519 \n",
      "(GPU: 0, epoch: 10, iters: 126560, time: 0.003) nll: 0.780232 \n",
      "(GPU: 0, epoch: 10, iters: 127360, time: 0.003) nll: 0.741363 \n",
      "(GPU: 0, epoch: 10, iters: 128160, time: 0.003) nll: 0.782779 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.003) nll: 0.788091 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.005) nll: 0.743429 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.005) nll: 0.886046 \n",
      "(GPU: 0, epoch: 10, iters: 129760, time: 0.003) nll: 0.920967 \n",
      "(GPU: 0, epoch: 10, iters: 130560, time: 0.003) nll: 0.970117 \n",
      "(GPU: 0, epoch: 10, iters: 131360, time: 0.003) nll: 0.924678 \n",
      "(GPU: 0, epoch: 10, iters: 132160, time: 0.003) nll: 0.771493 \n",
      "(GPU: 0, epoch: 10, iters: 132960, time: 0.003) nll: 0.706867 \n",
      "saving the latest model (epoch 10, total_steps 1540000)\n",
      "(GPU: 0, epoch: 10, iters: 133760, time: 0.003) nll: 0.776195 \n",
      "(GPU: 0, epoch: 10, iters: 134560, time: 0.003) nll: 0.689137 \n",
      "(GPU: 0, epoch: 10, iters: 135360, time: 0.003) nll: 0.808924 \n",
      "(GPU: 0, epoch: 10, iters: 136160, time: 0.003) nll: 0.845613 \n",
      "(GPU: 0, epoch: 10, iters: 136960, time: 0.003) nll: 0.509190 \n",
      "(GPU: 0, epoch: 10, iters: 137760, time: 0.003) nll: 0.803357 \n",
      "(GPU: 0, epoch: 10, iters: 138560, time: 0.003) nll: 0.850691 \n",
      "(GPU: 0, epoch: 10, iters: 139360, time: 0.003) nll: 0.729741 \n",
      "(GPU: 0, epoch: 10, iters: 140160, time: 0.003) nll: 0.830138 \n",
      "[*] End of epoch 10 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000953\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3083/4397 [05:57<02:43,  8.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 32, time: 0.002) nll: 0.769089 \n",
      "(GPU: 0, epoch: 11, iters: 32, time: 0.002) nll: 0.915195 \n",
      "(GPU: 0, epoch: 11, iters: 256, time: 0.003) nll: 0.660304 \n",
      "(GPU: 0, epoch: 11, iters: 1056, time: 0.003) nll: 0.868428 \n",
      "(GPU: 0, epoch: 11, iters: 1856, time: 0.003) nll: 0.775619 \n",
      "(GPU: 0, epoch: 11, iters: 2656, time: 0.003) nll: 0.807752 \n",
      "(GPU: 0, epoch: 11, iters: 3456, time: 0.003) nll: 1.078069 \n",
      "(GPU: 0, epoch: 11, iters: 4256, time: 0.003) nll: 0.987912 \n",
      "(GPU: 0, epoch: 11, iters: 5056, time: 0.003) nll: 0.854581 \n",
      "(GPU: 0, epoch: 11, iters: 5856, time: 0.003) nll: 1.512765 \n",
      "(GPU: 0, epoch: 11, iters: 6656, time: 0.003) nll: 0.686795 \n",
      "(GPU: 0, epoch: 11, iters: 7456, time: 0.003) nll: 1.116155 \n",
      "(GPU: 0, epoch: 11, iters: 8256, time: 0.003) nll: 1.116765 \n",
      "(GPU: 0, epoch: 11, iters: 9056, time: 0.003) nll: 0.743394 \n",
      "(GPU: 0, epoch: 11, iters: 9856, time: 0.003) nll: 0.735977 \n",
      "(GPU: 0, epoch: 11, iters: 10656, time: 0.003) nll: 0.656817 \n",
      "(GPU: 0, epoch: 11, iters: 11456, time: 0.003) nll: 0.777437 \n",
      "(GPU: 0, epoch: 11, iters: 12256, time: 0.003) nll: 0.839023 \n",
      "saving the latest model (epoch 11, total_steps 1560000)\n",
      "(GPU: 0, epoch: 11, iters: 13056, time: 0.003) nll: 0.695726 \n",
      "(GPU: 0, epoch: 11, iters: 13856, time: 0.003) nll: 0.819286 \n",
      "(GPU: 0, epoch: 11, iters: 14656, time: 0.003) nll: 0.722219 \n",
      "(GPU: 0, epoch: 11, iters: 15456, time: 0.003) nll: 0.915679 \n",
      "(GPU: 0, epoch: 11, iters: 16256, time: 0.003) nll: 0.747544 \n",
      "(GPU: 0, epoch: 11, iters: 17056, time: 0.003) nll: 0.709580 \n",
      "(GPU: 0, epoch: 11, iters: 17856, time: 0.003) nll: 0.729973 \n",
      "(GPU: 0, epoch: 11, iters: 18656, time: 0.003) nll: 0.696878 \n",
      "(GPU: 0, epoch: 11, iters: 19456, time: 0.003) nll: 0.742839 \n",
      "(GPU: 0, epoch: 11, iters: 20256, time: 0.003) nll: 0.735501 \n",
      "(GPU: 0, epoch: 11, iters: 21056, time: 0.003) nll: 0.869440 \n",
      "(GPU: 0, epoch: 11, iters: 21856, time: 0.003) nll: 0.908498 \n",
      "(GPU: 0, epoch: 11, iters: 22656, time: 0.003) nll: 0.803154 \n",
      "(GPU: 0, epoch: 11, iters: 23456, time: 0.003) nll: 0.898782 \n",
      "(GPU: 0, epoch: 11, iters: 24256, time: 0.003) nll: 0.895979 \n",
      "(GPU: 0, epoch: 11, iters: 25056, time: 0.003) nll: 0.578455 \n",
      "(GPU: 0, epoch: 11, iters: 25856, time: 0.003) nll: 0.730690 \n",
      "(GPU: 0, epoch: 11, iters: 26656, time: 0.003) nll: 0.640853 \n",
      "(GPU: 0, epoch: 11, iters: 27456, time: 0.003) nll: 0.868634 \n",
      "(GPU: 0, epoch: 11, iters: 28256, time: 0.003) nll: 0.700798 \n",
      "(GPU: 0, epoch: 11, iters: 29056, time: 0.003) nll: 0.961541 \n",
      "(GPU: 0, epoch: 11, iters: 29856, time: 0.003) nll: 1.030267 \n",
      "(GPU: 0, epoch: 11, iters: 30656, time: 0.003) nll: 0.731423 \n",
      "(GPU: 0, epoch: 11, iters: 31456, time: 0.003) nll: 1.161599 \n",
      "(GPU: 0, epoch: 11, iters: 32256, time: 0.003) nll: 1.208970 \n",
      "saving the latest model (epoch 11, total_steps 1580000)\n",
      "(GPU: 0, epoch: 11, iters: 33056, time: 0.003) nll: 1.161510 \n",
      "(GPU: 0, epoch: 11, iters: 33856, time: 0.003) nll: 0.997086 \n",
      "(GPU: 0, epoch: 11, iters: 34656, time: 0.003) nll: 0.984929 \n",
      "(GPU: 0, epoch: 11, iters: 35456, time: 0.003) nll: 1.002072 \n",
      "(GPU: 0, epoch: 11, iters: 36256, time: 0.003) nll: 0.818539 \n",
      "(GPU: 0, epoch: 11, iters: 37056, time: 0.003) nll: 0.856438 \n",
      "(GPU: 0, epoch: 11, iters: 37856, time: 0.003) nll: 0.924019 \n",
      "(GPU: 0, epoch: 11, iters: 38656, time: 0.003) nll: 0.908102 \n",
      "(GPU: 0, epoch: 11, iters: 39456, time: 0.003) nll: 0.734661 \n",
      "(GPU: 0, epoch: 11, iters: 40256, time: 0.003) nll: 0.710090 \n",
      "(GPU: 0, epoch: 11, iters: 41056, time: 0.003) nll: 1.215265 \n",
      "(GPU: 0, epoch: 11, iters: 41856, time: 0.003) nll: 0.649698 \n",
      "(GPU: 0, epoch: 11, iters: 42656, time: 0.003) nll: 1.029701 \n",
      "(GPU: 0, epoch: 11, iters: 43456, time: 0.003) nll: 0.946301 \n",
      "(GPU: 0, epoch: 11, iters: 44256, time: 0.003) nll: 0.683002 \n",
      "(GPU: 0, epoch: 11, iters: 45056, time: 0.003) nll: 0.755166 \n",
      "(GPU: 0, epoch: 11, iters: 45856, time: 0.003) nll: 0.810429 \n",
      "(GPU: 0, epoch: 11, iters: 46656, time: 0.003) nll: 0.741245 \n",
      "(GPU: 0, epoch: 11, iters: 47456, time: 0.003) nll: 0.664493 \n",
      "(GPU: 0, epoch: 11, iters: 48256, time: 0.003) nll: 0.889226 \n",
      "(GPU: 0, epoch: 11, iters: 49056, time: 0.003) nll: 0.750967 \n",
      "(GPU: 0, epoch: 11, iters: 49856, time: 0.003) nll: 0.873199 \n",
      "(GPU: 0, epoch: 11, iters: 50656, time: 0.003) nll: 0.670020 \n",
      "(GPU: 0, epoch: 11, iters: 51456, time: 0.003) nll: 0.929334 \n",
      "(GPU: 0, epoch: 11, iters: 52256, time: 0.003) nll: 0.842826 \n",
      "saving the latest model (epoch 11, total_steps 1600000)\n",
      "(GPU: 0, epoch: 11, iters: 53056, time: 0.003) nll: 1.316238 \n",
      "(GPU: 0, epoch: 11, iters: 53856, time: 0.003) nll: 0.820152 \n",
      "(GPU: 0, epoch: 11, iters: 54656, time: 0.003) nll: 0.827221 \n",
      "(GPU: 0, epoch: 11, iters: 55456, time: 0.003) nll: 0.935692 \n",
      "(GPU: 0, epoch: 11, iters: 56256, time: 0.003) nll: 0.683939 \n",
      "(GPU: 0, epoch: 11, iters: 57056, time: 0.003) nll: 0.927080 \n",
      "(GPU: 0, epoch: 11, iters: 57856, time: 0.003) nll: 0.873203 \n",
      "(GPU: 0, epoch: 11, iters: 58656, time: 0.003) nll: 0.942632 \n",
      "(GPU: 0, epoch: 11, iters: 59456, time: 0.003) nll: 0.753519 \n",
      "(GPU: 0, epoch: 11, iters: 60256, time: 0.003) nll: 0.722721 \n",
      "(GPU: 0, epoch: 11, iters: 61056, time: 0.003) nll: 0.671660 \n",
      "(GPU: 0, epoch: 11, iters: 61856, time: 0.003) nll: 0.745434 \n",
      "(GPU: 0, epoch: 11, iters: 62656, time: 0.003) nll: 0.828997 \n",
      "(GPU: 0, epoch: 11, iters: 63456, time: 0.003) nll: 0.814809 \n",
      "(GPU: 0, epoch: 11, iters: 64256, time: 0.003) nll: 0.763679 \n",
      "(GPU: 0, epoch: 11, iters: 65056, time: 0.003) nll: 1.122158 \n",
      "(GPU: 0, epoch: 11, iters: 65856, time: 0.003) nll: 0.773611 \n",
      "(GPU: 0, epoch: 11, iters: 66656, time: 0.003) nll: 0.887009 \n",
      "(GPU: 0, epoch: 11, iters: 67456, time: 0.003) nll: 0.693353 \n",
      "(GPU: 0, epoch: 11, iters: 68256, time: 0.003) nll: 0.700264 \n",
      "(GPU: 0, epoch: 11, iters: 69056, time: 0.003) nll: 0.767610 \n",
      "(GPU: 0, epoch: 11, iters: 69856, time: 0.003) nll: 0.727087 \n",
      "(GPU: 0, epoch: 11, iters: 70656, time: 0.003) nll: 0.757797 \n",
      "(GPU: 0, epoch: 11, iters: 71456, time: 0.003) nll: 0.551119 \n",
      "(GPU: 0, epoch: 11, iters: 72256, time: 0.003) nll: 0.846153 \n",
      "saving the latest model (epoch 11, total_steps 1620000)\n",
      "(GPU: 0, epoch: 11, iters: 73056, time: 0.003) nll: 0.732074 \n",
      "(GPU: 0, epoch: 11, iters: 73856, time: 0.003) nll: 0.918865 \n",
      "(GPU: 0, epoch: 11, iters: 74656, time: 0.003) nll: 0.824657 \n",
      "(GPU: 0, epoch: 11, iters: 75456, time: 0.003) nll: 0.805725 \n",
      "(GPU: 0, epoch: 11, iters: 76256, time: 0.003) nll: 1.019099 \n",
      "(GPU: 0, epoch: 11, iters: 77056, time: 0.003) nll: 0.841126 \n",
      "(GPU: 0, epoch: 11, iters: 77856, time: 0.003) nll: 0.714968 \n",
      "(GPU: 0, epoch: 11, iters: 78656, time: 0.003) nll: 0.843610 \n",
      "(GPU: 0, epoch: 11, iters: 79456, time: 0.003) nll: 0.633661 \n",
      "(GPU: 0, epoch: 11, iters: 80256, time: 0.003) nll: 0.785072 \n",
      "(GPU: 0, epoch: 11, iters: 81056, time: 0.003) nll: 1.670665 \n",
      "(GPU: 0, epoch: 11, iters: 81856, time: 0.003) nll: 0.769852 \n",
      "(GPU: 0, epoch: 11, iters: 82656, time: 0.003) nll: 0.755328 \n",
      "(GPU: 0, epoch: 11, iters: 83456, time: 0.003) nll: 0.844761 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.003) nll: 0.674952 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.005) nll: 0.672797 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.005) nll: 0.859984 \n",
      "(GPU: 0, epoch: 11, iters: 85056, time: 0.003) nll: 0.968059 \n",
      "(GPU: 0, epoch: 11, iters: 85856, time: 0.003) nll: 0.958730 \n",
      "(GPU: 0, epoch: 11, iters: 86656, time: 0.003) nll: 0.711474 \n",
      "(GPU: 0, epoch: 11, iters: 87456, time: 0.003) nll: 0.919485 \n",
      "(GPU: 0, epoch: 11, iters: 88256, time: 0.003) nll: 0.977799 \n",
      "(GPU: 0, epoch: 11, iters: 89056, time: 0.003) nll: 0.806521 \n",
      "(GPU: 0, epoch: 11, iters: 89856, time: 0.003) nll: 0.790675 \n",
      "(GPU: 0, epoch: 11, iters: 90656, time: 0.003) nll: 0.747053 \n",
      "(GPU: 0, epoch: 11, iters: 91456, time: 0.003) nll: 0.669731 \n",
      "(GPU: 0, epoch: 11, iters: 92256, time: 0.003) nll: 0.986620 \n",
      "saving the latest model (epoch 11, total_steps 1640000)\n",
      "(GPU: 0, epoch: 11, iters: 93056, time: 0.003) nll: 0.842629 \n",
      "(GPU: 0, epoch: 11, iters: 93856, time: 0.003) nll: 0.720703 \n",
      "(GPU: 0, epoch: 11, iters: 94656, time: 0.003) nll: 0.834711 \n",
      "(GPU: 0, epoch: 11, iters: 95456, time: 0.003) nll: 0.947938 \n",
      "(GPU: 0, epoch: 11, iters: 96256, time: 0.003) nll: 0.999798 \n",
      "(GPU: 0, epoch: 11, iters: 97056, time: 0.003) nll: 0.853321 \n",
      "(GPU: 0, epoch: 11, iters: 97856, time: 0.003) nll: 0.876699 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 98656, time: 0.003) nll: 0.879579 \n",
      "(GPU: 0, epoch: 11, iters: 99456, time: 0.003) nll: 0.817665 \n",
      "(GPU: 0, epoch: 11, iters: 100256, time: 0.003) nll: 0.810464 \n",
      "(GPU: 0, epoch: 11, iters: 101056, time: 0.003) nll: 0.808818 \n",
      "(GPU: 0, epoch: 11, iters: 101856, time: 0.003) nll: 0.822162 \n",
      "(GPU: 0, epoch: 11, iters: 102656, time: 0.003) nll: 0.782653 \n",
      "(GPU: 0, epoch: 11, iters: 103456, time: 0.003) nll: 0.708651 \n",
      "(GPU: 0, epoch: 11, iters: 104256, time: 0.003) nll: 0.675249 \n",
      "(GPU: 0, epoch: 11, iters: 105056, time: 0.003) nll: 0.650403 \n",
      "(GPU: 0, epoch: 11, iters: 105856, time: 0.003) nll: 0.848534 \n",
      "(GPU: 0, epoch: 11, iters: 106656, time: 0.003) nll: 0.910063 \n",
      "(GPU: 0, epoch: 11, iters: 107456, time: 0.003) nll: 0.670723 \n",
      "(GPU: 0, epoch: 11, iters: 108256, time: 0.003) nll: 0.664769 \n",
      "(GPU: 0, epoch: 11, iters: 109056, time: 0.003) nll: 0.601063 \n",
      "(GPU: 0, epoch: 11, iters: 109856, time: 0.003) nll: 0.815209 \n",
      "(GPU: 0, epoch: 11, iters: 110656, time: 0.003) nll: 0.744890 \n",
      "(GPU: 0, epoch: 11, iters: 111456, time: 0.003) nll: 0.966995 \n",
      "(GPU: 0, epoch: 11, iters: 112256, time: 0.003) nll: 0.673462 \n",
      "saving the latest model (epoch 11, total_steps 1660000)\n",
      "(GPU: 0, epoch: 11, iters: 113056, time: 0.003) nll: 0.617607 \n",
      "(GPU: 0, epoch: 11, iters: 113856, time: 0.003) nll: 0.742481 \n",
      "(GPU: 0, epoch: 11, iters: 114656, time: 0.003) nll: 0.987522 \n",
      "(GPU: 0, epoch: 11, iters: 115456, time: 0.003) nll: 1.037015 \n",
      "(GPU: 0, epoch: 11, iters: 116256, time: 0.003) nll: 0.789102 \n",
      "(GPU: 0, epoch: 11, iters: 117056, time: 0.003) nll: 0.844760 \n",
      "(GPU: 0, epoch: 11, iters: 117856, time: 0.003) nll: 0.529420 \n",
      "(GPU: 0, epoch: 11, iters: 118656, time: 0.003) nll: 0.617728 \n",
      "(GPU: 0, epoch: 11, iters: 119456, time: 0.003) nll: 0.803535 \n",
      "(GPU: 0, epoch: 11, iters: 120256, time: 0.003) nll: 0.895836 \n",
      "(GPU: 0, epoch: 11, iters: 121056, time: 0.003) nll: 0.824141 \n",
      "(GPU: 0, epoch: 11, iters: 121856, time: 0.003) nll: 0.690940 \n",
      "(GPU: 0, epoch: 11, iters: 122656, time: 0.003) nll: 0.838480 \n",
      "(GPU: 0, epoch: 11, iters: 123456, time: 0.003) nll: 0.736964 \n",
      "(GPU: 0, epoch: 11, iters: 124256, time: 0.003) nll: 0.669327 \n",
      "(GPU: 0, epoch: 11, iters: 125056, time: 0.003) nll: 0.686195 \n",
      "(GPU: 0, epoch: 11, iters: 125856, time: 0.003) nll: 0.842522 \n",
      "(GPU: 0, epoch: 11, iters: 126656, time: 0.003) nll: 1.047626 \n",
      "(GPU: 0, epoch: 11, iters: 127456, time: 0.003) nll: 0.758216 \n",
      "(GPU: 0, epoch: 11, iters: 128256, time: 0.003) nll: 0.844530 \n",
      "(GPU: 0, epoch: 11, iters: 129056, time: 0.003) nll: 0.830697 \n",
      "(GPU: 0, epoch: 11, iters: 129856, time: 0.003) nll: 0.836812 \n",
      "(GPU: 0, epoch: 11, iters: 130656, time: 0.003) nll: 0.890106 \n",
      "(GPU: 0, epoch: 11, iters: 131456, time: 0.003) nll: 0.678016 \n",
      "(GPU: 0, epoch: 11, iters: 132256, time: 0.003) nll: 0.766141 \n",
      "saving the latest model (epoch 11, total_steps 1680000)\n",
      "(GPU: 0, epoch: 11, iters: 133056, time: 0.003) nll: 0.823302 \n",
      "(GPU: 0, epoch: 11, iters: 133856, time: 0.003) nll: 0.734805 \n",
      "(GPU: 0, epoch: 11, iters: 134656, time: 0.003) nll: 0.735645 \n",
      "(GPU: 0, epoch: 11, iters: 135456, time: 0.003) nll: 0.811298 \n",
      "(GPU: 0, epoch: 11, iters: 136256, time: 0.003) nll: 0.889186 \n",
      "(GPU: 0, epoch: 11, iters: 137056, time: 0.003) nll: 0.703093 \n",
      "(GPU: 0, epoch: 11, iters: 137856, time: 0.003) nll: 0.752214 \n",
      "(GPU: 0, epoch: 11, iters: 138656, time: 0.003) nll: 0.817503 \n",
      "(GPU: 0, epoch: 11, iters: 139456, time: 0.003) nll: 0.996963 \n",
      "(GPU: 0, epoch: 11, iters: 140256, time: 0.003) nll: 0.824741 \n",
      "[*] End of epoch 11 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000913\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3085/4397 [05:57<02:18,  9.44it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 32, time: 0.002) nll: 0.906661 \n",
      "(GPU: 0, epoch: 12, iters: 32, time: 0.002) nll: 0.739044 \n",
      "(GPU: 0, epoch: 12, iters: 352, time: 0.003) nll: 0.716029 \n",
      "(GPU: 0, epoch: 12, iters: 1152, time: 0.003) nll: 1.066376 \n",
      "(GPU: 0, epoch: 12, iters: 1952, time: 0.003) nll: 0.608405 \n",
      "(GPU: 0, epoch: 12, iters: 2752, time: 0.003) nll: 0.878364 \n",
      "(GPU: 0, epoch: 12, iters: 3552, time: 0.003) nll: 0.697122 \n",
      "(GPU: 0, epoch: 12, iters: 4352, time: 0.003) nll: 0.667644 \n",
      "(GPU: 0, epoch: 12, iters: 5152, time: 0.003) nll: 0.798345 \n",
      "(GPU: 0, epoch: 12, iters: 5952, time: 0.003) nll: 0.803500 \n",
      "(GPU: 0, epoch: 12, iters: 6752, time: 0.003) nll: 0.896353 \n",
      "(GPU: 0, epoch: 12, iters: 7552, time: 0.003) nll: 0.894063 \n",
      "(GPU: 0, epoch: 12, iters: 8352, time: 0.003) nll: 0.830854 \n",
      "(GPU: 0, epoch: 12, iters: 9152, time: 0.003) nll: 0.875378 \n",
      "(GPU: 0, epoch: 12, iters: 9952, time: 0.003) nll: 0.890519 \n",
      "(GPU: 0, epoch: 12, iters: 10752, time: 0.003) nll: 0.766374 \n",
      "(GPU: 0, epoch: 12, iters: 11552, time: 0.003) nll: 0.829542 \n",
      "saving the latest model (epoch 12, total_steps 1700000)\n",
      "(GPU: 0, epoch: 12, iters: 12352, time: 0.003) nll: 0.898597 \n",
      "(GPU: 0, epoch: 12, iters: 13152, time: 0.003) nll: 0.896114 \n",
      "(GPU: 0, epoch: 12, iters: 13952, time: 0.003) nll: 0.920447 \n",
      "(GPU: 0, epoch: 12, iters: 14752, time: 0.003) nll: 0.757519 \n",
      "(GPU: 0, epoch: 12, iters: 15552, time: 0.003) nll: 0.815160 \n",
      "(GPU: 0, epoch: 12, iters: 16352, time: 0.003) nll: 0.822952 \n",
      "(GPU: 0, epoch: 12, iters: 17152, time: 0.003) nll: 0.785506 \n",
      "(GPU: 0, epoch: 12, iters: 17952, time: 0.003) nll: 1.260659 \n",
      "(GPU: 0, epoch: 12, iters: 18752, time: 0.003) nll: 1.088735 \n",
      "(GPU: 0, epoch: 12, iters: 19552, time: 0.003) nll: 0.748625 \n",
      "(GPU: 0, epoch: 12, iters: 20352, time: 0.003) nll: 0.650892 \n",
      "(GPU: 0, epoch: 12, iters: 21152, time: 0.003) nll: 0.897131 \n",
      "(GPU: 0, epoch: 12, iters: 21952, time: 0.003) nll: 0.795292 \n",
      "(GPU: 0, epoch: 12, iters: 22752, time: 0.003) nll: 0.769686 \n",
      "(GPU: 0, epoch: 12, iters: 23552, time: 0.003) nll: 0.890546 \n",
      "(GPU: 0, epoch: 12, iters: 24352, time: 0.003) nll: 0.987997 \n",
      "(GPU: 0, epoch: 12, iters: 25152, time: 0.003) nll: 0.994207 \n",
      "(GPU: 0, epoch: 12, iters: 25952, time: 0.003) nll: 0.772324 \n",
      "(GPU: 0, epoch: 12, iters: 26752, time: 0.003) nll: 1.170548 \n",
      "(GPU: 0, epoch: 12, iters: 27552, time: 0.003) nll: 1.008206 \n",
      "(GPU: 0, epoch: 12, iters: 28352, time: 0.003) nll: 0.770273 \n",
      "(GPU: 0, epoch: 12, iters: 29152, time: 0.003) nll: 0.851110 \n",
      "(GPU: 0, epoch: 12, iters: 29952, time: 0.003) nll: 0.714093 \n",
      "(GPU: 0, epoch: 12, iters: 30752, time: 0.003) nll: 0.605113 \n",
      "(GPU: 0, epoch: 12, iters: 31552, time: 0.003) nll: 0.886885 \n",
      "saving the latest model (epoch 12, total_steps 1720000)\n",
      "(GPU: 0, epoch: 12, iters: 32352, time: 0.003) nll: 0.739464 \n",
      "(GPU: 0, epoch: 12, iters: 33152, time: 0.003) nll: 0.602762 \n",
      "(GPU: 0, epoch: 12, iters: 33952, time: 0.003) nll: 0.941700 \n",
      "(GPU: 0, epoch: 12, iters: 34752, time: 0.003) nll: 0.655743 \n",
      "(GPU: 0, epoch: 12, iters: 35552, time: 0.003) nll: 0.804816 \n",
      "(GPU: 0, epoch: 12, iters: 36352, time: 0.003) nll: 0.840996 \n",
      "(GPU: 0, epoch: 12, iters: 37152, time: 0.003) nll: 0.698288 \n",
      "(GPU: 0, epoch: 12, iters: 37952, time: 0.003) nll: 0.781313 \n",
      "(GPU: 0, epoch: 12, iters: 38752, time: 0.003) nll: 0.826250 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.003) nll: 0.966778 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.005) nll: 0.959354 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.005) nll: 0.742022 \n",
      "(GPU: 0, epoch: 12, iters: 40352, time: 0.003) nll: 0.889603 \n",
      "(GPU: 0, epoch: 12, iters: 41152, time: 0.003) nll: 0.885249 \n",
      "(GPU: 0, epoch: 12, iters: 41952, time: 0.003) nll: 0.765561 \n",
      "(GPU: 0, epoch: 12, iters: 42752, time: 0.003) nll: 0.766964 \n",
      "(GPU: 0, epoch: 12, iters: 43552, time: 0.003) nll: 0.581959 \n",
      "(GPU: 0, epoch: 12, iters: 44352, time: 0.003) nll: 0.752608 \n",
      "(GPU: 0, epoch: 12, iters: 45152, time: 0.003) nll: 0.679941 \n",
      "(GPU: 0, epoch: 12, iters: 45952, time: 0.003) nll: 0.865225 \n",
      "(GPU: 0, epoch: 12, iters: 46752, time: 0.003) nll: 0.739416 \n",
      "(GPU: 0, epoch: 12, iters: 47552, time: 0.003) nll: 0.691340 \n",
      "(GPU: 0, epoch: 12, iters: 48352, time: 0.003) nll: 0.793244 \n",
      "(GPU: 0, epoch: 12, iters: 49152, time: 0.003) nll: 0.644154 \n",
      "(GPU: 0, epoch: 12, iters: 49952, time: 0.003) nll: 0.853896 \n",
      "(GPU: 0, epoch: 12, iters: 50752, time: 0.003) nll: 0.729974 \n",
      "(GPU: 0, epoch: 12, iters: 51552, time: 0.003) nll: 0.643021 \n",
      "saving the latest model (epoch 12, total_steps 1740000)\n",
      "(GPU: 0, epoch: 12, iters: 52352, time: 0.003) nll: 0.829575 \n",
      "(GPU: 0, epoch: 12, iters: 53152, time: 0.003) nll: 1.092835 \n",
      "(GPU: 0, epoch: 12, iters: 53952, time: 0.003) nll: 0.743688 \n",
      "(GPU: 0, epoch: 12, iters: 54752, time: 0.003) nll: 0.724219 \n",
      "(GPU: 0, epoch: 12, iters: 55552, time: 0.003) nll: 1.014473 \n",
      "(GPU: 0, epoch: 12, iters: 56352, time: 0.003) nll: 1.022000 \n",
      "(GPU: 0, epoch: 12, iters: 57152, time: 0.003) nll: 0.708604 \n",
      "(GPU: 0, epoch: 12, iters: 57952, time: 0.003) nll: 0.672499 \n",
      "(GPU: 0, epoch: 12, iters: 58752, time: 0.003) nll: 0.631723 \n",
      "(GPU: 0, epoch: 12, iters: 59552, time: 0.003) nll: 0.882980 \n",
      "(GPU: 0, epoch: 12, iters: 60352, time: 0.003) nll: 0.804169 \n",
      "(GPU: 0, epoch: 12, iters: 61152, time: 0.003) nll: 0.836308 \n",
      "(GPU: 0, epoch: 12, iters: 61952, time: 0.003) nll: 0.677141 \n",
      "(GPU: 0, epoch: 12, iters: 62752, time: 0.003) nll: 0.975447 \n",
      "(GPU: 0, epoch: 12, iters: 63552, time: 0.003) nll: 0.650730 \n",
      "(GPU: 0, epoch: 12, iters: 64352, time: 0.003) nll: 0.862420 \n",
      "(GPU: 0, epoch: 12, iters: 65152, time: 0.003) nll: 0.764280 \n",
      "(GPU: 0, epoch: 12, iters: 65952, time: 0.003) nll: 0.855743 \n",
      "(GPU: 0, epoch: 12, iters: 66752, time: 0.003) nll: 0.901633 \n",
      "(GPU: 0, epoch: 12, iters: 67552, time: 0.003) nll: 0.908082 \n",
      "(GPU: 0, epoch: 12, iters: 68352, time: 0.003) nll: 0.857452 \n",
      "(GPU: 0, epoch: 12, iters: 69152, time: 0.003) nll: 0.729388 \n",
      "(GPU: 0, epoch: 12, iters: 69952, time: 0.003) nll: 0.728602 \n",
      "(GPU: 0, epoch: 12, iters: 70752, time: 0.003) nll: 0.694075 \n",
      "(GPU: 0, epoch: 12, iters: 71552, time: 0.003) nll: 1.145478 \n",
      "saving the latest model (epoch 12, total_steps 1760000)\n",
      "(GPU: 0, epoch: 12, iters: 72352, time: 0.003) nll: 0.741081 \n",
      "(GPU: 0, epoch: 12, iters: 73152, time: 0.003) nll: 0.854551 \n",
      "(GPU: 0, epoch: 12, iters: 73952, time: 0.003) nll: 0.856694 \n",
      "(GPU: 0, epoch: 12, iters: 74752, time: 0.003) nll: 0.980371 \n",
      "(GPU: 0, epoch: 12, iters: 75552, time: 0.003) nll: 0.702312 \n",
      "(GPU: 0, epoch: 12, iters: 76352, time: 0.003) nll: 0.719132 \n",
      "(GPU: 0, epoch: 12, iters: 77152, time: 0.003) nll: 0.894565 \n",
      "(GPU: 0, epoch: 12, iters: 77952, time: 0.003) nll: 0.664606 \n",
      "(GPU: 0, epoch: 12, iters: 78752, time: 0.003) nll: 0.751009 \n",
      "(GPU: 0, epoch: 12, iters: 79552, time: 0.003) nll: 0.944559 \n",
      "(GPU: 0, epoch: 12, iters: 80352, time: 0.003) nll: 0.635747 \n",
      "(GPU: 0, epoch: 12, iters: 81152, time: 0.003) nll: 0.795643 \n",
      "(GPU: 0, epoch: 12, iters: 81952, time: 0.003) nll: 0.639208 \n",
      "(GPU: 0, epoch: 12, iters: 82752, time: 0.003) nll: 0.696497 \n",
      "(GPU: 0, epoch: 12, iters: 83552, time: 0.003) nll: 0.935742 \n",
      "(GPU: 0, epoch: 12, iters: 84352, time: 0.003) nll: 0.915503 \n",
      "(GPU: 0, epoch: 12, iters: 85152, time: 0.003) nll: 0.691084 \n",
      "(GPU: 0, epoch: 12, iters: 85952, time: 0.003) nll: 0.803262 \n",
      "(GPU: 0, epoch: 12, iters: 86752, time: 0.003) nll: 0.666445 \n",
      "(GPU: 0, epoch: 12, iters: 87552, time: 0.003) nll: 0.701197 \n",
      "(GPU: 0, epoch: 12, iters: 88352, time: 0.003) nll: 0.733822 \n",
      "(GPU: 0, epoch: 12, iters: 89152, time: 0.003) nll: 0.976081 \n",
      "(GPU: 0, epoch: 12, iters: 89952, time: 0.003) nll: 1.228087 \n",
      "(GPU: 0, epoch: 12, iters: 90752, time: 0.003) nll: 0.596031 \n",
      "(GPU: 0, epoch: 12, iters: 91552, time: 0.003) nll: 0.799563 \n",
      "saving the latest model (epoch 12, total_steps 1780000)\n",
      "(GPU: 0, epoch: 12, iters: 92352, time: 0.003) nll: 0.728507 \n",
      "(GPU: 0, epoch: 12, iters: 93152, time: 0.003) nll: 0.592897 \n",
      "(GPU: 0, epoch: 12, iters: 93952, time: 0.003) nll: 0.633530 \n",
      "(GPU: 0, epoch: 12, iters: 94752, time: 0.003) nll: 0.906004 \n",
      "(GPU: 0, epoch: 12, iters: 95552, time: 0.003) nll: 1.040290 \n",
      "(GPU: 0, epoch: 12, iters: 96352, time: 0.003) nll: 0.970676 \n",
      "(GPU: 0, epoch: 12, iters: 97152, time: 0.003) nll: 0.765586 \n",
      "(GPU: 0, epoch: 12, iters: 97952, time: 0.003) nll: 0.850898 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 98752, time: 0.003) nll: 1.031965 \n",
      "(GPU: 0, epoch: 12, iters: 99552, time: 0.003) nll: 0.712578 \n",
      "(GPU: 0, epoch: 12, iters: 100352, time: 0.003) nll: 0.626062 \n",
      "(GPU: 0, epoch: 12, iters: 101152, time: 0.003) nll: 0.845899 \n",
      "(GPU: 0, epoch: 12, iters: 101952, time: 0.003) nll: 0.503169 \n",
      "(GPU: 0, epoch: 12, iters: 102752, time: 0.003) nll: 0.843825 \n",
      "(GPU: 0, epoch: 12, iters: 103552, time: 0.003) nll: 0.763466 \n",
      "(GPU: 0, epoch: 12, iters: 104352, time: 0.003) nll: 1.260840 \n",
      "(GPU: 0, epoch: 12, iters: 105152, time: 0.003) nll: 0.847323 \n",
      "(GPU: 0, epoch: 12, iters: 105952, time: 0.003) nll: 0.650846 \n",
      "(GPU: 0, epoch: 12, iters: 106752, time: 0.003) nll: 0.993363 \n",
      "(GPU: 0, epoch: 12, iters: 107552, time: 0.003) nll: 0.613330 \n",
      "(GPU: 0, epoch: 12, iters: 108352, time: 0.003) nll: 0.861432 \n",
      "(GPU: 0, epoch: 12, iters: 109152, time: 0.003) nll: 0.747348 \n",
      "(GPU: 0, epoch: 12, iters: 109952, time: 0.003) nll: 0.652040 \n",
      "(GPU: 0, epoch: 12, iters: 110752, time: 0.003) nll: 0.744196 \n",
      "(GPU: 0, epoch: 12, iters: 111552, time: 0.003) nll: 0.672651 \n",
      "saving the latest model (epoch 12, total_steps 1800000)\n",
      "(GPU: 0, epoch: 12, iters: 112352, time: 0.003) nll: 0.785839 \n",
      "(GPU: 0, epoch: 12, iters: 113152, time: 0.003) nll: 1.000449 \n",
      "(GPU: 0, epoch: 12, iters: 113952, time: 0.003) nll: 0.832937 \n",
      "(GPU: 0, epoch: 12, iters: 114752, time: 0.003) nll: 0.596511 \n",
      "(GPU: 0, epoch: 12, iters: 115552, time: 0.003) nll: 0.640479 \n",
      "(GPU: 0, epoch: 12, iters: 116352, time: 0.003) nll: 0.628655 \n",
      "(GPU: 0, epoch: 12, iters: 117152, time: 0.003) nll: 0.678991 \n",
      "(GPU: 0, epoch: 12, iters: 117952, time: 0.003) nll: 0.762757 \n",
      "(GPU: 0, epoch: 12, iters: 118752, time: 0.003) nll: 0.654126 \n",
      "(GPU: 0, epoch: 12, iters: 119552, time: 0.003) nll: 0.829139 \n",
      "(GPU: 0, epoch: 12, iters: 120352, time: 0.003) nll: 0.853284 \n",
      "(GPU: 0, epoch: 12, iters: 121152, time: 0.003) nll: 0.718499 \n",
      "(GPU: 0, epoch: 12, iters: 121952, time: 0.003) nll: 0.850768 \n",
      "(GPU: 0, epoch: 12, iters: 122752, time: 0.003) nll: 1.018642 \n",
      "(GPU: 0, epoch: 12, iters: 123552, time: 0.003) nll: 0.789035 \n",
      "(GPU: 0, epoch: 12, iters: 124352, time: 0.003) nll: 0.820401 \n",
      "(GPU: 0, epoch: 12, iters: 125152, time: 0.003) nll: 0.685136 \n",
      "(GPU: 0, epoch: 12, iters: 125952, time: 0.003) nll: 0.797716 \n",
      "(GPU: 0, epoch: 12, iters: 126752, time: 0.003) nll: 0.837926 \n",
      "(GPU: 0, epoch: 12, iters: 127552, time: 0.003) nll: 1.050887 \n",
      "(GPU: 0, epoch: 12, iters: 128352, time: 0.003) nll: 0.838899 \n",
      "(GPU: 0, epoch: 12, iters: 129152, time: 0.003) nll: 1.000929 \n",
      "(GPU: 0, epoch: 12, iters: 129952, time: 0.003) nll: 0.687853 \n",
      "(GPU: 0, epoch: 12, iters: 130752, time: 0.003) nll: 0.819569 \n",
      "(GPU: 0, epoch: 12, iters: 131552, time: 0.003) nll: 0.837508 \n",
      "saving the latest model (epoch 12, total_steps 1820000)\n",
      "(GPU: 0, epoch: 12, iters: 132352, time: 0.003) nll: 0.830225 \n",
      "(GPU: 0, epoch: 12, iters: 133152, time: 0.003) nll: 0.951106 \n",
      "(GPU: 0, epoch: 12, iters: 133952, time: 0.003) nll: 0.814710 \n",
      "(GPU: 0, epoch: 12, iters: 134752, time: 0.003) nll: 0.810283 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.003) nll: 0.832776 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.005) nll: 0.822368 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.005) nll: 0.907297 \n",
      "(GPU: 0, epoch: 12, iters: 136352, time: 0.003) nll: 0.944687 \n",
      "(GPU: 0, epoch: 12, iters: 137152, time: 0.003) nll: 1.009379 \n",
      "(GPU: 0, epoch: 12, iters: 137952, time: 0.003) nll: 0.724032 \n",
      "(GPU: 0, epoch: 12, iters: 138752, time: 0.003) nll: 0.880119 \n",
      "(GPU: 0, epoch: 12, iters: 139552, time: 0.003) nll: 0.998441 \n",
      "(GPU: 0, epoch: 12, iters: 140352, time: 0.003) nll: 0.620832 \n",
      "saving the model at the end of epoch 12, iters 1829152\n",
      "([test] GPU: 0, epoch: 12) \n",
      "OrderedDict()\n",
      "[*] End of epoch 12 / 25 \t Time Taken: 522 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000877\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3088/4397 [05:58<02:18,  9.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 32, time: 0.002) nll: 0.861754 \n",
      "(GPU: 0, epoch: 13, iters: 32, time: 0.002) nll: 0.653883 \n",
      "(GPU: 0, epoch: 13, iters: 448, time: 0.003) nll: 0.798500 \n",
      "(GPU: 0, epoch: 13, iters: 1248, time: 0.003) nll: 0.576459 \n",
      "(GPU: 0, epoch: 13, iters: 2048, time: 0.003) nll: 0.564359 \n",
      "(GPU: 0, epoch: 13, iters: 2848, time: 0.003) nll: 0.838040 \n",
      "(GPU: 0, epoch: 13, iters: 3648, time: 0.003) nll: 0.458353 \n",
      "(GPU: 0, epoch: 13, iters: 4448, time: 0.003) nll: 0.976835 \n",
      "(GPU: 0, epoch: 13, iters: 5248, time: 0.003) nll: 0.886797 \n",
      "(GPU: 0, epoch: 13, iters: 6048, time: 0.003) nll: 0.636732 \n",
      "(GPU: 0, epoch: 13, iters: 6848, time: 0.003) nll: 0.752516 \n",
      "(GPU: 0, epoch: 13, iters: 7648, time: 0.003) nll: 0.727101 \n",
      "(GPU: 0, epoch: 13, iters: 8448, time: 0.003) nll: 0.640056 \n",
      "(GPU: 0, epoch: 13, iters: 9248, time: 0.003) nll: 0.768264 \n",
      "(GPU: 0, epoch: 13, iters: 10048, time: 0.003) nll: 0.831924 \n",
      "(GPU: 0, epoch: 13, iters: 10848, time: 0.003) nll: 0.946462 \n",
      "saving the latest model (epoch 13, total_steps 1840000)\n",
      "(GPU: 0, epoch: 13, iters: 11648, time: 0.003) nll: 0.787921 \n",
      "(GPU: 0, epoch: 13, iters: 12448, time: 0.003) nll: 0.663474 \n",
      "(GPU: 0, epoch: 13, iters: 13248, time: 0.003) nll: 0.731056 \n",
      "(GPU: 0, epoch: 13, iters: 14048, time: 0.003) nll: 0.909608 \n",
      "(GPU: 0, epoch: 13, iters: 14848, time: 0.003) nll: 0.670607 \n",
      "(GPU: 0, epoch: 13, iters: 15648, time: 0.003) nll: 0.505422 \n",
      "(GPU: 0, epoch: 13, iters: 16448, time: 0.003) nll: 0.709471 \n",
      "(GPU: 0, epoch: 13, iters: 17248, time: 0.003) nll: 0.863133 \n",
      "(GPU: 0, epoch: 13, iters: 18048, time: 0.003) nll: 0.496169 \n",
      "(GPU: 0, epoch: 13, iters: 18848, time: 0.003) nll: 0.647948 \n",
      "(GPU: 0, epoch: 13, iters: 19648, time: 0.003) nll: 0.788406 \n",
      "(GPU: 0, epoch: 13, iters: 20448, time: 0.003) nll: 0.755779 \n",
      "(GPU: 0, epoch: 13, iters: 21248, time: 0.003) nll: 1.002308 \n",
      "(GPU: 0, epoch: 13, iters: 22048, time: 0.003) nll: 1.143811 \n",
      "(GPU: 0, epoch: 13, iters: 22848, time: 0.003) nll: 0.621548 \n",
      "(GPU: 0, epoch: 13, iters: 23648, time: 0.003) nll: 0.662725 \n",
      "(GPU: 0, epoch: 13, iters: 24448, time: 0.003) nll: 0.732769 \n",
      "(GPU: 0, epoch: 13, iters: 25248, time: 0.003) nll: 0.760714 \n",
      "(GPU: 0, epoch: 13, iters: 26048, time: 0.003) nll: 1.062920 \n",
      "(GPU: 0, epoch: 13, iters: 26848, time: 0.003) nll: 0.645716 \n",
      "(GPU: 0, epoch: 13, iters: 27648, time: 0.003) nll: 0.789010 \n",
      "(GPU: 0, epoch: 13, iters: 28448, time: 0.003) nll: 0.857485 \n",
      "(GPU: 0, epoch: 13, iters: 29248, time: 0.003) nll: 0.743216 \n",
      "(GPU: 0, epoch: 13, iters: 30048, time: 0.003) nll: 0.682968 \n",
      "(GPU: 0, epoch: 13, iters: 30848, time: 0.003) nll: 1.047128 \n",
      "saving the latest model (epoch 13, total_steps 1860000)\n",
      "(GPU: 0, epoch: 13, iters: 31648, time: 0.003) nll: 0.968581 \n",
      "(GPU: 0, epoch: 13, iters: 32448, time: 0.003) nll: 0.897425 \n",
      "(GPU: 0, epoch: 13, iters: 33248, time: 0.003) nll: 0.991243 \n",
      "(GPU: 0, epoch: 13, iters: 34048, time: 0.003) nll: 0.735575 \n",
      "(GPU: 0, epoch: 13, iters: 34848, time: 0.003) nll: 0.598895 \n",
      "(GPU: 0, epoch: 13, iters: 35648, time: 0.003) nll: 0.763799 \n",
      "(GPU: 0, epoch: 13, iters: 36448, time: 0.003) nll: 0.865800 \n",
      "(GPU: 0, epoch: 13, iters: 37248, time: 0.003) nll: 0.662301 \n",
      "(GPU: 0, epoch: 13, iters: 38048, time: 0.003) nll: 0.703595 \n",
      "(GPU: 0, epoch: 13, iters: 38848, time: 0.003) nll: 0.921544 \n",
      "(GPU: 0, epoch: 13, iters: 39648, time: 0.003) nll: 1.031750 \n",
      "(GPU: 0, epoch: 13, iters: 40448, time: 0.003) nll: 0.703286 \n",
      "(GPU: 0, epoch: 13, iters: 41248, time: 0.003) nll: 0.958496 \n",
      "(GPU: 0, epoch: 13, iters: 42048, time: 0.003) nll: 0.867480 \n",
      "(GPU: 0, epoch: 13, iters: 42848, time: 0.003) nll: 1.037972 \n",
      "(GPU: 0, epoch: 13, iters: 43648, time: 0.003) nll: 0.672345 \n",
      "(GPU: 0, epoch: 13, iters: 44448, time: 0.003) nll: 1.226526 \n",
      "(GPU: 0, epoch: 13, iters: 45248, time: 0.003) nll: 0.890311 \n",
      "(GPU: 0, epoch: 13, iters: 46048, time: 0.003) nll: 0.826945 \n",
      "(GPU: 0, epoch: 13, iters: 46848, time: 0.003) nll: 0.919206 \n",
      "(GPU: 0, epoch: 13, iters: 47648, time: 0.003) nll: 0.826902 \n",
      "(GPU: 0, epoch: 13, iters: 48448, time: 0.003) nll: 0.833269 \n",
      "(GPU: 0, epoch: 13, iters: 49248, time: 0.003) nll: 0.524540 \n",
      "(GPU: 0, epoch: 13, iters: 50048, time: 0.003) nll: 0.532972 \n",
      "(GPU: 0, epoch: 13, iters: 50848, time: 0.003) nll: 0.650997 \n",
      "saving the latest model (epoch 13, total_steps 1880000)\n",
      "(GPU: 0, epoch: 13, iters: 51648, time: 0.003) nll: 0.740800 \n",
      "(GPU: 0, epoch: 13, iters: 52448, time: 0.003) nll: 0.805835 \n",
      "(GPU: 0, epoch: 13, iters: 53248, time: 0.003) nll: 0.752573 \n",
      "(GPU: 0, epoch: 13, iters: 54048, time: 0.003) nll: 0.667211 \n",
      "(GPU: 0, epoch: 13, iters: 54848, time: 0.003) nll: 0.817147 \n",
      "(GPU: 0, epoch: 13, iters: 55648, time: 0.003) nll: 0.545409 \n",
      "(GPU: 0, epoch: 13, iters: 56448, time: 0.003) nll: 0.715569 \n",
      "(GPU: 0, epoch: 13, iters: 57248, time: 0.003) nll: 0.527073 \n",
      "(GPU: 0, epoch: 13, iters: 58048, time: 0.003) nll: 0.852127 \n",
      "(GPU: 0, epoch: 13, iters: 58848, time: 0.003) nll: 0.820198 \n",
      "(GPU: 0, epoch: 13, iters: 59648, time: 0.003) nll: 0.838895 \n",
      "(GPU: 0, epoch: 13, iters: 60448, time: 0.003) nll: 0.931928 \n",
      "(GPU: 0, epoch: 13, iters: 61248, time: 0.003) nll: 0.775030 \n",
      "(GPU: 0, epoch: 13, iters: 62048, time: 0.003) nll: 0.747000 \n",
      "(GPU: 0, epoch: 13, iters: 62848, time: 0.003) nll: 0.946557 \n",
      "(GPU: 0, epoch: 13, iters: 63648, time: 0.003) nll: 0.604660 \n",
      "(GPU: 0, epoch: 13, iters: 64448, time: 0.003) nll: 0.781041 \n",
      "(GPU: 0, epoch: 13, iters: 65248, time: 0.003) nll: 0.638052 \n",
      "(GPU: 0, epoch: 13, iters: 66048, time: 0.003) nll: 0.772806 \n",
      "(GPU: 0, epoch: 13, iters: 66848, time: 0.003) nll: 0.812900 \n",
      "(GPU: 0, epoch: 13, iters: 67648, time: 0.003) nll: 0.739078 \n",
      "(GPU: 0, epoch: 13, iters: 68448, time: 0.003) nll: 0.899128 \n",
      "(GPU: 0, epoch: 13, iters: 69248, time: 0.003) nll: 0.746617 \n",
      "(GPU: 0, epoch: 13, iters: 70048, time: 0.003) nll: 0.725703 \n",
      "(GPU: 0, epoch: 13, iters: 70848, time: 0.003) nll: 0.650075 \n",
      "saving the latest model (epoch 13, total_steps 1900000)\n",
      "(GPU: 0, epoch: 13, iters: 71648, time: 0.003) nll: 0.767935 \n",
      "(GPU: 0, epoch: 13, iters: 72448, time: 0.003) nll: 0.745591 \n",
      "(GPU: 0, epoch: 13, iters: 73248, time: 0.003) nll: 0.762367 \n",
      "(GPU: 0, epoch: 13, iters: 74048, time: 0.003) nll: 0.755091 \n",
      "(GPU: 0, epoch: 13, iters: 74848, time: 0.003) nll: 1.003756 \n",
      "(GPU: 0, epoch: 13, iters: 75648, time: 0.003) nll: 0.846164 \n",
      "(GPU: 0, epoch: 13, iters: 76448, time: 0.003) nll: 0.734427 \n",
      "(GPU: 0, epoch: 13, iters: 77248, time: 0.003) nll: 0.777316 \n",
      "(GPU: 0, epoch: 13, iters: 78048, time: 0.003) nll: 0.856456 \n",
      "(GPU: 0, epoch: 13, iters: 78848, time: 0.003) nll: 0.650978 \n",
      "(GPU: 0, epoch: 13, iters: 79648, time: 0.003) nll: 0.826470 \n",
      "(GPU: 0, epoch: 13, iters: 80448, time: 0.003) nll: 1.022030 \n",
      "(GPU: 0, epoch: 13, iters: 81248, time: 0.003) nll: 0.924689 \n",
      "(GPU: 0, epoch: 13, iters: 82048, time: 0.003) nll: 0.805082 \n",
      "(GPU: 0, epoch: 13, iters: 82848, time: 0.003) nll: 0.832884 \n",
      "(GPU: 0, epoch: 13, iters: 83648, time: 0.003) nll: 0.650555 \n",
      "(GPU: 0, epoch: 13, iters: 84448, time: 0.003) nll: 0.762362 \n",
      "(GPU: 0, epoch: 13, iters: 85248, time: 0.003) nll: 0.789349 \n",
      "(GPU: 0, epoch: 13, iters: 86048, time: 0.003) nll: 0.722285 \n",
      "(GPU: 0, epoch: 13, iters: 86848, time: 0.003) nll: 0.743541 \n",
      "(GPU: 0, epoch: 13, iters: 87648, time: 0.003) nll: 0.891888 \n",
      "(GPU: 0, epoch: 13, iters: 88448, time: 0.003) nll: 0.798643 \n",
      "(GPU: 0, epoch: 13, iters: 89248, time: 0.003) nll: 0.611134 \n",
      "(GPU: 0, epoch: 13, iters: 90048, time: 0.003) nll: 0.827491 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.003) nll: 0.668630 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.005) nll: 0.673743 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.005) nll: 0.819462 \n",
      "saving the latest model (epoch 13, total_steps 1920000)\n",
      "(GPU: 0, epoch: 13, iters: 91648, time: 0.003) nll: 0.735230 \n",
      "(GPU: 0, epoch: 13, iters: 92448, time: 0.003) nll: 0.814560 \n",
      "(GPU: 0, epoch: 13, iters: 93248, time: 0.003) nll: 0.794395 \n",
      "(GPU: 0, epoch: 13, iters: 94048, time: 0.003) nll: 1.158198 \n",
      "(GPU: 0, epoch: 13, iters: 94848, time: 0.003) nll: 0.924107 \n",
      "(GPU: 0, epoch: 13, iters: 95648, time: 0.003) nll: 0.685767 \n",
      "(GPU: 0, epoch: 13, iters: 96448, time: 0.003) nll: 0.720815 \n",
      "(GPU: 0, epoch: 13, iters: 97248, time: 0.003) nll: 0.662912 \n",
      "(GPU: 0, epoch: 13, iters: 98048, time: 0.003) nll: 0.926192 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:28<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 98848, time: 0.003) nll: 0.884716 \n",
      "(GPU: 0, epoch: 13, iters: 99648, time: 0.003) nll: 0.774420 \n",
      "(GPU: 0, epoch: 13, iters: 100448, time: 0.003) nll: 0.575976 \n",
      "(GPU: 0, epoch: 13, iters: 101248, time: 0.003) nll: 1.019776 \n",
      "(GPU: 0, epoch: 13, iters: 102048, time: 0.003) nll: 0.645420 \n",
      "(GPU: 0, epoch: 13, iters: 102848, time: 0.003) nll: 0.803867 \n",
      "(GPU: 0, epoch: 13, iters: 103648, time: 0.003) nll: 0.724549 \n",
      "(GPU: 0, epoch: 13, iters: 104448, time: 0.003) nll: 0.751299 \n",
      "(GPU: 0, epoch: 13, iters: 105248, time: 0.003) nll: 0.812355 \n",
      "(GPU: 0, epoch: 13, iters: 106048, time: 0.003) nll: 0.622345 \n",
      "(GPU: 0, epoch: 13, iters: 106848, time: 0.003) nll: 0.868056 \n",
      "(GPU: 0, epoch: 13, iters: 107648, time: 0.003) nll: 0.815566 \n",
      "(GPU: 0, epoch: 13, iters: 108448, time: 0.003) nll: 0.875395 \n",
      "(GPU: 0, epoch: 13, iters: 109248, time: 0.003) nll: 0.755618 \n",
      "(GPU: 0, epoch: 13, iters: 110048, time: 0.003) nll: 0.830682 \n",
      "(GPU: 0, epoch: 13, iters: 110848, time: 0.003) nll: 1.105108 \n",
      "saving the latest model (epoch 13, total_steps 1940000)\n",
      "(GPU: 0, epoch: 13, iters: 111648, time: 0.003) nll: 0.603689 \n",
      "(GPU: 0, epoch: 13, iters: 112448, time: 0.003) nll: 0.615239 \n",
      "(GPU: 0, epoch: 13, iters: 113248, time: 0.003) nll: 0.584316 \n",
      "(GPU: 0, epoch: 13, iters: 114048, time: 0.003) nll: 0.792273 \n",
      "(GPU: 0, epoch: 13, iters: 114848, time: 0.003) nll: 0.636423 \n",
      "(GPU: 0, epoch: 13, iters: 115648, time: 0.003) nll: 0.871882 \n",
      "(GPU: 0, epoch: 13, iters: 116448, time: 0.003) nll: 0.826010 \n",
      "(GPU: 0, epoch: 13, iters: 117248, time: 0.003) nll: 0.790702 \n",
      "(GPU: 0, epoch: 13, iters: 118048, time: 0.003) nll: 0.868415 \n",
      "(GPU: 0, epoch: 13, iters: 118848, time: 0.003) nll: 0.920778 \n",
      "(GPU: 0, epoch: 13, iters: 119648, time: 0.003) nll: 0.794357 \n",
      "(GPU: 0, epoch: 13, iters: 120448, time: 0.003) nll: 1.070713 \n",
      "(GPU: 0, epoch: 13, iters: 121248, time: 0.003) nll: 0.802618 \n",
      "(GPU: 0, epoch: 13, iters: 122048, time: 0.003) nll: 0.699065 \n",
      "(GPU: 0, epoch: 13, iters: 122848, time: 0.003) nll: 0.742434 \n",
      "(GPU: 0, epoch: 13, iters: 123648, time: 0.003) nll: 0.815339 \n",
      "(GPU: 0, epoch: 13, iters: 124448, time: 0.003) nll: 0.734668 \n",
      "(GPU: 0, epoch: 13, iters: 125248, time: 0.003) nll: 1.068193 \n",
      "(GPU: 0, epoch: 13, iters: 126048, time: 0.003) nll: 0.964393 \n",
      "(GPU: 0, epoch: 13, iters: 126848, time: 0.003) nll: 0.751518 \n",
      "(GPU: 0, epoch: 13, iters: 127648, time: 0.003) nll: 0.661752 \n",
      "(GPU: 0, epoch: 13, iters: 128448, time: 0.003) nll: 1.040618 \n",
      "(GPU: 0, epoch: 13, iters: 129248, time: 0.003) nll: 0.780412 \n",
      "(GPU: 0, epoch: 13, iters: 130048, time: 0.003) nll: 0.882207 \n",
      "(GPU: 0, epoch: 13, iters: 130848, time: 0.003) nll: 0.561842 \n",
      "saving the latest model (epoch 13, total_steps 1960000)\n",
      "(GPU: 0, epoch: 13, iters: 131648, time: 0.003) nll: 0.572728 \n",
      "(GPU: 0, epoch: 13, iters: 132448, time: 0.003) nll: 0.679234 \n",
      "(GPU: 0, epoch: 13, iters: 133248, time: 0.003) nll: 0.895353 \n",
      "(GPU: 0, epoch: 13, iters: 134048, time: 0.003) nll: 0.518852 \n",
      "(GPU: 0, epoch: 13, iters: 134848, time: 0.003) nll: 0.638394 \n",
      "(GPU: 0, epoch: 13, iters: 135648, time: 0.003) nll: 0.835153 \n",
      "(GPU: 0, epoch: 13, iters: 136448, time: 0.003) nll: 0.750238 \n",
      "(GPU: 0, epoch: 13, iters: 137248, time: 0.003) nll: 0.836101 \n",
      "(GPU: 0, epoch: 13, iters: 138048, time: 0.003) nll: 0.877741 \n",
      "(GPU: 0, epoch: 13, iters: 138848, time: 0.003) nll: 0.796394 \n",
      "(GPU: 0, epoch: 13, iters: 139648, time: 0.003) nll: 0.864373 \n",
      "(GPU: 0, epoch: 13, iters: 140448, time: 0.003) nll: 0.800137 \n",
      "[*] End of epoch 13 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000845\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3092/4397 [05:59<02:43,  7.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 32, time: 0.002) nll: 0.907134 \n",
      "(GPU: 0, epoch: 14, iters: 32, time: 0.002) nll: 1.151576 \n",
      "(GPU: 0, epoch: 14, iters: 544, time: 0.003) nll: 0.848212 \n",
      "(GPU: 0, epoch: 14, iters: 1344, time: 0.003) nll: 0.809117 \n",
      "(GPU: 0, epoch: 14, iters: 2144, time: 0.003) nll: 0.869875 \n",
      "(GPU: 0, epoch: 14, iters: 2944, time: 0.003) nll: 0.620395 \n",
      "(GPU: 0, epoch: 14, iters: 3744, time: 0.003) nll: 0.733093 \n",
      "(GPU: 0, epoch: 14, iters: 4544, time: 0.003) nll: 0.835733 \n",
      "(GPU: 0, epoch: 14, iters: 5344, time: 0.003) nll: 0.802415 \n",
      "(GPU: 0, epoch: 14, iters: 6144, time: 0.003) nll: 0.638117 \n",
      "(GPU: 0, epoch: 14, iters: 6944, time: 0.003) nll: 0.627440 \n",
      "(GPU: 0, epoch: 14, iters: 7744, time: 0.003) nll: 0.731083 \n",
      "(GPU: 0, epoch: 14, iters: 8544, time: 0.003) nll: 0.574918 \n",
      "(GPU: 0, epoch: 14, iters: 9344, time: 0.003) nll: 0.793191 \n",
      "(GPU: 0, epoch: 14, iters: 10144, time: 0.003) nll: 0.767310 \n",
      "saving the latest model (epoch 14, total_steps 1980000)\n",
      "(GPU: 0, epoch: 14, iters: 10944, time: 0.003) nll: 0.783375 \n",
      "(GPU: 0, epoch: 14, iters: 11744, time: 0.003) nll: 0.732088 \n",
      "(GPU: 0, epoch: 14, iters: 12544, time: 0.003) nll: 0.804586 \n",
      "(GPU: 0, epoch: 14, iters: 13344, time: 0.003) nll: 0.673103 \n",
      "(GPU: 0, epoch: 14, iters: 14144, time: 0.003) nll: 0.682139 \n",
      "(GPU: 0, epoch: 14, iters: 14944, time: 0.003) nll: 0.772796 \n",
      "(GPU: 0, epoch: 14, iters: 15744, time: 0.003) nll: 0.735421 \n",
      "(GPU: 0, epoch: 14, iters: 16544, time: 0.003) nll: 0.674553 \n",
      "(GPU: 0, epoch: 14, iters: 17344, time: 0.003) nll: 1.013853 \n",
      "(GPU: 0, epoch: 14, iters: 18144, time: 0.003) nll: 0.775021 \n",
      "(GPU: 0, epoch: 14, iters: 18944, time: 0.003) nll: 0.885043 \n",
      "(GPU: 0, epoch: 14, iters: 19744, time: 0.003) nll: 0.675731 \n",
      "(GPU: 0, epoch: 14, iters: 20544, time: 0.003) nll: 0.616172 \n",
      "(GPU: 0, epoch: 14, iters: 21344, time: 0.003) nll: 0.745524 \n",
      "(GPU: 0, epoch: 14, iters: 22144, time: 0.003) nll: 0.717530 \n",
      "(GPU: 0, epoch: 14, iters: 22944, time: 0.003) nll: 0.600641 \n",
      "(GPU: 0, epoch: 14, iters: 23744, time: 0.003) nll: 0.904756 \n",
      "(GPU: 0, epoch: 14, iters: 24544, time: 0.003) nll: 0.794543 \n",
      "(GPU: 0, epoch: 14, iters: 25344, time: 0.003) nll: 0.944778 \n",
      "(GPU: 0, epoch: 14, iters: 26144, time: 0.003) nll: 0.915433 \n",
      "(GPU: 0, epoch: 14, iters: 26944, time: 0.003) nll: 0.915493 \n",
      "(GPU: 0, epoch: 14, iters: 27744, time: 0.003) nll: 0.958643 \n",
      "(GPU: 0, epoch: 14, iters: 28544, time: 0.003) nll: 0.771308 \n",
      "(GPU: 0, epoch: 14, iters: 29344, time: 0.003) nll: 0.951688 \n",
      "(GPU: 0, epoch: 14, iters: 30144, time: 0.003) nll: 0.799970 \n",
      "saving the latest model (epoch 14, total_steps 2000000)\n",
      "(GPU: 0, epoch: 14, iters: 30944, time: 0.003) nll: 0.697847 \n",
      "(GPU: 0, epoch: 14, iters: 31744, time: 0.003) nll: 0.594849 \n",
      "(GPU: 0, epoch: 14, iters: 32544, time: 0.003) nll: 0.620684 \n",
      "(GPU: 0, epoch: 14, iters: 33344, time: 0.003) nll: 0.606853 \n",
      "(GPU: 0, epoch: 14, iters: 34144, time: 0.003) nll: 0.683478 \n",
      "(GPU: 0, epoch: 14, iters: 34944, time: 0.003) nll: 0.870468 \n",
      "(GPU: 0, epoch: 14, iters: 35744, time: 0.003) nll: 0.814540 \n",
      "(GPU: 0, epoch: 14, iters: 36544, time: 0.003) nll: 0.726454 \n",
      "(GPU: 0, epoch: 14, iters: 37344, time: 0.003) nll: 0.827779 \n",
      "(GPU: 0, epoch: 14, iters: 38144, time: 0.003) nll: 0.680064 \n",
      "(GPU: 0, epoch: 14, iters: 38944, time: 0.003) nll: 0.579359 \n",
      "(GPU: 0, epoch: 14, iters: 39744, time: 0.003) nll: 0.677493 \n",
      "(GPU: 0, epoch: 14, iters: 40544, time: 0.003) nll: 0.598784 \n",
      "(GPU: 0, epoch: 14, iters: 41344, time: 0.003) nll: 0.825881 \n",
      "(GPU: 0, epoch: 14, iters: 42144, time: 0.003) nll: 0.872215 \n",
      "(GPU: 0, epoch: 14, iters: 42944, time: 0.003) nll: 0.850894 \n",
      "(GPU: 0, epoch: 14, iters: 43744, time: 0.003) nll: 0.759900 \n",
      "(GPU: 0, epoch: 14, iters: 44544, time: 0.003) nll: 0.776801 \n",
      "(GPU: 0, epoch: 14, iters: 45344, time: 0.003) nll: 0.962702 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.003) nll: 0.714426 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.005) nll: 0.710068 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.005) nll: 0.632577 \n",
      "(GPU: 0, epoch: 14, iters: 46944, time: 0.003) nll: 0.626314 \n",
      "(GPU: 0, epoch: 14, iters: 47744, time: 0.003) nll: 0.804601 \n",
      "(GPU: 0, epoch: 14, iters: 48544, time: 0.003) nll: 0.829552 \n",
      "(GPU: 0, epoch: 14, iters: 49344, time: 0.003) nll: 0.783030 \n",
      "(GPU: 0, epoch: 14, iters: 50144, time: 0.003) nll: 0.674320 \n",
      "saving the latest model (epoch 14, total_steps 2020000)\n",
      "(GPU: 0, epoch: 14, iters: 50944, time: 0.003) nll: 0.838959 \n",
      "(GPU: 0, epoch: 14, iters: 51744, time: 0.003) nll: 0.963789 \n",
      "(GPU: 0, epoch: 14, iters: 52544, time: 0.003) nll: 0.870778 \n",
      "(GPU: 0, epoch: 14, iters: 53344, time: 0.003) nll: 0.942140 \n",
      "(GPU: 0, epoch: 14, iters: 54144, time: 0.003) nll: 0.653893 \n",
      "(GPU: 0, epoch: 14, iters: 54944, time: 0.003) nll: 0.698032 \n",
      "(GPU: 0, epoch: 14, iters: 55744, time: 0.003) nll: 0.846605 \n",
      "(GPU: 0, epoch: 14, iters: 56544, time: 0.003) nll: 0.625202 \n",
      "(GPU: 0, epoch: 14, iters: 57344, time: 0.003) nll: 0.590117 \n",
      "(GPU: 0, epoch: 14, iters: 58144, time: 0.003) nll: 0.871585 \n",
      "(GPU: 0, epoch: 14, iters: 58944, time: 0.003) nll: 0.657812 \n",
      "(GPU: 0, epoch: 14, iters: 59744, time: 0.003) nll: 0.776238 \n",
      "(GPU: 0, epoch: 14, iters: 60544, time: 0.003) nll: 0.738893 \n",
      "(GPU: 0, epoch: 14, iters: 61344, time: 0.003) nll: 0.714473 \n",
      "(GPU: 0, epoch: 14, iters: 62144, time: 0.003) nll: 0.615697 \n",
      "(GPU: 0, epoch: 14, iters: 62944, time: 0.003) nll: 0.937561 \n",
      "(GPU: 0, epoch: 14, iters: 63744, time: 0.003) nll: 0.964273 \n",
      "(GPU: 0, epoch: 14, iters: 64544, time: 0.003) nll: 0.646170 \n",
      "(GPU: 0, epoch: 14, iters: 65344, time: 0.003) nll: 1.112265 \n",
      "(GPU: 0, epoch: 14, iters: 66144, time: 0.003) nll: 0.846325 \n",
      "(GPU: 0, epoch: 14, iters: 66944, time: 0.003) nll: 0.821236 \n",
      "(GPU: 0, epoch: 14, iters: 67744, time: 0.003) nll: 0.755976 \n",
      "(GPU: 0, epoch: 14, iters: 68544, time: 0.003) nll: 0.739315 \n",
      "(GPU: 0, epoch: 14, iters: 69344, time: 0.003) nll: 0.922209 \n",
      "(GPU: 0, epoch: 14, iters: 70144, time: 0.003) nll: 0.944993 \n",
      "saving the latest model (epoch 14, total_steps 2040000)\n",
      "(GPU: 0, epoch: 14, iters: 70944, time: 0.003) nll: 0.737618 \n",
      "(GPU: 0, epoch: 14, iters: 71744, time: 0.003) nll: 0.775096 \n",
      "(GPU: 0, epoch: 14, iters: 72544, time: 0.003) nll: 0.796148 \n",
      "(GPU: 0, epoch: 14, iters: 73344, time: 0.003) nll: 0.586229 \n",
      "(GPU: 0, epoch: 14, iters: 74144, time: 0.003) nll: 0.816189 \n",
      "(GPU: 0, epoch: 14, iters: 74944, time: 0.003) nll: 1.018535 \n",
      "(GPU: 0, epoch: 14, iters: 75744, time: 0.003) nll: 0.860130 \n",
      "(GPU: 0, epoch: 14, iters: 76544, time: 0.003) nll: 0.726941 \n",
      "(GPU: 0, epoch: 14, iters: 77344, time: 0.003) nll: 0.699776 \n",
      "(GPU: 0, epoch: 14, iters: 78144, time: 0.003) nll: 0.652847 \n",
      "(GPU: 0, epoch: 14, iters: 78944, time: 0.003) nll: 0.849401 \n",
      "(GPU: 0, epoch: 14, iters: 79744, time: 0.003) nll: 0.722120 \n",
      "(GPU: 0, epoch: 14, iters: 80544, time: 0.003) nll: 1.073151 \n",
      "(GPU: 0, epoch: 14, iters: 81344, time: 0.003) nll: 0.805697 \n",
      "(GPU: 0, epoch: 14, iters: 82144, time: 0.003) nll: 0.718096 \n",
      "(GPU: 0, epoch: 14, iters: 82944, time: 0.003) nll: 0.750099 \n",
      "(GPU: 0, epoch: 14, iters: 83744, time: 0.003) nll: 0.862630 \n",
      "(GPU: 0, epoch: 14, iters: 84544, time: 0.003) nll: 0.679131 \n",
      "(GPU: 0, epoch: 14, iters: 85344, time: 0.003) nll: 0.700342 \n",
      "(GPU: 0, epoch: 14, iters: 86144, time: 0.003) nll: 0.666828 \n",
      "(GPU: 0, epoch: 14, iters: 86944, time: 0.003) nll: 0.708029 \n",
      "(GPU: 0, epoch: 14, iters: 87744, time: 0.003) nll: 0.671288 \n",
      "(GPU: 0, epoch: 14, iters: 88544, time: 0.003) nll: 0.602376 \n",
      "(GPU: 0, epoch: 14, iters: 89344, time: 0.003) nll: 0.615350 \n",
      "(GPU: 0, epoch: 14, iters: 90144, time: 0.003) nll: 0.811454 \n",
      "saving the latest model (epoch 14, total_steps 2060000)\n",
      "(GPU: 0, epoch: 14, iters: 90944, time: 0.003) nll: 0.797545 \n",
      "(GPU: 0, epoch: 14, iters: 91744, time: 0.003) nll: 0.819590 \n",
      "(GPU: 0, epoch: 14, iters: 92544, time: 0.003) nll: 0.718805 \n",
      "(GPU: 0, epoch: 14, iters: 93344, time: 0.003) nll: 0.546024 \n",
      "(GPU: 0, epoch: 14, iters: 94144, time: 0.003) nll: 0.639391 \n",
      "(GPU: 0, epoch: 14, iters: 94944, time: 0.003) nll: 0.710561 \n",
      "(GPU: 0, epoch: 14, iters: 95744, time: 0.003) nll: 0.961083 \n",
      "(GPU: 0, epoch: 14, iters: 96544, time: 0.003) nll: 0.743623 \n",
      "(GPU: 0, epoch: 14, iters: 97344, time: 0.003) nll: 0.723759 \n",
      "(GPU: 0, epoch: 14, iters: 98144, time: 0.003) nll: 0.824229 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 98944, time: 0.003) nll: 0.832300 \n",
      "(GPU: 0, epoch: 14, iters: 99744, time: 0.003) nll: 0.859906 \n",
      "(GPU: 0, epoch: 14, iters: 100544, time: 0.003) nll: 0.759272 \n",
      "(GPU: 0, epoch: 14, iters: 101344, time: 0.003) nll: 0.760406 \n",
      "(GPU: 0, epoch: 14, iters: 102144, time: 0.003) nll: 0.812895 \n",
      "(GPU: 0, epoch: 14, iters: 102944, time: 0.003) nll: 0.703989 \n",
      "(GPU: 0, epoch: 14, iters: 103744, time: 0.003) nll: 0.732898 \n",
      "(GPU: 0, epoch: 14, iters: 104544, time: 0.003) nll: 1.038079 \n",
      "(GPU: 0, epoch: 14, iters: 105344, time: 0.003) nll: 0.784075 \n",
      "(GPU: 0, epoch: 14, iters: 106144, time: 0.003) nll: 0.938482 \n",
      "(GPU: 0, epoch: 14, iters: 106944, time: 0.003) nll: 0.903082 \n",
      "(GPU: 0, epoch: 14, iters: 107744, time: 0.003) nll: 0.747096 \n",
      "(GPU: 0, epoch: 14, iters: 108544, time: 0.003) nll: 0.849034 \n",
      "(GPU: 0, epoch: 14, iters: 109344, time: 0.003) nll: 0.824325 \n",
      "(GPU: 0, epoch: 14, iters: 110144, time: 0.003) nll: 1.017902 \n",
      "saving the latest model (epoch 14, total_steps 2080000)\n",
      "(GPU: 0, epoch: 14, iters: 110944, time: 0.003) nll: 0.731251 \n",
      "(GPU: 0, epoch: 14, iters: 111744, time: 0.003) nll: 0.762372 \n",
      "(GPU: 0, epoch: 14, iters: 112544, time: 0.003) nll: 0.990841 \n",
      "(GPU: 0, epoch: 14, iters: 113344, time: 0.003) nll: 0.789298 \n",
      "(GPU: 0, epoch: 14, iters: 114144, time: 0.003) nll: 0.515119 \n",
      "(GPU: 0, epoch: 14, iters: 114944, time: 0.003) nll: 0.760301 \n",
      "(GPU: 0, epoch: 14, iters: 115744, time: 0.003) nll: 1.041683 \n",
      "(GPU: 0, epoch: 14, iters: 116544, time: 0.003) nll: 0.632448 \n",
      "(GPU: 0, epoch: 14, iters: 117344, time: 0.003) nll: 0.648880 \n",
      "(GPU: 0, epoch: 14, iters: 118144, time: 0.003) nll: 0.974123 \n",
      "(GPU: 0, epoch: 14, iters: 118944, time: 0.003) nll: 0.851127 \n",
      "(GPU: 0, epoch: 14, iters: 119744, time: 0.003) nll: 0.792700 \n",
      "(GPU: 0, epoch: 14, iters: 120544, time: 0.003) nll: 0.755209 \n",
      "(GPU: 0, epoch: 14, iters: 121344, time: 0.003) nll: 0.749676 \n",
      "(GPU: 0, epoch: 14, iters: 122144, time: 0.003) nll: 0.772852 \n",
      "(GPU: 0, epoch: 14, iters: 122944, time: 0.003) nll: 0.708175 \n",
      "(GPU: 0, epoch: 14, iters: 123744, time: 0.003) nll: 0.735440 \n",
      "(GPU: 0, epoch: 14, iters: 124544, time: 0.003) nll: 0.663055 \n",
      "(GPU: 0, epoch: 14, iters: 125344, time: 0.003) nll: 0.611202 \n",
      "(GPU: 0, epoch: 14, iters: 126144, time: 0.003) nll: 0.865597 \n",
      "(GPU: 0, epoch: 14, iters: 126944, time: 0.003) nll: 0.753066 \n",
      "(GPU: 0, epoch: 14, iters: 127744, time: 0.003) nll: 0.687991 \n",
      "(GPU: 0, epoch: 14, iters: 128544, time: 0.003) nll: 0.756812 \n",
      "(GPU: 0, epoch: 14, iters: 129344, time: 0.003) nll: 0.822951 \n",
      "(GPU: 0, epoch: 14, iters: 130144, time: 0.003) nll: 0.640503 \n",
      "saving the latest model (epoch 14, total_steps 2100000)\n",
      "(GPU: 0, epoch: 14, iters: 130944, time: 0.003) nll: 1.139713 \n",
      "(GPU: 0, epoch: 14, iters: 131744, time: 0.003) nll: 0.748873 \n",
      "(GPU: 0, epoch: 14, iters: 132544, time: 0.003) nll: 0.863163 \n",
      "(GPU: 0, epoch: 14, iters: 133344, time: 0.003) nll: 1.047354 \n",
      "(GPU: 0, epoch: 14, iters: 134144, time: 0.003) nll: 0.647759 \n",
      "(GPU: 0, epoch: 14, iters: 134944, time: 0.003) nll: 0.431996 \n",
      "(GPU: 0, epoch: 14, iters: 135744, time: 0.003) nll: 1.051465 \n",
      "(GPU: 0, epoch: 14, iters: 136544, time: 0.003) nll: 0.623204 \n",
      "(GPU: 0, epoch: 14, iters: 137344, time: 0.003) nll: 0.723400 \n",
      "(GPU: 0, epoch: 14, iters: 138144, time: 0.003) nll: 0.791448 \n",
      "(GPU: 0, epoch: 14, iters: 138944, time: 0.003) nll: 0.805418 \n",
      "(GPU: 0, epoch: 14, iters: 139744, time: 0.003) nll: 0.824911 \n",
      "(GPU: 0, epoch: 14, iters: 140544, time: 0.003) nll: 0.900902 \n",
      "[*] End of epoch 14 / 25 \t Time Taken: 510 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000816\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3044/4397 [05:54<02:21,  9.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 32, time: 0.002) nll: 0.734745 \n",
      "(GPU: 0, epoch: 15, iters: 32, time: 0.002) nll: 0.674335 \n",
      "(GPU: 0, epoch: 15, iters: 640, time: 0.003) nll: 0.751289 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.003) nll: 0.678189 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.005) nll: 0.710724 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.005) nll: 0.831792 \n",
      "(GPU: 0, epoch: 15, iters: 2240, time: 0.003) nll: 0.665129 \n",
      "(GPU: 0, epoch: 15, iters: 3040, time: 0.003) nll: 0.770437 \n",
      "(GPU: 0, epoch: 15, iters: 3840, time: 0.003) nll: 0.692794 \n",
      "(GPU: 0, epoch: 15, iters: 4640, time: 0.003) nll: 0.740926 \n",
      "(GPU: 0, epoch: 15, iters: 5440, time: 0.003) nll: 0.734107 \n",
      "(GPU: 0, epoch: 15, iters: 6240, time: 0.003) nll: 0.797014 \n",
      "(GPU: 0, epoch: 15, iters: 7040, time: 0.003) nll: 0.709987 \n",
      "(GPU: 0, epoch: 15, iters: 7840, time: 0.003) nll: 0.735275 \n",
      "(GPU: 0, epoch: 15, iters: 8640, time: 0.003) nll: 0.703036 \n",
      "(GPU: 0, epoch: 15, iters: 9440, time: 0.003) nll: 0.769533 \n",
      "saving the latest model (epoch 15, total_steps 2120000)\n",
      "(GPU: 0, epoch: 15, iters: 10240, time: 0.003) nll: 0.887320 \n",
      "(GPU: 0, epoch: 15, iters: 11040, time: 0.003) nll: 0.878899 \n",
      "(GPU: 0, epoch: 15, iters: 11840, time: 0.003) nll: 0.651443 \n",
      "(GPU: 0, epoch: 15, iters: 12640, time: 0.003) nll: 0.698905 \n",
      "(GPU: 0, epoch: 15, iters: 13440, time: 0.003) nll: 0.808636 \n",
      "(GPU: 0, epoch: 15, iters: 14240, time: 0.003) nll: 0.625972 \n",
      "(GPU: 0, epoch: 15, iters: 15040, time: 0.003) nll: 0.799226 \n",
      "(GPU: 0, epoch: 15, iters: 15840, time: 0.003) nll: 0.670333 \n",
      "(GPU: 0, epoch: 15, iters: 16640, time: 0.003) nll: 0.631941 \n",
      "(GPU: 0, epoch: 15, iters: 17440, time: 0.003) nll: 1.034608 \n",
      "(GPU: 0, epoch: 15, iters: 18240, time: 0.003) nll: 0.871594 \n",
      "(GPU: 0, epoch: 15, iters: 19040, time: 0.003) nll: 0.670990 \n",
      "(GPU: 0, epoch: 15, iters: 19840, time: 0.003) nll: 0.702794 \n",
      "(GPU: 0, epoch: 15, iters: 20640, time: 0.003) nll: 0.953255 \n",
      "(GPU: 0, epoch: 15, iters: 21440, time: 0.003) nll: 0.853957 \n",
      "(GPU: 0, epoch: 15, iters: 22240, time: 0.003) nll: 0.766744 \n",
      "(GPU: 0, epoch: 15, iters: 23040, time: 0.003) nll: 0.980917 \n",
      "(GPU: 0, epoch: 15, iters: 23840, time: 0.003) nll: 0.782028 \n",
      "(GPU: 0, epoch: 15, iters: 24640, time: 0.003) nll: 0.837546 \n",
      "(GPU: 0, epoch: 15, iters: 25440, time: 0.003) nll: 0.631309 \n",
      "(GPU: 0, epoch: 15, iters: 26240, time: 0.003) nll: 0.766770 \n",
      "(GPU: 0, epoch: 15, iters: 27040, time: 0.003) nll: 0.582612 \n",
      "(GPU: 0, epoch: 15, iters: 27840, time: 0.003) nll: 0.641419 \n",
      "(GPU: 0, epoch: 15, iters: 28640, time: 0.003) nll: 0.722844 \n",
      "(GPU: 0, epoch: 15, iters: 29440, time: 0.003) nll: 0.841218 \n",
      "saving the latest model (epoch 15, total_steps 2140000)\n",
      "(GPU: 0, epoch: 15, iters: 30240, time: 0.003) nll: 0.778768 \n",
      "(GPU: 0, epoch: 15, iters: 31040, time: 0.003) nll: 0.830192 \n",
      "(GPU: 0, epoch: 15, iters: 31840, time: 0.003) nll: 0.701215 \n",
      "(GPU: 0, epoch: 15, iters: 32640, time: 0.003) nll: 0.759281 \n",
      "(GPU: 0, epoch: 15, iters: 33440, time: 0.003) nll: 0.991592 \n",
      "(GPU: 0, epoch: 15, iters: 34240, time: 0.003) nll: 1.027550 \n",
      "(GPU: 0, epoch: 15, iters: 35040, time: 0.003) nll: 0.722163 \n",
      "(GPU: 0, epoch: 15, iters: 35840, time: 0.003) nll: 1.005275 \n",
      "(GPU: 0, epoch: 15, iters: 36640, time: 0.003) nll: 0.801030 \n",
      "(GPU: 0, epoch: 15, iters: 37440, time: 0.003) nll: 0.671358 \n",
      "(GPU: 0, epoch: 15, iters: 38240, time: 0.003) nll: 0.808843 \n",
      "(GPU: 0, epoch: 15, iters: 39040, time: 0.004) nll: 0.590893 \n",
      "(GPU: 0, epoch: 15, iters: 39840, time: 0.003) nll: 0.766760 \n",
      "(GPU: 0, epoch: 15, iters: 40640, time: 0.003) nll: 0.775636 \n",
      "(GPU: 0, epoch: 15, iters: 41440, time: 0.003) nll: 0.651227 \n",
      "(GPU: 0, epoch: 15, iters: 42240, time: 0.003) nll: 0.967706 \n",
      "(GPU: 0, epoch: 15, iters: 43040, time: 0.003) nll: 0.580917 \n",
      "(GPU: 0, epoch: 15, iters: 43840, time: 0.003) nll: 0.710624 \n",
      "(GPU: 0, epoch: 15, iters: 44640, time: 0.003) nll: 0.754241 \n",
      "(GPU: 0, epoch: 15, iters: 45440, time: 0.003) nll: 0.525582 \n",
      "(GPU: 0, epoch: 15, iters: 46240, time: 0.003) nll: 0.820206 \n",
      "(GPU: 0, epoch: 15, iters: 47040, time: 0.003) nll: 0.929217 \n",
      "(GPU: 0, epoch: 15, iters: 47840, time: 0.003) nll: 0.768839 \n",
      "(GPU: 0, epoch: 15, iters: 48640, time: 0.003) nll: 0.929954 \n",
      "(GPU: 0, epoch: 15, iters: 49440, time: 0.003) nll: 0.719271 \n",
      "saving the latest model (epoch 15, total_steps 2160000)\n",
      "(GPU: 0, epoch: 15, iters: 50240, time: 0.003) nll: 0.859841 \n",
      "(GPU: 0, epoch: 15, iters: 51040, time: 0.003) nll: 0.559778 \n",
      "(GPU: 0, epoch: 15, iters: 51840, time: 0.003) nll: 0.821996 \n",
      "(GPU: 0, epoch: 15, iters: 52640, time: 0.003) nll: 0.734100 \n",
      "(GPU: 0, epoch: 15, iters: 53440, time: 0.003) nll: 0.897826 \n",
      "(GPU: 0, epoch: 15, iters: 54240, time: 0.003) nll: 0.937281 \n",
      "(GPU: 0, epoch: 15, iters: 55040, time: 0.003) nll: 0.763426 \n",
      "(GPU: 0, epoch: 15, iters: 55840, time: 0.003) nll: 0.707280 \n",
      "(GPU: 0, epoch: 15, iters: 56640, time: 0.003) nll: 0.871006 \n",
      "(GPU: 0, epoch: 15, iters: 57440, time: 0.003) nll: 1.107560 \n",
      "(GPU: 0, epoch: 15, iters: 58240, time: 0.003) nll: 0.927949 \n",
      "(GPU: 0, epoch: 15, iters: 59040, time: 0.003) nll: 0.713139 \n",
      "(GPU: 0, epoch: 15, iters: 59840, time: 0.003) nll: 0.564100 \n",
      "(GPU: 0, epoch: 15, iters: 60640, time: 0.003) nll: 0.609453 \n",
      "(GPU: 0, epoch: 15, iters: 61440, time: 0.003) nll: 0.740348 \n",
      "(GPU: 0, epoch: 15, iters: 62240, time: 0.003) nll: 0.652907 \n",
      "(GPU: 0, epoch: 15, iters: 63040, time: 0.003) nll: 0.838861 \n",
      "(GPU: 0, epoch: 15, iters: 63840, time: 0.003) nll: 0.938748 \n",
      "(GPU: 0, epoch: 15, iters: 64640, time: 0.003) nll: 0.812788 \n",
      "(GPU: 0, epoch: 15, iters: 65440, time: 0.003) nll: 0.778907 \n",
      "(GPU: 0, epoch: 15, iters: 66240, time: 0.003) nll: 0.860516 \n",
      "(GPU: 0, epoch: 15, iters: 67040, time: 0.003) nll: 0.862772 \n",
      "(GPU: 0, epoch: 15, iters: 67840, time: 0.003) nll: 0.790228 \n",
      "(GPU: 0, epoch: 15, iters: 68640, time: 0.003) nll: 0.826649 \n",
      "(GPU: 0, epoch: 15, iters: 69440, time: 0.003) nll: 0.788798 \n",
      "saving the latest model (epoch 15, total_steps 2180000)\n",
      "(GPU: 0, epoch: 15, iters: 70240, time: 0.003) nll: 0.982765 \n",
      "(GPU: 0, epoch: 15, iters: 71040, time: 0.003) nll: 0.870836 \n",
      "(GPU: 0, epoch: 15, iters: 71840, time: 0.003) nll: 0.633515 \n",
      "(GPU: 0, epoch: 15, iters: 72640, time: 0.003) nll: 0.901049 \n",
      "(GPU: 0, epoch: 15, iters: 73440, time: 0.003) nll: 0.773287 \n",
      "(GPU: 0, epoch: 15, iters: 74240, time: 0.003) nll: 0.619053 \n",
      "(GPU: 0, epoch: 15, iters: 75040, time: 0.003) nll: 0.838927 \n",
      "(GPU: 0, epoch: 15, iters: 75840, time: 0.003) nll: 0.675734 \n",
      "(GPU: 0, epoch: 15, iters: 76640, time: 0.003) nll: 0.676627 \n",
      "(GPU: 0, epoch: 15, iters: 77440, time: 0.003) nll: 0.773711 \n",
      "(GPU: 0, epoch: 15, iters: 78240, time: 0.003) nll: 0.706758 \n",
      "(GPU: 0, epoch: 15, iters: 79040, time: 0.003) nll: 0.757659 \n",
      "(GPU: 0, epoch: 15, iters: 79840, time: 0.003) nll: 1.030617 \n",
      "(GPU: 0, epoch: 15, iters: 80640, time: 0.003) nll: 0.900896 \n",
      "(GPU: 0, epoch: 15, iters: 81440, time: 0.003) nll: 0.799579 \n",
      "(GPU: 0, epoch: 15, iters: 82240, time: 0.003) nll: 1.039030 \n",
      "(GPU: 0, epoch: 15, iters: 83040, time: 0.003) nll: 0.850137 \n",
      "(GPU: 0, epoch: 15, iters: 83840, time: 0.003) nll: 0.974380 \n",
      "(GPU: 0, epoch: 15, iters: 84640, time: 0.003) nll: 0.781109 \n",
      "(GPU: 0, epoch: 15, iters: 85440, time: 0.003) nll: 1.032901 \n",
      "(GPU: 0, epoch: 15, iters: 86240, time: 0.003) nll: 0.715407 \n",
      "(GPU: 0, epoch: 15, iters: 87040, time: 0.003) nll: 0.896090 \n",
      "(GPU: 0, epoch: 15, iters: 87840, time: 0.003) nll: 0.811045 \n",
      "(GPU: 0, epoch: 15, iters: 88640, time: 0.003) nll: 1.076874 \n",
      "(GPU: 0, epoch: 15, iters: 89440, time: 0.003) nll: 0.751838 \n",
      "saving the latest model (epoch 15, total_steps 2200000)\n",
      "(GPU: 0, epoch: 15, iters: 90240, time: 0.003) nll: 0.641070 \n",
      "(GPU: 0, epoch: 15, iters: 91040, time: 0.003) nll: 0.792785 \n",
      "(GPU: 0, epoch: 15, iters: 91840, time: 0.003) nll: 0.651830 \n",
      "(GPU: 0, epoch: 15, iters: 92640, time: 0.003) nll: 0.968934 \n",
      "(GPU: 0, epoch: 15, iters: 93440, time: 0.003) nll: 0.758197 \n",
      "(GPU: 0, epoch: 15, iters: 94240, time: 0.003) nll: 0.628004 \n",
      "(GPU: 0, epoch: 15, iters: 95040, time: 0.003) nll: 0.705044 \n",
      "(GPU: 0, epoch: 15, iters: 95840, time: 0.003) nll: 0.944147 \n",
      "(GPU: 0, epoch: 15, iters: 96640, time: 0.003) nll: 0.795584 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.003) nll: 0.725050 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.005) nll: 0.720837 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.005) nll: 0.757438 \n",
      "(GPU: 0, epoch: 15, iters: 98240, time: 0.003) nll: 0.843506 \n",
      "(GPU: 0, epoch: 15, iters: 99040, time: 0.003) nll: 0.882118 \n",
      "(GPU: 0, epoch: 15, iters: 99840, time: 0.003) nll: 0.763611 \n",
      "(GPU: 0, epoch: 15, iters: 100640, time: 0.003) nll: 0.714267 \n",
      "(GPU: 0, epoch: 15, iters: 101440, time: 0.003) nll: 0.684780 \n",
      "(GPU: 0, epoch: 15, iters: 102240, time: 0.003) nll: 0.755744 \n",
      "(GPU: 0, epoch: 15, iters: 103040, time: 0.003) nll: 0.709657 \n",
      "(GPU: 0, epoch: 15, iters: 103840, time: 0.003) nll: 0.661636 \n",
      "(GPU: 0, epoch: 15, iters: 104640, time: 0.003) nll: 0.663209 \n",
      "(GPU: 0, epoch: 15, iters: 105440, time: 0.003) nll: 0.862260 \n",
      "(GPU: 0, epoch: 15, iters: 106240, time: 0.003) nll: 0.897412 \n",
      "(GPU: 0, epoch: 15, iters: 107040, time: 0.003) nll: 0.954232 \n",
      "(GPU: 0, epoch: 15, iters: 107840, time: 0.003) nll: 0.783458 \n",
      "(GPU: 0, epoch: 15, iters: 108640, time: 0.003) nll: 0.946396 \n",
      "(GPU: 0, epoch: 15, iters: 109440, time: 0.003) nll: 0.676349 \n",
      "saving the latest model (epoch 15, total_steps 2220000)\n",
      "(GPU: 0, epoch: 15, iters: 110240, time: 0.003) nll: 0.776815 \n",
      "(GPU: 0, epoch: 15, iters: 111040, time: 0.003) nll: 0.820558 \n",
      "(GPU: 0, epoch: 15, iters: 111840, time: 0.003) nll: 0.657568 \n",
      "(GPU: 0, epoch: 15, iters: 112640, time: 0.003) nll: 0.909187 \n",
      "(GPU: 0, epoch: 15, iters: 113440, time: 0.003) nll: 0.901775 \n",
      "(GPU: 0, epoch: 15, iters: 114240, time: 0.003) nll: 0.892007 \n",
      "(GPU: 0, epoch: 15, iters: 115040, time: 0.003) nll: 1.176592 \n",
      "(GPU: 0, epoch: 15, iters: 115840, time: 0.003) nll: 0.698301 \n",
      "(GPU: 0, epoch: 15, iters: 116640, time: 0.003) nll: 0.921604 \n",
      "(GPU: 0, epoch: 15, iters: 117440, time: 0.003) nll: 0.992997 \n",
      "(GPU: 0, epoch: 15, iters: 118240, time: 0.003) nll: 0.807905 \n",
      "(GPU: 0, epoch: 15, iters: 119040, time: 0.003) nll: 0.897561 \n",
      "(GPU: 0, epoch: 15, iters: 119840, time: 0.003) nll: 0.813287 \n",
      "(GPU: 0, epoch: 15, iters: 120640, time: 0.003) nll: 0.694940 \n",
      "(GPU: 0, epoch: 15, iters: 121440, time: 0.003) nll: 0.744358 \n",
      "(GPU: 0, epoch: 15, iters: 122240, time: 0.003) nll: 0.805741 \n",
      "(GPU: 0, epoch: 15, iters: 123040, time: 0.003) nll: 1.035316 \n",
      "(GPU: 0, epoch: 15, iters: 123840, time: 0.003) nll: 0.712760 \n",
      "(GPU: 0, epoch: 15, iters: 124640, time: 0.003) nll: 0.632260 \n",
      "(GPU: 0, epoch: 15, iters: 125440, time: 0.003) nll: 0.626296 \n",
      "(GPU: 0, epoch: 15, iters: 126240, time: 0.003) nll: 1.014780 \n",
      "(GPU: 0, epoch: 15, iters: 127040, time: 0.003) nll: 0.865730 \n",
      "(GPU: 0, epoch: 15, iters: 127840, time: 0.003) nll: 0.849634 \n",
      "(GPU: 0, epoch: 15, iters: 128640, time: 0.003) nll: 0.789702 \n",
      "(GPU: 0, epoch: 15, iters: 129440, time: 0.003) nll: 0.716010 \n",
      "saving the latest model (epoch 15, total_steps 2240000)\n",
      "(GPU: 0, epoch: 15, iters: 130240, time: 0.003) nll: 0.836570 \n",
      "(GPU: 0, epoch: 15, iters: 131040, time: 0.003) nll: 0.571791 \n",
      "(GPU: 0, epoch: 15, iters: 131840, time: 0.003) nll: 0.793439 \n",
      "(GPU: 0, epoch: 15, iters: 132640, time: 0.003) nll: 0.813894 \n",
      "(GPU: 0, epoch: 15, iters: 133440, time: 0.003) nll: 0.652799 \n",
      "(GPU: 0, epoch: 15, iters: 134240, time: 0.003) nll: 0.736118 \n",
      "(GPU: 0, epoch: 15, iters: 135040, time: 0.003) nll: 1.210706 \n",
      "(GPU: 0, epoch: 15, iters: 135840, time: 0.003) nll: 0.702347 \n",
      "(GPU: 0, epoch: 15, iters: 136640, time: 0.003) nll: 0.790803 \n",
      "(GPU: 0, epoch: 15, iters: 137440, time: 0.003) nll: 0.729653 \n",
      "(GPU: 0, epoch: 15, iters: 138240, time: 0.003) nll: 0.700521 \n",
      "(GPU: 0, epoch: 15, iters: 139040, time: 0.003) nll: 0.686979 \n",
      "(GPU: 0, epoch: 15, iters: 139840, time: 0.003) nll: 0.908403 \n",
      "(GPU: 0, epoch: 15, iters: 140640, time: 0.003) nll: 0.927371 \n",
      "saving the model at the end of epoch 15, iters 2251264\n",
      "([test] GPU: 0, epoch: 15) \n",
      "OrderedDict()\n",
      "[*] End of epoch 15 / 25 \t Time Taken: 523 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000791\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3098/4397 [05:59<02:42,  7.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 32, time: 0.002) nll: 0.495915 \n",
      "(GPU: 0, epoch: 16, iters: 32, time: 0.002) nll: 0.652232 \n",
      "(GPU: 0, epoch: 16, iters: 736, time: 0.003) nll: 0.835204 \n",
      "(GPU: 0, epoch: 16, iters: 1536, time: 0.003) nll: 0.844919 \n",
      "(GPU: 0, epoch: 16, iters: 2336, time: 0.003) nll: 0.889455 \n",
      "(GPU: 0, epoch: 16, iters: 3136, time: 0.003) nll: 0.956596 \n",
      "(GPU: 0, epoch: 16, iters: 3936, time: 0.003) nll: 0.896744 \n",
      "(GPU: 0, epoch: 16, iters: 4736, time: 0.003) nll: 0.607827 \n",
      "(GPU: 0, epoch: 16, iters: 5536, time: 0.003) nll: 0.622517 \n",
      "(GPU: 0, epoch: 16, iters: 6336, time: 0.003) nll: 0.934665 \n",
      "(GPU: 0, epoch: 16, iters: 7136, time: 0.003) nll: 0.749254 \n",
      "(GPU: 0, epoch: 16, iters: 7936, time: 0.003) nll: 0.946008 \n",
      "(GPU: 0, epoch: 16, iters: 8736, time: 0.003) nll: 0.795174 \n",
      "saving the latest model (epoch 16, total_steps 2260000)\n",
      "(GPU: 0, epoch: 16, iters: 9536, time: 0.003) nll: 0.779074 \n",
      "(GPU: 0, epoch: 16, iters: 10336, time: 0.003) nll: 0.700990 \n",
      "(GPU: 0, epoch: 16, iters: 11136, time: 0.003) nll: 0.953750 \n",
      "(GPU: 0, epoch: 16, iters: 11936, time: 0.003) nll: 0.795162 \n",
      "(GPU: 0, epoch: 16, iters: 12736, time: 0.003) nll: 0.821228 \n",
      "(GPU: 0, epoch: 16, iters: 13536, time: 0.003) nll: 0.716943 \n",
      "(GPU: 0, epoch: 16, iters: 14336, time: 0.003) nll: 0.878224 \n",
      "(GPU: 0, epoch: 16, iters: 15136, time: 0.003) nll: 0.860725 \n",
      "(GPU: 0, epoch: 16, iters: 15936, time: 0.003) nll: 0.605224 \n",
      "(GPU: 0, epoch: 16, iters: 16736, time: 0.003) nll: 0.915269 \n",
      "(GPU: 0, epoch: 16, iters: 17536, time: 0.003) nll: 0.968116 \n",
      "(GPU: 0, epoch: 16, iters: 18336, time: 0.003) nll: 0.674701 \n",
      "(GPU: 0, epoch: 16, iters: 19136, time: 0.003) nll: 0.922021 \n",
      "(GPU: 0, epoch: 16, iters: 19936, time: 0.003) nll: 0.558844 \n",
      "(GPU: 0, epoch: 16, iters: 20736, time: 0.003) nll: 0.968008 \n",
      "(GPU: 0, epoch: 16, iters: 21536, time: 0.003) nll: 0.737828 \n",
      "(GPU: 0, epoch: 16, iters: 22336, time: 0.003) nll: 1.021780 \n",
      "(GPU: 0, epoch: 16, iters: 23136, time: 0.003) nll: 0.640163 \n",
      "(GPU: 0, epoch: 16, iters: 23936, time: 0.003) nll: 0.774143 \n",
      "(GPU: 0, epoch: 16, iters: 24736, time: 0.003) nll: 0.841220 \n",
      "(GPU: 0, epoch: 16, iters: 25536, time: 0.003) nll: 0.654806 \n",
      "(GPU: 0, epoch: 16, iters: 26336, time: 0.003) nll: 0.858291 \n",
      "(GPU: 0, epoch: 16, iters: 27136, time: 0.003) nll: 1.146940 \n",
      "(GPU: 0, epoch: 16, iters: 27936, time: 0.003) nll: 1.060818 \n",
      "(GPU: 0, epoch: 16, iters: 28736, time: 0.003) nll: 0.702923 \n",
      "saving the latest model (epoch 16, total_steps 2280000)\n",
      "(GPU: 0, epoch: 16, iters: 29536, time: 0.003) nll: 0.727771 \n",
      "(GPU: 0, epoch: 16, iters: 30336, time: 0.003) nll: 0.999426 \n",
      "(GPU: 0, epoch: 16, iters: 31136, time: 0.003) nll: 0.922996 \n",
      "(GPU: 0, epoch: 16, iters: 31936, time: 0.003) nll: 0.767428 \n",
      "(GPU: 0, epoch: 16, iters: 32736, time: 0.003) nll: 0.986005 \n",
      "(GPU: 0, epoch: 16, iters: 33536, time: 0.003) nll: 0.919059 \n",
      "(GPU: 0, epoch: 16, iters: 34336, time: 0.003) nll: 0.936487 \n",
      "(GPU: 0, epoch: 16, iters: 35136, time: 0.003) nll: 0.976568 \n",
      "(GPU: 0, epoch: 16, iters: 35936, time: 0.003) nll: 0.818020 \n",
      "(GPU: 0, epoch: 16, iters: 36736, time: 0.003) nll: 0.814694 \n",
      "(GPU: 0, epoch: 16, iters: 37536, time: 0.003) nll: 0.791859 \n",
      "(GPU: 0, epoch: 16, iters: 38336, time: 0.003) nll: 0.816268 \n",
      "(GPU: 0, epoch: 16, iters: 39136, time: 0.003) nll: 1.008641 \n",
      "(GPU: 0, epoch: 16, iters: 39936, time: 0.003) nll: 0.705289 \n",
      "(GPU: 0, epoch: 16, iters: 40736, time: 0.003) nll: 1.044905 \n",
      "(GPU: 0, epoch: 16, iters: 41536, time: 0.003) nll: 1.015444 \n",
      "(GPU: 0, epoch: 16, iters: 42336, time: 0.003) nll: 0.728140 \n",
      "(GPU: 0, epoch: 16, iters: 43136, time: 0.003) nll: 0.900186 \n",
      "(GPU: 0, epoch: 16, iters: 43936, time: 0.003) nll: 0.643839 \n",
      "(GPU: 0, epoch: 16, iters: 44736, time: 0.003) nll: 0.827484 \n",
      "(GPU: 0, epoch: 16, iters: 45536, time: 0.003) nll: 0.927609 \n",
      "(GPU: 0, epoch: 16, iters: 46336, time: 0.003) nll: 0.513498 \n",
      "(GPU: 0, epoch: 16, iters: 47136, time: 0.003) nll: 0.829569 \n",
      "(GPU: 0, epoch: 16, iters: 47936, time: 0.003) nll: 0.921302 \n",
      "(GPU: 0, epoch: 16, iters: 48736, time: 0.003) nll: 0.737956 \n",
      "saving the latest model (epoch 16, total_steps 2300000)\n",
      "(GPU: 0, epoch: 16, iters: 49536, time: 0.003) nll: 0.654997 \n",
      "(GPU: 0, epoch: 16, iters: 50336, time: 0.003) nll: 0.936779 \n",
      "(GPU: 0, epoch: 16, iters: 51136, time: 0.003) nll: 0.615737 \n",
      "(GPU: 0, epoch: 16, iters: 51936, time: 0.003) nll: 0.774139 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.003) nll: 0.510422 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.005) nll: 0.601834 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.005) nll: 0.663067 \n",
      "(GPU: 0, epoch: 16, iters: 53536, time: 0.003) nll: 1.276075 \n",
      "(GPU: 0, epoch: 16, iters: 54336, time: 0.003) nll: 0.729534 \n",
      "(GPU: 0, epoch: 16, iters: 55136, time: 0.003) nll: 0.772202 \n",
      "(GPU: 0, epoch: 16, iters: 55936, time: 0.003) nll: 0.739818 \n",
      "(GPU: 0, epoch: 16, iters: 56736, time: 0.003) nll: 1.498751 \n",
      "(GPU: 0, epoch: 16, iters: 57536, time: 0.003) nll: 0.785793 \n",
      "(GPU: 0, epoch: 16, iters: 58336, time: 0.003) nll: 0.885537 \n",
      "(GPU: 0, epoch: 16, iters: 59136, time: 0.003) nll: 0.688319 \n",
      "(GPU: 0, epoch: 16, iters: 59936, time: 0.003) nll: 0.833959 \n",
      "(GPU: 0, epoch: 16, iters: 60736, time: 0.003) nll: 0.760909 \n",
      "(GPU: 0, epoch: 16, iters: 61536, time: 0.003) nll: 1.106720 \n",
      "(GPU: 0, epoch: 16, iters: 62336, time: 0.003) nll: 0.920552 \n",
      "(GPU: 0, epoch: 16, iters: 63136, time: 0.003) nll: 0.636487 \n",
      "(GPU: 0, epoch: 16, iters: 63936, time: 0.003) nll: 0.663995 \n",
      "(GPU: 0, epoch: 16, iters: 64736, time: 0.003) nll: 0.696582 \n",
      "(GPU: 0, epoch: 16, iters: 65536, time: 0.003) nll: 0.891686 \n",
      "(GPU: 0, epoch: 16, iters: 66336, time: 0.003) nll: 0.638401 \n",
      "(GPU: 0, epoch: 16, iters: 67136, time: 0.003) nll: 0.817348 \n",
      "(GPU: 0, epoch: 16, iters: 67936, time: 0.003) nll: 0.842589 \n",
      "(GPU: 0, epoch: 16, iters: 68736, time: 0.003) nll: 0.617553 \n",
      "saving the latest model (epoch 16, total_steps 2320000)\n",
      "(GPU: 0, epoch: 16, iters: 69536, time: 0.003) nll: 0.783906 \n",
      "(GPU: 0, epoch: 16, iters: 70336, time: 0.003) nll: 0.770970 \n",
      "(GPU: 0, epoch: 16, iters: 71136, time: 0.003) nll: 0.820314 \n",
      "(GPU: 0, epoch: 16, iters: 71936, time: 0.003) nll: 0.687433 \n",
      "(GPU: 0, epoch: 16, iters: 72736, time: 0.003) nll: 0.774772 \n",
      "(GPU: 0, epoch: 16, iters: 73536, time: 0.003) nll: 1.021893 \n",
      "(GPU: 0, epoch: 16, iters: 74336, time: 0.003) nll: 0.567742 \n",
      "(GPU: 0, epoch: 16, iters: 75136, time: 0.003) nll: 0.606014 \n",
      "(GPU: 0, epoch: 16, iters: 75936, time: 0.003) nll: 0.892758 \n",
      "(GPU: 0, epoch: 16, iters: 76736, time: 0.003) nll: 0.629276 \n",
      "(GPU: 0, epoch: 16, iters: 77536, time: 0.003) nll: 0.741826 \n",
      "(GPU: 0, epoch: 16, iters: 78336, time: 0.003) nll: 0.778205 \n",
      "(GPU: 0, epoch: 16, iters: 79136, time: 0.003) nll: 0.676985 \n",
      "(GPU: 0, epoch: 16, iters: 79936, time: 0.003) nll: 0.612679 \n",
      "(GPU: 0, epoch: 16, iters: 80736, time: 0.003) nll: 0.930814 \n",
      "(GPU: 0, epoch: 16, iters: 81536, time: 0.003) nll: 0.720739 \n",
      "(GPU: 0, epoch: 16, iters: 82336, time: 0.003) nll: 0.611401 \n",
      "(GPU: 0, epoch: 16, iters: 83136, time: 0.003) nll: 0.854990 \n",
      "(GPU: 0, epoch: 16, iters: 83936, time: 0.003) nll: 1.009934 \n",
      "(GPU: 0, epoch: 16, iters: 84736, time: 0.003) nll: 0.745092 \n",
      "(GPU: 0, epoch: 16, iters: 85536, time: 0.003) nll: 0.709997 \n",
      "(GPU: 0, epoch: 16, iters: 86336, time: 0.003) nll: 0.583243 \n",
      "(GPU: 0, epoch: 16, iters: 87136, time: 0.003) nll: 0.782980 \n",
      "(GPU: 0, epoch: 16, iters: 87936, time: 0.003) nll: 0.676050 \n",
      "(GPU: 0, epoch: 16, iters: 88736, time: 0.003) nll: 0.823424 \n",
      "saving the latest model (epoch 16, total_steps 2340000)\n",
      "(GPU: 0, epoch: 16, iters: 89536, time: 0.003) nll: 0.828175 \n",
      "(GPU: 0, epoch: 16, iters: 90336, time: 0.003) nll: 0.922534 \n",
      "(GPU: 0, epoch: 16, iters: 91136, time: 0.003) nll: 0.677988 \n",
      "(GPU: 0, epoch: 16, iters: 91936, time: 0.003) nll: 0.877548 \n",
      "(GPU: 0, epoch: 16, iters: 92736, time: 0.003) nll: 1.074330 \n",
      "(GPU: 0, epoch: 16, iters: 93536, time: 0.003) nll: 0.932001 \n",
      "(GPU: 0, epoch: 16, iters: 94336, time: 0.003) nll: 0.805942 \n",
      "(GPU: 0, epoch: 16, iters: 95136, time: 0.003) nll: 1.050928 \n",
      "(GPU: 0, epoch: 16, iters: 95936, time: 0.003) nll: 0.924963 \n",
      "(GPU: 0, epoch: 16, iters: 96736, time: 0.003) nll: 0.699705 \n",
      "(GPU: 0, epoch: 16, iters: 97536, time: 0.003) nll: 0.814486 \n",
      "(GPU: 0, epoch: 16, iters: 98336, time: 0.003) nll: 0.818412 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 99136, time: 0.003) nll: 0.706574 \n",
      "(GPU: 0, epoch: 16, iters: 99936, time: 0.003) nll: 0.814048 \n",
      "(GPU: 0, epoch: 16, iters: 100736, time: 0.003) nll: 0.923973 \n",
      "(GPU: 0, epoch: 16, iters: 101536, time: 0.003) nll: 1.164594 \n",
      "(GPU: 0, epoch: 16, iters: 102336, time: 0.003) nll: 0.720231 \n",
      "(GPU: 0, epoch: 16, iters: 103136, time: 0.003) nll: 0.874911 \n",
      "(GPU: 0, epoch: 16, iters: 103936, time: 0.003) nll: 0.814501 \n",
      "(GPU: 0, epoch: 16, iters: 104736, time: 0.003) nll: 0.953221 \n",
      "(GPU: 0, epoch: 16, iters: 105536, time: 0.003) nll: 0.661555 \n",
      "(GPU: 0, epoch: 16, iters: 106336, time: 0.003) nll: 0.641533 \n",
      "(GPU: 0, epoch: 16, iters: 107136, time: 0.003) nll: 0.668507 \n",
      "(GPU: 0, epoch: 16, iters: 107936, time: 0.003) nll: 0.874861 \n",
      "(GPU: 0, epoch: 16, iters: 108736, time: 0.003) nll: 0.731670 \n",
      "saving the latest model (epoch 16, total_steps 2360000)\n",
      "(GPU: 0, epoch: 16, iters: 109536, time: 0.003) nll: 0.661320 \n",
      "(GPU: 0, epoch: 16, iters: 110336, time: 0.003) nll: 0.769448 \n",
      "(GPU: 0, epoch: 16, iters: 111136, time: 0.003) nll: 0.796905 \n",
      "(GPU: 0, epoch: 16, iters: 111936, time: 0.003) nll: 0.970627 \n",
      "(GPU: 0, epoch: 16, iters: 112736, time: 0.003) nll: 0.709704 \n",
      "(GPU: 0, epoch: 16, iters: 113536, time: 0.003) nll: 0.667960 \n",
      "(GPU: 0, epoch: 16, iters: 114336, time: 0.003) nll: 0.733110 \n",
      "(GPU: 0, epoch: 16, iters: 115136, time: 0.003) nll: 0.794890 \n",
      "(GPU: 0, epoch: 16, iters: 115936, time: 0.003) nll: 0.834241 \n",
      "(GPU: 0, epoch: 16, iters: 116736, time: 0.003) nll: 0.785156 \n",
      "(GPU: 0, epoch: 16, iters: 117536, time: 0.003) nll: 0.947037 \n",
      "(GPU: 0, epoch: 16, iters: 118336, time: 0.003) nll: 0.691109 \n",
      "(GPU: 0, epoch: 16, iters: 119136, time: 0.003) nll: 0.800529 \n",
      "(GPU: 0, epoch: 16, iters: 119936, time: 0.003) nll: 0.899210 \n",
      "(GPU: 0, epoch: 16, iters: 120736, time: 0.003) nll: 0.714200 \n",
      "(GPU: 0, epoch: 16, iters: 121536, time: 0.003) nll: 1.095424 \n",
      "(GPU: 0, epoch: 16, iters: 122336, time: 0.003) nll: 0.679832 \n",
      "(GPU: 0, epoch: 16, iters: 123136, time: 0.003) nll: 0.725548 \n",
      "(GPU: 0, epoch: 16, iters: 123936, time: 0.003) nll: 0.856838 \n",
      "(GPU: 0, epoch: 16, iters: 124736, time: 0.003) nll: 0.753859 \n",
      "(GPU: 0, epoch: 16, iters: 125536, time: 0.003) nll: 0.784882 \n",
      "(GPU: 0, epoch: 16, iters: 126336, time: 0.003) nll: 0.662328 \n",
      "(GPU: 0, epoch: 16, iters: 127136, time: 0.003) nll: 0.669508 \n",
      "(GPU: 0, epoch: 16, iters: 127936, time: 0.003) nll: 0.819741 \n",
      "(GPU: 0, epoch: 16, iters: 128736, time: 0.003) nll: 0.930604 \n",
      "saving the latest model (epoch 16, total_steps 2380000)\n",
      "(GPU: 0, epoch: 16, iters: 129536, time: 0.003) nll: 0.904175 \n",
      "(GPU: 0, epoch: 16, iters: 130336, time: 0.003) nll: 0.874317 \n",
      "(GPU: 0, epoch: 16, iters: 131136, time: 0.003) nll: 0.726547 \n",
      "(GPU: 0, epoch: 16, iters: 131936, time: 0.003) nll: 0.921461 \n",
      "(GPU: 0, epoch: 16, iters: 132736, time: 0.003) nll: 0.777933 \n",
      "(GPU: 0, epoch: 16, iters: 133536, time: 0.003) nll: 0.876506 \n",
      "(GPU: 0, epoch: 16, iters: 134336, time: 0.003) nll: 0.713116 \n",
      "(GPU: 0, epoch: 16, iters: 135136, time: 0.003) nll: 0.509821 \n",
      "(GPU: 0, epoch: 16, iters: 135936, time: 0.003) nll: 0.603138 \n",
      "(GPU: 0, epoch: 16, iters: 136736, time: 0.003) nll: 0.949924 \n",
      "(GPU: 0, epoch: 16, iters: 137536, time: 0.003) nll: 0.916004 \n",
      "(GPU: 0, epoch: 16, iters: 138336, time: 0.003) nll: 0.871887 \n",
      "(GPU: 0, epoch: 16, iters: 139136, time: 0.003) nll: 0.847074 \n",
      "(GPU: 0, epoch: 16, iters: 139936, time: 0.003) nll: 0.809021 \n",
      "[*] End of epoch 16 / 25 \t Time Taken: 510 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000767\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3075/4397 [05:57<02:19,  9.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 32, time: 0.002) nll: 0.713629 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.004) nll: 0.709538 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.004) nll: 0.820001 \n",
      "(GPU: 0, epoch: 17, iters: 832, time: 0.003) nll: 1.170366 \n",
      "(GPU: 0, epoch: 17, iters: 1632, time: 0.003) nll: 0.674314 \n",
      "(GPU: 0, epoch: 17, iters: 2432, time: 0.003) nll: 0.936478 \n",
      "(GPU: 0, epoch: 17, iters: 3232, time: 0.003) nll: 0.928060 \n",
      "(GPU: 0, epoch: 17, iters: 4032, time: 0.003) nll: 0.712256 \n",
      "(GPU: 0, epoch: 17, iters: 4832, time: 0.003) nll: 0.919924 \n",
      "(GPU: 0, epoch: 17, iters: 5632, time: 0.003) nll: 0.972680 \n",
      "(GPU: 0, epoch: 17, iters: 6432, time: 0.003) nll: 0.909520 \n",
      "(GPU: 0, epoch: 17, iters: 7232, time: 0.003) nll: 0.795915 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.003) nll: 0.561702 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.005) nll: 0.626453 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.005) nll: 0.901417 \n",
      "saving the latest model (epoch 17, total_steps 2400000)\n",
      "(GPU: 0, epoch: 17, iters: 8832, time: 0.003) nll: 0.695335 \n",
      "(GPU: 0, epoch: 17, iters: 9632, time: 0.003) nll: 0.738139 \n",
      "(GPU: 0, epoch: 17, iters: 10432, time: 0.003) nll: 0.487578 \n",
      "(GPU: 0, epoch: 17, iters: 11232, time: 0.003) nll: 0.805118 \n",
      "(GPU: 0, epoch: 17, iters: 12032, time: 0.003) nll: 0.754452 \n",
      "(GPU: 0, epoch: 17, iters: 12832, time: 0.003) nll: 0.655265 \n",
      "(GPU: 0, epoch: 17, iters: 13632, time: 0.003) nll: 0.828056 \n",
      "(GPU: 0, epoch: 17, iters: 14432, time: 0.003) nll: 1.007128 \n",
      "(GPU: 0, epoch: 17, iters: 15232, time: 0.003) nll: 0.845219 \n",
      "(GPU: 0, epoch: 17, iters: 16032, time: 0.003) nll: 0.656919 \n",
      "(GPU: 0, epoch: 17, iters: 16832, time: 0.003) nll: 0.867563 \n",
      "(GPU: 0, epoch: 17, iters: 17632, time: 0.003) nll: 0.712312 \n",
      "(GPU: 0, epoch: 17, iters: 18432, time: 0.003) nll: 0.830352 \n",
      "(GPU: 0, epoch: 17, iters: 19232, time: 0.003) nll: 1.031604 \n",
      "(GPU: 0, epoch: 17, iters: 20032, time: 0.003) nll: 0.686563 \n",
      "(GPU: 0, epoch: 17, iters: 20832, time: 0.003) nll: 0.900087 \n",
      "(GPU: 0, epoch: 17, iters: 21632, time: 0.003) nll: 0.671682 \n",
      "(GPU: 0, epoch: 17, iters: 22432, time: 0.003) nll: 0.871914 \n",
      "(GPU: 0, epoch: 17, iters: 23232, time: 0.003) nll: 0.819126 \n",
      "(GPU: 0, epoch: 17, iters: 24032, time: 0.003) nll: 0.707256 \n",
      "(GPU: 0, epoch: 17, iters: 24832, time: 0.003) nll: 1.059745 \n",
      "(GPU: 0, epoch: 17, iters: 25632, time: 0.003) nll: 0.889441 \n",
      "(GPU: 0, epoch: 17, iters: 26432, time: 0.003) nll: 0.774767 \n",
      "(GPU: 0, epoch: 17, iters: 27232, time: 0.003) nll: 0.955505 \n",
      "(GPU: 0, epoch: 17, iters: 28032, time: 0.003) nll: 0.758925 \n",
      "saving the latest model (epoch 17, total_steps 2420000)\n",
      "(GPU: 0, epoch: 17, iters: 28832, time: 0.003) nll: 0.862615 \n",
      "(GPU: 0, epoch: 17, iters: 29632, time: 0.003) nll: 0.884949 \n",
      "(GPU: 0, epoch: 17, iters: 30432, time: 0.003) nll: 0.770707 \n",
      "(GPU: 0, epoch: 17, iters: 31232, time: 0.003) nll: 0.746497 \n",
      "(GPU: 0, epoch: 17, iters: 32032, time: 0.003) nll: 0.748201 \n",
      "(GPU: 0, epoch: 17, iters: 32832, time: 0.003) nll: 0.701259 \n",
      "(GPU: 0, epoch: 17, iters: 33632, time: 0.003) nll: 0.488205 \n",
      "(GPU: 0, epoch: 17, iters: 34432, time: 0.003) nll: 0.842234 \n",
      "(GPU: 0, epoch: 17, iters: 35232, time: 0.003) nll: 0.592602 \n",
      "(GPU: 0, epoch: 17, iters: 36032, time: 0.003) nll: 0.873678 \n",
      "(GPU: 0, epoch: 17, iters: 36832, time: 0.003) nll: 0.634418 \n",
      "(GPU: 0, epoch: 17, iters: 37632, time: 0.003) nll: 0.732074 \n",
      "(GPU: 0, epoch: 17, iters: 38432, time: 0.003) nll: 0.879081 \n",
      "(GPU: 0, epoch: 17, iters: 39232, time: 0.003) nll: 0.802561 \n",
      "(GPU: 0, epoch: 17, iters: 40032, time: 0.003) nll: 0.760091 \n",
      "(GPU: 0, epoch: 17, iters: 40832, time: 0.003) nll: 0.889853 \n",
      "(GPU: 0, epoch: 17, iters: 41632, time: 0.003) nll: 0.586178 \n",
      "(GPU: 0, epoch: 17, iters: 42432, time: 0.003) nll: 0.933487 \n",
      "(GPU: 0, epoch: 17, iters: 43232, time: 0.003) nll: 0.773465 \n",
      "(GPU: 0, epoch: 17, iters: 44032, time: 0.003) nll: 0.761463 \n",
      "(GPU: 0, epoch: 17, iters: 44832, time: 0.003) nll: 0.581947 \n",
      "(GPU: 0, epoch: 17, iters: 45632, time: 0.003) nll: 0.698584 \n",
      "(GPU: 0, epoch: 17, iters: 46432, time: 0.003) nll: 0.670124 \n",
      "(GPU: 0, epoch: 17, iters: 47232, time: 0.003) nll: 0.786560 \n",
      "(GPU: 0, epoch: 17, iters: 48032, time: 0.003) nll: 0.468479 \n",
      "saving the latest model (epoch 17, total_steps 2440000)\n",
      "(GPU: 0, epoch: 17, iters: 48832, time: 0.003) nll: 0.620409 \n",
      "(GPU: 0, epoch: 17, iters: 49632, time: 0.003) nll: 0.798805 \n",
      "(GPU: 0, epoch: 17, iters: 50432, time: 0.003) nll: 0.635041 \n",
      "(GPU: 0, epoch: 17, iters: 51232, time: 0.003) nll: 0.686002 \n",
      "(GPU: 0, epoch: 17, iters: 52032, time: 0.003) nll: 0.943741 \n",
      "(GPU: 0, epoch: 17, iters: 52832, time: 0.003) nll: 0.830738 \n",
      "(GPU: 0, epoch: 17, iters: 53632, time: 0.003) nll: 0.682688 \n",
      "(GPU: 0, epoch: 17, iters: 54432, time: 0.003) nll: 0.607960 \n",
      "(GPU: 0, epoch: 17, iters: 55232, time: 0.003) nll: 0.983411 \n",
      "(GPU: 0, epoch: 17, iters: 56032, time: 0.003) nll: 0.769735 \n",
      "(GPU: 0, epoch: 17, iters: 56832, time: 0.003) nll: 0.722402 \n",
      "(GPU: 0, epoch: 17, iters: 57632, time: 0.003) nll: 0.929330 \n",
      "(GPU: 0, epoch: 17, iters: 58432, time: 0.003) nll: 0.601080 \n",
      "(GPU: 0, epoch: 17, iters: 59232, time: 0.003) nll: 0.668633 \n",
      "(GPU: 0, epoch: 17, iters: 60032, time: 0.003) nll: 0.527969 \n",
      "(GPU: 0, epoch: 17, iters: 60832, time: 0.003) nll: 0.578434 \n",
      "(GPU: 0, epoch: 17, iters: 61632, time: 0.003) nll: 0.666538 \n",
      "(GPU: 0, epoch: 17, iters: 62432, time: 0.003) nll: 0.748235 \n",
      "(GPU: 0, epoch: 17, iters: 63232, time: 0.003) nll: 0.817055 \n",
      "(GPU: 0, epoch: 17, iters: 64032, time: 0.003) nll: 0.789520 \n",
      "(GPU: 0, epoch: 17, iters: 64832, time: 0.003) nll: 0.735119 \n",
      "(GPU: 0, epoch: 17, iters: 65632, time: 0.003) nll: 0.705396 \n",
      "(GPU: 0, epoch: 17, iters: 66432, time: 0.003) nll: 0.991779 \n",
      "(GPU: 0, epoch: 17, iters: 67232, time: 0.003) nll: 0.841800 \n",
      "(GPU: 0, epoch: 17, iters: 68032, time: 0.003) nll: 0.662842 \n",
      "saving the latest model (epoch 17, total_steps 2460000)\n",
      "(GPU: 0, epoch: 17, iters: 68832, time: 0.003) nll: 0.972088 \n",
      "(GPU: 0, epoch: 17, iters: 69632, time: 0.003) nll: 0.568670 \n",
      "(GPU: 0, epoch: 17, iters: 70432, time: 0.003) nll: 0.907471 \n",
      "(GPU: 0, epoch: 17, iters: 71232, time: 0.003) nll: 0.656899 \n",
      "(GPU: 0, epoch: 17, iters: 72032, time: 0.003) nll: 0.688665 \n",
      "(GPU: 0, epoch: 17, iters: 72832, time: 0.003) nll: 0.981317 \n",
      "(GPU: 0, epoch: 17, iters: 73632, time: 0.003) nll: 0.764350 \n",
      "(GPU: 0, epoch: 17, iters: 74432, time: 0.003) nll: 0.832768 \n",
      "(GPU: 0, epoch: 17, iters: 75232, time: 0.003) nll: 0.965205 \n",
      "(GPU: 0, epoch: 17, iters: 76032, time: 0.003) nll: 1.055254 \n",
      "(GPU: 0, epoch: 17, iters: 76832, time: 0.003) nll: 0.942774 \n",
      "(GPU: 0, epoch: 17, iters: 77632, time: 0.003) nll: 0.634186 \n",
      "(GPU: 0, epoch: 17, iters: 78432, time: 0.003) nll: 0.651163 \n",
      "(GPU: 0, epoch: 17, iters: 79232, time: 0.003) nll: 0.823478 \n",
      "(GPU: 0, epoch: 17, iters: 80032, time: 0.003) nll: 0.826478 \n",
      "(GPU: 0, epoch: 17, iters: 80832, time: 0.003) nll: 0.554293 \n",
      "(GPU: 0, epoch: 17, iters: 81632, time: 0.003) nll: 0.820020 \n",
      "(GPU: 0, epoch: 17, iters: 82432, time: 0.003) nll: 0.823821 \n",
      "(GPU: 0, epoch: 17, iters: 83232, time: 0.003) nll: 0.802541 \n",
      "(GPU: 0, epoch: 17, iters: 84032, time: 0.003) nll: 0.864218 \n",
      "(GPU: 0, epoch: 17, iters: 84832, time: 0.003) nll: 0.758218 \n",
      "(GPU: 0, epoch: 17, iters: 85632, time: 0.003) nll: 0.869466 \n",
      "(GPU: 0, epoch: 17, iters: 86432, time: 0.003) nll: 0.793681 \n",
      "(GPU: 0, epoch: 17, iters: 87232, time: 0.003) nll: 0.765649 \n",
      "(GPU: 0, epoch: 17, iters: 88032, time: 0.003) nll: 0.940054 \n",
      "saving the latest model (epoch 17, total_steps 2480000)\n",
      "(GPU: 0, epoch: 17, iters: 88832, time: 0.003) nll: 0.758684 \n",
      "(GPU: 0, epoch: 17, iters: 89632, time: 0.003) nll: 0.854690 \n",
      "(GPU: 0, epoch: 17, iters: 90432, time: 0.003) nll: 0.715173 \n",
      "(GPU: 0, epoch: 17, iters: 91232, time: 0.003) nll: 0.694443 \n",
      "(GPU: 0, epoch: 17, iters: 92032, time: 0.003) nll: 0.696381 \n",
      "(GPU: 0, epoch: 17, iters: 92832, time: 0.003) nll: 0.797313 \n",
      "(GPU: 0, epoch: 17, iters: 93632, time: 0.003) nll: 0.661456 \n",
      "(GPU: 0, epoch: 17, iters: 94432, time: 0.003) nll: 0.873868 \n",
      "(GPU: 0, epoch: 17, iters: 95232, time: 0.003) nll: 0.647470 \n",
      "(GPU: 0, epoch: 17, iters: 96032, time: 0.003) nll: 0.765920 \n",
      "(GPU: 0, epoch: 17, iters: 96832, time: 0.003) nll: 0.902154 \n",
      "(GPU: 0, epoch: 17, iters: 97632, time: 0.003) nll: 0.734695 \n",
      "(GPU: 0, epoch: 17, iters: 98432, time: 0.003) nll: 0.597372 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 99232, time: 0.003) nll: 0.822024 \n",
      "(GPU: 0, epoch: 17, iters: 100032, time: 0.003) nll: 0.775235 \n",
      "(GPU: 0, epoch: 17, iters: 100832, time: 0.003) nll: 0.687563 \n",
      "(GPU: 0, epoch: 17, iters: 101632, time: 0.003) nll: 0.905688 \n",
      "(GPU: 0, epoch: 17, iters: 102432, time: 0.003) nll: 0.758916 \n",
      "(GPU: 0, epoch: 17, iters: 103232, time: 0.003) nll: 0.845123 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.003) nll: 0.753948 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.005) nll: 0.748483 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.005) nll: 0.867732 \n",
      "(GPU: 0, epoch: 17, iters: 104832, time: 0.003) nll: 0.980909 \n",
      "(GPU: 0, epoch: 17, iters: 105632, time: 0.003) nll: 0.836940 \n",
      "(GPU: 0, epoch: 17, iters: 106432, time: 0.003) nll: 0.740971 \n",
      "(GPU: 0, epoch: 17, iters: 107232, time: 0.003) nll: 0.836477 \n",
      "(GPU: 0, epoch: 17, iters: 108032, time: 0.003) nll: 0.551366 \n",
      "saving the latest model (epoch 17, total_steps 2500000)\n",
      "(GPU: 0, epoch: 17, iters: 108832, time: 0.003) nll: 0.931877 \n",
      "(GPU: 0, epoch: 17, iters: 109632, time: 0.003) nll: 0.881719 \n",
      "(GPU: 0, epoch: 17, iters: 110432, time: 0.003) nll: 0.924414 \n",
      "(GPU: 0, epoch: 17, iters: 111232, time: 0.003) nll: 0.782129 \n",
      "(GPU: 0, epoch: 17, iters: 112032, time: 0.003) nll: 0.648092 \n",
      "(GPU: 0, epoch: 17, iters: 112832, time: 0.003) nll: 0.587166 \n",
      "(GPU: 0, epoch: 17, iters: 113632, time: 0.003) nll: 1.044025 \n",
      "(GPU: 0, epoch: 17, iters: 114432, time: 0.003) nll: 0.744646 \n",
      "(GPU: 0, epoch: 17, iters: 115232, time: 0.003) nll: 0.580765 \n",
      "(GPU: 0, epoch: 17, iters: 116032, time: 0.003) nll: 0.815312 \n",
      "(GPU: 0, epoch: 17, iters: 116832, time: 0.003) nll: 0.688906 \n",
      "(GPU: 0, epoch: 17, iters: 117632, time: 0.003) nll: 0.605776 \n",
      "(GPU: 0, epoch: 17, iters: 118432, time: 0.003) nll: 1.134517 \n",
      "(GPU: 0, epoch: 17, iters: 119232, time: 0.003) nll: 0.805692 \n",
      "(GPU: 0, epoch: 17, iters: 120032, time: 0.003) nll: 0.906814 \n",
      "(GPU: 0, epoch: 17, iters: 120832, time: 0.003) nll: 0.663304 \n",
      "(GPU: 0, epoch: 17, iters: 121632, time: 0.003) nll: 0.608324 \n",
      "(GPU: 0, epoch: 17, iters: 122432, time: 0.003) nll: 0.908647 \n",
      "(GPU: 0, epoch: 17, iters: 123232, time: 0.003) nll: 0.773034 \n",
      "(GPU: 0, epoch: 17, iters: 124032, time: 0.003) nll: 1.002107 \n",
      "(GPU: 0, epoch: 17, iters: 124832, time: 0.003) nll: 1.003151 \n",
      "(GPU: 0, epoch: 17, iters: 125632, time: 0.003) nll: 0.758426 \n",
      "(GPU: 0, epoch: 17, iters: 126432, time: 0.003) nll: 0.773859 \n",
      "(GPU: 0, epoch: 17, iters: 127232, time: 0.003) nll: 0.843620 \n",
      "(GPU: 0, epoch: 17, iters: 128032, time: 0.003) nll: 0.623190 \n",
      "saving the latest model (epoch 17, total_steps 2520000)\n",
      "(GPU: 0, epoch: 17, iters: 128832, time: 0.003) nll: 0.623000 \n",
      "(GPU: 0, epoch: 17, iters: 129632, time: 0.003) nll: 0.795347 \n",
      "(GPU: 0, epoch: 17, iters: 130432, time: 0.003) nll: 0.884120 \n",
      "(GPU: 0, epoch: 17, iters: 131232, time: 0.003) nll: 0.828411 \n",
      "(GPU: 0, epoch: 17, iters: 132032, time: 0.003) nll: 0.990755 \n",
      "(GPU: 0, epoch: 17, iters: 132832, time: 0.003) nll: 0.814890 \n",
      "(GPU: 0, epoch: 17, iters: 133632, time: 0.003) nll: 0.896396 \n",
      "(GPU: 0, epoch: 17, iters: 134432, time: 0.003) nll: 0.745353 \n",
      "(GPU: 0, epoch: 17, iters: 135232, time: 0.003) nll: 0.942979 \n",
      "(GPU: 0, epoch: 17, iters: 136032, time: 0.003) nll: 0.755957 \n",
      "(GPU: 0, epoch: 17, iters: 136832, time: 0.003) nll: 0.910392 \n",
      "(GPU: 0, epoch: 17, iters: 137632, time: 0.003) nll: 0.759276 \n",
      "(GPU: 0, epoch: 17, iters: 138432, time: 0.003) nll: 0.889874 \n",
      "(GPU: 0, epoch: 17, iters: 139232, time: 0.003) nll: 0.708609 \n",
      "(GPU: 0, epoch: 17, iters: 140032, time: 0.003) nll: 0.712905 \n",
      "[*] End of epoch 17 / 25 \t Time Taken: 510 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000745\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3079/4397 [05:57<02:44,  8.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 32, time: 0.002) nll: 0.686094 \n",
      "(GPU: 0, epoch: 18, iters: 32, time: 0.002) nll: 0.803809 \n",
      "(GPU: 0, epoch: 18, iters: 128, time: 0.003) nll: 0.707404 \n",
      "(GPU: 0, epoch: 18, iters: 928, time: 0.003) nll: 0.779661 \n",
      "(GPU: 0, epoch: 18, iters: 1728, time: 0.003) nll: 0.647966 \n",
      "(GPU: 0, epoch: 18, iters: 2528, time: 0.003) nll: 0.882812 \n",
      "(GPU: 0, epoch: 18, iters: 3328, time: 0.003) nll: 0.823536 \n",
      "(GPU: 0, epoch: 18, iters: 4128, time: 0.003) nll: 0.856092 \n",
      "(GPU: 0, epoch: 18, iters: 4928, time: 0.003) nll: 0.735321 \n",
      "(GPU: 0, epoch: 18, iters: 5728, time: 0.003) nll: 0.781544 \n",
      "(GPU: 0, epoch: 18, iters: 6528, time: 0.003) nll: 0.480518 \n",
      "(GPU: 0, epoch: 18, iters: 7328, time: 0.003) nll: 0.749037 \n",
      "saving the latest model (epoch 18, total_steps 2540000)\n",
      "(GPU: 0, epoch: 18, iters: 8128, time: 0.003) nll: 0.860900 \n",
      "(GPU: 0, epoch: 18, iters: 8928, time: 0.003) nll: 0.788336 \n",
      "(GPU: 0, epoch: 18, iters: 9728, time: 0.003) nll: 0.602316 \n",
      "(GPU: 0, epoch: 18, iters: 10528, time: 0.003) nll: 1.038065 \n",
      "(GPU: 0, epoch: 18, iters: 11328, time: 0.003) nll: 0.730919 \n",
      "(GPU: 0, epoch: 18, iters: 12128, time: 0.003) nll: 0.880495 \n",
      "(GPU: 0, epoch: 18, iters: 12928, time: 0.003) nll: 0.390998 \n",
      "(GPU: 0, epoch: 18, iters: 13728, time: 0.003) nll: 0.684221 \n",
      "(GPU: 0, epoch: 18, iters: 14528, time: 0.003) nll: 0.764059 \n",
      "(GPU: 0, epoch: 18, iters: 15328, time: 0.003) nll: 0.970883 \n",
      "(GPU: 0, epoch: 18, iters: 16128, time: 0.003) nll: 0.727482 \n",
      "(GPU: 0, epoch: 18, iters: 16928, time: 0.003) nll: 0.745162 \n",
      "(GPU: 0, epoch: 18, iters: 17728, time: 0.003) nll: 0.851261 \n",
      "(GPU: 0, epoch: 18, iters: 18528, time: 0.003) nll: 1.009184 \n",
      "(GPU: 0, epoch: 18, iters: 19328, time: 0.003) nll: 0.809799 \n",
      "(GPU: 0, epoch: 18, iters: 20128, time: 0.003) nll: 0.881131 \n",
      "(GPU: 0, epoch: 18, iters: 20928, time: 0.003) nll: 0.710438 \n",
      "(GPU: 0, epoch: 18, iters: 21728, time: 0.003) nll: 0.958198 \n",
      "(GPU: 0, epoch: 18, iters: 22528, time: 0.003) nll: 0.839953 \n",
      "(GPU: 0, epoch: 18, iters: 23328, time: 0.003) nll: 1.157204 \n",
      "(GPU: 0, epoch: 18, iters: 24128, time: 0.003) nll: 0.624778 \n",
      "(GPU: 0, epoch: 18, iters: 24928, time: 0.003) nll: 1.078225 \n",
      "(GPU: 0, epoch: 18, iters: 25728, time: 0.003) nll: 0.962722 \n",
      "(GPU: 0, epoch: 18, iters: 26528, time: 0.003) nll: 0.715902 \n",
      "(GPU: 0, epoch: 18, iters: 27328, time: 0.003) nll: 0.687497 \n",
      "saving the latest model (epoch 18, total_steps 2560000)\n",
      "(GPU: 0, epoch: 18, iters: 28128, time: 0.003) nll: 0.786183 \n",
      "(GPU: 0, epoch: 18, iters: 28928, time: 0.003) nll: 0.728372 \n",
      "(GPU: 0, epoch: 18, iters: 29728, time: 0.003) nll: 0.765552 \n",
      "(GPU: 0, epoch: 18, iters: 30528, time: 0.003) nll: 0.892857 \n",
      "(GPU: 0, epoch: 18, iters: 31328, time: 0.003) nll: 0.945142 \n",
      "(GPU: 0, epoch: 18, iters: 32128, time: 0.003) nll: 0.987665 \n",
      "(GPU: 0, epoch: 18, iters: 32928, time: 0.003) nll: 0.941893 \n",
      "(GPU: 0, epoch: 18, iters: 33728, time: 0.003) nll: 0.809150 \n",
      "(GPU: 0, epoch: 18, iters: 34528, time: 0.003) nll: 0.730437 \n",
      "(GPU: 0, epoch: 18, iters: 35328, time: 0.003) nll: 0.641869 \n",
      "(GPU: 0, epoch: 18, iters: 36128, time: 0.003) nll: 0.707396 \n",
      "(GPU: 0, epoch: 18, iters: 36928, time: 0.003) nll: 0.910616 \n",
      "(GPU: 0, epoch: 18, iters: 37728, time: 0.003) nll: 1.004933 \n",
      "(GPU: 0, epoch: 18, iters: 38528, time: 0.003) nll: 0.938888 \n",
      "(GPU: 0, epoch: 18, iters: 39328, time: 0.003) nll: 0.697778 \n",
      "(GPU: 0, epoch: 18, iters: 40128, time: 0.003) nll: 0.771667 \n",
      "(GPU: 0, epoch: 18, iters: 40928, time: 0.003) nll: 0.666241 \n",
      "(GPU: 0, epoch: 18, iters: 41728, time: 0.003) nll: 0.801299 \n",
      "(GPU: 0, epoch: 18, iters: 42528, time: 0.003) nll: 0.668490 \n",
      "(GPU: 0, epoch: 18, iters: 43328, time: 0.003) nll: 0.730343 \n",
      "(GPU: 0, epoch: 18, iters: 44128, time: 0.003) nll: 0.479788 \n",
      "(GPU: 0, epoch: 18, iters: 44928, time: 0.003) nll: 0.636173 \n",
      "(GPU: 0, epoch: 18, iters: 45728, time: 0.003) nll: 0.836403 \n",
      "(GPU: 0, epoch: 18, iters: 46528, time: 0.003) nll: 0.516811 \n",
      "(GPU: 0, epoch: 18, iters: 47328, time: 0.003) nll: 0.684397 \n",
      "saving the latest model (epoch 18, total_steps 2580000)\n",
      "(GPU: 0, epoch: 18, iters: 48128, time: 0.003) nll: 0.934487 \n",
      "(GPU: 0, epoch: 18, iters: 48928, time: 0.003) nll: 0.665105 \n",
      "(GPU: 0, epoch: 18, iters: 49728, time: 0.003) nll: 0.568296 \n",
      "(GPU: 0, epoch: 18, iters: 50528, time: 0.003) nll: 0.933790 \n",
      "(GPU: 0, epoch: 18, iters: 51328, time: 0.003) nll: 0.907530 \n",
      "(GPU: 0, epoch: 18, iters: 52128, time: 0.003) nll: 0.830292 \n",
      "(GPU: 0, epoch: 18, iters: 52928, time: 0.003) nll: 0.677638 \n",
      "(GPU: 0, epoch: 18, iters: 53728, time: 0.003) nll: 0.778213 \n",
      "(GPU: 0, epoch: 18, iters: 54528, time: 0.003) nll: 0.730951 \n",
      "(GPU: 0, epoch: 18, iters: 55328, time: 0.003) nll: 0.667066 \n",
      "(GPU: 0, epoch: 18, iters: 56128, time: 0.003) nll: 0.618987 \n",
      "(GPU: 0, epoch: 18, iters: 56928, time: 0.003) nll: 0.779859 \n",
      "(GPU: 0, epoch: 18, iters: 57728, time: 0.003) nll: 0.782914 \n",
      "(GPU: 0, epoch: 18, iters: 58528, time: 0.003) nll: 0.613655 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.003) nll: 0.685392 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.005) nll: 0.681347 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.005) nll: 0.655829 \n",
      "(GPU: 0, epoch: 18, iters: 60128, time: 0.003) nll: 0.868315 \n",
      "(GPU: 0, epoch: 18, iters: 60928, time: 0.003) nll: 0.835253 \n",
      "(GPU: 0, epoch: 18, iters: 61728, time: 0.003) nll: 0.641292 \n",
      "(GPU: 0, epoch: 18, iters: 62528, time: 0.003) nll: 0.865210 \n",
      "(GPU: 0, epoch: 18, iters: 63328, time: 0.003) nll: 0.553976 \n",
      "(GPU: 0, epoch: 18, iters: 64128, time: 0.003) nll: 0.804569 \n",
      "(GPU: 0, epoch: 18, iters: 64928, time: 0.003) nll: 0.593318 \n",
      "(GPU: 0, epoch: 18, iters: 65728, time: 0.003) nll: 0.749325 \n",
      "(GPU: 0, epoch: 18, iters: 66528, time: 0.003) nll: 0.898562 \n",
      "(GPU: 0, epoch: 18, iters: 67328, time: 0.003) nll: 0.844931 \n",
      "saving the latest model (epoch 18, total_steps 2600000)\n",
      "(GPU: 0, epoch: 18, iters: 68128, time: 0.003) nll: 0.845864 \n",
      "(GPU: 0, epoch: 18, iters: 68928, time: 0.003) nll: 0.776206 \n",
      "(GPU: 0, epoch: 18, iters: 69728, time: 0.003) nll: 0.741984 \n",
      "(GPU: 0, epoch: 18, iters: 70528, time: 0.003) nll: 0.756396 \n",
      "(GPU: 0, epoch: 18, iters: 71328, time: 0.003) nll: 0.765871 \n",
      "(GPU: 0, epoch: 18, iters: 72128, time: 0.003) nll: 0.684085 \n",
      "(GPU: 0, epoch: 18, iters: 72928, time: 0.003) nll: 0.828996 \n",
      "(GPU: 0, epoch: 18, iters: 73728, time: 0.003) nll: 0.934536 \n",
      "(GPU: 0, epoch: 18, iters: 74528, time: 0.003) nll: 0.658178 \n",
      "(GPU: 0, epoch: 18, iters: 75328, time: 0.003) nll: 0.909101 \n",
      "(GPU: 0, epoch: 18, iters: 76128, time: 0.003) nll: 0.600759 \n",
      "(GPU: 0, epoch: 18, iters: 76928, time: 0.003) nll: 0.650406 \n",
      "(GPU: 0, epoch: 18, iters: 77728, time: 0.003) nll: 1.038154 \n",
      "(GPU: 0, epoch: 18, iters: 78528, time: 0.003) nll: 0.698776 \n",
      "(GPU: 0, epoch: 18, iters: 79328, time: 0.003) nll: 0.851591 \n",
      "(GPU: 0, epoch: 18, iters: 80128, time: 0.003) nll: 1.036995 \n",
      "(GPU: 0, epoch: 18, iters: 80928, time: 0.003) nll: 0.772517 \n",
      "(GPU: 0, epoch: 18, iters: 81728, time: 0.003) nll: 0.634581 \n",
      "(GPU: 0, epoch: 18, iters: 82528, time: 0.003) nll: 0.617838 \n",
      "(GPU: 0, epoch: 18, iters: 83328, time: 0.003) nll: 0.780984 \n",
      "(GPU: 0, epoch: 18, iters: 84128, time: 0.003) nll: 0.705772 \n",
      "(GPU: 0, epoch: 18, iters: 84928, time: 0.003) nll: 0.830755 \n",
      "(GPU: 0, epoch: 18, iters: 85728, time: 0.003) nll: 0.581301 \n",
      "(GPU: 0, epoch: 18, iters: 86528, time: 0.003) nll: 0.648328 \n",
      "(GPU: 0, epoch: 18, iters: 87328, time: 0.003) nll: 0.739677 \n",
      "saving the latest model (epoch 18, total_steps 2620000)\n",
      "(GPU: 0, epoch: 18, iters: 88128, time: 0.003) nll: 0.652750 \n",
      "(GPU: 0, epoch: 18, iters: 88928, time: 0.003) nll: 0.660306 \n",
      "(GPU: 0, epoch: 18, iters: 89728, time: 0.003) nll: 0.896833 \n",
      "(GPU: 0, epoch: 18, iters: 90528, time: 0.003) nll: 0.663876 \n",
      "(GPU: 0, epoch: 18, iters: 91328, time: 0.003) nll: 0.729982 \n",
      "(GPU: 0, epoch: 18, iters: 92128, time: 0.003) nll: 0.864329 \n",
      "(GPU: 0, epoch: 18, iters: 92928, time: 0.003) nll: 0.581403 \n",
      "(GPU: 0, epoch: 18, iters: 93728, time: 0.003) nll: 1.014088 \n",
      "(GPU: 0, epoch: 18, iters: 94528, time: 0.003) nll: 0.641092 \n",
      "(GPU: 0, epoch: 18, iters: 95328, time: 0.003) nll: 0.731613 \n",
      "(GPU: 0, epoch: 18, iters: 96128, time: 0.003) nll: 0.652770 \n",
      "(GPU: 0, epoch: 18, iters: 96928, time: 0.003) nll: 0.936632 \n",
      "(GPU: 0, epoch: 18, iters: 97728, time: 0.003) nll: 0.713216 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 98528, time: 0.003) nll: 0.700517 \n",
      "(GPU: 0, epoch: 18, iters: 99328, time: 0.003) nll: 0.789330 \n",
      "(GPU: 0, epoch: 18, iters: 100128, time: 0.003) nll: 0.825801 \n",
      "(GPU: 0, epoch: 18, iters: 100928, time: 0.003) nll: 0.846599 \n",
      "(GPU: 0, epoch: 18, iters: 101728, time: 0.003) nll: 0.708302 \n",
      "(GPU: 0, epoch: 18, iters: 102528, time: 0.003) nll: 1.232991 \n",
      "(GPU: 0, epoch: 18, iters: 103328, time: 0.003) nll: 0.723428 \n",
      "(GPU: 0, epoch: 18, iters: 104128, time: 0.003) nll: 0.827898 \n",
      "(GPU: 0, epoch: 18, iters: 104928, time: 0.003) nll: 0.939500 \n",
      "(GPU: 0, epoch: 18, iters: 105728, time: 0.003) nll: 0.741183 \n",
      "(GPU: 0, epoch: 18, iters: 106528, time: 0.003) nll: 0.993966 \n",
      "(GPU: 0, epoch: 18, iters: 107328, time: 0.003) nll: 0.587900 \n",
      "saving the latest model (epoch 18, total_steps 2640000)\n",
      "(GPU: 0, epoch: 18, iters: 108128, time: 0.003) nll: 0.751447 \n",
      "(GPU: 0, epoch: 18, iters: 108928, time: 0.003) nll: 1.000801 \n",
      "(GPU: 0, epoch: 18, iters: 109728, time: 0.003) nll: 0.656691 \n",
      "(GPU: 0, epoch: 18, iters: 110528, time: 0.003) nll: 0.528785 \n",
      "(GPU: 0, epoch: 18, iters: 111328, time: 0.003) nll: 0.756312 \n",
      "(GPU: 0, epoch: 18, iters: 112128, time: 0.003) nll: 0.727301 \n",
      "(GPU: 0, epoch: 18, iters: 112928, time: 0.003) nll: 0.730621 \n",
      "(GPU: 0, epoch: 18, iters: 113728, time: 0.003) nll: 0.691427 \n",
      "(GPU: 0, epoch: 18, iters: 114528, time: 0.003) nll: 1.180725 \n",
      "(GPU: 0, epoch: 18, iters: 115328, time: 0.003) nll: 0.635872 \n",
      "(GPU: 0, epoch: 18, iters: 116128, time: 0.003) nll: 0.750182 \n",
      "(GPU: 0, epoch: 18, iters: 116928, time: 0.003) nll: 0.749865 \n",
      "(GPU: 0, epoch: 18, iters: 117728, time: 0.003) nll: 0.639510 \n",
      "(GPU: 0, epoch: 18, iters: 118528, time: 0.003) nll: 0.885382 \n",
      "(GPU: 0, epoch: 18, iters: 119328, time: 0.003) nll: 0.988910 \n",
      "(GPU: 0, epoch: 18, iters: 120128, time: 0.003) nll: 0.734788 \n",
      "(GPU: 0, epoch: 18, iters: 120928, time: 0.003) nll: 0.841108 \n",
      "(GPU: 0, epoch: 18, iters: 121728, time: 0.003) nll: 0.573786 \n",
      "(GPU: 0, epoch: 18, iters: 122528, time: 0.003) nll: 0.776078 \n",
      "(GPU: 0, epoch: 18, iters: 123328, time: 0.003) nll: 0.640871 \n",
      "(GPU: 0, epoch: 18, iters: 124128, time: 0.003) nll: 0.674292 \n",
      "(GPU: 0, epoch: 18, iters: 124928, time: 0.003) nll: 0.667762 \n",
      "(GPU: 0, epoch: 18, iters: 125728, time: 0.003) nll: 0.796585 \n",
      "(GPU: 0, epoch: 18, iters: 126528, time: 0.003) nll: 0.824575 \n",
      "(GPU: 0, epoch: 18, iters: 127328, time: 0.003) nll: 0.633013 \n",
      "saving the latest model (epoch 18, total_steps 2660000)\n",
      "(GPU: 0, epoch: 18, iters: 128128, time: 0.003) nll: 0.892849 \n",
      "(GPU: 0, epoch: 18, iters: 128928, time: 0.003) nll: 0.779016 \n",
      "(GPU: 0, epoch: 18, iters: 129728, time: 0.003) nll: 0.681705 \n",
      "(GPU: 0, epoch: 18, iters: 130528, time: 0.003) nll: 0.773466 \n",
      "(GPU: 0, epoch: 18, iters: 131328, time: 0.003) nll: 0.913785 \n",
      "(GPU: 0, epoch: 18, iters: 132128, time: 0.003) nll: 0.797721 \n",
      "(GPU: 0, epoch: 18, iters: 132928, time: 0.003) nll: 0.661091 \n",
      "(GPU: 0, epoch: 18, iters: 133728, time: 0.003) nll: 0.872970 \n",
      "(GPU: 0, epoch: 18, iters: 134528, time: 0.003) nll: 0.762106 \n",
      "(GPU: 0, epoch: 18, iters: 135328, time: 0.003) nll: 0.639119 \n",
      "(GPU: 0, epoch: 18, iters: 136128, time: 0.003) nll: 0.833857 \n",
      "(GPU: 0, epoch: 18, iters: 136928, time: 0.003) nll: 0.690932 \n",
      "(GPU: 0, epoch: 18, iters: 137728, time: 0.003) nll: 0.764207 \n",
      "(GPU: 0, epoch: 18, iters: 138528, time: 0.003) nll: 0.701906 \n",
      "(GPU: 0, epoch: 18, iters: 139328, time: 0.003) nll: 0.704581 \n",
      "(GPU: 0, epoch: 18, iters: 140128, time: 0.003) nll: 0.850306 \n",
      "saving the model at the end of epoch 18, iters 2673376\n",
      "([test] GPU: 0, epoch: 18) \n",
      "OrderedDict()\n",
      "[*] End of epoch 18 / 25 \t Time Taken: 522 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000725\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3082/4397 [05:57<02:45,  7.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 19, iters: 32, time: 0.002) nll: 0.723530 \n",
      "(GPU: 0, epoch: 19, iters: 32, time: 0.002) nll: 0.881633 \n",
      "(GPU: 0, epoch: 19, iters: 224, time: 0.003) nll: 0.720635 \n",
      "(GPU: 0, epoch: 19, iters: 1024, time: 0.003) nll: 0.798212 \n",
      "(GPU: 0, epoch: 19, iters: 1824, time: 0.003) nll: 0.584909 \n",
      "(GPU: 0, epoch: 19, iters: 2624, time: 0.003) nll: 0.934215 \n",
      "(GPU: 0, epoch: 19, iters: 3424, time: 0.003) nll: 1.112461 \n",
      "(GPU: 0, epoch: 19, iters: 4224, time: 0.003) nll: 0.661071 \n",
      "(GPU: 0, epoch: 19, iters: 5024, time: 0.003) nll: 0.691814 \n",
      "(GPU: 0, epoch: 19, iters: 5824, time: 0.003) nll: 1.031212 \n",
      "(GPU: 0, epoch: 19, iters: 6624, time: 0.003) nll: 0.977321 \n",
      "saving the latest model (epoch 19, total_steps 2680000)\n",
      "(GPU: 0, epoch: 19, iters: 7424, time: 0.003) nll: 0.653810 \n",
      "(GPU: 0, epoch: 19, iters: 8224, time: 0.003) nll: 0.700852 \n",
      "(GPU: 0, epoch: 19, iters: 9024, time: 0.003) nll: 0.613853 \n",
      "(GPU: 0, epoch: 19, iters: 9824, time: 0.003) nll: 0.518380 \n",
      "(GPU: 0, epoch: 19, iters: 10624, time: 0.003) nll: 0.825889 \n",
      "(GPU: 0, epoch: 19, iters: 11424, time: 0.003) nll: 0.871806 \n",
      "(GPU: 0, epoch: 19, iters: 12224, time: 0.003) nll: 0.866775 \n",
      "(GPU: 0, epoch: 19, iters: 13024, time: 0.003) nll: 1.137569 \n",
      "(GPU: 0, epoch: 19, iters: 13824, time: 0.003) nll: 0.738199 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.003) nll: 0.619323 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.005) nll: 0.645191 \n",
      "(GPU: 0, epoch: 19, iters: 14624, time: 0.005) nll: 0.763743 \n",
      "(GPU: 0, epoch: 19, iters: 15424, time: 0.003) nll: 0.722369 \n",
      "(GPU: 0, epoch: 19, iters: 16224, time: 0.003) nll: 0.860729 \n",
      "(GPU: 0, epoch: 19, iters: 17024, time: 0.003) nll: 0.868102 \n",
      "(GPU: 0, epoch: 19, iters: 17824, time: 0.003) nll: 0.744959 \n",
      "(GPU: 0, epoch: 19, iters: 18624, time: 0.003) nll: 0.936233 \n",
      "(GPU: 0, epoch: 19, iters: 19424, time: 0.003) nll: 0.640974 \n",
      "(GPU: 0, epoch: 19, iters: 20224, time: 0.003) nll: 0.803838 \n",
      "(GPU: 0, epoch: 19, iters: 21024, time: 0.003) nll: 0.610237 \n",
      "(GPU: 0, epoch: 19, iters: 21824, time: 0.003) nll: 0.803652 \n",
      "(GPU: 0, epoch: 19, iters: 22624, time: 0.003) nll: 0.653460 \n",
      "(GPU: 0, epoch: 19, iters: 23424, time: 0.003) nll: 0.923171 \n",
      "(GPU: 0, epoch: 19, iters: 24224, time: 0.003) nll: 1.032134 \n",
      "(GPU: 0, epoch: 19, iters: 25024, time: 0.003) nll: 0.920752 \n",
      "(GPU: 0, epoch: 19, iters: 25824, time: 0.003) nll: 1.222754 \n",
      "(GPU: 0, epoch: 19, iters: 26624, time: 0.003) nll: 0.840228 \n",
      "saving the latest model (epoch 19, total_steps 2700000)\n",
      "(GPU: 0, epoch: 19, iters: 27424, time: 0.003) nll: 1.010078 \n",
      "(GPU: 0, epoch: 19, iters: 28224, time: 0.003) nll: 0.933742 \n",
      "(GPU: 0, epoch: 19, iters: 29024, time: 0.003) nll: 0.752948 \n",
      "(GPU: 0, epoch: 19, iters: 29824, time: 0.003) nll: 0.826699 \n",
      "(GPU: 0, epoch: 19, iters: 30624, time: 0.003) nll: 1.136074 \n",
      "(GPU: 0, epoch: 19, iters: 31424, time: 0.003) nll: 1.079478 \n",
      "(GPU: 0, epoch: 19, iters: 32224, time: 0.003) nll: 0.903488 \n",
      "(GPU: 0, epoch: 19, iters: 33024, time: 0.003) nll: 0.731560 \n",
      "(GPU: 0, epoch: 19, iters: 33824, time: 0.003) nll: 0.719269 \n",
      "(GPU: 0, epoch: 19, iters: 34624, time: 0.003) nll: 0.835025 \n",
      "(GPU: 0, epoch: 19, iters: 35424, time: 0.003) nll: 1.237175 \n",
      "(GPU: 0, epoch: 19, iters: 36224, time: 0.003) nll: 0.640223 \n",
      "(GPU: 0, epoch: 19, iters: 37024, time: 0.003) nll: 0.749829 \n",
      "(GPU: 0, epoch: 19, iters: 37824, time: 0.003) nll: 0.924882 \n",
      "(GPU: 0, epoch: 19, iters: 38624, time: 0.003) nll: 0.683939 \n",
      "(GPU: 0, epoch: 19, iters: 39424, time: 0.003) nll: 0.772591 \n",
      "(GPU: 0, epoch: 19, iters: 40224, time: 0.003) nll: 0.607371 \n",
      "(GPU: 0, epoch: 19, iters: 41024, time: 0.003) nll: 0.697956 \n",
      "(GPU: 0, epoch: 19, iters: 41824, time: 0.003) nll: 0.564869 \n",
      "(GPU: 0, epoch: 19, iters: 42624, time: 0.003) nll: 0.823811 \n",
      "(GPU: 0, epoch: 19, iters: 43424, time: 0.003) nll: 0.929070 \n",
      "(GPU: 0, epoch: 19, iters: 44224, time: 0.003) nll: 0.698635 \n",
      "(GPU: 0, epoch: 19, iters: 45024, time: 0.003) nll: 1.154647 \n",
      "(GPU: 0, epoch: 19, iters: 45824, time: 0.003) nll: 0.631561 \n",
      "(GPU: 0, epoch: 19, iters: 46624, time: 0.003) nll: 0.891045 \n",
      "saving the latest model (epoch 19, total_steps 2720000)\n",
      "(GPU: 0, epoch: 19, iters: 47424, time: 0.003) nll: 0.807033 \n",
      "(GPU: 0, epoch: 19, iters: 48224, time: 0.003) nll: 0.814078 \n",
      "(GPU: 0, epoch: 19, iters: 49024, time: 0.003) nll: 0.848133 \n",
      "(GPU: 0, epoch: 19, iters: 49824, time: 0.003) nll: 0.782284 \n",
      "(GPU: 0, epoch: 19, iters: 50624, time: 0.003) nll: 0.668726 \n",
      "(GPU: 0, epoch: 19, iters: 51424, time: 0.003) nll: 0.728720 \n",
      "(GPU: 0, epoch: 19, iters: 52224, time: 0.003) nll: 0.783504 \n",
      "(GPU: 0, epoch: 19, iters: 53024, time: 0.003) nll: 0.732877 \n",
      "(GPU: 0, epoch: 19, iters: 53824, time: 0.003) nll: 1.249632 \n",
      "(GPU: 0, epoch: 19, iters: 54624, time: 0.003) nll: 0.760051 \n",
      "(GPU: 0, epoch: 19, iters: 55424, time: 0.003) nll: 0.790731 \n",
      "(GPU: 0, epoch: 19, iters: 56224, time: 0.003) nll: 0.609204 \n",
      "(GPU: 0, epoch: 19, iters: 57024, time: 0.003) nll: 0.704692 \n",
      "(GPU: 0, epoch: 19, iters: 57824, time: 0.003) nll: 0.694694 \n",
      "(GPU: 0, epoch: 19, iters: 58624, time: 0.003) nll: 0.810983 \n",
      "(GPU: 0, epoch: 19, iters: 59424, time: 0.003) nll: 0.741568 \n",
      "(GPU: 0, epoch: 19, iters: 60224, time: 0.003) nll: 1.025667 \n",
      "(GPU: 0, epoch: 19, iters: 61024, time: 0.003) nll: 0.561483 \n",
      "(GPU: 0, epoch: 19, iters: 61824, time: 0.003) nll: 0.728003 \n",
      "(GPU: 0, epoch: 19, iters: 62624, time: 0.003) nll: 0.624529 \n",
      "(GPU: 0, epoch: 19, iters: 63424, time: 0.003) nll: 0.672661 \n",
      "(GPU: 0, epoch: 19, iters: 64224, time: 0.003) nll: 0.738567 \n",
      "(GPU: 0, epoch: 19, iters: 65024, time: 0.003) nll: 0.859705 \n",
      "(GPU: 0, epoch: 19, iters: 65824, time: 0.003) nll: 0.557800 \n",
      "(GPU: 0, epoch: 19, iters: 66624, time: 0.003) nll: 0.828207 \n",
      "saving the latest model (epoch 19, total_steps 2740000)\n",
      "(GPU: 0, epoch: 19, iters: 67424, time: 0.003) nll: 0.653476 \n",
      "(GPU: 0, epoch: 19, iters: 68224, time: 0.003) nll: 0.773396 \n",
      "(GPU: 0, epoch: 19, iters: 69024, time: 0.003) nll: 0.864601 \n",
      "(GPU: 0, epoch: 19, iters: 69824, time: 0.003) nll: 0.739775 \n",
      "(GPU: 0, epoch: 19, iters: 70624, time: 0.003) nll: 0.721011 \n",
      "(GPU: 0, epoch: 19, iters: 71424, time: 0.003) nll: 0.963113 \n",
      "(GPU: 0, epoch: 19, iters: 72224, time: 0.003) nll: 0.541418 \n",
      "(GPU: 0, epoch: 19, iters: 73024, time: 0.003) nll: 1.154776 \n",
      "(GPU: 0, epoch: 19, iters: 73824, time: 0.003) nll: 0.863645 \n",
      "(GPU: 0, epoch: 19, iters: 74624, time: 0.003) nll: 0.687689 \n",
      "(GPU: 0, epoch: 19, iters: 75424, time: 0.003) nll: 0.877631 \n",
      "(GPU: 0, epoch: 19, iters: 76224, time: 0.003) nll: 0.821860 \n",
      "(GPU: 0, epoch: 19, iters: 77024, time: 0.003) nll: 0.727287 \n",
      "(GPU: 0, epoch: 19, iters: 77824, time: 0.003) nll: 0.644592 \n",
      "(GPU: 0, epoch: 19, iters: 78624, time: 0.003) nll: 0.791167 \n",
      "(GPU: 0, epoch: 19, iters: 79424, time: 0.003) nll: 0.742163 \n",
      "(GPU: 0, epoch: 19, iters: 80224, time: 0.003) nll: 0.893956 \n",
      "(GPU: 0, epoch: 19, iters: 81024, time: 0.003) nll: 0.969501 \n",
      "(GPU: 0, epoch: 19, iters: 81824, time: 0.003) nll: 0.586928 \n",
      "(GPU: 0, epoch: 19, iters: 82624, time: 0.003) nll: 0.682922 \n",
      "(GPU: 0, epoch: 19, iters: 83424, time: 0.003) nll: 0.731907 \n",
      "(GPU: 0, epoch: 19, iters: 84224, time: 0.003) nll: 0.946064 \n",
      "(GPU: 0, epoch: 19, iters: 85024, time: 0.003) nll: 0.831930 \n",
      "(GPU: 0, epoch: 19, iters: 85824, time: 0.003) nll: 0.986581 \n",
      "(GPU: 0, epoch: 19, iters: 86624, time: 0.003) nll: 0.506259 \n",
      "saving the latest model (epoch 19, total_steps 2760000)\n",
      "(GPU: 0, epoch: 19, iters: 87424, time: 0.003) nll: 0.942181 \n",
      "(GPU: 0, epoch: 19, iters: 88224, time: 0.003) nll: 0.687681 \n",
      "(GPU: 0, epoch: 19, iters: 89024, time: 0.003) nll: 0.776055 \n",
      "(GPU: 0, epoch: 19, iters: 89824, time: 0.003) nll: 0.904184 \n",
      "(GPU: 0, epoch: 19, iters: 90624, time: 0.003) nll: 0.609129 \n",
      "(GPU: 0, epoch: 19, iters: 91424, time: 0.003) nll: 0.830624 \n",
      "(GPU: 0, epoch: 19, iters: 92224, time: 0.003) nll: 0.804077 \n",
      "(GPU: 0, epoch: 19, iters: 93024, time: 0.003) nll: 0.618406 \n",
      "(GPU: 0, epoch: 19, iters: 93824, time: 0.003) nll: 0.713320 \n",
      "(GPU: 0, epoch: 19, iters: 94624, time: 0.003) nll: 0.741348 \n",
      "(GPU: 0, epoch: 19, iters: 95424, time: 0.003) nll: 0.933016 \n",
      "(GPU: 0, epoch: 19, iters: 96224, time: 0.003) nll: 0.591106 \n",
      "(GPU: 0, epoch: 19, iters: 97024, time: 0.003) nll: 0.703750 \n",
      "(GPU: 0, epoch: 19, iters: 97824, time: 0.003) nll: 0.944824 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 19, iters: 98624, time: 0.003) nll: 0.737546 \n",
      "(GPU: 0, epoch: 19, iters: 99424, time: 0.003) nll: 0.881012 \n",
      "(GPU: 0, epoch: 19, iters: 100224, time: 0.003) nll: 0.896623 \n",
      "(GPU: 0, epoch: 19, iters: 101024, time: 0.003) nll: 0.730453 \n",
      "(GPU: 0, epoch: 19, iters: 101824, time: 0.003) nll: 0.766381 \n",
      "(GPU: 0, epoch: 19, iters: 102624, time: 0.003) nll: 0.725888 \n",
      "(GPU: 0, epoch: 19, iters: 103424, time: 0.003) nll: 0.695102 \n",
      "(GPU: 0, epoch: 19, iters: 104224, time: 0.003) nll: 0.855564 \n",
      "(GPU: 0, epoch: 19, iters: 105024, time: 0.003) nll: 0.841880 \n",
      "(GPU: 0, epoch: 19, iters: 105824, time: 0.003) nll: 0.682093 \n",
      "(GPU: 0, epoch: 19, iters: 106624, time: 0.003) nll: 0.726535 \n",
      "saving the latest model (epoch 19, total_steps 2780000)\n",
      "(GPU: 0, epoch: 19, iters: 107424, time: 0.003) nll: 0.678688 \n",
      "(GPU: 0, epoch: 19, iters: 108224, time: 0.003) nll: 0.742481 \n",
      "(GPU: 0, epoch: 19, iters: 109024, time: 0.003) nll: 0.745941 \n",
      "(GPU: 0, epoch: 19, iters: 109824, time: 0.003) nll: 0.710991 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.003) nll: 0.866102 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.005) nll: 0.856477 \n",
      "(GPU: 0, epoch: 19, iters: 110624, time: 0.005) nll: 0.904610 \n",
      "(GPU: 0, epoch: 19, iters: 111424, time: 0.003) nll: 0.726692 \n",
      "(GPU: 0, epoch: 19, iters: 112224, time: 0.003) nll: 0.795283 \n",
      "(GPU: 0, epoch: 19, iters: 113024, time: 0.003) nll: 0.691117 \n",
      "(GPU: 0, epoch: 19, iters: 113824, time: 0.003) nll: 0.601504 \n",
      "(GPU: 0, epoch: 19, iters: 114624, time: 0.003) nll: 0.904132 \n",
      "(GPU: 0, epoch: 19, iters: 115424, time: 0.003) nll: 0.845565 \n",
      "(GPU: 0, epoch: 19, iters: 116224, time: 0.003) nll: 0.787097 \n",
      "(GPU: 0, epoch: 19, iters: 117024, time: 0.003) nll: 0.510771 \n",
      "(GPU: 0, epoch: 19, iters: 117824, time: 0.003) nll: 0.870533 \n",
      "(GPU: 0, epoch: 19, iters: 118624, time: 0.003) nll: 0.754962 \n",
      "(GPU: 0, epoch: 19, iters: 119424, time: 0.003) nll: 0.660804 \n",
      "(GPU: 0, epoch: 19, iters: 120224, time: 0.003) nll: 0.621405 \n",
      "(GPU: 0, epoch: 19, iters: 121024, time: 0.003) nll: 0.821580 \n",
      "(GPU: 0, epoch: 19, iters: 121824, time: 0.003) nll: 0.756925 \n",
      "(GPU: 0, epoch: 19, iters: 122624, time: 0.003) nll: 0.562273 \n",
      "(GPU: 0, epoch: 19, iters: 123424, time: 0.003) nll: 0.860074 \n",
      "(GPU: 0, epoch: 19, iters: 124224, time: 0.003) nll: 0.705232 \n",
      "(GPU: 0, epoch: 19, iters: 125024, time: 0.003) nll: 0.913726 \n",
      "(GPU: 0, epoch: 19, iters: 125824, time: 0.003) nll: 0.867936 \n",
      "(GPU: 0, epoch: 19, iters: 126624, time: 0.003) nll: 0.751305 \n",
      "saving the latest model (epoch 19, total_steps 2800000)\n",
      "(GPU: 0, epoch: 19, iters: 127424, time: 0.003) nll: 0.892497 \n",
      "(GPU: 0, epoch: 19, iters: 128224, time: 0.003) nll: 0.649442 \n",
      "(GPU: 0, epoch: 19, iters: 129024, time: 0.003) nll: 0.724906 \n",
      "(GPU: 0, epoch: 19, iters: 129824, time: 0.003) nll: 0.915067 \n",
      "(GPU: 0, epoch: 19, iters: 130624, time: 0.003) nll: 0.760846 \n",
      "(GPU: 0, epoch: 19, iters: 131424, time: 0.003) nll: 0.658542 \n",
      "(GPU: 0, epoch: 19, iters: 132224, time: 0.003) nll: 0.801270 \n",
      "(GPU: 0, epoch: 19, iters: 133024, time: 0.003) nll: 0.777125 \n",
      "(GPU: 0, epoch: 19, iters: 133824, time: 0.003) nll: 0.817224 \n",
      "(GPU: 0, epoch: 19, iters: 134624, time: 0.003) nll: 0.729953 \n",
      "(GPU: 0, epoch: 19, iters: 135424, time: 0.003) nll: 0.627361 \n",
      "(GPU: 0, epoch: 19, iters: 136224, time: 0.003) nll: 0.884633 \n",
      "(GPU: 0, epoch: 19, iters: 137024, time: 0.003) nll: 0.888841 \n",
      "(GPU: 0, epoch: 19, iters: 137824, time: 0.003) nll: 0.962808 \n",
      "(GPU: 0, epoch: 19, iters: 138624, time: 0.003) nll: 0.855716 \n",
      "(GPU: 0, epoch: 19, iters: 139424, time: 0.003) nll: 0.836868 \n",
      "(GPU: 0, epoch: 19, iters: 140224, time: 0.003) nll: 0.814989 \n",
      "[*] End of epoch 19 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000707\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3084/4397 [05:58<02:17,  9.56it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 20, iters: 32, time: 0.002) nll: 0.714239 \n",
      "(GPU: 0, epoch: 20, iters: 32, time: 0.002) nll: 0.797206 \n",
      "(GPU: 0, epoch: 20, iters: 320, time: 0.003) nll: 0.977282 \n",
      "(GPU: 0, epoch: 20, iters: 1120, time: 0.003) nll: 0.930486 \n",
      "(GPU: 0, epoch: 20, iters: 1920, time: 0.003) nll: 0.838619 \n",
      "(GPU: 0, epoch: 20, iters: 2720, time: 0.003) nll: 0.816722 \n",
      "(GPU: 0, epoch: 20, iters: 3520, time: 0.003) nll: 0.977565 \n",
      "(GPU: 0, epoch: 20, iters: 4320, time: 0.003) nll: 0.804464 \n",
      "(GPU: 0, epoch: 20, iters: 5120, time: 0.003) nll: 0.790535 \n",
      "(GPU: 0, epoch: 20, iters: 5920, time: 0.003) nll: 0.710761 \n",
      "saving the latest model (epoch 20, total_steps 2820000)\n",
      "(GPU: 0, epoch: 20, iters: 6720, time: 0.003) nll: 0.884126 \n",
      "(GPU: 0, epoch: 20, iters: 7520, time: 0.003) nll: 0.789267 \n",
      "(GPU: 0, epoch: 20, iters: 8320, time: 0.003) nll: 0.763711 \n",
      "(GPU: 0, epoch: 20, iters: 9120, time: 0.003) nll: 0.674982 \n",
      "(GPU: 0, epoch: 20, iters: 9920, time: 0.003) nll: 0.945245 \n",
      "(GPU: 0, epoch: 20, iters: 10720, time: 0.003) nll: 0.739861 \n",
      "(GPU: 0, epoch: 20, iters: 11520, time: 0.003) nll: 0.832390 \n",
      "(GPU: 0, epoch: 20, iters: 12320, time: 0.003) nll: 0.752464 \n",
      "(GPU: 0, epoch: 20, iters: 13120, time: 0.003) nll: 0.796641 \n",
      "(GPU: 0, epoch: 20, iters: 13920, time: 0.003) nll: 0.754928 \n",
      "(GPU: 0, epoch: 20, iters: 14720, time: 0.003) nll: 0.932074 \n",
      "(GPU: 0, epoch: 20, iters: 15520, time: 0.003) nll: 0.844288 \n",
      "(GPU: 0, epoch: 20, iters: 16320, time: 0.003) nll: 0.809612 \n",
      "(GPU: 0, epoch: 20, iters: 17120, time: 0.003) nll: 0.758879 \n",
      "(GPU: 0, epoch: 20, iters: 17920, time: 0.003) nll: 0.789958 \n",
      "(GPU: 0, epoch: 20, iters: 18720, time: 0.003) nll: 0.894031 \n",
      "(GPU: 0, epoch: 20, iters: 19520, time: 0.003) nll: 1.068557 \n",
      "(GPU: 0, epoch: 20, iters: 20320, time: 0.003) nll: 0.709339 \n",
      "(GPU: 0, epoch: 20, iters: 21120, time: 0.003) nll: 0.664830 \n",
      "(GPU: 0, epoch: 20, iters: 21920, time: 0.003) nll: 0.610636 \n",
      "(GPU: 0, epoch: 20, iters: 22720, time: 0.003) nll: 0.932416 \n",
      "(GPU: 0, epoch: 20, iters: 23520, time: 0.003) nll: 0.704133 \n",
      "(GPU: 0, epoch: 20, iters: 24320, time: 0.003) nll: 0.688051 \n",
      "(GPU: 0, epoch: 20, iters: 25120, time: 0.003) nll: 0.503297 \n",
      "(GPU: 0, epoch: 20, iters: 25920, time: 0.003) nll: 0.932497 \n",
      "saving the latest model (epoch 20, total_steps 2840000)\n",
      "(GPU: 0, epoch: 20, iters: 26720, time: 0.003) nll: 0.610217 \n",
      "(GPU: 0, epoch: 20, iters: 27520, time: 0.003) nll: 0.976920 \n",
      "(GPU: 0, epoch: 20, iters: 28320, time: 0.003) nll: 0.755526 \n",
      "(GPU: 0, epoch: 20, iters: 29120, time: 0.003) nll: 0.428125 \n",
      "(GPU: 0, epoch: 20, iters: 29920, time: 0.003) nll: 0.683314 \n",
      "(GPU: 0, epoch: 20, iters: 30720, time: 0.003) nll: 0.917082 \n",
      "(GPU: 0, epoch: 20, iters: 31520, time: 0.003) nll: 0.656524 \n",
      "(GPU: 0, epoch: 20, iters: 32320, time: 0.003) nll: 0.671375 \n",
      "(GPU: 0, epoch: 20, iters: 33120, time: 0.003) nll: 0.593183 \n",
      "(GPU: 0, epoch: 20, iters: 33920, time: 0.003) nll: 0.830177 \n",
      "(GPU: 0, epoch: 20, iters: 34720, time: 0.003) nll: 0.761115 \n",
      "(GPU: 0, epoch: 20, iters: 35520, time: 0.003) nll: 0.807841 \n",
      "(GPU: 0, epoch: 20, iters: 36320, time: 0.003) nll: 0.626007 \n",
      "(GPU: 0, epoch: 20, iters: 37120, time: 0.003) nll: 0.765343 \n",
      "(GPU: 0, epoch: 20, iters: 37920, time: 0.003) nll: 0.674727 \n",
      "(GPU: 0, epoch: 20, iters: 38720, time: 0.003) nll: 0.738224 \n",
      "(GPU: 0, epoch: 20, iters: 39520, time: 0.003) nll: 0.559444 \n",
      "(GPU: 0, epoch: 20, iters: 40320, time: 0.003) nll: 0.851291 \n",
      "(GPU: 0, epoch: 20, iters: 41120, time: 0.003) nll: 0.624180 \n",
      "(GPU: 0, epoch: 20, iters: 41920, time: 0.003) nll: 0.778653 \n",
      "(GPU: 0, epoch: 20, iters: 42720, time: 0.003) nll: 0.895556 \n",
      "(GPU: 0, epoch: 20, iters: 43520, time: 0.003) nll: 0.829645 \n",
      "(GPU: 0, epoch: 20, iters: 44320, time: 0.003) nll: 0.820946 \n",
      "(GPU: 0, epoch: 20, iters: 45120, time: 0.003) nll: 0.891576 \n",
      "(GPU: 0, epoch: 20, iters: 45920, time: 0.003) nll: 0.866455 \n",
      "saving the latest model (epoch 20, total_steps 2860000)\n",
      "(GPU: 0, epoch: 20, iters: 46720, time: 0.003) nll: 0.582413 \n",
      "(GPU: 0, epoch: 20, iters: 47520, time: 0.003) nll: 1.186137 \n",
      "(GPU: 0, epoch: 20, iters: 48320, time: 0.003) nll: 0.623818 \n",
      "(GPU: 0, epoch: 20, iters: 49120, time: 0.003) nll: 0.857189 \n",
      "(GPU: 0, epoch: 20, iters: 49920, time: 0.003) nll: 0.565797 \n",
      "(GPU: 0, epoch: 20, iters: 50720, time: 0.003) nll: 0.850299 \n",
      "(GPU: 0, epoch: 20, iters: 51520, time: 0.003) nll: 0.860050 \n",
      "(GPU: 0, epoch: 20, iters: 52320, time: 0.003) nll: 0.405006 \n",
      "(GPU: 0, epoch: 20, iters: 53120, time: 0.003) nll: 0.861964 \n",
      "(GPU: 0, epoch: 20, iters: 53920, time: 0.003) nll: 0.881588 \n",
      "(GPU: 0, epoch: 20, iters: 54720, time: 0.003) nll: 0.823733 \n",
      "(GPU: 0, epoch: 20, iters: 55520, time: 0.003) nll: 0.975333 \n",
      "(GPU: 0, epoch: 20, iters: 56320, time: 0.003) nll: 0.823767 \n",
      "(GPU: 0, epoch: 20, iters: 57120, time: 0.003) nll: 0.642502 \n",
      "(GPU: 0, epoch: 20, iters: 57920, time: 0.003) nll: 1.343579 \n",
      "(GPU: 0, epoch: 20, iters: 58720, time: 0.003) nll: 0.878806 \n",
      "(GPU: 0, epoch: 20, iters: 59520, time: 0.003) nll: 0.753921 \n",
      "(GPU: 0, epoch: 20, iters: 60320, time: 0.003) nll: 0.821314 \n",
      "(GPU: 0, epoch: 20, iters: 61120, time: 0.003) nll: 0.862647 \n",
      "(GPU: 0, epoch: 20, iters: 61920, time: 0.003) nll: 0.705826 \n",
      "(GPU: 0, epoch: 20, iters: 62720, time: 0.003) nll: 0.850279 \n",
      "(GPU: 0, epoch: 20, iters: 63520, time: 0.003) nll: 0.752929 \n",
      "(GPU: 0, epoch: 20, iters: 64320, time: 0.003) nll: 0.653058 \n",
      "(GPU: 0, epoch: 20, iters: 65120, time: 0.003) nll: 0.861600 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.003) nll: 0.782290 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.005) nll: 0.764793 \n",
      "(GPU: 0, epoch: 20, iters: 65920, time: 0.005) nll: 0.774143 \n",
      "saving the latest model (epoch 20, total_steps 2880000)\n",
      "(GPU: 0, epoch: 20, iters: 66720, time: 0.003) nll: 0.774957 \n",
      "(GPU: 0, epoch: 20, iters: 67520, time: 0.003) nll: 0.625054 \n",
      "(GPU: 0, epoch: 20, iters: 68320, time: 0.003) nll: 0.714307 \n",
      "(GPU: 0, epoch: 20, iters: 69120, time: 0.003) nll: 0.789811 \n",
      "(GPU: 0, epoch: 20, iters: 69920, time: 0.003) nll: 0.932973 \n",
      "(GPU: 0, epoch: 20, iters: 70720, time: 0.003) nll: 0.859872 \n",
      "(GPU: 0, epoch: 20, iters: 71520, time: 0.003) nll: 0.818080 \n",
      "(GPU: 0, epoch: 20, iters: 72320, time: 0.003) nll: 0.741197 \n",
      "(GPU: 0, epoch: 20, iters: 73120, time: 0.003) nll: 0.706599 \n",
      "(GPU: 0, epoch: 20, iters: 73920, time: 0.003) nll: 0.732562 \n",
      "(GPU: 0, epoch: 20, iters: 74720, time: 0.003) nll: 0.539473 \n",
      "(GPU: 0, epoch: 20, iters: 75520, time: 0.003) nll: 0.775460 \n",
      "(GPU: 0, epoch: 20, iters: 76320, time: 0.003) nll: 0.709104 \n",
      "(GPU: 0, epoch: 20, iters: 77120, time: 0.003) nll: 0.794839 \n",
      "(GPU: 0, epoch: 20, iters: 77920, time: 0.003) nll: 0.855208 \n",
      "(GPU: 0, epoch: 20, iters: 78720, time: 0.003) nll: 0.950112 \n",
      "(GPU: 0, epoch: 20, iters: 79520, time: 0.003) nll: 0.865556 \n",
      "(GPU: 0, epoch: 20, iters: 80320, time: 0.003) nll: 0.707608 \n",
      "(GPU: 0, epoch: 20, iters: 81120, time: 0.003) nll: 0.784335 \n",
      "(GPU: 0, epoch: 20, iters: 81920, time: 0.003) nll: 0.691046 \n",
      "(GPU: 0, epoch: 20, iters: 82720, time: 0.003) nll: 0.844459 \n",
      "(GPU: 0, epoch: 20, iters: 83520, time: 0.003) nll: 1.016627 \n",
      "(GPU: 0, epoch: 20, iters: 84320, time: 0.003) nll: 0.844260 \n",
      "(GPU: 0, epoch: 20, iters: 85120, time: 0.003) nll: 1.024788 \n",
      "(GPU: 0, epoch: 20, iters: 85920, time: 0.003) nll: 0.760908 \n",
      "saving the latest model (epoch 20, total_steps 2900000)\n",
      "(GPU: 0, epoch: 20, iters: 86720, time: 0.003) nll: 0.659815 \n",
      "(GPU: 0, epoch: 20, iters: 87520, time: 0.003) nll: 0.860751 \n",
      "(GPU: 0, epoch: 20, iters: 88320, time: 0.003) nll: 0.752986 \n",
      "(GPU: 0, epoch: 20, iters: 89120, time: 0.003) nll: 0.821477 \n",
      "(GPU: 0, epoch: 20, iters: 89920, time: 0.003) nll: 0.829875 \n",
      "(GPU: 0, epoch: 20, iters: 90720, time: 0.003) nll: 0.826404 \n",
      "(GPU: 0, epoch: 20, iters: 91520, time: 0.003) nll: 0.736674 \n",
      "(GPU: 0, epoch: 20, iters: 92320, time: 0.003) nll: 0.867821 \n",
      "(GPU: 0, epoch: 20, iters: 93120, time: 0.003) nll: 0.704146 \n",
      "(GPU: 0, epoch: 20, iters: 93920, time: 0.003) nll: 0.739800 \n",
      "(GPU: 0, epoch: 20, iters: 94720, time: 0.003) nll: 0.739010 \n",
      "(GPU: 0, epoch: 20, iters: 95520, time: 0.003) nll: 0.791466 \n",
      "(GPU: 0, epoch: 20, iters: 96320, time: 0.003) nll: 1.026532 \n",
      "(GPU: 0, epoch: 20, iters: 97120, time: 0.003) nll: 0.621618 \n",
      "(GPU: 0, epoch: 20, iters: 97920, time: 0.003) nll: 0.742599 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 20, iters: 98720, time: 0.003) nll: 0.740751 \n",
      "(GPU: 0, epoch: 20, iters: 99520, time: 0.003) nll: 0.739914 \n",
      "(GPU: 0, epoch: 20, iters: 100320, time: 0.003) nll: 0.493475 \n",
      "(GPU: 0, epoch: 20, iters: 101120, time: 0.003) nll: 0.671396 \n",
      "(GPU: 0, epoch: 20, iters: 101920, time: 0.003) nll: 0.683488 \n",
      "(GPU: 0, epoch: 20, iters: 102720, time: 0.003) nll: 0.784447 \n",
      "(GPU: 0, epoch: 20, iters: 103520, time: 0.003) nll: 0.475685 \n",
      "(GPU: 0, epoch: 20, iters: 104320, time: 0.003) nll: 0.920978 \n",
      "(GPU: 0, epoch: 20, iters: 105120, time: 0.003) nll: 0.844150 \n",
      "(GPU: 0, epoch: 20, iters: 105920, time: 0.003) nll: 0.730342 \n",
      "saving the latest model (epoch 20, total_steps 2920000)\n",
      "(GPU: 0, epoch: 20, iters: 106720, time: 0.003) nll: 0.729478 \n",
      "(GPU: 0, epoch: 20, iters: 107520, time: 0.003) nll: 0.770627 \n",
      "(GPU: 0, epoch: 20, iters: 108320, time: 0.003) nll: 0.736843 \n",
      "(GPU: 0, epoch: 20, iters: 109120, time: 0.003) nll: 0.830637 \n",
      "(GPU: 0, epoch: 20, iters: 109920, time: 0.003) nll: 0.690639 \n",
      "(GPU: 0, epoch: 20, iters: 110720, time: 0.003) nll: 0.855508 \n",
      "(GPU: 0, epoch: 20, iters: 111520, time: 0.003) nll: 0.692092 \n",
      "(GPU: 0, epoch: 20, iters: 112320, time: 0.003) nll: 0.586259 \n",
      "(GPU: 0, epoch: 20, iters: 113120, time: 0.003) nll: 0.714130 \n",
      "(GPU: 0, epoch: 20, iters: 113920, time: 0.003) nll: 0.751672 \n",
      "(GPU: 0, epoch: 20, iters: 114720, time: 0.003) nll: 0.835255 \n",
      "(GPU: 0, epoch: 20, iters: 115520, time: 0.003) nll: 0.669663 \n",
      "(GPU: 0, epoch: 20, iters: 116320, time: 0.003) nll: 0.957311 \n",
      "(GPU: 0, epoch: 20, iters: 117120, time: 0.003) nll: 0.755747 \n",
      "(GPU: 0, epoch: 20, iters: 117920, time: 0.003) nll: 1.026706 \n",
      "(GPU: 0, epoch: 20, iters: 118720, time: 0.003) nll: 0.858077 \n",
      "(GPU: 0, epoch: 20, iters: 119520, time: 0.003) nll: 0.652239 \n",
      "(GPU: 0, epoch: 20, iters: 120320, time: 0.003) nll: 0.644888 \n",
      "(GPU: 0, epoch: 20, iters: 121120, time: 0.003) nll: 0.848340 \n",
      "(GPU: 0, epoch: 20, iters: 121920, time: 0.003) nll: 0.847546 \n",
      "(GPU: 0, epoch: 20, iters: 122720, time: 0.003) nll: 0.845905 \n",
      "(GPU: 0, epoch: 20, iters: 123520, time: 0.003) nll: 0.653155 \n",
      "(GPU: 0, epoch: 20, iters: 124320, time: 0.003) nll: 0.698362 \n",
      "(GPU: 0, epoch: 20, iters: 125120, time: 0.003) nll: 0.918114 \n",
      "(GPU: 0, epoch: 20, iters: 125920, time: 0.003) nll: 0.566390 \n",
      "saving the latest model (epoch 20, total_steps 2940000)\n",
      "(GPU: 0, epoch: 20, iters: 126720, time: 0.003) nll: 0.638958 \n",
      "(GPU: 0, epoch: 20, iters: 127520, time: 0.003) nll: 0.796208 \n",
      "(GPU: 0, epoch: 20, iters: 128320, time: 0.003) nll: 0.709195 \n",
      "(GPU: 0, epoch: 20, iters: 129120, time: 0.003) nll: 0.816606 \n",
      "(GPU: 0, epoch: 20, iters: 129920, time: 0.003) nll: 0.693727 \n",
      "(GPU: 0, epoch: 20, iters: 130720, time: 0.003) nll: 0.704855 \n",
      "(GPU: 0, epoch: 20, iters: 131520, time: 0.003) nll: 0.651171 \n",
      "(GPU: 0, epoch: 20, iters: 132320, time: 0.003) nll: 1.017012 \n",
      "(GPU: 0, epoch: 20, iters: 133120, time: 0.003) nll: 0.724528 \n",
      "(GPU: 0, epoch: 20, iters: 133920, time: 0.003) nll: 0.771677 \n",
      "(GPU: 0, epoch: 20, iters: 134720, time: 0.003) nll: 0.711248 \n",
      "(GPU: 0, epoch: 20, iters: 135520, time: 0.003) nll: 0.941123 \n",
      "(GPU: 0, epoch: 20, iters: 136320, time: 0.003) nll: 0.961246 \n",
      "(GPU: 0, epoch: 20, iters: 137120, time: 0.003) nll: 0.843669 \n",
      "(GPU: 0, epoch: 20, iters: 137920, time: 0.003) nll: 0.656290 \n",
      "(GPU: 0, epoch: 20, iters: 138720, time: 0.003) nll: 0.940698 \n",
      "(GPU: 0, epoch: 20, iters: 139520, time: 0.003) nll: 0.832964 \n",
      "(GPU: 0, epoch: 20, iters: 140320, time: 0.003) nll: 0.894168 \n",
      "[*] End of epoch 20 / 25 \t Time Taken: 510 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000690\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3087/4397 [05:58<02:20,  9.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 21, iters: 32, time: 0.002) nll: 0.920144 \n",
      "(GPU: 0, epoch: 21, iters: 32, time: 0.002) nll: 0.908960 \n",
      "(GPU: 0, epoch: 21, iters: 416, time: 0.003) nll: 0.775682 \n",
      "(GPU: 0, epoch: 21, iters: 1216, time: 0.003) nll: 0.703830 \n",
      "(GPU: 0, epoch: 21, iters: 2016, time: 0.003) nll: 0.756502 \n",
      "(GPU: 0, epoch: 21, iters: 2816, time: 0.003) nll: 0.583885 \n",
      "(GPU: 0, epoch: 21, iters: 3616, time: 0.003) nll: 0.550119 \n",
      "(GPU: 0, epoch: 21, iters: 4416, time: 0.003) nll: 0.685283 \n",
      "(GPU: 0, epoch: 21, iters: 5216, time: 0.003) nll: 0.689055 \n",
      "saving the latest model (epoch 21, total_steps 2960000)\n",
      "(GPU: 0, epoch: 21, iters: 6016, time: 0.003) nll: 0.857733 \n",
      "(GPU: 0, epoch: 21, iters: 6816, time: 0.003) nll: 0.796070 \n",
      "(GPU: 0, epoch: 21, iters: 7616, time: 0.003) nll: 0.587189 \n",
      "(GPU: 0, epoch: 21, iters: 8416, time: 0.003) nll: 0.711892 \n",
      "(GPU: 0, epoch: 21, iters: 9216, time: 0.003) nll: 0.859351 \n",
      "(GPU: 0, epoch: 21, iters: 10016, time: 0.003) nll: 0.685890 \n",
      "(GPU: 0, epoch: 21, iters: 10816, time: 0.003) nll: 0.988463 \n",
      "(GPU: 0, epoch: 21, iters: 11616, time: 0.003) nll: 0.730523 \n",
      "(GPU: 0, epoch: 21, iters: 12416, time: 0.003) nll: 0.592704 \n",
      "(GPU: 0, epoch: 21, iters: 13216, time: 0.003) nll: 0.743946 \n",
      "(GPU: 0, epoch: 21, iters: 14016, time: 0.003) nll: 0.835196 \n",
      "(GPU: 0, epoch: 21, iters: 14816, time: 0.003) nll: 0.909686 \n",
      "(GPU: 0, epoch: 21, iters: 15616, time: 0.003) nll: 0.535124 \n",
      "(GPU: 0, epoch: 21, iters: 16416, time: 0.003) nll: 0.655170 \n",
      "(GPU: 0, epoch: 21, iters: 17216, time: 0.003) nll: 0.755594 \n",
      "(GPU: 0, epoch: 21, iters: 18016, time: 0.003) nll: 0.743193 \n",
      "(GPU: 0, epoch: 21, iters: 18816, time: 0.003) nll: 0.979411 \n",
      "(GPU: 0, epoch: 21, iters: 19616, time: 0.003) nll: 0.893062 \n",
      "(GPU: 0, epoch: 21, iters: 20416, time: 0.003) nll: 0.997938 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.003) nll: 0.560954 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.005) nll: 0.667562 \n",
      "(GPU: 0, epoch: 21, iters: 21216, time: 0.005) nll: 1.240226 \n",
      "(GPU: 0, epoch: 21, iters: 22016, time: 0.003) nll: 0.948400 \n",
      "(GPU: 0, epoch: 21, iters: 22816, time: 0.003) nll: 0.774198 \n",
      "(GPU: 0, epoch: 21, iters: 23616, time: 0.003) nll: 0.855738 \n",
      "(GPU: 0, epoch: 21, iters: 24416, time: 0.003) nll: 1.033940 \n",
      "(GPU: 0, epoch: 21, iters: 25216, time: 0.003) nll: 0.865926 \n",
      "saving the latest model (epoch 21, total_steps 2980000)\n",
      "(GPU: 0, epoch: 21, iters: 26016, time: 0.003) nll: 0.817432 \n",
      "(GPU: 0, epoch: 21, iters: 26816, time: 0.003) nll: 1.016274 \n",
      "(GPU: 0, epoch: 21, iters: 27616, time: 0.003) nll: 0.922289 \n",
      "(GPU: 0, epoch: 21, iters: 28416, time: 0.003) nll: 0.599945 \n",
      "(GPU: 0, epoch: 21, iters: 29216, time: 0.003) nll: 0.836442 \n",
      "(GPU: 0, epoch: 21, iters: 30016, time: 0.003) nll: 0.791905 \n",
      "(GPU: 0, epoch: 21, iters: 30816, time: 0.003) nll: 0.672308 \n",
      "(GPU: 0, epoch: 21, iters: 31616, time: 0.003) nll: 0.854033 \n",
      "(GPU: 0, epoch: 21, iters: 32416, time: 0.003) nll: 0.744926 \n",
      "(GPU: 0, epoch: 21, iters: 33216, time: 0.003) nll: 0.717619 \n",
      "(GPU: 0, epoch: 21, iters: 34016, time: 0.003) nll: 0.639996 \n",
      "(GPU: 0, epoch: 21, iters: 34816, time: 0.003) nll: 0.858214 \n",
      "(GPU: 0, epoch: 21, iters: 35616, time: 0.003) nll: 0.650101 \n",
      "(GPU: 0, epoch: 21, iters: 36416, time: 0.003) nll: 0.789683 \n",
      "(GPU: 0, epoch: 21, iters: 37216, time: 0.003) nll: 0.916895 \n",
      "(GPU: 0, epoch: 21, iters: 38016, time: 0.003) nll: 0.827622 \n",
      "(GPU: 0, epoch: 21, iters: 38816, time: 0.003) nll: 0.763532 \n",
      "(GPU: 0, epoch: 21, iters: 39616, time: 0.003) nll: 0.902170 \n",
      "(GPU: 0, epoch: 21, iters: 40416, time: 0.003) nll: 0.625850 \n",
      "(GPU: 0, epoch: 21, iters: 41216, time: 0.003) nll: 0.674599 \n",
      "(GPU: 0, epoch: 21, iters: 42016, time: 0.003) nll: 0.842756 \n",
      "(GPU: 0, epoch: 21, iters: 42816, time: 0.003) nll: 0.795822 \n",
      "(GPU: 0, epoch: 21, iters: 43616, time: 0.003) nll: 0.690466 \n",
      "(GPU: 0, epoch: 21, iters: 44416, time: 0.003) nll: 0.766991 \n",
      "(GPU: 0, epoch: 21, iters: 45216, time: 0.003) nll: 0.757430 \n",
      "saving the latest model (epoch 21, total_steps 3000000)\n",
      "(GPU: 0, epoch: 21, iters: 46016, time: 0.003) nll: 0.761315 \n",
      "(GPU: 0, epoch: 21, iters: 46816, time: 0.003) nll: 0.837792 \n",
      "(GPU: 0, epoch: 21, iters: 47616, time: 0.003) nll: 0.967576 \n",
      "(GPU: 0, epoch: 21, iters: 48416, time: 0.003) nll: 0.851527 \n",
      "(GPU: 0, epoch: 21, iters: 49216, time: 0.003) nll: 0.947467 \n",
      "(GPU: 0, epoch: 21, iters: 50016, time: 0.003) nll: 0.835330 \n",
      "(GPU: 0, epoch: 21, iters: 50816, time: 0.003) nll: 0.765666 \n",
      "(GPU: 0, epoch: 21, iters: 51616, time: 0.003) nll: 0.691178 \n",
      "(GPU: 0, epoch: 21, iters: 52416, time: 0.003) nll: 0.735057 \n",
      "(GPU: 0, epoch: 21, iters: 53216, time: 0.003) nll: 0.779085 \n",
      "(GPU: 0, epoch: 21, iters: 54016, time: 0.003) nll: 0.641544 \n",
      "(GPU: 0, epoch: 21, iters: 54816, time: 0.003) nll: 0.785422 \n",
      "(GPU: 0, epoch: 21, iters: 55616, time: 0.003) nll: 0.868138 \n",
      "(GPU: 0, epoch: 21, iters: 56416, time: 0.003) nll: 0.698637 \n",
      "(GPU: 0, epoch: 21, iters: 57216, time: 0.003) nll: 0.985255 \n",
      "(GPU: 0, epoch: 21, iters: 58016, time: 0.003) nll: 0.657800 \n",
      "(GPU: 0, epoch: 21, iters: 58816, time: 0.003) nll: 0.742626 \n",
      "(GPU: 0, epoch: 21, iters: 59616, time: 0.003) nll: 0.785809 \n",
      "(GPU: 0, epoch: 21, iters: 60416, time: 0.003) nll: 0.780090 \n",
      "(GPU: 0, epoch: 21, iters: 61216, time: 0.003) nll: 1.033956 \n",
      "(GPU: 0, epoch: 21, iters: 62016, time: 0.003) nll: 0.973603 \n",
      "(GPU: 0, epoch: 21, iters: 62816, time: 0.003) nll: 0.770021 \n",
      "(GPU: 0, epoch: 21, iters: 63616, time: 0.003) nll: 0.687565 \n",
      "(GPU: 0, epoch: 21, iters: 64416, time: 0.003) nll: 1.153765 \n",
      "(GPU: 0, epoch: 21, iters: 65216, time: 0.003) nll: 0.718807 \n",
      "saving the latest model (epoch 21, total_steps 3020000)\n",
      "(GPU: 0, epoch: 21, iters: 66016, time: 0.003) nll: 0.875071 \n",
      "(GPU: 0, epoch: 21, iters: 66816, time: 0.003) nll: 0.700534 \n",
      "(GPU: 0, epoch: 21, iters: 67616, time: 0.003) nll: 0.794306 \n",
      "(GPU: 0, epoch: 21, iters: 68416, time: 0.003) nll: 0.795402 \n",
      "(GPU: 0, epoch: 21, iters: 69216, time: 0.003) nll: 0.802664 \n",
      "(GPU: 0, epoch: 21, iters: 70016, time: 0.003) nll: 0.709553 \n",
      "(GPU: 0, epoch: 21, iters: 70816, time: 0.003) nll: 0.690763 \n",
      "(GPU: 0, epoch: 21, iters: 71616, time: 0.003) nll: 0.773190 \n",
      "(GPU: 0, epoch: 21, iters: 72416, time: 0.003) nll: 0.671448 \n",
      "(GPU: 0, epoch: 21, iters: 73216, time: 0.003) nll: 0.937294 \n",
      "(GPU: 0, epoch: 21, iters: 74016, time: 0.003) nll: 0.652923 \n",
      "(GPU: 0, epoch: 21, iters: 74816, time: 0.003) nll: 0.850423 \n",
      "(GPU: 0, epoch: 21, iters: 75616, time: 0.003) nll: 0.809260 \n",
      "(GPU: 0, epoch: 21, iters: 76416, time: 0.003) nll: 1.081007 \n",
      "(GPU: 0, epoch: 21, iters: 77216, time: 0.003) nll: 0.948417 \n",
      "(GPU: 0, epoch: 21, iters: 78016, time: 0.003) nll: 0.900729 \n",
      "(GPU: 0, epoch: 21, iters: 78816, time: 0.003) nll: 0.852800 \n",
      "(GPU: 0, epoch: 21, iters: 79616, time: 0.003) nll: 0.843345 \n",
      "(GPU: 0, epoch: 21, iters: 80416, time: 0.003) nll: 0.742355 \n",
      "(GPU: 0, epoch: 21, iters: 81216, time: 0.003) nll: 0.573704 \n",
      "(GPU: 0, epoch: 21, iters: 82016, time: 0.003) nll: 0.964646 \n",
      "(GPU: 0, epoch: 21, iters: 82816, time: 0.003) nll: 0.886491 \n",
      "(GPU: 0, epoch: 21, iters: 83616, time: 0.003) nll: 0.657544 \n",
      "(GPU: 0, epoch: 21, iters: 84416, time: 0.003) nll: 0.717639 \n",
      "(GPU: 0, epoch: 21, iters: 85216, time: 0.003) nll: 0.934895 \n",
      "saving the latest model (epoch 21, total_steps 3040000)\n",
      "(GPU: 0, epoch: 21, iters: 86016, time: 0.003) nll: 0.714423 \n",
      "(GPU: 0, epoch: 21, iters: 86816, time: 0.003) nll: 0.704782 \n",
      "(GPU: 0, epoch: 21, iters: 87616, time: 0.003) nll: 0.691399 \n",
      "(GPU: 0, epoch: 21, iters: 88416, time: 0.003) nll: 0.683132 \n",
      "(GPU: 0, epoch: 21, iters: 89216, time: 0.003) nll: 0.668357 \n",
      "(GPU: 0, epoch: 21, iters: 90016, time: 0.003) nll: 0.690781 \n",
      "(GPU: 0, epoch: 21, iters: 90816, time: 0.003) nll: 0.625379 \n",
      "(GPU: 0, epoch: 21, iters: 91616, time: 0.003) nll: 0.726880 \n",
      "(GPU: 0, epoch: 21, iters: 92416, time: 0.003) nll: 0.680579 \n",
      "(GPU: 0, epoch: 21, iters: 93216, time: 0.003) nll: 1.033947 \n",
      "(GPU: 0, epoch: 21, iters: 94016, time: 0.003) nll: 0.838516 \n",
      "(GPU: 0, epoch: 21, iters: 94816, time: 0.003) nll: 0.855507 \n",
      "(GPU: 0, epoch: 21, iters: 95616, time: 0.003) nll: 0.511577 \n",
      "(GPU: 0, epoch: 21, iters: 96416, time: 0.003) nll: 0.920826 \n",
      "(GPU: 0, epoch: 21, iters: 97216, time: 0.003) nll: 0.599490 \n",
      "(GPU: 0, epoch: 21, iters: 98016, time: 0.003) nll: 0.738402 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:29<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 21, iters: 98816, time: 0.003) nll: 0.800576 \n",
      "(GPU: 0, epoch: 21, iters: 99616, time: 0.003) nll: 0.751984 \n",
      "(GPU: 0, epoch: 21, iters: 100416, time: 0.003) nll: 0.729563 \n",
      "(GPU: 0, epoch: 21, iters: 101216, time: 0.003) nll: 0.859672 \n",
      "(GPU: 0, epoch: 21, iters: 102016, time: 0.003) nll: 0.875498 \n",
      "(GPU: 0, epoch: 21, iters: 102816, time: 0.003) nll: 0.653322 \n",
      "(GPU: 0, epoch: 21, iters: 103616, time: 0.003) nll: 0.625160 \n",
      "(GPU: 0, epoch: 21, iters: 104416, time: 0.003) nll: 0.588411 \n",
      "(GPU: 0, epoch: 21, iters: 105216, time: 0.003) nll: 0.876480 \n",
      "saving the latest model (epoch 21, total_steps 3060000)\n",
      "(GPU: 0, epoch: 21, iters: 106016, time: 0.003) nll: 0.835751 \n",
      "(GPU: 0, epoch: 21, iters: 106816, time: 0.003) nll: 0.880905 \n",
      "(GPU: 0, epoch: 21, iters: 107616, time: 0.003) nll: 0.681985 \n",
      "(GPU: 0, epoch: 21, iters: 108416, time: 0.003) nll: 0.776293 \n",
      "(GPU: 0, epoch: 21, iters: 109216, time: 0.003) nll: 0.898699 \n",
      "(GPU: 0, epoch: 21, iters: 110016, time: 0.003) nll: 0.855729 \n",
      "(GPU: 0, epoch: 21, iters: 110816, time: 0.003) nll: 0.602913 \n",
      "(GPU: 0, epoch: 21, iters: 111616, time: 0.003) nll: 0.938767 \n",
      "(GPU: 0, epoch: 21, iters: 112416, time: 0.003) nll: 1.062431 \n",
      "(GPU: 0, epoch: 21, iters: 113216, time: 0.003) nll: 0.783726 \n",
      "(GPU: 0, epoch: 21, iters: 114016, time: 0.003) nll: 0.662853 \n",
      "(GPU: 0, epoch: 21, iters: 114816, time: 0.003) nll: 0.755739 \n",
      "(GPU: 0, epoch: 21, iters: 115616, time: 0.003) nll: 0.566327 \n",
      "(GPU: 0, epoch: 21, iters: 116416, time: 0.003) nll: 0.757080 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.003) nll: 0.990171 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.005) nll: 0.995070 \n",
      "(GPU: 0, epoch: 21, iters: 117216, time: 0.005) nll: 0.687490 \n",
      "(GPU: 0, epoch: 21, iters: 118016, time: 0.003) nll: 0.729727 \n",
      "(GPU: 0, epoch: 21, iters: 118816, time: 0.003) nll: 0.808083 \n",
      "(GPU: 0, epoch: 21, iters: 119616, time: 0.003) nll: 0.750158 \n",
      "(GPU: 0, epoch: 21, iters: 120416, time: 0.003) nll: 0.660853 \n",
      "(GPU: 0, epoch: 21, iters: 121216, time: 0.003) nll: 0.774233 \n",
      "(GPU: 0, epoch: 21, iters: 122016, time: 0.003) nll: 0.474542 \n",
      "(GPU: 0, epoch: 21, iters: 122816, time: 0.003) nll: 0.745918 \n",
      "(GPU: 0, epoch: 21, iters: 123616, time: 0.003) nll: 0.648057 \n",
      "(GPU: 0, epoch: 21, iters: 124416, time: 0.003) nll: 0.660994 \n",
      "(GPU: 0, epoch: 21, iters: 125216, time: 0.003) nll: 0.862658 \n",
      "saving the latest model (epoch 21, total_steps 3080000)\n",
      "(GPU: 0, epoch: 21, iters: 126016, time: 0.003) nll: 0.910322 \n",
      "(GPU: 0, epoch: 21, iters: 126816, time: 0.003) nll: 0.722811 \n",
      "(GPU: 0, epoch: 21, iters: 127616, time: 0.003) nll: 0.716260 \n",
      "(GPU: 0, epoch: 21, iters: 128416, time: 0.003) nll: 0.519916 \n",
      "(GPU: 0, epoch: 21, iters: 129216, time: 0.003) nll: 0.770765 \n",
      "(GPU: 0, epoch: 21, iters: 130016, time: 0.003) nll: 0.648504 \n",
      "(GPU: 0, epoch: 21, iters: 130816, time: 0.003) nll: 0.662029 \n",
      "(GPU: 0, epoch: 21, iters: 131616, time: 0.003) nll: 0.938178 \n",
      "(GPU: 0, epoch: 21, iters: 132416, time: 0.003) nll: 0.778505 \n",
      "(GPU: 0, epoch: 21, iters: 133216, time: 0.003) nll: 1.047023 \n",
      "(GPU: 0, epoch: 21, iters: 134016, time: 0.003) nll: 0.783767 \n",
      "(GPU: 0, epoch: 21, iters: 134816, time: 0.003) nll: 0.818167 \n",
      "(GPU: 0, epoch: 21, iters: 135616, time: 0.003) nll: 0.860724 \n",
      "(GPU: 0, epoch: 21, iters: 136416, time: 0.003) nll: 0.793159 \n",
      "(GPU: 0, epoch: 21, iters: 137216, time: 0.003) nll: 0.771619 \n",
      "(GPU: 0, epoch: 21, iters: 138016, time: 0.003) nll: 0.723617 \n",
      "(GPU: 0, epoch: 21, iters: 138816, time: 0.003) nll: 0.716327 \n",
      "(GPU: 0, epoch: 21, iters: 139616, time: 0.003) nll: 0.764532 \n",
      "(GPU: 0, epoch: 21, iters: 140416, time: 0.003) nll: 0.758898 \n",
      "saving the model at the end of epoch 21, iters 3095488\n",
      "([test] GPU: 0, epoch: 21) \n",
      "OrderedDict()\n",
      "[*] End of epoch 21 / 25 \t Time Taken: 523 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000674\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3090/4397 [05:57<02:17,  9.50it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 22, iters: 32, time: 0.002) nll: 0.575454 \n",
      "(GPU: 0, epoch: 22, iters: 32, time: 0.002) nll: 0.661732 \n",
      "(GPU: 0, epoch: 22, iters: 512, time: 0.003) nll: 0.663062 \n",
      "(GPU: 0, epoch: 22, iters: 1312, time: 0.003) nll: 0.810983 \n",
      "(GPU: 0, epoch: 22, iters: 2112, time: 0.003) nll: 0.686023 \n",
      "(GPU: 0, epoch: 22, iters: 2912, time: 0.003) nll: 0.670234 \n",
      "(GPU: 0, epoch: 22, iters: 3712, time: 0.003) nll: 0.786196 \n",
      "(GPU: 0, epoch: 22, iters: 4512, time: 0.003) nll: 0.579072 \n",
      "saving the latest model (epoch 22, total_steps 3100000)\n",
      "(GPU: 0, epoch: 22, iters: 5312, time: 0.003) nll: 0.808270 \n",
      "(GPU: 0, epoch: 22, iters: 6112, time: 0.003) nll: 0.753317 \n",
      "(GPU: 0, epoch: 22, iters: 6912, time: 0.003) nll: 0.762833 \n",
      "(GPU: 0, epoch: 22, iters: 7712, time: 0.003) nll: 0.847753 \n",
      "(GPU: 0, epoch: 22, iters: 8512, time: 0.003) nll: 0.788195 \n",
      "(GPU: 0, epoch: 22, iters: 9312, time: 0.003) nll: 0.968008 \n",
      "(GPU: 0, epoch: 22, iters: 10112, time: 0.003) nll: 0.651066 \n",
      "(GPU: 0, epoch: 22, iters: 10912, time: 0.003) nll: 0.881024 \n",
      "(GPU: 0, epoch: 22, iters: 11712, time: 0.003) nll: 0.727740 \n",
      "(GPU: 0, epoch: 22, iters: 12512, time: 0.003) nll: 0.744246 \n",
      "(GPU: 0, epoch: 22, iters: 13312, time: 0.003) nll: 0.900543 \n",
      "(GPU: 0, epoch: 22, iters: 14112, time: 0.003) nll: 0.827283 \n",
      "(GPU: 0, epoch: 22, iters: 14912, time: 0.003) nll: 0.844749 \n",
      "(GPU: 0, epoch: 22, iters: 15712, time: 0.003) nll: 0.614353 \n",
      "(GPU: 0, epoch: 22, iters: 16512, time: 0.003) nll: 0.780819 \n",
      "(GPU: 0, epoch: 22, iters: 17312, time: 0.003) nll: 0.904872 \n",
      "(GPU: 0, epoch: 22, iters: 18112, time: 0.003) nll: 0.634928 \n",
      "(GPU: 0, epoch: 22, iters: 18912, time: 0.003) nll: 0.890953 \n",
      "(GPU: 0, epoch: 22, iters: 19712, time: 0.003) nll: 1.037030 \n",
      "(GPU: 0, epoch: 22, iters: 20512, time: 0.003) nll: 0.560054 \n",
      "(GPU: 0, epoch: 22, iters: 21312, time: 0.003) nll: 1.156494 \n",
      "(GPU: 0, epoch: 22, iters: 22112, time: 0.003) nll: 1.193056 \n",
      "(GPU: 0, epoch: 22, iters: 22912, time: 0.003) nll: 0.655554 \n",
      "(GPU: 0, epoch: 22, iters: 23712, time: 0.003) nll: 0.654037 \n",
      "(GPU: 0, epoch: 22, iters: 24512, time: 0.003) nll: 1.005677 \n",
      "saving the latest model (epoch 22, total_steps 3120000)\n",
      "(GPU: 0, epoch: 22, iters: 25312, time: 0.003) nll: 0.767171 \n",
      "(GPU: 0, epoch: 22, iters: 26112, time: 0.003) nll: 0.860568 \n",
      "(GPU: 0, epoch: 22, iters: 26912, time: 0.003) nll: 0.829710 \n",
      "(GPU: 0, epoch: 22, iters: 27712, time: 0.003) nll: 0.793242 \n",
      "(GPU: 0, epoch: 22, iters: 28512, time: 0.003) nll: 0.914118 \n",
      "(GPU: 0, epoch: 22, iters: 29312, time: 0.003) nll: 0.781310 \n",
      "(GPU: 0, epoch: 22, iters: 30112, time: 0.003) nll: 0.841200 \n",
      "(GPU: 0, epoch: 22, iters: 30912, time: 0.003) nll: 0.949787 \n",
      "(GPU: 0, epoch: 22, iters: 31712, time: 0.003) nll: 0.912926 \n",
      "(GPU: 0, epoch: 22, iters: 32512, time: 0.003) nll: 0.864826 \n",
      "(GPU: 0, epoch: 22, iters: 33312, time: 0.003) nll: 0.660761 \n",
      "(GPU: 0, epoch: 22, iters: 34112, time: 0.003) nll: 0.745859 \n",
      "(GPU: 0, epoch: 22, iters: 34912, time: 0.003) nll: 0.657389 \n",
      "(GPU: 0, epoch: 22, iters: 35712, time: 0.003) nll: 0.803946 \n",
      "(GPU: 0, epoch: 22, iters: 36512, time: 0.003) nll: 0.818534 \n",
      "(GPU: 0, epoch: 22, iters: 37312, time: 0.003) nll: 0.648810 \n",
      "(GPU: 0, epoch: 22, iters: 38112, time: 0.003) nll: 0.799117 \n",
      "(GPU: 0, epoch: 22, iters: 38912, time: 0.003) nll: 0.793228 \n",
      "(GPU: 0, epoch: 22, iters: 39712, time: 0.003) nll: 0.634172 \n",
      "(GPU: 0, epoch: 22, iters: 40512, time: 0.003) nll: 0.692817 \n",
      "(GPU: 0, epoch: 22, iters: 41312, time: 0.003) nll: 0.815400 \n",
      "(GPU: 0, epoch: 22, iters: 42112, time: 0.003) nll: 0.805833 \n",
      "(GPU: 0, epoch: 22, iters: 42912, time: 0.003) nll: 1.029179 \n",
      "(GPU: 0, epoch: 22, iters: 43712, time: 0.003) nll: 0.914303 \n",
      "(GPU: 0, epoch: 22, iters: 44512, time: 0.003) nll: 0.649734 \n",
      "saving the latest model (epoch 22, total_steps 3140000)\n",
      "(GPU: 0, epoch: 22, iters: 45312, time: 0.003) nll: 0.962972 \n",
      "(GPU: 0, epoch: 22, iters: 46112, time: 0.003) nll: 0.688776 \n",
      "(GPU: 0, epoch: 22, iters: 46912, time: 0.003) nll: 0.842046 \n",
      "(GPU: 0, epoch: 22, iters: 47712, time: 0.003) nll: 0.854057 \n",
      "(GPU: 0, epoch: 22, iters: 48512, time: 0.003) nll: 0.639349 \n",
      "(GPU: 0, epoch: 22, iters: 49312, time: 0.003) nll: 0.787516 \n",
      "(GPU: 0, epoch: 22, iters: 50112, time: 0.003) nll: 0.553267 \n",
      "(GPU: 0, epoch: 22, iters: 50912, time: 0.003) nll: 0.901512 \n",
      "(GPU: 0, epoch: 22, iters: 51712, time: 0.003) nll: 0.753410 \n",
      "(GPU: 0, epoch: 22, iters: 52512, time: 0.003) nll: 0.763166 \n",
      "(GPU: 0, epoch: 22, iters: 53312, time: 0.003) nll: 0.846281 \n",
      "(GPU: 0, epoch: 22, iters: 54112, time: 0.003) nll: 0.694510 \n",
      "(GPU: 0, epoch: 22, iters: 54912, time: 0.003) nll: 0.789254 \n",
      "(GPU: 0, epoch: 22, iters: 55712, time: 0.003) nll: 1.071333 \n",
      "(GPU: 0, epoch: 22, iters: 56512, time: 0.003) nll: 0.483119 \n",
      "(GPU: 0, epoch: 22, iters: 57312, time: 0.003) nll: 0.703803 \n",
      "(GPU: 0, epoch: 22, iters: 58112, time: 0.003) nll: 0.825457 \n",
      "(GPU: 0, epoch: 22, iters: 58912, time: 0.003) nll: 0.844332 \n",
      "(GPU: 0, epoch: 22, iters: 59712, time: 0.003) nll: 0.708605 \n",
      "(GPU: 0, epoch: 22, iters: 60512, time: 0.003) nll: 0.720665 \n",
      "(GPU: 0, epoch: 22, iters: 61312, time: 0.003) nll: 0.819465 \n",
      "(GPU: 0, epoch: 22, iters: 62112, time: 0.003) nll: 0.773107 \n",
      "(GPU: 0, epoch: 22, iters: 62912, time: 0.003) nll: 0.897126 \n",
      "(GPU: 0, epoch: 22, iters: 63712, time: 0.003) nll: 0.604812 \n",
      "(GPU: 0, epoch: 22, iters: 64512, time: 0.003) nll: 0.567886 \n",
      "saving the latest model (epoch 22, total_steps 3160000)\n",
      "(GPU: 0, epoch: 22, iters: 65312, time: 0.003) nll: 1.052579 \n",
      "(GPU: 0, epoch: 22, iters: 66112, time: 0.003) nll: 0.549285 \n",
      "(GPU: 0, epoch: 22, iters: 66912, time: 0.003) nll: 0.889530 \n",
      "(GPU: 0, epoch: 22, iters: 67712, time: 0.003) nll: 0.694272 \n",
      "(GPU: 0, epoch: 22, iters: 68512, time: 0.003) nll: 0.950753 \n",
      "(GPU: 0, epoch: 22, iters: 69312, time: 0.003) nll: 0.840962 \n",
      "(GPU: 0, epoch: 22, iters: 70112, time: 0.003) nll: 0.771116 \n",
      "(GPU: 0, epoch: 22, iters: 70912, time: 0.003) nll: 0.812315 \n",
      "(GPU: 0, epoch: 22, iters: 71712, time: 0.003) nll: 0.862450 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.003) nll: 0.698468 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.005) nll: 0.693329 \n",
      "(GPU: 0, epoch: 22, iters: 72512, time: 0.005) nll: 0.705434 \n",
      "(GPU: 0, epoch: 22, iters: 73312, time: 0.003) nll: 0.998677 \n",
      "(GPU: 0, epoch: 22, iters: 74112, time: 0.003) nll: 0.425576 \n",
      "(GPU: 0, epoch: 22, iters: 74912, time: 0.003) nll: 0.759910 \n",
      "(GPU: 0, epoch: 22, iters: 75712, time: 0.003) nll: 0.908863 \n",
      "(GPU: 0, epoch: 22, iters: 76512, time: 0.003) nll: 0.632390 \n",
      "(GPU: 0, epoch: 22, iters: 77312, time: 0.003) nll: 0.572315 \n",
      "(GPU: 0, epoch: 22, iters: 78112, time: 0.003) nll: 0.953840 \n",
      "(GPU: 0, epoch: 22, iters: 78912, time: 0.003) nll: 0.916056 \n",
      "(GPU: 0, epoch: 22, iters: 79712, time: 0.003) nll: 0.835749 \n",
      "(GPU: 0, epoch: 22, iters: 80512, time: 0.003) nll: 0.865076 \n",
      "(GPU: 0, epoch: 22, iters: 81312, time: 0.003) nll: 0.827210 \n",
      "(GPU: 0, epoch: 22, iters: 82112, time: 0.003) nll: 0.762062 \n",
      "(GPU: 0, epoch: 22, iters: 82912, time: 0.003) nll: 0.836946 \n",
      "(GPU: 0, epoch: 22, iters: 83712, time: 0.003) nll: 0.717194 \n",
      "(GPU: 0, epoch: 22, iters: 84512, time: 0.003) nll: 0.644107 \n",
      "saving the latest model (epoch 22, total_steps 3180000)\n",
      "(GPU: 0, epoch: 22, iters: 85312, time: 0.003) nll: 0.728204 \n",
      "(GPU: 0, epoch: 22, iters: 86112, time: 0.003) nll: 0.792490 \n",
      "(GPU: 0, epoch: 22, iters: 86912, time: 0.003) nll: 0.764286 \n",
      "(GPU: 0, epoch: 22, iters: 87712, time: 0.003) nll: 0.914505 \n",
      "(GPU: 0, epoch: 22, iters: 88512, time: 0.003) nll: 0.584740 \n",
      "(GPU: 0, epoch: 22, iters: 89312, time: 0.003) nll: 0.653454 \n",
      "(GPU: 0, epoch: 22, iters: 90112, time: 0.003) nll: 0.715533 \n",
      "(GPU: 0, epoch: 22, iters: 90912, time: 0.003) nll: 0.701952 \n",
      "(GPU: 0, epoch: 22, iters: 91712, time: 0.003) nll: 0.541411 \n",
      "(GPU: 0, epoch: 22, iters: 92512, time: 0.003) nll: 0.837515 \n",
      "(GPU: 0, epoch: 22, iters: 93312, time: 0.003) nll: 0.925344 \n",
      "(GPU: 0, epoch: 22, iters: 94112, time: 0.003) nll: 0.826438 \n",
      "(GPU: 0, epoch: 22, iters: 94912, time: 0.003) nll: 0.625994 \n",
      "(GPU: 0, epoch: 22, iters: 95712, time: 0.003) nll: 0.815567 \n",
      "(GPU: 0, epoch: 22, iters: 96512, time: 0.003) nll: 0.753307 \n",
      "(GPU: 0, epoch: 22, iters: 97312, time: 0.003) nll: 0.969381 \n",
      "(GPU: 0, epoch: 22, iters: 98112, time: 0.003) nll: 0.935948 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:28<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 22, iters: 98912, time: 0.003) nll: 0.880002 \n",
      "(GPU: 0, epoch: 22, iters: 99712, time: 0.003) nll: 0.574772 \n",
      "(GPU: 0, epoch: 22, iters: 100512, time: 0.003) nll: 0.573032 \n",
      "(GPU: 0, epoch: 22, iters: 101312, time: 0.003) nll: 0.549656 \n",
      "(GPU: 0, epoch: 22, iters: 102112, time: 0.003) nll: 0.659497 \n",
      "(GPU: 0, epoch: 22, iters: 102912, time: 0.003) nll: 0.758055 \n",
      "(GPU: 0, epoch: 22, iters: 103712, time: 0.003) nll: 0.788305 \n",
      "(GPU: 0, epoch: 22, iters: 104512, time: 0.003) nll: 0.643401 \n",
      "saving the latest model (epoch 22, total_steps 3200000)\n",
      "(GPU: 0, epoch: 22, iters: 105312, time: 0.003) nll: 0.675853 \n",
      "(GPU: 0, epoch: 22, iters: 106112, time: 0.003) nll: 0.796989 \n",
      "(GPU: 0, epoch: 22, iters: 106912, time: 0.003) nll: 0.930476 \n",
      "(GPU: 0, epoch: 22, iters: 107712, time: 0.003) nll: 0.731482 \n",
      "(GPU: 0, epoch: 22, iters: 108512, time: 0.003) nll: 0.771504 \n",
      "(GPU: 0, epoch: 22, iters: 109312, time: 0.003) nll: 0.880079 \n",
      "(GPU: 0, epoch: 22, iters: 110112, time: 0.003) nll: 0.734398 \n",
      "(GPU: 0, epoch: 22, iters: 110912, time: 0.003) nll: 0.847414 \n",
      "(GPU: 0, epoch: 22, iters: 111712, time: 0.003) nll: 0.939220 \n",
      "(GPU: 0, epoch: 22, iters: 112512, time: 0.003) nll: 0.846656 \n",
      "(GPU: 0, epoch: 22, iters: 113312, time: 0.003) nll: 1.031142 \n",
      "(GPU: 0, epoch: 22, iters: 114112, time: 0.003) nll: 0.899434 \n",
      "(GPU: 0, epoch: 22, iters: 114912, time: 0.003) nll: 0.690723 \n",
      "(GPU: 0, epoch: 22, iters: 115712, time: 0.003) nll: 0.708354 \n",
      "(GPU: 0, epoch: 22, iters: 116512, time: 0.003) nll: 0.774449 \n",
      "(GPU: 0, epoch: 22, iters: 117312, time: 0.003) nll: 0.664891 \n",
      "(GPU: 0, epoch: 22, iters: 118112, time: 0.003) nll: 0.817591 \n",
      "(GPU: 0, epoch: 22, iters: 118912, time: 0.003) nll: 0.932341 \n",
      "(GPU: 0, epoch: 22, iters: 119712, time: 0.003) nll: 0.827081 \n",
      "(GPU: 0, epoch: 22, iters: 120512, time: 0.003) nll: 0.859914 \n",
      "(GPU: 0, epoch: 22, iters: 121312, time: 0.003) nll: 0.741297 \n",
      "(GPU: 0, epoch: 22, iters: 122112, time: 0.003) nll: 0.988285 \n",
      "(GPU: 0, epoch: 22, iters: 122912, time: 0.003) nll: 0.782417 \n",
      "(GPU: 0, epoch: 22, iters: 123712, time: 0.003) nll: 0.582033 \n",
      "(GPU: 0, epoch: 22, iters: 124512, time: 0.003) nll: 0.762464 \n",
      "saving the latest model (epoch 22, total_steps 3220000)\n",
      "(GPU: 0, epoch: 22, iters: 125312, time: 0.003) nll: 0.631270 \n",
      "(GPU: 0, epoch: 22, iters: 126112, time: 0.003) nll: 0.772452 \n",
      "(GPU: 0, epoch: 22, iters: 126912, time: 0.003) nll: 0.698351 \n",
      "(GPU: 0, epoch: 22, iters: 127712, time: 0.003) nll: 0.620010 \n",
      "(GPU: 0, epoch: 22, iters: 128512, time: 0.003) nll: 0.911531 \n",
      "(GPU: 0, epoch: 22, iters: 129312, time: 0.003) nll: 0.897808 \n",
      "(GPU: 0, epoch: 22, iters: 130112, time: 0.003) nll: 0.754068 \n",
      "(GPU: 0, epoch: 22, iters: 130912, time: 0.003) nll: 0.747704 \n",
      "(GPU: 0, epoch: 22, iters: 131712, time: 0.003) nll: 0.694013 \n",
      "(GPU: 0, epoch: 22, iters: 132512, time: 0.003) nll: 0.723119 \n",
      "(GPU: 0, epoch: 22, iters: 133312, time: 0.003) nll: 0.899397 \n",
      "(GPU: 0, epoch: 22, iters: 134112, time: 0.003) nll: 0.727509 \n",
      "(GPU: 0, epoch: 22, iters: 134912, time: 0.003) nll: 0.646809 \n",
      "(GPU: 0, epoch: 22, iters: 135712, time: 0.003) nll: 0.686800 \n",
      "(GPU: 0, epoch: 22, iters: 136512, time: 0.003) nll: 0.934739 \n",
      "(GPU: 0, epoch: 22, iters: 137312, time: 0.003) nll: 0.802517 \n",
      "(GPU: 0, epoch: 22, iters: 138112, time: 0.003) nll: 0.591355 \n",
      "(GPU: 0, epoch: 22, iters: 138912, time: 0.003) nll: 0.851337 \n",
      "(GPU: 0, epoch: 22, iters: 139712, time: 0.003) nll: 0.800551 \n",
      "(GPU: 0, epoch: 22, iters: 140512, time: 0.003) nll: 0.963983 \n",
      "[*] End of epoch 22 / 25 \t Time Taken: 509 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000659\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3093/4397 [05:59<02:16,  9.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 23, iters: 32, time: 0.002) nll: 0.856792 \n",
      "(GPU: 0, epoch: 23, iters: 32, time: 0.002) nll: 0.715801 \n",
      "(GPU: 0, epoch: 23, iters: 608, time: 0.003) nll: 1.010626 \n",
      "(GPU: 0, epoch: 23, iters: 1408, time: 0.003) nll: 0.716198 \n",
      "(GPU: 0, epoch: 23, iters: 2208, time: 0.003) nll: 0.760230 \n",
      "(GPU: 0, epoch: 23, iters: 3008, time: 0.003) nll: 0.850081 \n",
      "(GPU: 0, epoch: 23, iters: 3808, time: 0.003) nll: 0.743394 \n",
      "saving the latest model (epoch 23, total_steps 3240000)\n",
      "(GPU: 0, epoch: 23, iters: 4608, time: 0.003) nll: 0.852099 \n",
      "(GPU: 0, epoch: 23, iters: 5408, time: 0.003) nll: 0.916909 \n",
      "(GPU: 0, epoch: 23, iters: 6208, time: 0.003) nll: 0.699930 \n",
      "(GPU: 0, epoch: 23, iters: 7008, time: 0.003) nll: 0.678744 \n",
      "(GPU: 0, epoch: 23, iters: 7808, time: 0.003) nll: 0.703461 \n",
      "(GPU: 0, epoch: 23, iters: 8608, time: 0.003) nll: 0.734771 \n",
      "(GPU: 0, epoch: 23, iters: 9408, time: 0.003) nll: 0.548036 \n",
      "(GPU: 0, epoch: 23, iters: 10208, time: 0.003) nll: 0.733429 \n",
      "(GPU: 0, epoch: 23, iters: 11008, time: 0.003) nll: 0.888515 \n",
      "(GPU: 0, epoch: 23, iters: 11808, time: 0.003) nll: 0.618407 \n",
      "(GPU: 0, epoch: 23, iters: 12608, time: 0.003) nll: 0.604005 \n",
      "(GPU: 0, epoch: 23, iters: 13408, time: 0.003) nll: 0.733650 \n",
      "(GPU: 0, epoch: 23, iters: 14208, time: 0.003) nll: 0.790395 \n",
      "(GPU: 0, epoch: 23, iters: 15008, time: 0.003) nll: 0.752609 \n",
      "(GPU: 0, epoch: 23, iters: 15808, time: 0.003) nll: 0.687538 \n",
      "(GPU: 0, epoch: 23, iters: 16608, time: 0.003) nll: 0.965686 \n",
      "(GPU: 0, epoch: 23, iters: 17408, time: 0.003) nll: 0.863901 \n",
      "(GPU: 0, epoch: 23, iters: 18208, time: 0.003) nll: 0.978872 \n",
      "(GPU: 0, epoch: 23, iters: 19008, time: 0.003) nll: 0.749009 \n",
      "(GPU: 0, epoch: 23, iters: 19808, time: 0.003) nll: 0.823612 \n",
      "(GPU: 0, epoch: 23, iters: 20608, time: 0.003) nll: 0.802494 \n",
      "(GPU: 0, epoch: 23, iters: 21408, time: 0.003) nll: 0.687672 \n",
      "(GPU: 0, epoch: 23, iters: 22208, time: 0.003) nll: 0.791613 \n",
      "(GPU: 0, epoch: 23, iters: 23008, time: 0.003) nll: 0.772283 \n",
      "(GPU: 0, epoch: 23, iters: 23808, time: 0.003) nll: 1.009201 \n",
      "saving the latest model (epoch 23, total_steps 3260000)\n",
      "(GPU: 0, epoch: 23, iters: 24608, time: 0.003) nll: 0.765746 \n",
      "(GPU: 0, epoch: 23, iters: 25408, time: 0.003) nll: 0.907620 \n",
      "(GPU: 0, epoch: 23, iters: 26208, time: 0.003) nll: 0.821756 \n",
      "(GPU: 0, epoch: 23, iters: 27008, time: 0.003) nll: 1.004711 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.003) nll: 0.764343 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.005) nll: 0.760972 \n",
      "(GPU: 0, epoch: 23, iters: 27808, time: 0.005) nll: 0.921448 \n",
      "(GPU: 0, epoch: 23, iters: 28608, time: 0.003) nll: 0.653390 \n",
      "(GPU: 0, epoch: 23, iters: 29408, time: 0.003) nll: 0.875646 \n",
      "(GPU: 0, epoch: 23, iters: 30208, time: 0.003) nll: 0.698349 \n",
      "(GPU: 0, epoch: 23, iters: 31008, time: 0.003) nll: 0.728640 \n",
      "(GPU: 0, epoch: 23, iters: 31808, time: 0.003) nll: 0.778838 \n",
      "(GPU: 0, epoch: 23, iters: 32608, time: 0.003) nll: 1.035426 \n",
      "(GPU: 0, epoch: 23, iters: 33408, time: 0.003) nll: 0.809867 \n",
      "(GPU: 0, epoch: 23, iters: 34208, time: 0.003) nll: 0.802436 \n",
      "(GPU: 0, epoch: 23, iters: 35008, time: 0.003) nll: 1.315734 \n",
      "(GPU: 0, epoch: 23, iters: 35808, time: 0.003) nll: 0.886307 \n",
      "(GPU: 0, epoch: 23, iters: 36608, time: 0.003) nll: 0.594028 \n",
      "(GPU: 0, epoch: 23, iters: 37408, time: 0.003) nll: 0.760463 \n",
      "(GPU: 0, epoch: 23, iters: 38208, time: 0.003) nll: 0.634973 \n",
      "(GPU: 0, epoch: 23, iters: 39008, time: 0.003) nll: 0.587301 \n",
      "(GPU: 0, epoch: 23, iters: 39808, time: 0.003) nll: 0.688094 \n",
      "(GPU: 0, epoch: 23, iters: 40608, time: 0.003) nll: 0.692953 \n",
      "(GPU: 0, epoch: 23, iters: 41408, time: 0.003) nll: 0.851637 \n",
      "(GPU: 0, epoch: 23, iters: 42208, time: 0.003) nll: 0.792016 \n",
      "(GPU: 0, epoch: 23, iters: 43008, time: 0.003) nll: 0.732059 \n",
      "(GPU: 0, epoch: 23, iters: 43808, time: 0.003) nll: 1.026242 \n",
      "saving the latest model (epoch 23, total_steps 3280000)\n",
      "(GPU: 0, epoch: 23, iters: 44608, time: 0.003) nll: 0.732460 \n",
      "(GPU: 0, epoch: 23, iters: 45408, time: 0.003) nll: 0.680216 \n",
      "(GPU: 0, epoch: 23, iters: 46208, time: 0.003) nll: 0.673431 \n",
      "(GPU: 0, epoch: 23, iters: 47008, time: 0.003) nll: 0.797996 \n",
      "(GPU: 0, epoch: 23, iters: 47808, time: 0.003) nll: 0.749381 \n",
      "(GPU: 0, epoch: 23, iters: 48608, time: 0.003) nll: 0.819475 \n",
      "(GPU: 0, epoch: 23, iters: 49408, time: 0.003) nll: 0.698195 \n",
      "(GPU: 0, epoch: 23, iters: 50208, time: 0.003) nll: 0.889350 \n",
      "(GPU: 0, epoch: 23, iters: 51008, time: 0.003) nll: 0.904892 \n",
      "(GPU: 0, epoch: 23, iters: 51808, time: 0.003) nll: 0.780262 \n",
      "(GPU: 0, epoch: 23, iters: 52608, time: 0.003) nll: 0.654863 \n",
      "(GPU: 0, epoch: 23, iters: 53408, time: 0.003) nll: 0.798324 \n",
      "(GPU: 0, epoch: 23, iters: 54208, time: 0.003) nll: 0.678213 \n",
      "(GPU: 0, epoch: 23, iters: 55008, time: 0.003) nll: 0.722742 \n",
      "(GPU: 0, epoch: 23, iters: 55808, time: 0.003) nll: 0.619403 \n",
      "(GPU: 0, epoch: 23, iters: 56608, time: 0.003) nll: 0.644978 \n",
      "(GPU: 0, epoch: 23, iters: 57408, time: 0.003) nll: 0.912999 \n",
      "(GPU: 0, epoch: 23, iters: 58208, time: 0.003) nll: 0.726110 \n",
      "(GPU: 0, epoch: 23, iters: 59008, time: 0.003) nll: 0.626257 \n",
      "(GPU: 0, epoch: 23, iters: 59808, time: 0.003) nll: 0.892494 \n",
      "(GPU: 0, epoch: 23, iters: 60608, time: 0.003) nll: 0.902222 \n",
      "(GPU: 0, epoch: 23, iters: 61408, time: 0.003) nll: 0.622835 \n",
      "(GPU: 0, epoch: 23, iters: 62208, time: 0.003) nll: 0.881945 \n",
      "(GPU: 0, epoch: 23, iters: 63008, time: 0.003) nll: 0.690701 \n",
      "(GPU: 0, epoch: 23, iters: 63808, time: 0.003) nll: 0.932234 \n",
      "saving the latest model (epoch 23, total_steps 3300000)\n",
      "(GPU: 0, epoch: 23, iters: 64608, time: 0.003) nll: 0.886329 \n",
      "(GPU: 0, epoch: 23, iters: 65408, time: 0.003) nll: 0.555836 \n",
      "(GPU: 0, epoch: 23, iters: 66208, time: 0.003) nll: 0.920372 \n",
      "(GPU: 0, epoch: 23, iters: 67008, time: 0.003) nll: 0.722561 \n",
      "(GPU: 0, epoch: 23, iters: 67808, time: 0.003) nll: 0.618578 \n",
      "(GPU: 0, epoch: 23, iters: 68608, time: 0.003) nll: 0.822909 \n",
      "(GPU: 0, epoch: 23, iters: 69408, time: 0.003) nll: 0.734239 \n",
      "(GPU: 0, epoch: 23, iters: 70208, time: 0.003) nll: 0.780210 \n",
      "(GPU: 0, epoch: 23, iters: 71008, time: 0.003) nll: 0.713116 \n",
      "(GPU: 0, epoch: 23, iters: 71808, time: 0.003) nll: 1.177935 \n",
      "(GPU: 0, epoch: 23, iters: 72608, time: 0.003) nll: 0.729913 \n",
      "(GPU: 0, epoch: 23, iters: 73408, time: 0.003) nll: 0.838700 \n",
      "(GPU: 0, epoch: 23, iters: 74208, time: 0.003) nll: 0.789185 \n",
      "(GPU: 0, epoch: 23, iters: 75008, time: 0.003) nll: 0.605947 \n",
      "(GPU: 0, epoch: 23, iters: 75808, time: 0.003) nll: 0.750760 \n",
      "(GPU: 0, epoch: 23, iters: 76608, time: 0.003) nll: 0.887715 \n",
      "(GPU: 0, epoch: 23, iters: 77408, time: 0.003) nll: 0.633589 \n",
      "(GPU: 0, epoch: 23, iters: 78208, time: 0.003) nll: 0.761401 \n",
      "(GPU: 0, epoch: 23, iters: 79008, time: 0.003) nll: 1.020858 \n",
      "(GPU: 0, epoch: 23, iters: 79808, time: 0.003) nll: 0.845387 \n",
      "(GPU: 0, epoch: 23, iters: 80608, time: 0.003) nll: 0.947250 \n",
      "(GPU: 0, epoch: 23, iters: 81408, time: 0.003) nll: 0.735368 \n",
      "(GPU: 0, epoch: 23, iters: 82208, time: 0.003) nll: 0.750949 \n",
      "(GPU: 0, epoch: 23, iters: 83008, time: 0.003) nll: 0.669453 \n",
      "(GPU: 0, epoch: 23, iters: 83808, time: 0.003) nll: 1.087455 \n",
      "saving the latest model (epoch 23, total_steps 3320000)\n",
      "(GPU: 0, epoch: 23, iters: 84608, time: 0.003) nll: 0.753051 \n",
      "(GPU: 0, epoch: 23, iters: 85408, time: 0.003) nll: 0.717518 \n",
      "(GPU: 0, epoch: 23, iters: 86208, time: 0.003) nll: 0.689409 \n",
      "(GPU: 0, epoch: 23, iters: 87008, time: 0.003) nll: 0.837667 \n",
      "(GPU: 0, epoch: 23, iters: 87808, time: 0.003) nll: 0.883521 \n",
      "(GPU: 0, epoch: 23, iters: 88608, time: 0.003) nll: 0.858863 \n",
      "(GPU: 0, epoch: 23, iters: 89408, time: 0.003) nll: 0.708005 \n",
      "(GPU: 0, epoch: 23, iters: 90208, time: 0.003) nll: 0.713656 \n",
      "(GPU: 0, epoch: 23, iters: 91008, time: 0.003) nll: 0.858637 \n",
      "(GPU: 0, epoch: 23, iters: 91808, time: 0.003) nll: 0.868277 \n",
      "(GPU: 0, epoch: 23, iters: 92608, time: 0.003) nll: 0.865487 \n",
      "(GPU: 0, epoch: 23, iters: 93408, time: 0.003) nll: 0.615679 \n",
      "(GPU: 0, epoch: 23, iters: 94208, time: 0.003) nll: 0.806244 \n",
      "(GPU: 0, epoch: 23, iters: 95008, time: 0.003) nll: 0.905580 \n",
      "(GPU: 0, epoch: 23, iters: 95808, time: 0.003) nll: 0.712494 \n",
      "(GPU: 0, epoch: 23, iters: 96608, time: 0.003) nll: 0.697201 \n",
      "(GPU: 0, epoch: 23, iters: 97408, time: 0.003) nll: 0.846318 \n",
      "(GPU: 0, epoch: 23, iters: 98208, time: 0.003) nll: 0.819440 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 23, iters: 99008, time: 0.003) nll: 0.670957 \n",
      "(GPU: 0, epoch: 23, iters: 99808, time: 0.003) nll: 0.929846 \n",
      "(GPU: 0, epoch: 23, iters: 100608, time: 0.003) nll: 0.892268 \n",
      "(GPU: 0, epoch: 23, iters: 101408, time: 0.003) nll: 0.666785 \n",
      "(GPU: 0, epoch: 23, iters: 102208, time: 0.003) nll: 0.880718 \n",
      "(GPU: 0, epoch: 23, iters: 103008, time: 0.003) nll: 0.802807 \n",
      "(GPU: 0, epoch: 23, iters: 103808, time: 0.003) nll: 0.826135 \n",
      "saving the latest model (epoch 23, total_steps 3340000)\n",
      "(GPU: 0, epoch: 23, iters: 104608, time: 0.003) nll: 0.637673 \n",
      "(GPU: 0, epoch: 23, iters: 105408, time: 0.003) nll: 0.777949 \n",
      "(GPU: 0, epoch: 23, iters: 106208, time: 0.003) nll: 0.859275 \n",
      "(GPU: 0, epoch: 23, iters: 107008, time: 0.003) nll: 0.668008 \n",
      "(GPU: 0, epoch: 23, iters: 107808, time: 0.003) nll: 0.724170 \n",
      "(GPU: 0, epoch: 23, iters: 108608, time: 0.003) nll: 0.695334 \n",
      "(GPU: 0, epoch: 23, iters: 109408, time: 0.003) nll: 0.778217 \n",
      "(GPU: 0, epoch: 23, iters: 110208, time: 0.003) nll: 0.768751 \n",
      "(GPU: 0, epoch: 23, iters: 111008, time: 0.003) nll: 0.926468 \n",
      "(GPU: 0, epoch: 23, iters: 111808, time: 0.003) nll: 0.614960 \n",
      "(GPU: 0, epoch: 23, iters: 112608, time: 0.003) nll: 0.542445 \n",
      "(GPU: 0, epoch: 23, iters: 113408, time: 0.003) nll: 0.863791 \n",
      "(GPU: 0, epoch: 23, iters: 114208, time: 0.003) nll: 0.688991 \n",
      "(GPU: 0, epoch: 23, iters: 115008, time: 0.003) nll: 0.660765 \n",
      "(GPU: 0, epoch: 23, iters: 115808, time: 0.003) nll: 0.820067 \n",
      "(GPU: 0, epoch: 23, iters: 116608, time: 0.003) nll: 0.761824 \n",
      "(GPU: 0, epoch: 23, iters: 117408, time: 0.003) nll: 0.889353 \n",
      "(GPU: 0, epoch: 23, iters: 118208, time: 0.003) nll: 0.671372 \n",
      "(GPU: 0, epoch: 23, iters: 119008, time: 0.003) nll: 0.782447 \n",
      "(GPU: 0, epoch: 23, iters: 119808, time: 0.003) nll: 0.515832 \n",
      "(GPU: 0, epoch: 23, iters: 120608, time: 0.003) nll: 0.718930 \n",
      "(GPU: 0, epoch: 23, iters: 121408, time: 0.003) nll: 0.827529 \n",
      "(GPU: 0, epoch: 23, iters: 122208, time: 0.003) nll: 0.666794 \n",
      "(GPU: 0, epoch: 23, iters: 123008, time: 0.003) nll: 0.758647 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.003) nll: 0.882682 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.005) nll: 0.893226 \n",
      "(GPU: 0, epoch: 23, iters: 123808, time: 0.005) nll: 1.370296 \n",
      "saving the latest model (epoch 23, total_steps 3360000)\n",
      "(GPU: 0, epoch: 23, iters: 124608, time: 0.003) nll: 0.783770 \n",
      "(GPU: 0, epoch: 23, iters: 125408, time: 0.003) nll: 0.835911 \n",
      "(GPU: 0, epoch: 23, iters: 126208, time: 0.003) nll: 0.848719 \n",
      "(GPU: 0, epoch: 23, iters: 127008, time: 0.003) nll: 0.632897 \n",
      "(GPU: 0, epoch: 23, iters: 127808, time: 0.003) nll: 0.725427 \n",
      "(GPU: 0, epoch: 23, iters: 128608, time: 0.003) nll: 0.601950 \n",
      "(GPU: 0, epoch: 23, iters: 129408, time: 0.003) nll: 0.763695 \n",
      "(GPU: 0, epoch: 23, iters: 130208, time: 0.003) nll: 0.919588 \n",
      "(GPU: 0, epoch: 23, iters: 131008, time: 0.003) nll: 0.817898 \n",
      "(GPU: 0, epoch: 23, iters: 131808, time: 0.003) nll: 0.817100 \n",
      "(GPU: 0, epoch: 23, iters: 132608, time: 0.003) nll: 1.057095 \n",
      "(GPU: 0, epoch: 23, iters: 133408, time: 0.003) nll: 0.739705 \n",
      "(GPU: 0, epoch: 23, iters: 134208, time: 0.003) nll: 0.899777 \n",
      "(GPU: 0, epoch: 23, iters: 135008, time: 0.003) nll: 0.675294 \n",
      "(GPU: 0, epoch: 23, iters: 135808, time: 0.003) nll: 0.920394 \n",
      "(GPU: 0, epoch: 23, iters: 136608, time: 0.003) nll: 0.721644 \n",
      "(GPU: 0, epoch: 23, iters: 137408, time: 0.003) nll: 0.819829 \n",
      "(GPU: 0, epoch: 23, iters: 138208, time: 0.003) nll: 0.815808 \n",
      "(GPU: 0, epoch: 23, iters: 139008, time: 0.003) nll: 0.996472 \n",
      "(GPU: 0, epoch: 23, iters: 139808, time: 0.003) nll: 0.924514 \n",
      "(GPU: 0, epoch: 23, iters: 140608, time: 0.003) nll: 0.825131 \n",
      "[*] End of epoch 23 / 25 \t Time Taken: 510 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000645\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3096/4397 [06:00<02:17,  9.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 24, iters: 32, time: 0.002) nll: 0.758592 \n",
      "(GPU: 0, epoch: 24, iters: 32, time: 0.002) nll: 0.953290 \n",
      "(GPU: 0, epoch: 24, iters: 704, time: 0.003) nll: 0.885912 \n",
      "(GPU: 0, epoch: 24, iters: 1504, time: 0.003) nll: 0.674136 \n",
      "(GPU: 0, epoch: 24, iters: 2304, time: 0.003) nll: 0.840498 \n",
      "(GPU: 0, epoch: 24, iters: 3104, time: 0.003) nll: 0.665735 \n",
      "saving the latest model (epoch 24, total_steps 3380000)\n",
      "(GPU: 0, epoch: 24, iters: 3904, time: 0.003) nll: 0.939568 \n",
      "(GPU: 0, epoch: 24, iters: 4704, time: 0.003) nll: 0.727192 \n",
      "(GPU: 0, epoch: 24, iters: 5504, time: 0.003) nll: 0.831565 \n",
      "(GPU: 0, epoch: 24, iters: 6304, time: 0.003) nll: 0.875990 \n",
      "(GPU: 0, epoch: 24, iters: 7104, time: 0.003) nll: 0.745742 \n",
      "(GPU: 0, epoch: 24, iters: 7904, time: 0.003) nll: 0.604997 \n",
      "(GPU: 0, epoch: 24, iters: 8704, time: 0.003) nll: 0.551044 \n",
      "(GPU: 0, epoch: 24, iters: 9504, time: 0.003) nll: 0.865482 \n",
      "(GPU: 0, epoch: 24, iters: 10304, time: 0.003) nll: 0.891863 \n",
      "(GPU: 0, epoch: 24, iters: 11104, time: 0.003) nll: 1.163339 \n",
      "(GPU: 0, epoch: 24, iters: 11904, time: 0.003) nll: 0.840752 \n",
      "(GPU: 0, epoch: 24, iters: 12704, time: 0.003) nll: 0.579175 \n",
      "(GPU: 0, epoch: 24, iters: 13504, time: 0.003) nll: 0.660672 \n",
      "(GPU: 0, epoch: 24, iters: 14304, time: 0.003) nll: 0.625849 \n",
      "(GPU: 0, epoch: 24, iters: 15104, time: 0.003) nll: 0.760134 \n",
      "(GPU: 0, epoch: 24, iters: 15904, time: 0.003) nll: 0.638395 \n",
      "(GPU: 0, epoch: 24, iters: 16704, time: 0.003) nll: 0.636515 \n",
      "(GPU: 0, epoch: 24, iters: 17504, time: 0.003) nll: 0.931424 \n",
      "(GPU: 0, epoch: 24, iters: 18304, time: 0.003) nll: 0.843789 \n",
      "(GPU: 0, epoch: 24, iters: 19104, time: 0.003) nll: 0.686510 \n",
      "(GPU: 0, epoch: 24, iters: 19904, time: 0.003) nll: 0.788222 \n",
      "(GPU: 0, epoch: 24, iters: 20704, time: 0.003) nll: 0.802766 \n",
      "(GPU: 0, epoch: 24, iters: 21504, time: 0.003) nll: 0.785295 \n",
      "(GPU: 0, epoch: 24, iters: 22304, time: 0.003) nll: 0.851313 \n",
      "(GPU: 0, epoch: 24, iters: 23104, time: 0.003) nll: 0.812865 \n",
      "saving the latest model (epoch 24, total_steps 3400000)\n",
      "(GPU: 0, epoch: 24, iters: 23904, time: 0.003) nll: 0.676741 \n",
      "(GPU: 0, epoch: 24, iters: 24704, time: 0.003) nll: 0.852739 \n",
      "(GPU: 0, epoch: 24, iters: 25504, time: 0.003) nll: 0.688987 \n",
      "(GPU: 0, epoch: 24, iters: 26304, time: 0.003) nll: 0.885295 \n",
      "(GPU: 0, epoch: 24, iters: 27104, time: 0.003) nll: 0.869175 \n",
      "(GPU: 0, epoch: 24, iters: 27904, time: 0.003) nll: 0.620415 \n",
      "(GPU: 0, epoch: 24, iters: 28704, time: 0.003) nll: 0.833950 \n",
      "(GPU: 0, epoch: 24, iters: 29504, time: 0.003) nll: 0.942760 \n",
      "(GPU: 0, epoch: 24, iters: 30304, time: 0.003) nll: 0.563576 \n",
      "(GPU: 0, epoch: 24, iters: 31104, time: 0.003) nll: 0.703870 \n",
      "(GPU: 0, epoch: 24, iters: 31904, time: 0.003) nll: 0.761939 \n",
      "(GPU: 0, epoch: 24, iters: 32704, time: 0.003) nll: 0.760462 \n",
      "(GPU: 0, epoch: 24, iters: 33504, time: 0.003) nll: 0.907939 \n",
      "(GPU: 0, epoch: 24, iters: 34304, time: 0.003) nll: 0.680894 \n",
      "(GPU: 0, epoch: 24, iters: 35104, time: 0.003) nll: 0.640633 \n",
      "(GPU: 0, epoch: 24, iters: 35904, time: 0.003) nll: 0.776302 \n",
      "(GPU: 0, epoch: 24, iters: 36704, time: 0.003) nll: 0.899063 \n",
      "(GPU: 0, epoch: 24, iters: 37504, time: 0.003) nll: 0.932351 \n",
      "(GPU: 0, epoch: 24, iters: 38304, time: 0.003) nll: 0.879501 \n",
      "(GPU: 0, epoch: 24, iters: 39104, time: 0.003) nll: 0.739621 \n",
      "(GPU: 0, epoch: 24, iters: 39904, time: 0.003) nll: 0.850114 \n",
      "(GPU: 0, epoch: 24, iters: 40704, time: 0.003) nll: 0.935524 \n",
      "(GPU: 0, epoch: 24, iters: 41504, time: 0.003) nll: 0.727475 \n",
      "(GPU: 0, epoch: 24, iters: 42304, time: 0.003) nll: 0.736029 \n",
      "(GPU: 0, epoch: 24, iters: 43104, time: 0.003) nll: 0.966558 \n",
      "saving the latest model (epoch 24, total_steps 3420000)\n",
      "(GPU: 0, epoch: 24, iters: 43904, time: 0.003) nll: 0.921164 \n",
      "(GPU: 0, epoch: 24, iters: 44704, time: 0.003) nll: 1.046416 \n",
      "(GPU: 0, epoch: 24, iters: 45504, time: 0.003) nll: 0.726203 \n",
      "(GPU: 0, epoch: 24, iters: 46304, time: 0.003) nll: 0.638066 \n",
      "(GPU: 0, epoch: 24, iters: 47104, time: 0.003) nll: 1.058810 \n",
      "(GPU: 0, epoch: 24, iters: 47904, time: 0.003) nll: 0.684980 \n",
      "(GPU: 0, epoch: 24, iters: 48704, time: 0.003) nll: 0.876104 \n",
      "(GPU: 0, epoch: 24, iters: 49504, time: 0.003) nll: 0.728704 \n",
      "(GPU: 0, epoch: 24, iters: 50304, time: 0.003) nll: 0.886167 \n",
      "(GPU: 0, epoch: 24, iters: 51104, time: 0.003) nll: 0.505864 \n",
      "(GPU: 0, epoch: 24, iters: 51904, time: 0.003) nll: 0.693013 \n",
      "(GPU: 0, epoch: 24, iters: 52704, time: 0.003) nll: 0.556069 \n",
      "(GPU: 0, epoch: 24, iters: 53504, time: 0.003) nll: 0.828507 \n",
      "(GPU: 0, epoch: 24, iters: 54304, time: 0.003) nll: 1.042345 \n",
      "(GPU: 0, epoch: 24, iters: 55104, time: 0.003) nll: 0.449810 \n",
      "(GPU: 0, epoch: 24, iters: 55904, time: 0.003) nll: 0.881341 \n",
      "(GPU: 0, epoch: 24, iters: 56704, time: 0.003) nll: 0.782036 \n",
      "(GPU: 0, epoch: 24, iters: 57504, time: 0.003) nll: 0.845064 \n",
      "(GPU: 0, epoch: 24, iters: 58304, time: 0.003) nll: 0.725594 \n",
      "(GPU: 0, epoch: 24, iters: 59104, time: 0.003) nll: 0.788757 \n",
      "(GPU: 0, epoch: 24, iters: 59904, time: 0.003) nll: 0.931778 \n",
      "(GPU: 0, epoch: 24, iters: 60704, time: 0.003) nll: 0.800257 \n",
      "(GPU: 0, epoch: 24, iters: 61504, time: 0.003) nll: 0.640462 \n",
      "(GPU: 0, epoch: 24, iters: 62304, time: 0.003) nll: 0.720186 \n",
      "(GPU: 0, epoch: 24, iters: 63104, time: 0.003) nll: 1.077435 \n",
      "saving the latest model (epoch 24, total_steps 3440000)\n",
      "(GPU: 0, epoch: 24, iters: 63904, time: 0.003) nll: 1.100453 \n",
      "(GPU: 0, epoch: 24, iters: 64704, time: 0.003) nll: 0.711806 \n",
      "(GPU: 0, epoch: 24, iters: 65504, time: 0.003) nll: 0.782817 \n",
      "(GPU: 0, epoch: 24, iters: 66304, time: 0.003) nll: 0.715095 \n",
      "(GPU: 0, epoch: 24, iters: 67104, time: 0.003) nll: 0.893136 \n",
      "(GPU: 0, epoch: 24, iters: 67904, time: 0.003) nll: 1.074660 \n",
      "(GPU: 0, epoch: 24, iters: 68704, time: 0.003) nll: 0.662634 \n",
      "(GPU: 0, epoch: 24, iters: 69504, time: 0.003) nll: 0.622388 \n",
      "(GPU: 0, epoch: 24, iters: 70304, time: 0.003) nll: 0.697854 \n",
      "(GPU: 0, epoch: 24, iters: 71104, time: 0.003) nll: 0.669046 \n",
      "(GPU: 0, epoch: 24, iters: 71904, time: 0.003) nll: 0.796081 \n",
      "(GPU: 0, epoch: 24, iters: 72704, time: 0.003) nll: 0.769349 \n",
      "(GPU: 0, epoch: 24, iters: 73504, time: 0.003) nll: 0.761558 \n",
      "(GPU: 0, epoch: 24, iters: 74304, time: 0.003) nll: 0.748970 \n",
      "(GPU: 0, epoch: 24, iters: 75104, time: 0.003) nll: 0.772791 \n",
      "(GPU: 0, epoch: 24, iters: 75904, time: 0.003) nll: 0.685940 \n",
      "(GPU: 0, epoch: 24, iters: 76704, time: 0.003) nll: 1.235108 \n",
      "(GPU: 0, epoch: 24, iters: 77504, time: 0.003) nll: 0.748946 \n",
      "(GPU: 0, epoch: 24, iters: 78304, time: 0.003) nll: 0.718660 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.003) nll: 0.808931 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.005) nll: 0.794576 \n",
      "(GPU: 0, epoch: 24, iters: 79104, time: 0.005) nll: 0.748377 \n",
      "(GPU: 0, epoch: 24, iters: 79904, time: 0.003) nll: 0.877791 \n",
      "(GPU: 0, epoch: 24, iters: 80704, time: 0.003) nll: 0.881753 \n",
      "(GPU: 0, epoch: 24, iters: 81504, time: 0.003) nll: 0.608852 \n",
      "(GPU: 0, epoch: 24, iters: 82304, time: 0.003) nll: 0.697932 \n",
      "(GPU: 0, epoch: 24, iters: 83104, time: 0.003) nll: 0.799169 \n",
      "saving the latest model (epoch 24, total_steps 3460000)\n",
      "(GPU: 0, epoch: 24, iters: 83904, time: 0.003) nll: 0.864378 \n",
      "(GPU: 0, epoch: 24, iters: 84704, time: 0.003) nll: 0.962805 \n",
      "(GPU: 0, epoch: 24, iters: 85504, time: 0.003) nll: 0.719141 \n",
      "(GPU: 0, epoch: 24, iters: 86304, time: 0.003) nll: 0.943777 \n",
      "(GPU: 0, epoch: 24, iters: 87104, time: 0.003) nll: 0.777843 \n",
      "(GPU: 0, epoch: 24, iters: 87904, time: 0.003) nll: 0.583213 \n",
      "(GPU: 0, epoch: 24, iters: 88704, time: 0.003) nll: 1.042084 \n",
      "(GPU: 0, epoch: 24, iters: 89504, time: 0.003) nll: 0.860564 \n",
      "(GPU: 0, epoch: 24, iters: 90304, time: 0.003) nll: 0.693730 \n",
      "(GPU: 0, epoch: 24, iters: 91104, time: 0.003) nll: 0.938010 \n",
      "(GPU: 0, epoch: 24, iters: 91904, time: 0.003) nll: 1.015490 \n",
      "(GPU: 0, epoch: 24, iters: 92704, time: 0.003) nll: 0.605791 \n",
      "(GPU: 0, epoch: 24, iters: 93504, time: 0.003) nll: 0.761990 \n",
      "(GPU: 0, epoch: 24, iters: 94304, time: 0.003) nll: 0.654449 \n",
      "(GPU: 0, epoch: 24, iters: 95104, time: 0.003) nll: 0.536788 \n",
      "(GPU: 0, epoch: 24, iters: 95904, time: 0.003) nll: 0.719193 \n",
      "(GPU: 0, epoch: 24, iters: 96704, time: 0.003) nll: 0.751640 \n",
      "(GPU: 0, epoch: 24, iters: 97504, time: 0.003) nll: 0.741223 \n",
      "(GPU: 0, epoch: 24, iters: 98304, time: 0.003) nll: 0.763244 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [08:30<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 24, iters: 99104, time: 0.003) nll: 0.844255 \n",
      "(GPU: 0, epoch: 24, iters: 99904, time: 0.003) nll: 0.804868 \n",
      "(GPU: 0, epoch: 24, iters: 100704, time: 0.003) nll: 0.804137 \n",
      "(GPU: 0, epoch: 24, iters: 101504, time: 0.003) nll: 0.853688 \n",
      "(GPU: 0, epoch: 24, iters: 102304, time: 0.003) nll: 0.712093 \n",
      "(GPU: 0, epoch: 24, iters: 103104, time: 0.003) nll: 0.846068 \n",
      "saving the latest model (epoch 24, total_steps 3480000)\n",
      "(GPU: 0, epoch: 24, iters: 103904, time: 0.003) nll: 0.700297 \n",
      "(GPU: 0, epoch: 24, iters: 104704, time: 0.003) nll: 0.763368 \n",
      "(GPU: 0, epoch: 24, iters: 105504, time: 0.003) nll: 0.882637 \n",
      "(GPU: 0, epoch: 24, iters: 106304, time: 0.003) nll: 0.890382 \n",
      "(GPU: 0, epoch: 24, iters: 107104, time: 0.003) nll: 0.652429 \n",
      "(GPU: 0, epoch: 24, iters: 107904, time: 0.003) nll: 0.818195 \n",
      "(GPU: 0, epoch: 24, iters: 108704, time: 0.003) nll: 0.689233 \n",
      "(GPU: 0, epoch: 24, iters: 109504, time: 0.003) nll: 0.737623 \n",
      "(GPU: 0, epoch: 24, iters: 110304, time: 0.003) nll: 0.832598 \n",
      "(GPU: 0, epoch: 24, iters: 111104, time: 0.003) nll: 0.822663 \n",
      "(GPU: 0, epoch: 24, iters: 111904, time: 0.003) nll: 0.749193 \n",
      "(GPU: 0, epoch: 24, iters: 112704, time: 0.003) nll: 0.746088 \n",
      "(GPU: 0, epoch: 24, iters: 113504, time: 0.003) nll: 0.915252 \n",
      "(GPU: 0, epoch: 24, iters: 114304, time: 0.003) nll: 0.720783 \n",
      "(GPU: 0, epoch: 24, iters: 115104, time: 0.003) nll: 0.809766 \n",
      "(GPU: 0, epoch: 24, iters: 115904, time: 0.003) nll: 0.801457 \n",
      "(GPU: 0, epoch: 24, iters: 116704, time: 0.003) nll: 0.775837 \n",
      "(GPU: 0, epoch: 24, iters: 117504, time: 0.003) nll: 0.644134 \n",
      "(GPU: 0, epoch: 24, iters: 118304, time: 0.003) nll: 0.682631 \n",
      "(GPU: 0, epoch: 24, iters: 119104, time: 0.003) nll: 0.954444 \n",
      "(GPU: 0, epoch: 24, iters: 119904, time: 0.003) nll: 0.689505 \n",
      "(GPU: 0, epoch: 24, iters: 120704, time: 0.003) nll: 0.657779 \n",
      "(GPU: 0, epoch: 24, iters: 121504, time: 0.003) nll: 0.837114 \n",
      "(GPU: 0, epoch: 24, iters: 122304, time: 0.003) nll: 0.798887 \n",
      "(GPU: 0, epoch: 24, iters: 123104, time: 0.003) nll: 0.872239 \n",
      "saving the latest model (epoch 24, total_steps 3500000)\n",
      "(GPU: 0, epoch: 24, iters: 123904, time: 0.003) nll: 0.594983 \n",
      "(GPU: 0, epoch: 24, iters: 124704, time: 0.003) nll: 0.966284 \n",
      "(GPU: 0, epoch: 24, iters: 125504, time: 0.003) nll: 0.759379 \n",
      "(GPU: 0, epoch: 24, iters: 126304, time: 0.003) nll: 0.480541 \n",
      "(GPU: 0, epoch: 24, iters: 127104, time: 0.003) nll: 0.550123 \n",
      "(GPU: 0, epoch: 24, iters: 127904, time: 0.003) nll: 1.006923 \n",
      "(GPU: 0, epoch: 24, iters: 128704, time: 0.003) nll: 0.801422 \n",
      "(GPU: 0, epoch: 24, iters: 129504, time: 0.003) nll: 0.807588 \n",
      "(GPU: 0, epoch: 24, iters: 130304, time: 0.003) nll: 0.873462 \n",
      "(GPU: 0, epoch: 24, iters: 131104, time: 0.003) nll: 0.844331 \n",
      "(GPU: 0, epoch: 24, iters: 131904, time: 0.003) nll: 0.800796 \n",
      "(GPU: 0, epoch: 24, iters: 132704, time: 0.003) nll: 0.753105 \n",
      "(GPU: 0, epoch: 24, iters: 133504, time: 0.003) nll: 0.637055 \n",
      "(GPU: 0, epoch: 24, iters: 134304, time: 0.003) nll: 0.999599 \n",
      "(GPU: 0, epoch: 24, iters: 135104, time: 0.003) nll: 0.814937 \n",
      "(GPU: 0, epoch: 24, iters: 135904, time: 0.003) nll: 0.747711 \n",
      "(GPU: 0, epoch: 24, iters: 136704, time: 0.003) nll: 0.675106 \n",
      "(GPU: 0, epoch: 24, iters: 137504, time: 0.003) nll: 0.970171 \n",
      "(GPU: 0, epoch: 24, iters: 138304, time: 0.003) nll: 0.678188 \n",
      "(GPU: 0, epoch: 24, iters: 139104, time: 0.003) nll: 0.543543 \n",
      "(GPU: 0, epoch: 24, iters: 139904, time: 0.003) nll: 0.650927 \n",
      "(GPU: 0, epoch: 24, iters: 140704, time: 0.003) nll: 0.864653 \n",
      "saving the model at the end of epoch 24, iters 3517600\n",
      "([test] GPU: 0, epoch: 24) \n",
      "OrderedDict()\n",
      "[*] End of epoch 24 / 25 \t Time Taken: 523 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-8-network-normalized-input-to-bert\n",
      "[*] learning rate = 0.0000632\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_rand_tf_snet_code.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf46647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
