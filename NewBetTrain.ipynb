{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f9292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28ddad9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ./launchers/train_new_bert.sh: Permission denied\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_new_bert.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9b0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autosdf.yaml\t\t      filelists\t\t      README.md\r\n",
      "Compare.ipynb\t\t      info-shapenet.json      results\r\n",
      "configs\t\t\t      launchers\t\t      shape_set_paths.json\r\n",
      "datasets\t\t      logs\t\t      Test-Reproduce.ipynb\r\n",
      "demo_data\t\t      logs2\t\t      test_samples_paper.txt\r\n",
      "demo-lang-conditional.ipynb   models\t\t      text2ShapePP.json\r\n",
      "demo_shape_comp.ipynb\t      New-Bert-Sandbox.ipynb  train.py\r\n",
      "demo_single_view_recon.ipynb  NewBetTrain.ipynb       utils\r\n",
      "extract_code.py\t\t      options\r\n",
      "file.json\t\t      preprocess\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f6cb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 32\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: text2shape-seq\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: ./logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 100000000000\n",
      "model: bert2vqsc_v4\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "ndf: 64\n",
      "nepochs: 20\n",
      "nepochs_decay: 5\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: Text2Shape\n",
      "[*] # training images = 140707\n",
      "[*] # testing images = 16000\n",
      "---------- Networks initialized -------------\n",
      "-----------------------------------------------\n",
      "[*] Model has been created: BERT2VQSC-Model\n",
      "[*] \"bert2vqsc_v4\" initialized.\n",
      "[*] create image directory:\n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL/images...\n",
      "[*] saving model and dataset files: /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py, /cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/datasets/text2shape.py\n",
      "140707 Length train dataset\n",
      "16000 Length test dataset\n",
      "4397 Length train_dl\n",
      "500 Length test_dl\n",
      "[*] Start training. name: bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4397 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.023) nll: 5.353895 \n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3199/4397 [12:35<03:09,  6.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 32, time: 0.023) nll: 5.332068 \n",
      "(GPU: 0, epoch: 0, iters: 800, time: 0.002) nll: 1.782358 \n",
      "(GPU: 0, epoch: 0, iters: 1600, time: 0.002) nll: 1.093881 \n",
      "(GPU: 0, epoch: 0, iters: 2400, time: 0.002) nll: 1.115858 \n",
      "(GPU: 0, epoch: 0, iters: 3200, time: 0.005) nll: 1.043074 \n",
      "(GPU: 0, epoch: 0, iters: 4000, time: 0.003) nll: 0.937490 \n",
      "(GPU: 0, epoch: 0, iters: 4800, time: 0.002) nll: 0.985643 \n",
      "(GPU: 0, epoch: 0, iters: 5600, time: 0.005) nll: 0.954575 \n",
      "(GPU: 0, epoch: 0, iters: 6400, time: 0.005) nll: 0.959103 \n",
      "(GPU: 0, epoch: 0, iters: 7200, time: 0.005) nll: 0.827150 \n",
      "(GPU: 0, epoch: 0, iters: 8000, time: 0.005) nll: 0.720049 \n",
      "(GPU: 0, epoch: 0, iters: 8800, time: 0.002) nll: 1.005870 \n",
      "(GPU: 0, epoch: 0, iters: 9600, time: 0.002) nll: 1.029084 \n",
      "(GPU: 0, epoch: 0, iters: 10400, time: 0.005) nll: 0.678196 \n",
      "(GPU: 0, epoch: 0, iters: 11200, time: 0.005) nll: 0.845156 \n",
      "(GPU: 0, epoch: 0, iters: 12000, time: 0.004) nll: 0.817545 \n",
      "(GPU: 0, epoch: 0, iters: 12800, time: 0.002) nll: 0.896015 \n",
      "(GPU: 0, epoch: 0, iters: 13600, time: 0.005) nll: 0.990841 \n",
      "(GPU: 0, epoch: 0, iters: 14400, time: 0.005) nll: 0.835743 \n",
      "(GPU: 0, epoch: 0, iters: 15200, time: 0.005) nll: 0.804647 \n",
      "(GPU: 0, epoch: 0, iters: 16000, time: 0.005) nll: 0.938197 \n",
      "(GPU: 0, epoch: 0, iters: 16800, time: 0.005) nll: 0.811200 \n",
      "(GPU: 0, epoch: 0, iters: 17600, time: 0.005) nll: 0.783753 \n",
      "(GPU: 0, epoch: 0, iters: 18400, time: 0.004) nll: 0.722290 \n",
      "(GPU: 0, epoch: 0, iters: 19200, time: 0.005) nll: 1.061117 \n",
      "(GPU: 0, epoch: 0, iters: 20000, time: 0.004) nll: 1.080163 \n",
      "saving the latest model (epoch 0, total_steps 20000)\n",
      "(GPU: 0, epoch: 0, iters: 20800, time: 0.005) nll: 0.738862 \n",
      "(GPU: 0, epoch: 0, iters: 21600, time: 0.004) nll: 0.866349 \n",
      "(GPU: 0, epoch: 0, iters: 22400, time: 0.005) nll: 0.895339 \n",
      "(GPU: 0, epoch: 0, iters: 23200, time: 0.005) nll: 0.698582 \n",
      "(GPU: 0, epoch: 0, iters: 24000, time: 0.005) nll: 0.828992 \n",
      "(GPU: 0, epoch: 0, iters: 24800, time: 0.005) nll: 0.701151 \n",
      "(GPU: 0, epoch: 0, iters: 25600, time: 0.005) nll: 0.946855 \n",
      "(GPU: 0, epoch: 0, iters: 26400, time: 0.005) nll: 0.872386 \n",
      "(GPU: 0, epoch: 0, iters: 27200, time: 0.005) nll: 0.803093 \n",
      "(GPU: 0, epoch: 0, iters: 28000, time: 0.005) nll: 0.740791 \n",
      "(GPU: 0, epoch: 0, iters: 28800, time: 0.005) nll: 0.907925 \n",
      "(GPU: 0, epoch: 0, iters: 29600, time: 0.004) nll: 0.793733 \n",
      "(GPU: 0, epoch: 0, iters: 30400, time: 0.005) nll: 0.914783 \n",
      "(GPU: 0, epoch: 0, iters: 31200, time: 0.005) nll: 0.829763 \n",
      "(GPU: 0, epoch: 0, iters: 32000, time: 0.005) nll: 0.786601 \n",
      "(GPU: 0, epoch: 0, iters: 32800, time: 0.005) nll: 0.466315 \n",
      "(GPU: 0, epoch: 0, iters: 33600, time: 0.005) nll: 0.767166 \n",
      "(GPU: 0, epoch: 0, iters: 34400, time: 0.005) nll: 0.838807 \n",
      "(GPU: 0, epoch: 0, iters: 35200, time: 0.005) nll: 0.941068 \n",
      "(GPU: 0, epoch: 0, iters: 36000, time: 0.005) nll: 0.898501 \n",
      "(GPU: 0, epoch: 0, iters: 36800, time: 0.005) nll: 0.559180 \n",
      "(GPU: 0, epoch: 0, iters: 37600, time: 0.004) nll: 0.885783 \n",
      "(GPU: 0, epoch: 0, iters: 38400, time: 0.005) nll: 0.845482 \n",
      "(GPU: 0, epoch: 0, iters: 39200, time: 0.005) nll: 1.014776 \n",
      "(GPU: 0, epoch: 0, iters: 40000, time: 0.005) nll: 0.732242 \n",
      "saving the latest model (epoch 0, total_steps 40000)\n",
      "(GPU: 0, epoch: 0, iters: 40800, time: 0.004) nll: 0.853673 \n",
      "(GPU: 0, epoch: 0, iters: 41600, time: 0.005) nll: 0.627884 \n",
      "(GPU: 0, epoch: 0, iters: 42400, time: 0.005) nll: 0.818546 \n",
      "(GPU: 0, epoch: 0, iters: 43200, time: 0.005) nll: 0.695631 \n",
      "(GPU: 0, epoch: 0, iters: 44000, time: 0.005) nll: 0.797141 \n",
      "(GPU: 0, epoch: 0, iters: 44800, time: 0.005) nll: 0.728716 \n",
      "(GPU: 0, epoch: 0, iters: 45600, time: 0.005) nll: 0.748957 \n",
      "(GPU: 0, epoch: 0, iters: 46400, time: 0.005) nll: 0.591700 \n",
      "(GPU: 0, epoch: 0, iters: 47200, time: 0.004) nll: 0.728413 \n",
      "(GPU: 0, epoch: 0, iters: 48000, time: 0.005) nll: 0.821980 \n",
      "(GPU: 0, epoch: 0, iters: 48800, time: 0.005) nll: 0.991238 \n",
      "(GPU: 0, epoch: 0, iters: 49600, time: 0.005) nll: 1.036627 \n",
      "(GPU: 0, epoch: 0, iters: 50400, time: 0.005) nll: 0.579755 \n",
      "(GPU: 0, epoch: 0, iters: 51200, time: 0.005) nll: 0.982043 \n",
      "(GPU: 0, epoch: 0, iters: 52000, time: 0.005) nll: 0.863950 \n",
      "(GPU: 0, epoch: 0, iters: 52800, time: 0.005) nll: 0.719398 \n",
      "(GPU: 0, epoch: 0, iters: 53600, time: 0.005) nll: 0.714535 \n",
      "(GPU: 0, epoch: 0, iters: 54400, time: 0.005) nll: 0.889528 \n",
      "(GPU: 0, epoch: 0, iters: 55200, time: 0.005) nll: 0.944874 \n",
      "(GPU: 0, epoch: 0, iters: 56000, time: 0.005) nll: 0.617485 \n",
      "(GPU: 0, epoch: 0, iters: 56800, time: 0.004) nll: 0.858158 \n",
      "(GPU: 0, epoch: 0, iters: 57600, time: 0.005) nll: 0.926985 \n",
      "(GPU: 0, epoch: 0, iters: 58400, time: 0.005) nll: 0.645563 \n",
      "(GPU: 0, epoch: 0, iters: 59200, time: 0.005) nll: 0.816467 \n",
      "(GPU: 0, epoch: 0, iters: 60000, time: 0.005) nll: 0.800241 \n",
      "saving the latest model (epoch 0, total_steps 60000)\n",
      "(GPU: 0, epoch: 0, iters: 60800, time: 0.005) nll: 0.892745 \n",
      "(GPU: 0, epoch: 0, iters: 61600, time: 0.004) nll: 0.826198 \n",
      "(GPU: 0, epoch: 0, iters: 62400, time: 0.005) nll: 0.676312 \n",
      "(GPU: 0, epoch: 0, iters: 63200, time: 0.004) nll: 0.815298 \n",
      "(GPU: 0, epoch: 0, iters: 64000, time: 0.005) nll: 0.939340 \n",
      "(GPU: 0, epoch: 0, iters: 64800, time: 0.004) nll: 0.656374 \n",
      "(GPU: 0, epoch: 0, iters: 65600, time: 0.005) nll: 0.849534 \n",
      "(GPU: 0, epoch: 0, iters: 66400, time: 0.005) nll: 0.591606 \n",
      "(GPU: 0, epoch: 0, iters: 67200, time: 0.005) nll: 0.890603 \n",
      "(GPU: 0, epoch: 0, iters: 68000, time: 0.004) nll: 1.021320 \n",
      "(GPU: 0, epoch: 0, iters: 68800, time: 0.005) nll: 0.669027 \n",
      "(GPU: 0, epoch: 0, iters: 69600, time: 0.005) nll: 0.862197 \n",
      "(GPU: 0, epoch: 0, iters: 70400, time: 0.005) nll: 1.000732 \n",
      "(GPU: 0, epoch: 0, iters: 71200, time: 0.004) nll: 0.825167 \n",
      "(GPU: 0, epoch: 0, iters: 72000, time: 0.005) nll: 0.754227 \n",
      "(GPU: 0, epoch: 0, iters: 72800, time: 0.005) nll: 0.911463 \n",
      "(GPU: 0, epoch: 0, iters: 73600, time: 0.005) nll: 0.779520 \n",
      "(GPU: 0, epoch: 0, iters: 74400, time: 0.004) nll: 0.815531 \n",
      "(GPU: 0, epoch: 0, iters: 75200, time: 0.005) nll: 0.780991 \n",
      "(GPU: 0, epoch: 0, iters: 76000, time: 0.004) nll: 0.856756 \n",
      "(GPU: 0, epoch: 0, iters: 76800, time: 0.005) nll: 0.847895 \n",
      "(GPU: 0, epoch: 0, iters: 77600, time: 0.005) nll: 0.642738 \n",
      "(GPU: 0, epoch: 0, iters: 78400, time: 0.005) nll: 0.954635 \n",
      "(GPU: 0, epoch: 0, iters: 79200, time: 0.004) nll: 0.839436 \n",
      "(GPU: 0, epoch: 0, iters: 80000, time: 0.005) nll: 0.917122 \n",
      "saving the latest model (epoch 0, total_steps 80000)\n",
      "(GPU: 0, epoch: 0, iters: 80800, time: 0.005) nll: 0.811247 \n",
      "(GPU: 0, epoch: 0, iters: 81600, time: 0.005) nll: 0.663132 \n",
      "(GPU: 0, epoch: 0, iters: 82400, time: 0.004) nll: 0.680015 \n",
      "(GPU: 0, epoch: 0, iters: 83200, time: 0.005) nll: 0.719604 \n",
      "(GPU: 0, epoch: 0, iters: 84000, time: 0.004) nll: 0.668698 \n",
      "(GPU: 0, epoch: 0, iters: 84800, time: 0.005) nll: 0.987344 \n",
      "(GPU: 0, epoch: 0, iters: 85600, time: 0.005) nll: 0.949301 \n",
      "(GPU: 0, epoch: 0, iters: 86400, time: 0.005) nll: 0.802568 \n",
      "(GPU: 0, epoch: 0, iters: 87200, time: 0.005) nll: 0.855609 \n",
      "(GPU: 0, epoch: 0, iters: 88000, time: 0.005) nll: 1.217045 \n",
      "(GPU: 0, epoch: 0, iters: 88800, time: 0.005) nll: 0.705832 \n",
      "(GPU: 0, epoch: 0, iters: 89600, time: 0.005) nll: 0.714505 \n",
      "(GPU: 0, epoch: 0, iters: 90400, time: 0.004) nll: 0.584649 \n",
      "(GPU: 0, epoch: 0, iters: 91200, time: 0.005) nll: 0.725156 \n",
      "(GPU: 0, epoch: 0, iters: 92000, time: 0.005) nll: 0.798321 \n",
      "(GPU: 0, epoch: 0, iters: 92800, time: 0.005) nll: 0.906653 \n",
      "(GPU: 0, epoch: 0, iters: 93600, time: 0.005) nll: 0.858234 \n",
      "(GPU: 0, epoch: 0, iters: 94400, time: 0.005) nll: 0.788938 \n",
      "(GPU: 0, epoch: 0, iters: 95200, time: 0.005) nll: 0.635666 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.005) nll: 0.734371 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.008) nll: 0.729108 \n",
      "(GPU: 0, epoch: 0, iters: 96000, time: 0.008) nll: 0.937518 \n",
      "(GPU: 0, epoch: 0, iters: 96800, time: 0.004) nll: 0.801229 \n",
      "(GPU: 0, epoch: 0, iters: 97600, time: 0.005) nll: 0.762754 \n",
      "(GPU: 0, epoch: 0, iters: 98400, time: 0.004) nll: 0.950001 \n",
      "(GPU: 0, epoch: 0, iters: 99200, time: 0.005) nll: 0.868722 \n",
      "(GPU: 0, epoch: 0, iters: 100000, time: 0.005) nll: 1.062986 \n",
      "saving the latest model (epoch 0, total_steps 100000)\n",
      "(GPU: 0, epoch: 0, iters: 100800, time: 0.005) nll: 0.901595 \n",
      "(GPU: 0, epoch: 0, iters: 101600, time: 0.004) nll: 0.790168 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [16:10<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 0, iters: 102400, time: 0.005) nll: 0.536669 \n",
      "(GPU: 0, epoch: 0, iters: 103200, time: 0.005) nll: 1.119045 \n",
      "(GPU: 0, epoch: 0, iters: 104000, time: 0.005) nll: 0.759822 \n",
      "(GPU: 0, epoch: 0, iters: 104800, time: 0.005) nll: 0.945248 \n",
      "(GPU: 0, epoch: 0, iters: 105600, time: 0.005) nll: 0.909748 \n",
      "(GPU: 0, epoch: 0, iters: 106400, time: 0.005) nll: 0.836735 \n",
      "(GPU: 0, epoch: 0, iters: 107200, time: 0.005) nll: 0.715387 \n",
      "(GPU: 0, epoch: 0, iters: 108000, time: 0.005) nll: 0.696754 \n",
      "(GPU: 0, epoch: 0, iters: 108800, time: 0.005) nll: 0.903461 \n",
      "(GPU: 0, epoch: 0, iters: 109600, time: 0.005) nll: 0.770063 \n",
      "(GPU: 0, epoch: 0, iters: 110400, time: 0.005) nll: 0.734267 \n",
      "(GPU: 0, epoch: 0, iters: 111200, time: 0.005) nll: 0.762938 \n",
      "(GPU: 0, epoch: 0, iters: 112000, time: 0.005) nll: 0.827240 \n",
      "(GPU: 0, epoch: 0, iters: 112800, time: 0.005) nll: 0.760339 \n",
      "(GPU: 0, epoch: 0, iters: 113600, time: 0.005) nll: 0.907540 \n",
      "(GPU: 0, epoch: 0, iters: 114400, time: 0.005) nll: 0.798820 \n",
      "(GPU: 0, epoch: 0, iters: 115200, time: 0.005) nll: 1.125399 \n",
      "(GPU: 0, epoch: 0, iters: 116000, time: 0.004) nll: 0.698255 \n",
      "(GPU: 0, epoch: 0, iters: 116800, time: 0.005) nll: 0.554729 \n",
      "(GPU: 0, epoch: 0, iters: 117600, time: 0.004) nll: 0.980514 \n",
      "(GPU: 0, epoch: 0, iters: 118400, time: 0.005) nll: 0.902074 \n",
      "(GPU: 0, epoch: 0, iters: 119200, time: 0.005) nll: 0.779639 \n",
      "(GPU: 0, epoch: 0, iters: 120000, time: 0.005) nll: 0.890304 \n",
      "saving the latest model (epoch 0, total_steps 120000)\n",
      "(GPU: 0, epoch: 0, iters: 120800, time: 0.005) nll: 0.711515 \n",
      "(GPU: 0, epoch: 0, iters: 121600, time: 0.005) nll: 0.868839 \n",
      "(GPU: 0, epoch: 0, iters: 122400, time: 0.005) nll: 0.706975 \n",
      "(GPU: 0, epoch: 0, iters: 123200, time: 0.005) nll: 0.686167 \n",
      "(GPU: 0, epoch: 0, iters: 124000, time: 0.004) nll: 0.781122 \n",
      "(GPU: 0, epoch: 0, iters: 124800, time: 0.005) nll: 0.820671 \n",
      "(GPU: 0, epoch: 0, iters: 125600, time: 0.005) nll: 0.717378 \n",
      "(GPU: 0, epoch: 0, iters: 126400, time: 0.005) nll: 0.758293 \n",
      "(GPU: 0, epoch: 0, iters: 127200, time: 0.005) nll: 0.718475 \n",
      "(GPU: 0, epoch: 0, iters: 128000, time: 0.005) nll: 0.692619 \n",
      "(GPU: 0, epoch: 0, iters: 128800, time: 0.005) nll: 0.710209 \n",
      "(GPU: 0, epoch: 0, iters: 129600, time: 0.005) nll: 0.851886 \n",
      "(GPU: 0, epoch: 0, iters: 130400, time: 0.004) nll: 0.523792 \n",
      "(GPU: 0, epoch: 0, iters: 131200, time: 0.005) nll: 0.553190 \n",
      "(GPU: 0, epoch: 0, iters: 132000, time: 0.005) nll: 0.561126 \n",
      "(GPU: 0, epoch: 0, iters: 132800, time: 0.005) nll: 0.825647 \n",
      "(GPU: 0, epoch: 0, iters: 133600, time: 0.005) nll: 0.677540 \n",
      "(GPU: 0, epoch: 0, iters: 134400, time: 0.005) nll: 0.632022 \n",
      "(GPU: 0, epoch: 0, iters: 135200, time: 0.005) nll: 0.776468 \n",
      "(GPU: 0, epoch: 0, iters: 136000, time: 0.005) nll: 0.982572 \n",
      "(GPU: 0, epoch: 0, iters: 136800, time: 0.004) nll: 0.945825 \n",
      "(GPU: 0, epoch: 0, iters: 137600, time: 0.005) nll: 0.681542 \n",
      "(GPU: 0, epoch: 0, iters: 138400, time: 0.005) nll: 0.668055 \n",
      "(GPU: 0, epoch: 0, iters: 139200, time: 0.005) nll: 0.689018 \n",
      "(GPU: 0, epoch: 0, iters: 140000, time: 0.005) nll: 0.594308 \n",
      "saving the latest model (epoch 0, total_steps 140000)\n",
      "saving the model at the end of epoch 0, iters 140704\n",
      "([test] GPU: 0, epoch: 0) \n",
      "OrderedDict()\n",
      "[*] End of epoch 0 / 25 \t Time Taken: 992 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000100\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3152/4397 [09:13<03:18,  6.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 32, time: 0.003) nll: 0.832321 \n",
      "(GPU: 0, epoch: 1, iters: 32, time: 0.003) nll: 0.838881 \n",
      "(GPU: 0, epoch: 1, iters: 96, time: 0.004) nll: 0.754109 \n",
      "(GPU: 0, epoch: 1, iters: 896, time: 0.005) nll: 0.770939 \n",
      "(GPU: 0, epoch: 1, iters: 1696, time: 0.004) nll: 0.855278 \n",
      "(GPU: 0, epoch: 1, iters: 2496, time: 0.005) nll: 0.938058 \n",
      "(GPU: 0, epoch: 1, iters: 3296, time: 0.005) nll: 0.950820 \n",
      "(GPU: 0, epoch: 1, iters: 4096, time: 0.005) nll: 0.671220 \n",
      "(GPU: 0, epoch: 1, iters: 4896, time: 0.004) nll: 0.467758 \n",
      "(GPU: 0, epoch: 1, iters: 5696, time: 0.005) nll: 0.820413 \n",
      "(GPU: 0, epoch: 1, iters: 6496, time: 0.005) nll: 0.834888 \n",
      "(GPU: 0, epoch: 1, iters: 7296, time: 0.005) nll: 0.675891 \n",
      "(GPU: 0, epoch: 1, iters: 8096, time: 0.004) nll: 0.617466 \n",
      "(GPU: 0, epoch: 1, iters: 8896, time: 0.005) nll: 0.916644 \n",
      "(GPU: 0, epoch: 1, iters: 9696, time: 0.005) nll: 0.775253 \n",
      "(GPU: 0, epoch: 1, iters: 10496, time: 0.005) nll: 0.824977 \n",
      "(GPU: 0, epoch: 1, iters: 11296, time: 0.004) nll: 0.793582 \n",
      "(GPU: 0, epoch: 1, iters: 12096, time: 0.005) nll: 0.686069 \n",
      "(GPU: 0, epoch: 1, iters: 12896, time: 0.004) nll: 0.904320 \n",
      "(GPU: 0, epoch: 1, iters: 13696, time: 0.005) nll: 0.880869 \n",
      "(GPU: 0, epoch: 1, iters: 14496, time: 0.004) nll: 0.868062 \n",
      "(GPU: 0, epoch: 1, iters: 15296, time: 0.005) nll: 0.709096 \n",
      "(GPU: 0, epoch: 1, iters: 16096, time: 0.004) nll: 0.709809 \n",
      "(GPU: 0, epoch: 1, iters: 16896, time: 0.005) nll: 0.582537 \n",
      "(GPU: 0, epoch: 1, iters: 17696, time: 0.005) nll: 0.850828 \n",
      "(GPU: 0, epoch: 1, iters: 18496, time: 0.005) nll: 0.803015 \n",
      "(GPU: 0, epoch: 1, iters: 19296, time: 0.005) nll: 0.808515 \n",
      "saving the latest model (epoch 1, total_steps 160000)\n",
      "(GPU: 0, epoch: 1, iters: 20096, time: 0.005) nll: 0.629880 \n",
      "(GPU: 0, epoch: 1, iters: 20896, time: 0.004) nll: 0.709404 \n",
      "(GPU: 0, epoch: 1, iters: 21696, time: 0.005) nll: 0.821251 \n",
      "(GPU: 0, epoch: 1, iters: 22496, time: 0.004) nll: 0.772388 \n",
      "(GPU: 0, epoch: 1, iters: 23296, time: 0.005) nll: 0.836744 \n",
      "(GPU: 0, epoch: 1, iters: 24096, time: 0.005) nll: 0.883829 \n",
      "(GPU: 0, epoch: 1, iters: 24896, time: 0.005) nll: 0.618071 \n",
      "(GPU: 0, epoch: 1, iters: 25696, time: 0.005) nll: 0.570742 \n",
      "(GPU: 0, epoch: 1, iters: 26496, time: 0.005) nll: 0.819004 \n",
      "(GPU: 0, epoch: 1, iters: 27296, time: 0.005) nll: 0.768611 \n",
      "(GPU: 0, epoch: 1, iters: 28096, time: 0.005) nll: 0.938515 \n",
      "(GPU: 0, epoch: 1, iters: 28896, time: 0.004) nll: 0.829963 \n",
      "(GPU: 0, epoch: 1, iters: 29696, time: 0.005) nll: 0.600895 \n",
      "(GPU: 0, epoch: 1, iters: 30496, time: 0.004) nll: 0.989258 \n",
      "(GPU: 0, epoch: 1, iters: 31296, time: 0.005) nll: 0.813413 \n",
      "(GPU: 0, epoch: 1, iters: 32096, time: 0.004) nll: 1.124653 \n",
      "(GPU: 0, epoch: 1, iters: 32896, time: 0.005) nll: 0.747330 \n",
      "(GPU: 0, epoch: 1, iters: 33696, time: 0.004) nll: 0.797900 \n",
      "(GPU: 0, epoch: 1, iters: 34496, time: 0.005) nll: 0.617437 \n",
      "(GPU: 0, epoch: 1, iters: 35296, time: 0.004) nll: 0.885846 \n",
      "(GPU: 0, epoch: 1, iters: 36096, time: 0.005) nll: 0.606128 \n",
      "(GPU: 0, epoch: 1, iters: 36896, time: 0.004) nll: 0.646985 \n",
      "(GPU: 0, epoch: 1, iters: 37696, time: 0.005) nll: 0.846107 \n",
      "(GPU: 0, epoch: 1, iters: 38496, time: 0.005) nll: 0.923402 \n",
      "(GPU: 0, epoch: 1, iters: 39296, time: 0.005) nll: 0.790051 \n",
      "saving the latest model (epoch 1, total_steps 180000)\n",
      "(GPU: 0, epoch: 1, iters: 40096, time: 0.004) nll: 0.571478 \n",
      "(GPU: 0, epoch: 1, iters: 40896, time: 0.005) nll: 0.807756 \n",
      "(GPU: 0, epoch: 1, iters: 41696, time: 0.004) nll: 0.681768 \n",
      "(GPU: 0, epoch: 1, iters: 42496, time: 0.005) nll: 0.893995 \n",
      "(GPU: 0, epoch: 1, iters: 43296, time: 0.004) nll: 1.013016 \n",
      "(GPU: 0, epoch: 1, iters: 44096, time: 0.005) nll: 0.983632 \n",
      "(GPU: 0, epoch: 1, iters: 44896, time: 0.005) nll: 0.843562 \n",
      "(GPU: 0, epoch: 1, iters: 45696, time: 0.005) nll: 0.877757 \n",
      "(GPU: 0, epoch: 1, iters: 46496, time: 0.004) nll: 0.548716 \n",
      "(GPU: 0, epoch: 1, iters: 47296, time: 0.005) nll: 0.899664 \n",
      "(GPU: 0, epoch: 1, iters: 48096, time: 0.004) nll: 0.510537 \n",
      "(GPU: 0, epoch: 1, iters: 48896, time: 0.005) nll: 0.728220 \n",
      "(GPU: 0, epoch: 1, iters: 49696, time: 0.004) nll: 0.547966 \n",
      "(GPU: 0, epoch: 1, iters: 50496, time: 0.005) nll: 1.004285 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.004) nll: 0.813856 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.007) nll: 0.812116 \n",
      "(GPU: 0, epoch: 1, iters: 51296, time: 0.007) nll: 0.734710 \n",
      "(GPU: 0, epoch: 1, iters: 52096, time: 0.005) nll: 0.887947 \n",
      "(GPU: 0, epoch: 1, iters: 52896, time: 0.005) nll: 0.551404 \n",
      "(GPU: 0, epoch: 1, iters: 53696, time: 0.005) nll: 0.957882 \n",
      "(GPU: 0, epoch: 1, iters: 54496, time: 0.004) nll: 0.718321 \n",
      "(GPU: 0, epoch: 1, iters: 55296, time: 0.005) nll: 0.741246 \n",
      "(GPU: 0, epoch: 1, iters: 56096, time: 0.004) nll: 0.542243 \n",
      "(GPU: 0, epoch: 1, iters: 56896, time: 0.005) nll: 0.686607 \n",
      "(GPU: 0, epoch: 1, iters: 57696, time: 0.005) nll: 0.828383 \n",
      "(GPU: 0, epoch: 1, iters: 58496, time: 0.005) nll: 0.924517 \n",
      "(GPU: 0, epoch: 1, iters: 59296, time: 0.005) nll: 0.868953 \n",
      "saving the latest model (epoch 1, total_steps 200000)\n",
      "(GPU: 0, epoch: 1, iters: 60096, time: 0.005) nll: 0.694089 \n",
      "(GPU: 0, epoch: 1, iters: 60896, time: 0.005) nll: 0.694952 \n",
      "(GPU: 0, epoch: 1, iters: 61696, time: 0.005) nll: 0.708615 \n",
      "(GPU: 0, epoch: 1, iters: 62496, time: 0.004) nll: 0.930895 \n",
      "(GPU: 0, epoch: 1, iters: 63296, time: 0.005) nll: 0.623277 \n",
      "(GPU: 0, epoch: 1, iters: 64096, time: 0.004) nll: 0.757160 \n",
      "(GPU: 0, epoch: 1, iters: 64896, time: 0.005) nll: 1.031502 \n",
      "(GPU: 0, epoch: 1, iters: 65696, time: 0.005) nll: 0.536582 \n",
      "(GPU: 0, epoch: 1, iters: 66496, time: 0.005) nll: 0.755137 \n",
      "(GPU: 0, epoch: 1, iters: 67296, time: 0.004) nll: 0.677171 \n",
      "(GPU: 0, epoch: 1, iters: 68096, time: 0.005) nll: 0.784550 \n",
      "(GPU: 0, epoch: 1, iters: 68896, time: 0.004) nll: 0.718698 \n",
      "(GPU: 0, epoch: 1, iters: 69696, time: 0.005) nll: 0.841036 \n",
      "(GPU: 0, epoch: 1, iters: 70496, time: 0.004) nll: 0.834503 \n",
      "(GPU: 0, epoch: 1, iters: 71296, time: 0.005) nll: 0.735308 \n",
      "(GPU: 0, epoch: 1, iters: 72096, time: 0.004) nll: 0.768415 \n",
      "(GPU: 0, epoch: 1, iters: 72896, time: 0.005) nll: 0.729932 \n",
      "(GPU: 0, epoch: 1, iters: 73696, time: 0.004) nll: 0.672640 \n",
      "(GPU: 0, epoch: 1, iters: 74496, time: 0.005) nll: 0.812949 \n",
      "(GPU: 0, epoch: 1, iters: 75296, time: 0.005) nll: 0.618532 \n",
      "(GPU: 0, epoch: 1, iters: 76096, time: 0.005) nll: 0.872477 \n",
      "(GPU: 0, epoch: 1, iters: 76896, time: 0.005) nll: 0.539793 \n",
      "(GPU: 0, epoch: 1, iters: 77696, time: 0.005) nll: 0.691946 \n",
      "(GPU: 0, epoch: 1, iters: 78496, time: 0.004) nll: 1.221737 \n",
      "(GPU: 0, epoch: 1, iters: 79296, time: 0.005) nll: 0.857336 \n",
      "saving the latest model (epoch 1, total_steps 220000)\n",
      "(GPU: 0, epoch: 1, iters: 80096, time: 0.004) nll: 0.794995 \n",
      "(GPU: 0, epoch: 1, iters: 80896, time: 0.005) nll: 0.629674 \n",
      "(GPU: 0, epoch: 1, iters: 81696, time: 0.004) nll: 0.746635 \n",
      "(GPU: 0, epoch: 1, iters: 82496, time: 0.005) nll: 0.900609 \n",
      "(GPU: 0, epoch: 1, iters: 83296, time: 0.005) nll: 1.025367 \n",
      "(GPU: 0, epoch: 1, iters: 84096, time: 0.005) nll: 0.659837 \n",
      "(GPU: 0, epoch: 1, iters: 84896, time: 0.005) nll: 0.655442 \n",
      "(GPU: 0, epoch: 1, iters: 85696, time: 0.005) nll: 0.984978 \n",
      "(GPU: 0, epoch: 1, iters: 86496, time: 0.005) nll: 1.178439 \n",
      "(GPU: 0, epoch: 1, iters: 87296, time: 0.005) nll: 0.487570 \n",
      "(GPU: 0, epoch: 1, iters: 88096, time: 0.004) nll: 0.759121 \n",
      "(GPU: 0, epoch: 1, iters: 88896, time: 0.005) nll: 0.761511 \n",
      "(GPU: 0, epoch: 1, iters: 89696, time: 0.004) nll: 0.673671 \n",
      "(GPU: 0, epoch: 1, iters: 90496, time: 0.005) nll: 0.835295 \n",
      "(GPU: 0, epoch: 1, iters: 91296, time: 0.005) nll: 0.790792 \n",
      "(GPU: 0, epoch: 1, iters: 92096, time: 0.005) nll: 0.780646 \n",
      "(GPU: 0, epoch: 1, iters: 92896, time: 0.004) nll: 0.889986 \n",
      "(GPU: 0, epoch: 1, iters: 93696, time: 0.005) nll: 0.740643 \n",
      "(GPU: 0, epoch: 1, iters: 94496, time: 0.004) nll: 0.703345 \n",
      "(GPU: 0, epoch: 1, iters: 95296, time: 0.005) nll: 0.814247 \n",
      "(GPU: 0, epoch: 1, iters: 96096, time: 0.004) nll: 0.817719 \n",
      "(GPU: 0, epoch: 1, iters: 96896, time: 0.005) nll: 0.715106 \n",
      "(GPU: 0, epoch: 1, iters: 97696, time: 0.004) nll: 0.912873 \n",
      "(GPU: 0, epoch: 1, iters: 98496, time: 0.005) nll: 0.819621 \n",
      "(GPU: 0, epoch: 1, iters: 99296, time: 0.005) nll: 0.498893 \n",
      "saving the latest model (epoch 1, total_steps 240000)\n",
      "(GPU: 0, epoch: 1, iters: 100096, time: 0.005) nll: 0.906287 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:50<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 1, iters: 100896, time: 0.004) nll: 0.644658 \n",
      "(GPU: 0, epoch: 1, iters: 101696, time: 0.005) nll: 0.822264 \n",
      "(GPU: 0, epoch: 1, iters: 102496, time: 0.004) nll: 0.808704 \n",
      "(GPU: 0, epoch: 1, iters: 103296, time: 0.005) nll: 0.638835 \n",
      "(GPU: 0, epoch: 1, iters: 104096, time: 0.005) nll: 0.814719 \n",
      "(GPU: 0, epoch: 1, iters: 104896, time: 0.005) nll: 0.656811 \n",
      "(GPU: 0, epoch: 1, iters: 105696, time: 0.004) nll: 0.562716 \n",
      "(GPU: 0, epoch: 1, iters: 106496, time: 0.005) nll: 0.614519 \n",
      "(GPU: 0, epoch: 1, iters: 107296, time: 0.005) nll: 0.965320 \n",
      "(GPU: 0, epoch: 1, iters: 108096, time: 0.005) nll: 0.636056 \n",
      "(GPU: 0, epoch: 1, iters: 108896, time: 0.004) nll: 0.723344 \n",
      "(GPU: 0, epoch: 1, iters: 109696, time: 0.005) nll: 0.984286 \n",
      "(GPU: 0, epoch: 1, iters: 110496, time: 0.005) nll: 0.836946 \n",
      "(GPU: 0, epoch: 1, iters: 111296, time: 0.005) nll: 0.603730 \n",
      "(GPU: 0, epoch: 1, iters: 112096, time: 0.004) nll: 0.710165 \n",
      "(GPU: 0, epoch: 1, iters: 112896, time: 0.005) nll: 0.971078 \n",
      "(GPU: 0, epoch: 1, iters: 113696, time: 0.004) nll: 0.726845 \n",
      "(GPU: 0, epoch: 1, iters: 114496, time: 0.005) nll: 0.907704 \n",
      "(GPU: 0, epoch: 1, iters: 115296, time: 0.004) nll: 0.704149 \n",
      "(GPU: 0, epoch: 1, iters: 116096, time: 0.005) nll: 0.914747 \n",
      "(GPU: 0, epoch: 1, iters: 116896, time: 0.005) nll: 0.812708 \n",
      "(GPU: 0, epoch: 1, iters: 117696, time: 0.005) nll: 0.641757 \n",
      "(GPU: 0, epoch: 1, iters: 118496, time: 0.004) nll: 0.690655 \n",
      "(GPU: 0, epoch: 1, iters: 119296, time: 0.005) nll: 0.839875 \n",
      "saving the latest model (epoch 1, total_steps 260000)\n",
      "(GPU: 0, epoch: 1, iters: 120096, time: 0.005) nll: 0.765193 \n",
      "(GPU: 0, epoch: 1, iters: 120896, time: 0.005) nll: 0.792217 \n",
      "(GPU: 0, epoch: 1, iters: 121696, time: 0.005) nll: 0.719929 \n",
      "(GPU: 0, epoch: 1, iters: 122496, time: 0.005) nll: 0.747667 \n",
      "(GPU: 0, epoch: 1, iters: 123296, time: 0.005) nll: 0.800794 \n",
      "(GPU: 0, epoch: 1, iters: 124096, time: 0.005) nll: 0.881800 \n",
      "(GPU: 0, epoch: 1, iters: 124896, time: 0.004) nll: 0.865666 \n",
      "(GPU: 0, epoch: 1, iters: 125696, time: 0.005) nll: 0.746826 \n",
      "(GPU: 0, epoch: 1, iters: 126496, time: 0.004) nll: 0.752759 \n",
      "(GPU: 0, epoch: 1, iters: 127296, time: 0.005) nll: 0.773094 \n",
      "(GPU: 0, epoch: 1, iters: 128096, time: 0.005) nll: 0.975120 \n",
      "(GPU: 0, epoch: 1, iters: 128896, time: 0.005) nll: 1.190738 \n",
      "(GPU: 0, epoch: 1, iters: 129696, time: 0.005) nll: 0.762864 \n",
      "(GPU: 0, epoch: 1, iters: 130496, time: 0.005) nll: 0.811676 \n",
      "(GPU: 0, epoch: 1, iters: 131296, time: 0.005) nll: 0.691373 \n",
      "(GPU: 0, epoch: 1, iters: 132096, time: 0.005) nll: 0.915555 \n",
      "(GPU: 0, epoch: 1, iters: 132896, time: 0.005) nll: 0.990502 \n",
      "(GPU: 0, epoch: 1, iters: 133696, time: 0.005) nll: 0.893622 \n",
      "(GPU: 0, epoch: 1, iters: 134496, time: 0.005) nll: 0.810109 \n",
      "(GPU: 0, epoch: 1, iters: 135296, time: 0.005) nll: 0.774181 \n",
      "(GPU: 0, epoch: 1, iters: 136096, time: 0.004) nll: 0.647751 \n",
      "(GPU: 0, epoch: 1, iters: 136896, time: 0.005) nll: 0.663600 \n",
      "(GPU: 0, epoch: 1, iters: 137696, time: 0.005) nll: 1.111145 \n",
      "(GPU: 0, epoch: 1, iters: 138496, time: 0.005) nll: 0.631286 \n",
      "(GPU: 0, epoch: 1, iters: 139296, time: 0.004) nll: 0.707673 \n",
      "saving the latest model (epoch 1, total_steps 280000)\n",
      "(GPU: 0, epoch: 1, iters: 140096, time: 0.005) nll: 0.957425 \n",
      "[*] End of epoch 1 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000200\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3155/4397 [09:19<03:18,  6.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 32, time: 0.003) nll: 0.686719 \n",
      "(GPU: 0, epoch: 2, iters: 32, time: 0.003) nll: 0.556051 \n",
      "(GPU: 0, epoch: 2, iters: 192, time: 0.005) nll: 0.757711 \n",
      "(GPU: 0, epoch: 2, iters: 992, time: 0.004) nll: 0.806392 \n",
      "(GPU: 0, epoch: 2, iters: 1792, time: 0.005) nll: 1.128681 \n",
      "(GPU: 0, epoch: 2, iters: 2592, time: 0.004) nll: 1.061651 \n",
      "(GPU: 0, epoch: 2, iters: 3392, time: 0.005) nll: 0.720480 \n",
      "(GPU: 0, epoch: 2, iters: 4192, time: 0.005) nll: 0.755659 \n",
      "(GPU: 0, epoch: 2, iters: 4992, time: 0.005) nll: 0.687930 \n",
      "(GPU: 0, epoch: 2, iters: 5792, time: 0.005) nll: 0.798046 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.005) nll: 0.830494 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.008) nll: 0.825977 \n",
      "(GPU: 0, epoch: 2, iters: 6592, time: 0.008) nll: 0.594925 \n",
      "(GPU: 0, epoch: 2, iters: 7392, time: 0.004) nll: 0.807902 \n",
      "(GPU: 0, epoch: 2, iters: 8192, time: 0.005) nll: 0.809646 \n",
      "(GPU: 0, epoch: 2, iters: 8992, time: 0.004) nll: 0.972071 \n",
      "(GPU: 0, epoch: 2, iters: 9792, time: 0.005) nll: 0.678124 \n",
      "(GPU: 0, epoch: 2, iters: 10592, time: 0.004) nll: 0.666675 \n",
      "(GPU: 0, epoch: 2, iters: 11392, time: 0.005) nll: 0.602950 \n",
      "(GPU: 0, epoch: 2, iters: 12192, time: 0.004) nll: 0.799958 \n",
      "(GPU: 0, epoch: 2, iters: 12992, time: 0.005) nll: 0.676825 \n",
      "(GPU: 0, epoch: 2, iters: 13792, time: 0.005) nll: 0.664835 \n",
      "(GPU: 0, epoch: 2, iters: 14592, time: 0.005) nll: 0.939712 \n",
      "(GPU: 0, epoch: 2, iters: 15392, time: 0.004) nll: 0.612053 \n",
      "(GPU: 0, epoch: 2, iters: 16192, time: 0.005) nll: 0.783213 \n",
      "(GPU: 0, epoch: 2, iters: 16992, time: 0.005) nll: 0.715220 \n",
      "(GPU: 0, epoch: 2, iters: 17792, time: 0.005) nll: 0.887182 \n",
      "(GPU: 0, epoch: 2, iters: 18592, time: 0.004) nll: 0.840959 \n",
      "saving the latest model (epoch 2, total_steps 300000)\n",
      "(GPU: 0, epoch: 2, iters: 19392, time: 0.005) nll: 0.943524 \n",
      "(GPU: 0, epoch: 2, iters: 20192, time: 0.004) nll: 0.702611 \n",
      "(GPU: 0, epoch: 2, iters: 20992, time: 0.005) nll: 0.820963 \n",
      "(GPU: 0, epoch: 2, iters: 21792, time: 0.005) nll: 0.873308 \n",
      "(GPU: 0, epoch: 2, iters: 22592, time: 0.005) nll: 0.487701 \n",
      "(GPU: 0, epoch: 2, iters: 23392, time: 0.005) nll: 0.674838 \n",
      "(GPU: 0, epoch: 2, iters: 24192, time: 0.005) nll: 0.855577 \n",
      "(GPU: 0, epoch: 2, iters: 24992, time: 0.004) nll: 0.635796 \n",
      "(GPU: 0, epoch: 2, iters: 25792, time: 0.005) nll: 0.808424 \n",
      "(GPU: 0, epoch: 2, iters: 26592, time: 0.005) nll: 0.633575 \n",
      "(GPU: 0, epoch: 2, iters: 27392, time: 0.005) nll: 0.852392 \n",
      "(GPU: 0, epoch: 2, iters: 28192, time: 0.004) nll: 0.744414 \n",
      "(GPU: 0, epoch: 2, iters: 28992, time: 0.005) nll: 0.884775 \n",
      "(GPU: 0, epoch: 2, iters: 29792, time: 0.004) nll: 0.790103 \n",
      "(GPU: 0, epoch: 2, iters: 30592, time: 0.005) nll: 0.846904 \n",
      "(GPU: 0, epoch: 2, iters: 31392, time: 0.005) nll: 0.944144 \n",
      "(GPU: 0, epoch: 2, iters: 32192, time: 0.005) nll: 0.727405 \n",
      "(GPU: 0, epoch: 2, iters: 32992, time: 0.005) nll: 0.724893 \n",
      "(GPU: 0, epoch: 2, iters: 33792, time: 0.005) nll: 0.523993 \n",
      "(GPU: 0, epoch: 2, iters: 34592, time: 0.004) nll: 0.753283 \n",
      "(GPU: 0, epoch: 2, iters: 35392, time: 0.005) nll: 0.778850 \n",
      "(GPU: 0, epoch: 2, iters: 36192, time: 0.004) nll: 0.816899 \n",
      "(GPU: 0, epoch: 2, iters: 36992, time: 0.005) nll: 0.902417 \n",
      "(GPU: 0, epoch: 2, iters: 37792, time: 0.005) nll: 0.675076 \n",
      "(GPU: 0, epoch: 2, iters: 38592, time: 0.005) nll: 0.650191 \n",
      "saving the latest model (epoch 2, total_steps 320000)\n",
      "(GPU: 0, epoch: 2, iters: 39392, time: 0.005) nll: 0.813417 \n",
      "(GPU: 0, epoch: 2, iters: 40192, time: 0.005) nll: 1.102904 \n",
      "(GPU: 0, epoch: 2, iters: 40992, time: 0.004) nll: 0.731436 \n",
      "(GPU: 0, epoch: 2, iters: 41792, time: 0.005) nll: 0.759037 \n",
      "(GPU: 0, epoch: 2, iters: 42592, time: 0.004) nll: 0.800108 \n",
      "(GPU: 0, epoch: 2, iters: 43392, time: 0.005) nll: 0.923596 \n",
      "(GPU: 0, epoch: 2, iters: 44192, time: 0.004) nll: 0.815662 \n",
      "(GPU: 0, epoch: 2, iters: 44992, time: 0.005) nll: 0.812036 \n",
      "(GPU: 0, epoch: 2, iters: 45792, time: 0.004) nll: 0.751480 \n",
      "(GPU: 0, epoch: 2, iters: 46592, time: 0.005) nll: 0.649170 \n",
      "(GPU: 0, epoch: 2, iters: 47392, time: 0.004) nll: 0.847764 \n",
      "(GPU: 0, epoch: 2, iters: 48192, time: 0.005) nll: 0.944667 \n",
      "(GPU: 0, epoch: 2, iters: 48992, time: 0.004) nll: 0.720184 \n",
      "(GPU: 0, epoch: 2, iters: 49792, time: 0.005) nll: 0.832977 \n",
      "(GPU: 0, epoch: 2, iters: 50592, time: 0.004) nll: 0.899090 \n",
      "(GPU: 0, epoch: 2, iters: 51392, time: 0.005) nll: 0.790914 \n",
      "(GPU: 0, epoch: 2, iters: 52192, time: 0.005) nll: 0.644104 \n",
      "(GPU: 0, epoch: 2, iters: 52992, time: 0.005) nll: 1.080843 \n",
      "(GPU: 0, epoch: 2, iters: 53792, time: 0.004) nll: 0.640934 \n",
      "(GPU: 0, epoch: 2, iters: 54592, time: 0.005) nll: 0.425096 \n",
      "(GPU: 0, epoch: 2, iters: 55392, time: 0.005) nll: 0.849571 \n",
      "(GPU: 0, epoch: 2, iters: 56192, time: 0.005) nll: 0.705425 \n",
      "(GPU: 0, epoch: 2, iters: 56992, time: 0.005) nll: 0.736768 \n",
      "(GPU: 0, epoch: 2, iters: 57792, time: 0.005) nll: 0.835275 \n",
      "(GPU: 0, epoch: 2, iters: 58592, time: 0.005) nll: 0.758948 \n",
      "saving the latest model (epoch 2, total_steps 340000)\n",
      "(GPU: 0, epoch: 2, iters: 59392, time: 0.005) nll: 0.595746 \n",
      "(GPU: 0, epoch: 2, iters: 60192, time: 0.004) nll: 0.728748 \n",
      "(GPU: 0, epoch: 2, iters: 60992, time: 0.005) nll: 0.686098 \n",
      "(GPU: 0, epoch: 2, iters: 61792, time: 0.004) nll: 0.836047 \n",
      "(GPU: 0, epoch: 2, iters: 62592, time: 0.005) nll: 0.744624 \n",
      "(GPU: 0, epoch: 2, iters: 63392, time: 0.005) nll: 0.762103 \n",
      "(GPU: 0, epoch: 2, iters: 64192, time: 0.005) nll: 0.598174 \n",
      "(GPU: 0, epoch: 2, iters: 64992, time: 0.005) nll: 1.044770 \n",
      "(GPU: 0, epoch: 2, iters: 65792, time: 0.005) nll: 0.811739 \n",
      "(GPU: 0, epoch: 2, iters: 66592, time: 0.004) nll: 0.780230 \n",
      "(GPU: 0, epoch: 2, iters: 67392, time: 0.005) nll: 0.627115 \n",
      "(GPU: 0, epoch: 2, iters: 68192, time: 0.004) nll: 0.635232 \n",
      "(GPU: 0, epoch: 2, iters: 68992, time: 0.005) nll: 1.063375 \n",
      "(GPU: 0, epoch: 2, iters: 69792, time: 0.004) nll: 0.745484 \n",
      "(GPU: 0, epoch: 2, iters: 70592, time: 0.005) nll: 0.666765 \n",
      "(GPU: 0, epoch: 2, iters: 71392, time: 0.004) nll: 0.773257 \n",
      "(GPU: 0, epoch: 2, iters: 72192, time: 0.005) nll: 0.839470 \n",
      "(GPU: 0, epoch: 2, iters: 72992, time: 0.005) nll: 0.815211 \n",
      "(GPU: 0, epoch: 2, iters: 73792, time: 0.005) nll: 0.813291 \n",
      "(GPU: 0, epoch: 2, iters: 74592, time: 0.005) nll: 0.842199 \n",
      "(GPU: 0, epoch: 2, iters: 75392, time: 0.005) nll: 0.891267 \n",
      "(GPU: 0, epoch: 2, iters: 76192, time: 0.005) nll: 0.764587 \n",
      "(GPU: 0, epoch: 2, iters: 76992, time: 0.005) nll: 0.693221 \n",
      "(GPU: 0, epoch: 2, iters: 77792, time: 0.004) nll: 0.670686 \n",
      "(GPU: 0, epoch: 2, iters: 78592, time: 0.005) nll: 0.605861 \n",
      "saving the latest model (epoch 2, total_steps 360000)\n",
      "(GPU: 0, epoch: 2, iters: 79392, time: 0.005) nll: 0.804589 \n",
      "(GPU: 0, epoch: 2, iters: 80192, time: 0.005) nll: 0.755009 \n",
      "(GPU: 0, epoch: 2, iters: 80992, time: 0.005) nll: 0.711622 \n",
      "(GPU: 0, epoch: 2, iters: 81792, time: 0.005) nll: 0.495123 \n",
      "(GPU: 0, epoch: 2, iters: 82592, time: 0.004) nll: 0.596655 \n",
      "(GPU: 0, epoch: 2, iters: 83392, time: 0.005) nll: 0.876998 \n",
      "(GPU: 0, epoch: 2, iters: 84192, time: 0.005) nll: 0.927676 \n",
      "(GPU: 0, epoch: 2, iters: 84992, time: 0.005) nll: 0.862113 \n",
      "(GPU: 0, epoch: 2, iters: 85792, time: 0.004) nll: 0.662016 \n",
      "(GPU: 0, epoch: 2, iters: 86592, time: 0.005) nll: 0.858017 \n",
      "(GPU: 0, epoch: 2, iters: 87392, time: 0.005) nll: 0.951104 \n",
      "(GPU: 0, epoch: 2, iters: 88192, time: 0.005) nll: 0.633527 \n",
      "(GPU: 0, epoch: 2, iters: 88992, time: 0.004) nll: 0.768836 \n",
      "(GPU: 0, epoch: 2, iters: 89792, time: 0.005) nll: 0.895442 \n",
      "(GPU: 0, epoch: 2, iters: 90592, time: 0.004) nll: 0.768678 \n",
      "(GPU: 0, epoch: 2, iters: 91392, time: 0.005) nll: 0.767233 \n",
      "(GPU: 0, epoch: 2, iters: 92192, time: 0.005) nll: 0.795987 \n",
      "(GPU: 0, epoch: 2, iters: 92992, time: 0.005) nll: 0.977880 \n",
      "(GPU: 0, epoch: 2, iters: 93792, time: 0.005) nll: 0.925659 \n",
      "(GPU: 0, epoch: 2, iters: 94592, time: 0.005) nll: 0.731798 \n",
      "(GPU: 0, epoch: 2, iters: 95392, time: 0.004) nll: 0.637944 \n",
      "(GPU: 0, epoch: 2, iters: 96192, time: 0.005) nll: 0.674808 \n",
      "(GPU: 0, epoch: 2, iters: 96992, time: 0.005) nll: 0.642179 \n",
      "(GPU: 0, epoch: 2, iters: 97792, time: 0.005) nll: 0.662943 \n",
      "(GPU: 0, epoch: 2, iters: 98592, time: 0.004) nll: 0.564354 \n",
      "saving the latest model (epoch 2, total_steps 380000)\n",
      "(GPU: 0, epoch: 2, iters: 99392, time: 0.005) nll: 0.672951 \n",
      "(GPU: 0, epoch: 2, iters: 100192, time: 0.005) nll: 0.880311 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [13:00<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 2, iters: 100992, time: 0.005) nll: 0.980619 \n",
      "(GPU: 0, epoch: 2, iters: 101792, time: 0.004) nll: 1.000310 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.005) nll: 0.712039 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.008) nll: 0.705756 \n",
      "(GPU: 0, epoch: 2, iters: 102592, time: 0.008) nll: 0.863585 \n",
      "(GPU: 0, epoch: 2, iters: 103392, time: 0.004) nll: 0.593574 \n",
      "(GPU: 0, epoch: 2, iters: 104192, time: 0.005) nll: 0.857061 \n",
      "(GPU: 0, epoch: 2, iters: 104992, time: 0.004) nll: 0.704855 \n",
      "(GPU: 0, epoch: 2, iters: 105792, time: 0.005) nll: 0.997186 \n",
      "(GPU: 0, epoch: 2, iters: 106592, time: 0.004) nll: 0.753250 \n",
      "(GPU: 0, epoch: 2, iters: 107392, time: 0.005) nll: 0.690265 \n",
      "(GPU: 0, epoch: 2, iters: 108192, time: 0.004) nll: 0.618674 \n",
      "(GPU: 0, epoch: 2, iters: 108992, time: 0.005) nll: 0.707337 \n",
      "(GPU: 0, epoch: 2, iters: 109792, time: 0.005) nll: 1.031572 \n",
      "(GPU: 0, epoch: 2, iters: 110592, time: 0.005) nll: 0.816119 \n",
      "(GPU: 0, epoch: 2, iters: 111392, time: 0.004) nll: 0.865527 \n",
      "(GPU: 0, epoch: 2, iters: 112192, time: 0.005) nll: 0.678676 \n",
      "(GPU: 0, epoch: 2, iters: 112992, time: 0.004) nll: 0.832469 \n",
      "(GPU: 0, epoch: 2, iters: 113792, time: 0.005) nll: 0.847121 \n",
      "(GPU: 0, epoch: 2, iters: 114592, time: 0.004) nll: 0.802068 \n",
      "(GPU: 0, epoch: 2, iters: 115392, time: 0.005) nll: 0.902837 \n",
      "(GPU: 0, epoch: 2, iters: 116192, time: 0.005) nll: 0.875462 \n",
      "(GPU: 0, epoch: 2, iters: 116992, time: 0.005) nll: 0.775919 \n",
      "(GPU: 0, epoch: 2, iters: 117792, time: 0.005) nll: 0.867155 \n",
      "(GPU: 0, epoch: 2, iters: 118592, time: 0.005) nll: 0.866526 \n",
      "saving the latest model (epoch 2, total_steps 400000)\n",
      "(GPU: 0, epoch: 2, iters: 119392, time: 0.005) nll: 0.677161 \n",
      "(GPU: 0, epoch: 2, iters: 120192, time: 0.005) nll: 0.630255 \n",
      "(GPU: 0, epoch: 2, iters: 120992, time: 0.005) nll: 0.616454 \n",
      "(GPU: 0, epoch: 2, iters: 121792, time: 0.005) nll: 0.720485 \n",
      "(GPU: 0, epoch: 2, iters: 122592, time: 0.004) nll: 0.660250 \n",
      "(GPU: 0, epoch: 2, iters: 123392, time: 0.005) nll: 0.863937 \n",
      "(GPU: 0, epoch: 2, iters: 124192, time: 0.005) nll: 0.724686 \n",
      "(GPU: 0, epoch: 2, iters: 124992, time: 0.005) nll: 0.837345 \n",
      "(GPU: 0, epoch: 2, iters: 125792, time: 0.005) nll: 0.775009 \n",
      "(GPU: 0, epoch: 2, iters: 126592, time: 0.005) nll: 0.739616 \n",
      "(GPU: 0, epoch: 2, iters: 127392, time: 0.005) nll: 0.793728 \n",
      "(GPU: 0, epoch: 2, iters: 128192, time: 0.005) nll: 0.889587 \n",
      "(GPU: 0, epoch: 2, iters: 128992, time: 0.005) nll: 0.823610 \n",
      "(GPU: 0, epoch: 2, iters: 129792, time: 0.005) nll: 0.714806 \n",
      "(GPU: 0, epoch: 2, iters: 130592, time: 0.005) nll: 0.782263 \n",
      "(GPU: 0, epoch: 2, iters: 131392, time: 0.005) nll: 0.689694 \n",
      "(GPU: 0, epoch: 2, iters: 132192, time: 0.005) nll: 0.884619 \n",
      "(GPU: 0, epoch: 2, iters: 132992, time: 0.005) nll: 0.867202 \n",
      "(GPU: 0, epoch: 2, iters: 133792, time: 0.005) nll: 0.785869 \n",
      "(GPU: 0, epoch: 2, iters: 134592, time: 0.005) nll: 0.876043 \n",
      "(GPU: 0, epoch: 2, iters: 135392, time: 0.005) nll: 0.677988 \n",
      "(GPU: 0, epoch: 2, iters: 136192, time: 0.005) nll: 0.838387 \n",
      "(GPU: 0, epoch: 2, iters: 136992, time: 0.005) nll: 0.842496 \n",
      "(GPU: 0, epoch: 2, iters: 137792, time: 0.005) nll: 0.868693 \n",
      "(GPU: 0, epoch: 2, iters: 138592, time: 0.004) nll: 0.697415 \n",
      "saving the latest model (epoch 2, total_steps 420000)\n",
      "(GPU: 0, epoch: 2, iters: 139392, time: 0.005) nll: 0.800148 \n",
      "(GPU: 0, epoch: 2, iters: 140192, time: 0.005) nll: 0.883655 \n",
      "[*] End of epoch 2 / 25 \t Time Taken: 780 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000300\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3158/4397 [09:14<03:17,  6.26it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.942863 \n",
      "(GPU: 0, epoch: 3, iters: 32, time: 0.003) nll: 0.909258 \n",
      "(GPU: 0, epoch: 3, iters: 288, time: 0.005) nll: 1.005731 \n",
      "(GPU: 0, epoch: 3, iters: 1088, time: 0.005) nll: 0.606817 \n",
      "(GPU: 0, epoch: 3, iters: 1888, time: 0.004) nll: 0.712248 \n",
      "(GPU: 0, epoch: 3, iters: 2688, time: 0.005) nll: 0.740694 \n",
      "(GPU: 0, epoch: 3, iters: 3488, time: 0.004) nll: 0.906073 \n",
      "(GPU: 0, epoch: 3, iters: 4288, time: 0.005) nll: 0.670978 \n",
      "(GPU: 0, epoch: 3, iters: 5088, time: 0.005) nll: 0.787112 \n",
      "(GPU: 0, epoch: 3, iters: 5888, time: 0.005) nll: 0.769861 \n",
      "(GPU: 0, epoch: 3, iters: 6688, time: 0.005) nll: 0.643092 \n",
      "(GPU: 0, epoch: 3, iters: 7488, time: 0.005) nll: 0.714275 \n",
      "(GPU: 0, epoch: 3, iters: 8288, time: 0.004) nll: 0.766458 \n",
      "(GPU: 0, epoch: 3, iters: 9088, time: 0.005) nll: 0.643294 \n",
      "(GPU: 0, epoch: 3, iters: 9888, time: 0.004) nll: 0.635087 \n",
      "(GPU: 0, epoch: 3, iters: 10688, time: 0.005) nll: 0.795704 \n",
      "(GPU: 0, epoch: 3, iters: 11488, time: 0.005) nll: 0.900536 \n",
      "(GPU: 0, epoch: 3, iters: 12288, time: 0.005) nll: 0.837160 \n",
      "(GPU: 0, epoch: 3, iters: 13088, time: 0.005) nll: 0.761504 \n",
      "(GPU: 0, epoch: 3, iters: 13888, time: 0.005) nll: 0.969965 \n",
      "(GPU: 0, epoch: 3, iters: 14688, time: 0.005) nll: 0.792599 \n",
      "(GPU: 0, epoch: 3, iters: 15488, time: 0.005) nll: 0.639537 \n",
      "(GPU: 0, epoch: 3, iters: 16288, time: 0.004) nll: 0.838316 \n",
      "(GPU: 0, epoch: 3, iters: 17088, time: 0.005) nll: 0.884394 \n",
      "(GPU: 0, epoch: 3, iters: 17888, time: 0.004) nll: 0.593304 \n",
      "saving the latest model (epoch 3, total_steps 440000)\n",
      "(GPU: 0, epoch: 3, iters: 18688, time: 0.005) nll: 0.841288 \n",
      "(GPU: 0, epoch: 3, iters: 19488, time: 0.005) nll: 0.896184 \n",
      "(GPU: 0, epoch: 3, iters: 20288, time: 0.005) nll: 0.816753 \n",
      "(GPU: 0, epoch: 3, iters: 21088, time: 0.004) nll: 0.613968 \n",
      "(GPU: 0, epoch: 3, iters: 21888, time: 0.005) nll: 0.741789 \n",
      "(GPU: 0, epoch: 3, iters: 22688, time: 0.005) nll: 0.732472 \n",
      "(GPU: 0, epoch: 3, iters: 23488, time: 0.005) nll: 0.945621 \n",
      "(GPU: 0, epoch: 3, iters: 24288, time: 0.004) nll: 0.642354 \n",
      "(GPU: 0, epoch: 3, iters: 25088, time: 0.005) nll: 1.007162 \n",
      "(GPU: 0, epoch: 3, iters: 25888, time: 0.004) nll: 0.618563 \n",
      "(GPU: 0, epoch: 3, iters: 26688, time: 0.005) nll: 1.010953 \n",
      "(GPU: 0, epoch: 3, iters: 27488, time: 0.005) nll: 0.671939 \n",
      "(GPU: 0, epoch: 3, iters: 28288, time: 0.005) nll: 0.932533 \n",
      "(GPU: 0, epoch: 3, iters: 29088, time: 0.004) nll: 0.868145 \n",
      "(GPU: 0, epoch: 3, iters: 29888, time: 0.005) nll: 0.881624 \n",
      "(GPU: 0, epoch: 3, iters: 30688, time: 0.004) nll: 0.691871 \n",
      "(GPU: 0, epoch: 3, iters: 31488, time: 0.005) nll: 0.790204 \n",
      "(GPU: 0, epoch: 3, iters: 32288, time: 0.005) nll: 0.802853 \n",
      "(GPU: 0, epoch: 3, iters: 33088, time: 0.005) nll: 0.955296 \n",
      "(GPU: 0, epoch: 3, iters: 33888, time: 0.004) nll: 0.531654 \n",
      "(GPU: 0, epoch: 3, iters: 34688, time: 0.005) nll: 0.790072 \n",
      "(GPU: 0, epoch: 3, iters: 35488, time: 0.004) nll: 0.693447 \n",
      "(GPU: 0, epoch: 3, iters: 36288, time: 0.005) nll: 0.945646 \n",
      "(GPU: 0, epoch: 3, iters: 37088, time: 0.004) nll: 0.725564 \n",
      "(GPU: 0, epoch: 3, iters: 37888, time: 0.005) nll: 0.738467 \n",
      "saving the latest model (epoch 3, total_steps 460000)\n",
      "(GPU: 0, epoch: 3, iters: 38688, time: 0.005) nll: 0.900727 \n",
      "(GPU: 0, epoch: 3, iters: 39488, time: 0.005) nll: 0.841457 \n",
      "(GPU: 0, epoch: 3, iters: 40288, time: 0.005) nll: 0.851369 \n",
      "(GPU: 0, epoch: 3, iters: 41088, time: 0.005) nll: 0.701977 \n",
      "(GPU: 0, epoch: 3, iters: 41888, time: 0.005) nll: 0.806757 \n",
      "(GPU: 0, epoch: 3, iters: 42688, time: 0.005) nll: 0.938009 \n",
      "(GPU: 0, epoch: 3, iters: 43488, time: 0.005) nll: 0.779214 \n",
      "(GPU: 0, epoch: 3, iters: 44288, time: 0.005) nll: 0.493534 \n",
      "(GPU: 0, epoch: 3, iters: 45088, time: 0.004) nll: 0.960896 \n",
      "(GPU: 0, epoch: 3, iters: 45888, time: 0.005) nll: 0.588002 \n",
      "(GPU: 0, epoch: 3, iters: 46688, time: 0.005) nll: 0.787432 \n",
      "(GPU: 0, epoch: 3, iters: 47488, time: 0.005) nll: 0.576867 \n",
      "(GPU: 0, epoch: 3, iters: 48288, time: 0.005) nll: 0.566609 \n",
      "(GPU: 0, epoch: 3, iters: 49088, time: 0.005) nll: 0.806175 \n",
      "(GPU: 0, epoch: 3, iters: 49888, time: 0.005) nll: 0.779028 \n",
      "(GPU: 0, epoch: 3, iters: 50688, time: 0.005) nll: 0.823705 \n",
      "(GPU: 0, epoch: 3, iters: 51488, time: 0.005) nll: 0.885065 \n",
      "(GPU: 0, epoch: 3, iters: 52288, time: 0.005) nll: 0.795116 \n",
      "(GPU: 0, epoch: 3, iters: 53088, time: 0.005) nll: 0.811599 \n",
      "(GPU: 0, epoch: 3, iters: 53888, time: 0.005) nll: 0.880840 \n",
      "(GPU: 0, epoch: 3, iters: 54688, time: 0.004) nll: 0.637020 \n",
      "(GPU: 0, epoch: 3, iters: 55488, time: 0.005) nll: 0.828644 \n",
      "(GPU: 0, epoch: 3, iters: 56288, time: 0.005) nll: 0.659530 \n",
      "(GPU: 0, epoch: 3, iters: 57088, time: 0.005) nll: 0.846369 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.005) nll: 0.587764 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.008) nll: 0.583906 \n",
      "(GPU: 0, epoch: 3, iters: 57888, time: 0.008) nll: 0.713342 \n",
      "saving the latest model (epoch 3, total_steps 480000)\n",
      "(GPU: 0, epoch: 3, iters: 58688, time: 0.005) nll: 0.754010 \n",
      "(GPU: 0, epoch: 3, iters: 59488, time: 0.005) nll: 0.658210 \n",
      "(GPU: 0, epoch: 3, iters: 60288, time: 0.005) nll: 0.829055 \n",
      "(GPU: 0, epoch: 3, iters: 61088, time: 0.005) nll: 0.801525 \n",
      "(GPU: 0, epoch: 3, iters: 61888, time: 0.005) nll: 0.922566 \n",
      "(GPU: 0, epoch: 3, iters: 62688, time: 0.004) nll: 0.713088 \n",
      "(GPU: 0, epoch: 3, iters: 63488, time: 0.005) nll: 0.971091 \n",
      "(GPU: 0, epoch: 3, iters: 64288, time: 0.004) nll: 0.874496 \n",
      "(GPU: 0, epoch: 3, iters: 65088, time: 0.005) nll: 0.670350 \n",
      "(GPU: 0, epoch: 3, iters: 65888, time: 0.004) nll: 0.820771 \n",
      "(GPU: 0, epoch: 3, iters: 66688, time: 0.005) nll: 0.856912 \n",
      "(GPU: 0, epoch: 3, iters: 67488, time: 0.004) nll: 0.730086 \n",
      "(GPU: 0, epoch: 3, iters: 68288, time: 0.005) nll: 0.962930 \n",
      "(GPU: 0, epoch: 3, iters: 69088, time: 0.005) nll: 0.723630 \n",
      "(GPU: 0, epoch: 3, iters: 69888, time: 0.005) nll: 0.649798 \n",
      "(GPU: 0, epoch: 3, iters: 70688, time: 0.005) nll: 0.812026 \n",
      "(GPU: 0, epoch: 3, iters: 71488, time: 0.005) nll: 0.912501 \n",
      "(GPU: 0, epoch: 3, iters: 72288, time: 0.005) nll: 0.655941 \n",
      "(GPU: 0, epoch: 3, iters: 73088, time: 0.005) nll: 0.687428 \n",
      "(GPU: 0, epoch: 3, iters: 73888, time: 0.004) nll: 0.704534 \n",
      "(GPU: 0, epoch: 3, iters: 74688, time: 0.005) nll: 0.777710 \n",
      "(GPU: 0, epoch: 3, iters: 75488, time: 0.005) nll: 0.723048 \n",
      "(GPU: 0, epoch: 3, iters: 76288, time: 0.005) nll: 0.835362 \n",
      "(GPU: 0, epoch: 3, iters: 77088, time: 0.004) nll: 0.882882 \n",
      "(GPU: 0, epoch: 3, iters: 77888, time: 0.005) nll: 0.752029 \n",
      "saving the latest model (epoch 3, total_steps 500000)\n",
      "(GPU: 0, epoch: 3, iters: 78688, time: 0.004) nll: 0.874768 \n",
      "(GPU: 0, epoch: 3, iters: 79488, time: 0.005) nll: 0.803320 \n",
      "(GPU: 0, epoch: 3, iters: 80288, time: 0.004) nll: 0.892470 \n",
      "(GPU: 0, epoch: 3, iters: 81088, time: 0.005) nll: 0.969721 \n",
      "(GPU: 0, epoch: 3, iters: 81888, time: 0.004) nll: 0.584604 \n",
      "(GPU: 0, epoch: 3, iters: 82688, time: 0.005) nll: 0.886624 \n",
      "(GPU: 0, epoch: 3, iters: 83488, time: 0.005) nll: 0.751525 \n",
      "(GPU: 0, epoch: 3, iters: 84288, time: 0.005) nll: 0.700574 \n",
      "(GPU: 0, epoch: 3, iters: 85088, time: 0.004) nll: 0.855679 \n",
      "(GPU: 0, epoch: 3, iters: 85888, time: 0.005) nll: 0.589754 \n",
      "(GPU: 0, epoch: 3, iters: 86688, time: 0.005) nll: 0.938518 \n",
      "(GPU: 0, epoch: 3, iters: 87488, time: 0.005) nll: 0.690879 \n",
      "(GPU: 0, epoch: 3, iters: 88288, time: 0.005) nll: 0.648103 \n",
      "(GPU: 0, epoch: 3, iters: 89088, time: 0.005) nll: 0.683459 \n",
      "(GPU: 0, epoch: 3, iters: 89888, time: 0.005) nll: 0.613272 \n",
      "(GPU: 0, epoch: 3, iters: 90688, time: 0.005) nll: 0.846372 \n",
      "(GPU: 0, epoch: 3, iters: 91488, time: 0.004) nll: 0.815850 \n",
      "(GPU: 0, epoch: 3, iters: 92288, time: 0.005) nll: 0.664212 \n",
      "(GPU: 0, epoch: 3, iters: 93088, time: 0.004) nll: 0.815159 \n",
      "(GPU: 0, epoch: 3, iters: 93888, time: 0.005) nll: 0.893731 \n",
      "(GPU: 0, epoch: 3, iters: 94688, time: 0.004) nll: 0.505340 \n",
      "(GPU: 0, epoch: 3, iters: 95488, time: 0.005) nll: 0.629068 \n",
      "(GPU: 0, epoch: 3, iters: 96288, time: 0.005) nll: 1.104926 \n",
      "(GPU: 0, epoch: 3, iters: 97088, time: 0.005) nll: 0.500631 \n",
      "(GPU: 0, epoch: 3, iters: 97888, time: 0.004) nll: 0.946866 \n",
      "saving the latest model (epoch 3, total_steps 520000)\n",
      "(GPU: 0, epoch: 3, iters: 98688, time: 0.005) nll: 0.885412 \n",
      "(GPU: 0, epoch: 3, iters: 99488, time: 0.004) nll: 0.772653 \n",
      "(GPU: 0, epoch: 3, iters: 100288, time: 0.005) nll: 0.843243 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 3, iters: 101088, time: 0.005) nll: 1.365493 \n",
      "(GPU: 0, epoch: 3, iters: 101888, time: 0.005) nll: 0.788464 \n",
      "(GPU: 0, epoch: 3, iters: 102688, time: 0.004) nll: 0.734257 \n",
      "(GPU: 0, epoch: 3, iters: 103488, time: 0.005) nll: 0.920869 \n",
      "(GPU: 0, epoch: 3, iters: 104288, time: 0.004) nll: 0.905194 \n",
      "(GPU: 0, epoch: 3, iters: 105088, time: 0.005) nll: 0.729970 \n",
      "(GPU: 0, epoch: 3, iters: 105888, time: 0.005) nll: 0.742344 \n",
      "(GPU: 0, epoch: 3, iters: 106688, time: 0.005) nll: 1.009331 \n",
      "(GPU: 0, epoch: 3, iters: 107488, time: 0.005) nll: 0.650519 \n",
      "(GPU: 0, epoch: 3, iters: 108288, time: 0.005) nll: 0.759852 \n",
      "(GPU: 0, epoch: 3, iters: 109088, time: 0.004) nll: 0.735409 \n",
      "(GPU: 0, epoch: 3, iters: 109888, time: 0.005) nll: 0.990322 \n",
      "(GPU: 0, epoch: 3, iters: 110688, time: 0.005) nll: 1.045506 \n",
      "(GPU: 0, epoch: 3, iters: 111488, time: 0.005) nll: 0.870019 \n",
      "(GPU: 0, epoch: 3, iters: 112288, time: 0.004) nll: 0.600917 \n",
      "(GPU: 0, epoch: 3, iters: 113088, time: 0.005) nll: 0.702131 \n",
      "(GPU: 0, epoch: 3, iters: 113888, time: 0.004) nll: 0.845755 \n",
      "(GPU: 0, epoch: 3, iters: 114688, time: 0.005) nll: 0.889809 \n",
      "(GPU: 0, epoch: 3, iters: 115488, time: 0.005) nll: 0.762027 \n",
      "(GPU: 0, epoch: 3, iters: 116288, time: 0.005) nll: 0.738299 \n",
      "(GPU: 0, epoch: 3, iters: 117088, time: 0.004) nll: 0.973652 \n",
      "(GPU: 0, epoch: 3, iters: 117888, time: 0.005) nll: 0.838067 \n",
      "saving the latest model (epoch 3, total_steps 540000)\n",
      "(GPU: 0, epoch: 3, iters: 118688, time: 0.004) nll: 0.926861 \n",
      "(GPU: 0, epoch: 3, iters: 119488, time: 0.005) nll: 0.882229 \n",
      "(GPU: 0, epoch: 3, iters: 120288, time: 0.004) nll: 0.761657 \n",
      "(GPU: 0, epoch: 3, iters: 121088, time: 0.005) nll: 0.637751 \n",
      "(GPU: 0, epoch: 3, iters: 121888, time: 0.005) nll: 0.768112 \n",
      "(GPU: 0, epoch: 3, iters: 122688, time: 0.005) nll: 0.763468 \n",
      "(GPU: 0, epoch: 3, iters: 123488, time: 0.004) nll: 0.787311 \n",
      "(GPU: 0, epoch: 3, iters: 124288, time: 0.005) nll: 0.667756 \n",
      "(GPU: 0, epoch: 3, iters: 125088, time: 0.004) nll: 0.646104 \n",
      "(GPU: 0, epoch: 3, iters: 125888, time: 0.005) nll: 0.781453 \n",
      "(GPU: 0, epoch: 3, iters: 126688, time: 0.004) nll: 0.950281 \n",
      "(GPU: 0, epoch: 3, iters: 127488, time: 0.005) nll: 0.922170 \n",
      "(GPU: 0, epoch: 3, iters: 128288, time: 0.004) nll: 0.659292 \n",
      "(GPU: 0, epoch: 3, iters: 129088, time: 0.005) nll: 0.998570 \n",
      "(GPU: 0, epoch: 3, iters: 129888, time: 0.004) nll: 0.757310 \n",
      "(GPU: 0, epoch: 3, iters: 130688, time: 0.005) nll: 0.758360 \n",
      "(GPU: 0, epoch: 3, iters: 131488, time: 0.004) nll: 0.814568 \n",
      "(GPU: 0, epoch: 3, iters: 132288, time: 0.005) nll: 0.933104 \n",
      "(GPU: 0, epoch: 3, iters: 133088, time: 0.004) nll: 0.765413 \n",
      "(GPU: 0, epoch: 3, iters: 133888, time: 0.005) nll: 0.771742 \n",
      "(GPU: 0, epoch: 3, iters: 134688, time: 0.004) nll: 0.897693 \n",
      "(GPU: 0, epoch: 3, iters: 135488, time: 0.005) nll: 0.808214 \n",
      "(GPU: 0, epoch: 3, iters: 136288, time: 0.004) nll: 0.713813 \n",
      "(GPU: 0, epoch: 3, iters: 137088, time: 0.005) nll: 0.750618 \n",
      "(GPU: 0, epoch: 3, iters: 137888, time: 0.004) nll: 0.680095 \n",
      "saving the latest model (epoch 3, total_steps 560000)\n",
      "(GPU: 0, epoch: 3, iters: 138688, time: 0.005) nll: 0.718541 \n",
      "(GPU: 0, epoch: 3, iters: 139488, time: 0.004) nll: 0.801167 \n",
      "(GPU: 0, epoch: 3, iters: 140288, time: 0.005) nll: 0.921052 \n",
      "saving the model at the end of epoch 3, iters 562816\n",
      "([test] GPU: 0, epoch: 3) \n",
      "OrderedDict()\n",
      "[*] End of epoch 3 / 25 \t Time Taken: 790 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000400\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3161/4397 [09:13<03:16,  6.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 32, time: 0.003) nll: 0.940915 \n",
      "(GPU: 0, epoch: 4, iters: 32, time: 0.003) nll: 0.890584 \n",
      "(GPU: 0, epoch: 4, iters: 384, time: 0.005) nll: 0.579666 \n",
      "(GPU: 0, epoch: 4, iters: 1184, time: 0.005) nll: 0.845888 \n",
      "(GPU: 0, epoch: 4, iters: 1984, time: 0.005) nll: 0.552990 \n",
      "(GPU: 0, epoch: 4, iters: 2784, time: 0.004) nll: 1.000596 \n",
      "(GPU: 0, epoch: 4, iters: 3584, time: 0.005) nll: 0.760769 \n",
      "(GPU: 0, epoch: 4, iters: 4384, time: 0.005) nll: 0.509745 \n",
      "(GPU: 0, epoch: 4, iters: 5184, time: 0.005) nll: 0.862248 \n",
      "(GPU: 0, epoch: 4, iters: 5984, time: 0.005) nll: 0.787082 \n",
      "(GPU: 0, epoch: 4, iters: 6784, time: 0.005) nll: 0.820913 \n",
      "(GPU: 0, epoch: 4, iters: 7584, time: 0.004) nll: 0.442738 \n",
      "(GPU: 0, epoch: 4, iters: 8384, time: 0.005) nll: 1.080022 \n",
      "(GPU: 0, epoch: 4, iters: 9184, time: 0.004) nll: 0.824583 \n",
      "(GPU: 0, epoch: 4, iters: 9984, time: 0.005) nll: 0.925353 \n",
      "(GPU: 0, epoch: 4, iters: 10784, time: 0.004) nll: 0.709244 \n",
      "(GPU: 0, epoch: 4, iters: 11584, time: 0.005) nll: 0.764322 \n",
      "(GPU: 0, epoch: 4, iters: 12384, time: 0.005) nll: 0.865112 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.005) nll: 0.693390 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.008) nll: 0.687802 \n",
      "(GPU: 0, epoch: 4, iters: 13184, time: 0.008) nll: 0.685777 \n",
      "(GPU: 0, epoch: 4, iters: 13984, time: 0.004) nll: 0.764211 \n",
      "(GPU: 0, epoch: 4, iters: 14784, time: 0.005) nll: 0.598944 \n",
      "(GPU: 0, epoch: 4, iters: 15584, time: 0.004) nll: 0.736633 \n",
      "(GPU: 0, epoch: 4, iters: 16384, time: 0.005) nll: 0.549884 \n",
      "(GPU: 0, epoch: 4, iters: 17184, time: 0.005) nll: 0.775532 \n",
      "saving the latest model (epoch 4, total_steps 580000)\n",
      "(GPU: 0, epoch: 4, iters: 17984, time: 0.005) nll: 0.667888 \n",
      "(GPU: 0, epoch: 4, iters: 18784, time: 0.004) nll: 0.886270 \n",
      "(GPU: 0, epoch: 4, iters: 19584, time: 0.005) nll: 0.737436 \n",
      "(GPU: 0, epoch: 4, iters: 20384, time: 0.005) nll: 0.678028 \n",
      "(GPU: 0, epoch: 4, iters: 21184, time: 0.005) nll: 0.466154 \n",
      "(GPU: 0, epoch: 4, iters: 21984, time: 0.005) nll: 0.724547 \n",
      "(GPU: 0, epoch: 4, iters: 22784, time: 0.005) nll: 0.875490 \n",
      "(GPU: 0, epoch: 4, iters: 23584, time: 0.005) nll: 0.897668 \n",
      "(GPU: 0, epoch: 4, iters: 24384, time: 0.005) nll: 0.698132 \n",
      "(GPU: 0, epoch: 4, iters: 25184, time: 0.004) nll: 0.722280 \n",
      "(GPU: 0, epoch: 4, iters: 25984, time: 0.005) nll: 0.628882 \n",
      "(GPU: 0, epoch: 4, iters: 26784, time: 0.005) nll: 0.986503 \n",
      "(GPU: 0, epoch: 4, iters: 27584, time: 0.005) nll: 0.917819 \n",
      "(GPU: 0, epoch: 4, iters: 28384, time: 0.005) nll: 0.838955 \n",
      "(GPU: 0, epoch: 4, iters: 29184, time: 0.005) nll: 1.068954 \n",
      "(GPU: 0, epoch: 4, iters: 29984, time: 0.004) nll: 1.060608 \n",
      "(GPU: 0, epoch: 4, iters: 30784, time: 0.005) nll: 0.582990 \n",
      "(GPU: 0, epoch: 4, iters: 31584, time: 0.004) nll: 0.903956 \n",
      "(GPU: 0, epoch: 4, iters: 32384, time: 0.005) nll: 0.821473 \n",
      "(GPU: 0, epoch: 4, iters: 33184, time: 0.005) nll: 0.846229 \n",
      "(GPU: 0, epoch: 4, iters: 33984, time: 0.005) nll: 0.722506 \n",
      "(GPU: 0, epoch: 4, iters: 34784, time: 0.004) nll: 0.706681 \n",
      "(GPU: 0, epoch: 4, iters: 35584, time: 0.005) nll: 0.622769 \n",
      "(GPU: 0, epoch: 4, iters: 36384, time: 0.004) nll: 0.762207 \n",
      "(GPU: 0, epoch: 4, iters: 37184, time: 0.005) nll: 1.001748 \n",
      "saving the latest model (epoch 4, total_steps 600000)\n",
      "(GPU: 0, epoch: 4, iters: 37984, time: 0.005) nll: 0.778821 \n",
      "(GPU: 0, epoch: 4, iters: 38784, time: 0.005) nll: 0.734267 \n",
      "(GPU: 0, epoch: 4, iters: 39584, time: 0.005) nll: 0.824800 \n",
      "(GPU: 0, epoch: 4, iters: 40384, time: 0.005) nll: 0.791661 \n",
      "(GPU: 0, epoch: 4, iters: 41184, time: 0.004) nll: 0.839381 \n",
      "(GPU: 0, epoch: 4, iters: 41984, time: 0.005) nll: 0.693842 \n",
      "(GPU: 0, epoch: 4, iters: 42784, time: 0.005) nll: 0.727863 \n",
      "(GPU: 0, epoch: 4, iters: 43584, time: 0.005) nll: 0.728139 \n",
      "(GPU: 0, epoch: 4, iters: 44384, time: 0.005) nll: 0.461671 \n",
      "(GPU: 0, epoch: 4, iters: 45184, time: 0.005) nll: 0.744435 \n",
      "(GPU: 0, epoch: 4, iters: 45984, time: 0.004) nll: 0.565072 \n",
      "(GPU: 0, epoch: 4, iters: 46784, time: 0.005) nll: 0.745095 \n",
      "(GPU: 0, epoch: 4, iters: 47584, time: 0.004) nll: 0.939637 \n",
      "(GPU: 0, epoch: 4, iters: 48384, time: 0.005) nll: 1.133032 \n",
      "(GPU: 0, epoch: 4, iters: 49184, time: 0.004) nll: 0.950025 \n",
      "(GPU: 0, epoch: 4, iters: 49984, time: 0.005) nll: 0.826323 \n",
      "(GPU: 0, epoch: 4, iters: 50784, time: 0.005) nll: 0.942824 \n",
      "(GPU: 0, epoch: 4, iters: 51584, time: 0.005) nll: 0.726108 \n",
      "(GPU: 0, epoch: 4, iters: 52384, time: 0.004) nll: 0.857603 \n",
      "(GPU: 0, epoch: 4, iters: 53184, time: 0.005) nll: 0.666932 \n",
      "(GPU: 0, epoch: 4, iters: 53984, time: 0.005) nll: 0.757963 \n",
      "(GPU: 0, epoch: 4, iters: 54784, time: 0.005) nll: 0.739720 \n",
      "(GPU: 0, epoch: 4, iters: 55584, time: 0.004) nll: 0.677955 \n",
      "(GPU: 0, epoch: 4, iters: 56384, time: 0.005) nll: 0.877946 \n",
      "(GPU: 0, epoch: 4, iters: 57184, time: 0.004) nll: 0.772257 \n",
      "saving the latest model (epoch 4, total_steps 620000)\n",
      "(GPU: 0, epoch: 4, iters: 57984, time: 0.005) nll: 0.639216 \n",
      "(GPU: 0, epoch: 4, iters: 58784, time: 0.004) nll: 0.712822 \n",
      "(GPU: 0, epoch: 4, iters: 59584, time: 0.005) nll: 0.819839 \n",
      "(GPU: 0, epoch: 4, iters: 60384, time: 0.005) nll: 0.782874 \n",
      "(GPU: 0, epoch: 4, iters: 61184, time: 0.005) nll: 0.693838 \n",
      "(GPU: 0, epoch: 4, iters: 61984, time: 0.004) nll: 0.648629 \n",
      "(GPU: 0, epoch: 4, iters: 62784, time: 0.005) nll: 0.824159 \n",
      "(GPU: 0, epoch: 4, iters: 63584, time: 0.004) nll: 0.771451 \n",
      "(GPU: 0, epoch: 4, iters: 64384, time: 0.005) nll: 0.814184 \n",
      "(GPU: 0, epoch: 4, iters: 65184, time: 0.005) nll: 0.644209 \n",
      "(GPU: 0, epoch: 4, iters: 65984, time: 0.005) nll: 0.802970 \n",
      "(GPU: 0, epoch: 4, iters: 66784, time: 0.004) nll: 0.795688 \n",
      "(GPU: 0, epoch: 4, iters: 67584, time: 0.005) nll: 0.777288 \n",
      "(GPU: 0, epoch: 4, iters: 68384, time: 0.004) nll: 0.899443 \n",
      "(GPU: 0, epoch: 4, iters: 69184, time: 0.005) nll: 0.983643 \n",
      "(GPU: 0, epoch: 4, iters: 69984, time: 0.005) nll: 0.614318 \n",
      "(GPU: 0, epoch: 4, iters: 70784, time: 0.005) nll: 0.849654 \n",
      "(GPU: 0, epoch: 4, iters: 71584, time: 0.005) nll: 0.870125 \n",
      "(GPU: 0, epoch: 4, iters: 72384, time: 0.005) nll: 0.635148 \n",
      "(GPU: 0, epoch: 4, iters: 73184, time: 0.005) nll: 0.843700 \n",
      "(GPU: 0, epoch: 4, iters: 73984, time: 0.005) nll: 0.837062 \n",
      "(GPU: 0, epoch: 4, iters: 74784, time: 0.005) nll: 0.671298 \n",
      "(GPU: 0, epoch: 4, iters: 75584, time: 0.005) nll: 0.562637 \n",
      "(GPU: 0, epoch: 4, iters: 76384, time: 0.005) nll: 0.931277 \n",
      "(GPU: 0, epoch: 4, iters: 77184, time: 0.005) nll: 0.836133 \n",
      "saving the latest model (epoch 4, total_steps 640000)\n",
      "(GPU: 0, epoch: 4, iters: 77984, time: 0.005) nll: 0.777526 \n",
      "(GPU: 0, epoch: 4, iters: 78784, time: 0.005) nll: 0.777534 \n",
      "(GPU: 0, epoch: 4, iters: 79584, time: 0.004) nll: 0.647885 \n",
      "(GPU: 0, epoch: 4, iters: 80384, time: 0.005) nll: 0.865242 \n",
      "(GPU: 0, epoch: 4, iters: 81184, time: 0.005) nll: 0.654699 \n",
      "(GPU: 0, epoch: 4, iters: 81984, time: 0.005) nll: 0.751528 \n",
      "(GPU: 0, epoch: 4, iters: 82784, time: 0.005) nll: 0.668530 \n",
      "(GPU: 0, epoch: 4, iters: 83584, time: 0.005) nll: 0.796811 \n",
      "(GPU: 0, epoch: 4, iters: 84384, time: 0.005) nll: 0.745992 \n",
      "(GPU: 0, epoch: 4, iters: 85184, time: 0.005) nll: 0.738898 \n",
      "(GPU: 0, epoch: 4, iters: 85984, time: 0.004) nll: 0.689500 \n",
      "(GPU: 0, epoch: 4, iters: 86784, time: 0.005) nll: 0.719257 \n",
      "(GPU: 0, epoch: 4, iters: 87584, time: 0.004) nll: 0.846727 \n",
      "(GPU: 0, epoch: 4, iters: 88384, time: 0.005) nll: 0.759074 \n",
      "(GPU: 0, epoch: 4, iters: 89184, time: 0.004) nll: 1.040622 \n",
      "(GPU: 0, epoch: 4, iters: 89984, time: 0.005) nll: 0.757454 \n",
      "(GPU: 0, epoch: 4, iters: 90784, time: 0.004) nll: 0.722150 \n",
      "(GPU: 0, epoch: 4, iters: 91584, time: 0.005) nll: 0.646461 \n",
      "(GPU: 0, epoch: 4, iters: 92384, time: 0.005) nll: 0.752757 \n",
      "(GPU: 0, epoch: 4, iters: 93184, time: 0.005) nll: 0.619057 \n",
      "(GPU: 0, epoch: 4, iters: 93984, time: 0.005) nll: 0.857982 \n",
      "(GPU: 0, epoch: 4, iters: 94784, time: 0.005) nll: 0.584345 \n",
      "(GPU: 0, epoch: 4, iters: 95584, time: 0.005) nll: 0.878137 \n",
      "(GPU: 0, epoch: 4, iters: 96384, time: 0.005) nll: 0.881282 \n",
      "(GPU: 0, epoch: 4, iters: 97184, time: 0.004) nll: 0.734451 \n",
      "saving the latest model (epoch 4, total_steps 660000)\n",
      "(GPU: 0, epoch: 4, iters: 97984, time: 0.005) nll: 0.814183 \n",
      "(GPU: 0, epoch: 4, iters: 98784, time: 0.004) nll: 0.580455 \n",
      "(GPU: 0, epoch: 4, iters: 99584, time: 0.005) nll: 0.843055 \n",
      "(GPU: 0, epoch: 4, iters: 100384, time: 0.005) nll: 0.411558 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:50<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 4, iters: 101184, time: 0.005) nll: 0.867650 \n",
      "(GPU: 0, epoch: 4, iters: 101984, time: 0.005) nll: 0.955882 \n",
      "(GPU: 0, epoch: 4, iters: 102784, time: 0.005) nll: 1.033851 \n",
      "(GPU: 0, epoch: 4, iters: 103584, time: 0.004) nll: 0.829268 \n",
      "(GPU: 0, epoch: 4, iters: 104384, time: 0.005) nll: 0.663909 \n",
      "(GPU: 0, epoch: 4, iters: 105184, time: 0.005) nll: 0.792350 \n",
      "(GPU: 0, epoch: 4, iters: 105984, time: 0.005) nll: 0.866975 \n",
      "(GPU: 0, epoch: 4, iters: 106784, time: 0.004) nll: 0.878471 \n",
      "(GPU: 0, epoch: 4, iters: 107584, time: 0.005) nll: 0.725259 \n",
      "(GPU: 0, epoch: 4, iters: 108384, time: 0.004) nll: 0.839402 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.005) nll: 0.754104 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.008) nll: 0.749629 \n",
      "(GPU: 0, epoch: 4, iters: 109184, time: 0.008) nll: 0.925426 \n",
      "(GPU: 0, epoch: 4, iters: 109984, time: 0.004) nll: 0.837962 \n",
      "(GPU: 0, epoch: 4, iters: 110784, time: 0.005) nll: 0.598414 \n",
      "(GPU: 0, epoch: 4, iters: 111584, time: 0.005) nll: 0.761512 \n",
      "(GPU: 0, epoch: 4, iters: 112384, time: 0.005) nll: 0.729112 \n",
      "(GPU: 0, epoch: 4, iters: 113184, time: 0.004) nll: 0.787929 \n",
      "(GPU: 0, epoch: 4, iters: 113984, time: 0.005) nll: 0.731365 \n",
      "(GPU: 0, epoch: 4, iters: 114784, time: 0.004) nll: 0.685623 \n",
      "(GPU: 0, epoch: 4, iters: 115584, time: 0.005) nll: 0.884664 \n",
      "(GPU: 0, epoch: 4, iters: 116384, time: 0.005) nll: 0.690502 \n",
      "(GPU: 0, epoch: 4, iters: 117184, time: 0.005) nll: 0.971477 \n",
      "saving the latest model (epoch 4, total_steps 680000)\n",
      "(GPU: 0, epoch: 4, iters: 117984, time: 0.004) nll: 0.596971 \n",
      "(GPU: 0, epoch: 4, iters: 118784, time: 0.005) nll: 0.863042 \n",
      "(GPU: 0, epoch: 4, iters: 119584, time: 0.005) nll: 0.707947 \n",
      "(GPU: 0, epoch: 4, iters: 120384, time: 0.005) nll: 0.588198 \n",
      "(GPU: 0, epoch: 4, iters: 121184, time: 0.005) nll: 0.894059 \n",
      "(GPU: 0, epoch: 4, iters: 121984, time: 0.005) nll: 0.893445 \n",
      "(GPU: 0, epoch: 4, iters: 122784, time: 0.005) nll: 0.686553 \n",
      "(GPU: 0, epoch: 4, iters: 123584, time: 0.005) nll: 1.012979 \n",
      "(GPU: 0, epoch: 4, iters: 124384, time: 0.005) nll: 0.625156 \n",
      "(GPU: 0, epoch: 4, iters: 125184, time: 0.005) nll: 0.795353 \n",
      "(GPU: 0, epoch: 4, iters: 125984, time: 0.004) nll: 0.752055 \n",
      "(GPU: 0, epoch: 4, iters: 126784, time: 0.005) nll: 0.792988 \n",
      "(GPU: 0, epoch: 4, iters: 127584, time: 0.005) nll: 1.013923 \n",
      "(GPU: 0, epoch: 4, iters: 128384, time: 0.005) nll: 0.680082 \n",
      "(GPU: 0, epoch: 4, iters: 129184, time: 0.005) nll: 0.615583 \n",
      "(GPU: 0, epoch: 4, iters: 129984, time: 0.005) nll: 0.893085 \n",
      "(GPU: 0, epoch: 4, iters: 130784, time: 0.004) nll: 0.813396 \n",
      "(GPU: 0, epoch: 4, iters: 131584, time: 0.005) nll: 0.876512 \n",
      "(GPU: 0, epoch: 4, iters: 132384, time: 0.004) nll: 0.727108 \n",
      "(GPU: 0, epoch: 4, iters: 133184, time: 0.005) nll: 0.711474 \n",
      "(GPU: 0, epoch: 4, iters: 133984, time: 0.004) nll: 0.714937 \n",
      "(GPU: 0, epoch: 4, iters: 134784, time: 0.005) nll: 0.830790 \n",
      "(GPU: 0, epoch: 4, iters: 135584, time: 0.005) nll: 0.784781 \n",
      "(GPU: 0, epoch: 4, iters: 136384, time: 0.005) nll: 0.670273 \n",
      "(GPU: 0, epoch: 4, iters: 137184, time: 0.004) nll: 1.051682 \n",
      "saving the latest model (epoch 4, total_steps 700000)\n",
      "(GPU: 0, epoch: 4, iters: 137984, time: 0.005) nll: 0.872461 \n",
      "(GPU: 0, epoch: 4, iters: 138784, time: 0.005) nll: 0.651797 \n",
      "(GPU: 0, epoch: 4, iters: 139584, time: 0.005) nll: 0.840915 \n",
      "(GPU: 0, epoch: 4, iters: 140384, time: 0.005) nll: 0.927788 \n",
      "[*] End of epoch 4 / 25 \t Time Taken: 770 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000500\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3164/4397 [09:13<03:13,  6.38it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 32, time: 0.002) nll: 0.702507 \n",
      "(GPU: 0, epoch: 5, iters: 32, time: 0.002) nll: 0.532918 \n",
      "(GPU: 0, epoch: 5, iters: 480, time: 0.004) nll: 0.680631 \n",
      "(GPU: 0, epoch: 5, iters: 1280, time: 0.005) nll: 0.579509 \n",
      "(GPU: 0, epoch: 5, iters: 2080, time: 0.004) nll: 0.872680 \n",
      "(GPU: 0, epoch: 5, iters: 2880, time: 0.005) nll: 0.735522 \n",
      "(GPU: 0, epoch: 5, iters: 3680, time: 0.004) nll: 0.737382 \n",
      "(GPU: 0, epoch: 5, iters: 4480, time: 0.005) nll: 0.818691 \n",
      "(GPU: 0, epoch: 5, iters: 5280, time: 0.005) nll: 0.823410 \n",
      "(GPU: 0, epoch: 5, iters: 6080, time: 0.005) nll: 0.771002 \n",
      "(GPU: 0, epoch: 5, iters: 6880, time: 0.005) nll: 0.850051 \n",
      "(GPU: 0, epoch: 5, iters: 7680, time: 0.005) nll: 0.687064 \n",
      "(GPU: 0, epoch: 5, iters: 8480, time: 0.004) nll: 1.018884 \n",
      "(GPU: 0, epoch: 5, iters: 9280, time: 0.005) nll: 0.861244 \n",
      "(GPU: 0, epoch: 5, iters: 10080, time: 0.004) nll: 0.901502 \n",
      "(GPU: 0, epoch: 5, iters: 10880, time: 0.005) nll: 1.057802 \n",
      "(GPU: 0, epoch: 5, iters: 11680, time: 0.005) nll: 0.840340 \n",
      "(GPU: 0, epoch: 5, iters: 12480, time: 0.005) nll: 0.768251 \n",
      "(GPU: 0, epoch: 5, iters: 13280, time: 0.005) nll: 0.898681 \n",
      "(GPU: 0, epoch: 5, iters: 14080, time: 0.005) nll: 0.884736 \n",
      "(GPU: 0, epoch: 5, iters: 14880, time: 0.005) nll: 1.014263 \n",
      "(GPU: 0, epoch: 5, iters: 15680, time: 0.005) nll: 0.599083 \n",
      "(GPU: 0, epoch: 5, iters: 16480, time: 0.004) nll: 0.864257 \n",
      "saving the latest model (epoch 5, total_steps 720000)\n",
      "(GPU: 0, epoch: 5, iters: 17280, time: 0.005) nll: 0.627048 \n",
      "(GPU: 0, epoch: 5, iters: 18080, time: 0.005) nll: 0.689341 \n",
      "(GPU: 0, epoch: 5, iters: 18880, time: 0.005) nll: 0.622744 \n",
      "(GPU: 0, epoch: 5, iters: 19680, time: 0.005) nll: 0.676752 \n",
      "(GPU: 0, epoch: 5, iters: 20480, time: 0.005) nll: 0.862041 \n",
      "(GPU: 0, epoch: 5, iters: 21280, time: 0.005) nll: 0.585116 \n",
      "(GPU: 0, epoch: 5, iters: 22080, time: 0.005) nll: 0.824334 \n",
      "(GPU: 0, epoch: 5, iters: 22880, time: 0.005) nll: 0.905841 \n",
      "(GPU: 0, epoch: 5, iters: 23680, time: 0.005) nll: 0.774528 \n",
      "(GPU: 0, epoch: 5, iters: 24480, time: 0.004) nll: 0.673218 \n",
      "(GPU: 0, epoch: 5, iters: 25280, time: 0.005) nll: 0.535652 \n",
      "(GPU: 0, epoch: 5, iters: 26080, time: 0.005) nll: 0.453986 \n",
      "(GPU: 0, epoch: 5, iters: 26880, time: 0.005) nll: 0.874812 \n",
      "(GPU: 0, epoch: 5, iters: 27680, time: 0.005) nll: 0.621635 \n",
      "(GPU: 0, epoch: 5, iters: 28480, time: 0.005) nll: 0.598380 \n",
      "(GPU: 0, epoch: 5, iters: 29280, time: 0.005) nll: 1.013525 \n",
      "(GPU: 0, epoch: 5, iters: 30080, time: 0.005) nll: 0.761378 \n",
      "(GPU: 0, epoch: 5, iters: 30880, time: 0.004) nll: 0.737247 \n",
      "(GPU: 0, epoch: 5, iters: 31680, time: 0.005) nll: 0.735208 \n",
      "(GPU: 0, epoch: 5, iters: 32480, time: 0.004) nll: 0.657469 \n",
      "(GPU: 0, epoch: 5, iters: 33280, time: 0.005) nll: 0.943205 \n",
      "(GPU: 0, epoch: 5, iters: 34080, time: 0.004) nll: 1.038915 \n",
      "(GPU: 0, epoch: 5, iters: 34880, time: 0.005) nll: 0.835519 \n",
      "(GPU: 0, epoch: 5, iters: 35680, time: 0.005) nll: 0.609696 \n",
      "(GPU: 0, epoch: 5, iters: 36480, time: 0.005) nll: 0.813469 \n",
      "saving the latest model (epoch 5, total_steps 740000)\n",
      "(GPU: 0, epoch: 5, iters: 37280, time: 0.004) nll: 0.885895 \n",
      "(GPU: 0, epoch: 5, iters: 38080, time: 0.005) nll: 0.660933 \n",
      "(GPU: 0, epoch: 5, iters: 38880, time: 0.005) nll: 0.740698 \n",
      "(GPU: 0, epoch: 5, iters: 39680, time: 0.005) nll: 0.708575 \n",
      "(GPU: 0, epoch: 5, iters: 40480, time: 0.005) nll: 0.771694 \n",
      "(GPU: 0, epoch: 5, iters: 41280, time: 0.005) nll: 0.782583 \n",
      "(GPU: 0, epoch: 5, iters: 42080, time: 0.005) nll: 0.571683 \n",
      "(GPU: 0, epoch: 5, iters: 42880, time: 0.005) nll: 0.375958 \n",
      "(GPU: 0, epoch: 5, iters: 43680, time: 0.004) nll: 0.793019 \n",
      "(GPU: 0, epoch: 5, iters: 44480, time: 0.005) nll: 0.994098 \n",
      "(GPU: 0, epoch: 5, iters: 45280, time: 0.004) nll: 0.719492 \n",
      "(GPU: 0, epoch: 5, iters: 46080, time: 0.005) nll: 0.705702 \n",
      "(GPU: 0, epoch: 5, iters: 46880, time: 0.005) nll: 0.959199 \n",
      "(GPU: 0, epoch: 5, iters: 47680, time: 0.005) nll: 1.133681 \n",
      "(GPU: 0, epoch: 5, iters: 48480, time: 0.004) nll: 0.604339 \n",
      "(GPU: 0, epoch: 5, iters: 49280, time: 0.005) nll: 0.906071 \n",
      "(GPU: 0, epoch: 5, iters: 50080, time: 0.004) nll: 0.601370 \n",
      "(GPU: 0, epoch: 5, iters: 50880, time: 0.005) nll: 0.938450 \n",
      "(GPU: 0, epoch: 5, iters: 51680, time: 0.005) nll: 0.834096 \n",
      "(GPU: 0, epoch: 5, iters: 52480, time: 0.005) nll: 0.915267 \n",
      "(GPU: 0, epoch: 5, iters: 53280, time: 0.005) nll: 0.721587 \n",
      "(GPU: 0, epoch: 5, iters: 54080, time: 0.005) nll: 0.634884 \n",
      "(GPU: 0, epoch: 5, iters: 54880, time: 0.004) nll: 0.724128 \n",
      "(GPU: 0, epoch: 5, iters: 55680, time: 0.005) nll: 0.630993 \n",
      "(GPU: 0, epoch: 5, iters: 56480, time: 0.004) nll: 0.810594 \n",
      "saving the latest model (epoch 5, total_steps 760000)\n",
      "(GPU: 0, epoch: 5, iters: 57280, time: 0.005) nll: 0.660091 \n",
      "(GPU: 0, epoch: 5, iters: 58080, time: 0.004) nll: 0.813465 \n",
      "(GPU: 0, epoch: 5, iters: 58880, time: 0.005) nll: 0.642986 \n",
      "(GPU: 0, epoch: 5, iters: 59680, time: 0.005) nll: 0.670548 \n",
      "(GPU: 0, epoch: 5, iters: 60480, time: 0.005) nll: 0.532287 \n",
      "(GPU: 0, epoch: 5, iters: 61280, time: 0.005) nll: 0.958761 \n",
      "(GPU: 0, epoch: 5, iters: 62080, time: 0.005) nll: 0.528647 \n",
      "(GPU: 0, epoch: 5, iters: 62880, time: 0.005) nll: 0.523060 \n",
      "(GPU: 0, epoch: 5, iters: 63680, time: 0.005) nll: 0.651196 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.004) nll: 0.657432 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.007) nll: 0.653550 \n",
      "(GPU: 0, epoch: 5, iters: 64480, time: 0.007) nll: 0.572548 \n",
      "(GPU: 0, epoch: 5, iters: 65280, time: 0.005) nll: 0.828635 \n",
      "(GPU: 0, epoch: 5, iters: 66080, time: 0.004) nll: 0.827505 \n",
      "(GPU: 0, epoch: 5, iters: 66880, time: 0.005) nll: 0.716199 \n",
      "(GPU: 0, epoch: 5, iters: 67680, time: 0.004) nll: 0.950056 \n",
      "(GPU: 0, epoch: 5, iters: 68480, time: 0.005) nll: 0.755517 \n",
      "(GPU: 0, epoch: 5, iters: 69280, time: 0.005) nll: 0.710465 \n",
      "(GPU: 0, epoch: 5, iters: 70080, time: 0.005) nll: 0.655161 \n",
      "(GPU: 0, epoch: 5, iters: 70880, time: 0.005) nll: 0.612276 \n",
      "(GPU: 0, epoch: 5, iters: 71680, time: 0.005) nll: 0.987454 \n",
      "(GPU: 0, epoch: 5, iters: 72480, time: 0.005) nll: 0.545488 \n",
      "(GPU: 0, epoch: 5, iters: 73280, time: 0.005) nll: 0.923174 \n",
      "(GPU: 0, epoch: 5, iters: 74080, time: 0.005) nll: 0.848740 \n",
      "(GPU: 0, epoch: 5, iters: 74880, time: 0.005) nll: 0.867424 \n",
      "(GPU: 0, epoch: 5, iters: 75680, time: 0.005) nll: 1.114567 \n",
      "(GPU: 0, epoch: 5, iters: 76480, time: 0.005) nll: 0.586664 \n",
      "saving the latest model (epoch 5, total_steps 780000)\n",
      "(GPU: 0, epoch: 5, iters: 77280, time: 0.004) nll: 0.818512 \n",
      "(GPU: 0, epoch: 5, iters: 78080, time: 0.005) nll: 0.579602 \n",
      "(GPU: 0, epoch: 5, iters: 78880, time: 0.005) nll: 0.669101 \n",
      "(GPU: 0, epoch: 5, iters: 79680, time: 0.005) nll: 0.659039 \n",
      "(GPU: 0, epoch: 5, iters: 80480, time: 0.005) nll: 0.931053 \n",
      "(GPU: 0, epoch: 5, iters: 81280, time: 0.005) nll: 0.865814 \n",
      "(GPU: 0, epoch: 5, iters: 82080, time: 0.005) nll: 0.762972 \n",
      "(GPU: 0, epoch: 5, iters: 82880, time: 0.005) nll: 0.894166 \n",
      "(GPU: 0, epoch: 5, iters: 83680, time: 0.005) nll: 0.768406 \n",
      "(GPU: 0, epoch: 5, iters: 84480, time: 0.005) nll: 0.868365 \n",
      "(GPU: 0, epoch: 5, iters: 85280, time: 0.005) nll: 0.865171 \n",
      "(GPU: 0, epoch: 5, iters: 86080, time: 0.005) nll: 0.751050 \n",
      "(GPU: 0, epoch: 5, iters: 86880, time: 0.004) nll: 0.764874 \n",
      "(GPU: 0, epoch: 5, iters: 87680, time: 0.005) nll: 0.743859 \n",
      "(GPU: 0, epoch: 5, iters: 88480, time: 0.004) nll: 0.859807 \n",
      "(GPU: 0, epoch: 5, iters: 89280, time: 0.005) nll: 0.891872 \n",
      "(GPU: 0, epoch: 5, iters: 90080, time: 0.004) nll: 0.747479 \n",
      "(GPU: 0, epoch: 5, iters: 90880, time: 0.005) nll: 0.760128 \n",
      "(GPU: 0, epoch: 5, iters: 91680, time: 0.004) nll: 0.611989 \n",
      "(GPU: 0, epoch: 5, iters: 92480, time: 0.005) nll: 0.847372 \n",
      "(GPU: 0, epoch: 5, iters: 93280, time: 0.004) nll: 0.686028 \n",
      "(GPU: 0, epoch: 5, iters: 94080, time: 0.005) nll: 0.822269 \n",
      "(GPU: 0, epoch: 5, iters: 94880, time: 0.005) nll: 0.893366 \n",
      "(GPU: 0, epoch: 5, iters: 95680, time: 0.005) nll: 0.903340 \n",
      "(GPU: 0, epoch: 5, iters: 96480, time: 0.005) nll: 0.751022 \n",
      "saving the latest model (epoch 5, total_steps 800000)\n",
      "(GPU: 0, epoch: 5, iters: 97280, time: 0.005) nll: 0.689340 \n",
      "(GPU: 0, epoch: 5, iters: 98080, time: 0.005) nll: 0.802417 \n",
      "(GPU: 0, epoch: 5, iters: 98880, time: 0.005) nll: 0.594731 \n",
      "(GPU: 0, epoch: 5, iters: 99680, time: 0.005) nll: 0.895184 \n",
      "(GPU: 0, epoch: 5, iters: 100480, time: 0.005) nll: 0.754896 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 5, iters: 101280, time: 0.005) nll: 0.717949 \n",
      "(GPU: 0, epoch: 5, iters: 102080, time: 0.005) nll: 0.730991 \n",
      "(GPU: 0, epoch: 5, iters: 102880, time: 0.004) nll: 0.956269 \n",
      "(GPU: 0, epoch: 5, iters: 103680, time: 0.005) nll: 0.577946 \n",
      "(GPU: 0, epoch: 5, iters: 104480, time: 0.005) nll: 0.638973 \n",
      "(GPU: 0, epoch: 5, iters: 105280, time: 0.005) nll: 0.837323 \n",
      "(GPU: 0, epoch: 5, iters: 106080, time: 0.005) nll: 0.965758 \n",
      "(GPU: 0, epoch: 5, iters: 106880, time: 0.005) nll: 0.793170 \n",
      "(GPU: 0, epoch: 5, iters: 107680, time: 0.005) nll: 0.736319 \n",
      "(GPU: 0, epoch: 5, iters: 108480, time: 0.005) nll: 0.803176 \n",
      "(GPU: 0, epoch: 5, iters: 109280, time: 0.005) nll: 0.806945 \n",
      "(GPU: 0, epoch: 5, iters: 110080, time: 0.005) nll: 0.941217 \n",
      "(GPU: 0, epoch: 5, iters: 110880, time: 0.004) nll: 0.571787 \n",
      "(GPU: 0, epoch: 5, iters: 111680, time: 0.005) nll: 0.816156 \n",
      "(GPU: 0, epoch: 5, iters: 112480, time: 0.004) nll: 0.622621 \n",
      "(GPU: 0, epoch: 5, iters: 113280, time: 0.005) nll: 0.872307 \n",
      "(GPU: 0, epoch: 5, iters: 114080, time: 0.005) nll: 0.883672 \n",
      "(GPU: 0, epoch: 5, iters: 114880, time: 0.005) nll: 0.788121 \n",
      "(GPU: 0, epoch: 5, iters: 115680, time: 0.005) nll: 0.803762 \n",
      "(GPU: 0, epoch: 5, iters: 116480, time: 0.005) nll: 0.745591 \n",
      "saving the latest model (epoch 5, total_steps 820000)\n",
      "(GPU: 0, epoch: 5, iters: 117280, time: 0.005) nll: 0.769720 \n",
      "(GPU: 0, epoch: 5, iters: 118080, time: 0.005) nll: 0.901335 \n",
      "(GPU: 0, epoch: 5, iters: 118880, time: 0.004) nll: 0.962231 \n",
      "(GPU: 0, epoch: 5, iters: 119680, time: 0.005) nll: 0.699655 \n",
      "(GPU: 0, epoch: 5, iters: 120480, time: 0.005) nll: 0.642141 \n",
      "(GPU: 0, epoch: 5, iters: 121280, time: 0.005) nll: 0.877645 \n",
      "(GPU: 0, epoch: 5, iters: 122080, time: 0.005) nll: 0.891134 \n",
      "(GPU: 0, epoch: 5, iters: 122880, time: 0.005) nll: 0.801716 \n",
      "(GPU: 0, epoch: 5, iters: 123680, time: 0.005) nll: 0.832057 \n",
      "(GPU: 0, epoch: 5, iters: 124480, time: 0.005) nll: 0.864890 \n",
      "(GPU: 0, epoch: 5, iters: 125280, time: 0.005) nll: 0.644604 \n",
      "(GPU: 0, epoch: 5, iters: 126080, time: 0.005) nll: 0.778471 \n",
      "(GPU: 0, epoch: 5, iters: 126880, time: 0.005) nll: 0.947539 \n",
      "(GPU: 0, epoch: 5, iters: 127680, time: 0.005) nll: 0.507461 \n",
      "(GPU: 0, epoch: 5, iters: 128480, time: 0.004) nll: 0.893668 \n",
      "(GPU: 0, epoch: 5, iters: 129280, time: 0.005) nll: 0.778383 \n",
      "(GPU: 0, epoch: 5, iters: 130080, time: 0.005) nll: 0.625117 \n",
      "(GPU: 0, epoch: 5, iters: 130880, time: 0.005) nll: 0.719088 \n",
      "(GPU: 0, epoch: 5, iters: 131680, time: 0.004) nll: 0.584040 \n",
      "(GPU: 0, epoch: 5, iters: 132480, time: 0.005) nll: 0.677812 \n",
      "(GPU: 0, epoch: 5, iters: 133280, time: 0.004) nll: 0.866251 \n",
      "(GPU: 0, epoch: 5, iters: 134080, time: 0.005) nll: 0.566465 \n",
      "(GPU: 0, epoch: 5, iters: 134880, time: 0.004) nll: 0.745350 \n",
      "(GPU: 0, epoch: 5, iters: 135680, time: 0.005) nll: 0.773380 \n",
      "(GPU: 0, epoch: 5, iters: 136480, time: 0.005) nll: 0.819082 \n",
      "saving the latest model (epoch 5, total_steps 840000)\n",
      "(GPU: 0, epoch: 5, iters: 137280, time: 0.005) nll: 0.823374 \n",
      "(GPU: 0, epoch: 5, iters: 138080, time: 0.005) nll: 0.827037 \n",
      "(GPU: 0, epoch: 5, iters: 138880, time: 0.005) nll: 0.880149 \n",
      "(GPU: 0, epoch: 5, iters: 139680, time: 0.004) nll: 0.788546 \n",
      "(GPU: 0, epoch: 5, iters: 140480, time: 0.005) nll: 0.773577 \n",
      "[*] End of epoch 5 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000600\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3167/4397 [09:13<03:16,  6.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 32, time: 0.003) nll: 0.831650 \n",
      "(GPU: 0, epoch: 6, iters: 32, time: 0.003) nll: 0.962709 \n",
      "(GPU: 0, epoch: 6, iters: 576, time: 0.005) nll: 0.683543 \n",
      "(GPU: 0, epoch: 6, iters: 1376, time: 0.005) nll: 0.690106 \n",
      "(GPU: 0, epoch: 6, iters: 2176, time: 0.005) nll: 0.792698 \n",
      "(GPU: 0, epoch: 6, iters: 2976, time: 0.005) nll: 0.676858 \n",
      "(GPU: 0, epoch: 6, iters: 3776, time: 0.005) nll: 0.697914 \n",
      "(GPU: 0, epoch: 6, iters: 4576, time: 0.004) nll: 0.585813 \n",
      "(GPU: 0, epoch: 6, iters: 5376, time: 0.005) nll: 0.914873 \n",
      "(GPU: 0, epoch: 6, iters: 6176, time: 0.005) nll: 0.637248 \n",
      "(GPU: 0, epoch: 6, iters: 6976, time: 0.005) nll: 0.569706 \n",
      "(GPU: 0, epoch: 6, iters: 7776, time: 0.004) nll: 0.644616 \n",
      "(GPU: 0, epoch: 6, iters: 8576, time: 0.005) nll: 0.923483 \n",
      "(GPU: 0, epoch: 6, iters: 9376, time: 0.005) nll: 0.564584 \n",
      "(GPU: 0, epoch: 6, iters: 10176, time: 0.005) nll: 0.978274 \n",
      "(GPU: 0, epoch: 6, iters: 10976, time: 0.005) nll: 0.821116 \n",
      "(GPU: 0, epoch: 6, iters: 11776, time: 0.005) nll: 0.935898 \n",
      "(GPU: 0, epoch: 6, iters: 12576, time: 0.004) nll: 0.842373 \n",
      "(GPU: 0, epoch: 6, iters: 13376, time: 0.005) nll: 0.907648 \n",
      "(GPU: 0, epoch: 6, iters: 14176, time: 0.005) nll: 0.868361 \n",
      "(GPU: 0, epoch: 6, iters: 14976, time: 0.005) nll: 0.839305 \n",
      "(GPU: 0, epoch: 6, iters: 15776, time: 0.004) nll: 0.745515 \n",
      "saving the latest model (epoch 6, total_steps 860000)\n",
      "(GPU: 0, epoch: 6, iters: 16576, time: 0.005) nll: 0.657889 \n",
      "(GPU: 0, epoch: 6, iters: 17376, time: 0.005) nll: 0.836500 \n",
      "(GPU: 0, epoch: 6, iters: 18176, time: 0.005) nll: 0.790892 \n",
      "(GPU: 0, epoch: 6, iters: 18976, time: 0.004) nll: 0.712539 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.005) nll: 0.970870 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.008) nll: 0.965551 \n",
      "(GPU: 0, epoch: 6, iters: 19776, time: 0.008) nll: 0.812506 \n",
      "(GPU: 0, epoch: 6, iters: 20576, time: 0.005) nll: 0.914638 \n",
      "(GPU: 0, epoch: 6, iters: 21376, time: 0.005) nll: 0.723603 \n",
      "(GPU: 0, epoch: 6, iters: 22176, time: 0.004) nll: 0.620609 \n",
      "(GPU: 0, epoch: 6, iters: 22976, time: 0.005) nll: 0.810049 \n",
      "(GPU: 0, epoch: 6, iters: 23776, time: 0.005) nll: 1.030493 \n",
      "(GPU: 0, epoch: 6, iters: 24576, time: 0.005) nll: 0.915322 \n",
      "(GPU: 0, epoch: 6, iters: 25376, time: 0.005) nll: 0.920744 \n",
      "(GPU: 0, epoch: 6, iters: 26176, time: 0.005) nll: 0.960062 \n",
      "(GPU: 0, epoch: 6, iters: 26976, time: 0.004) nll: 0.581623 \n",
      "(GPU: 0, epoch: 6, iters: 27776, time: 0.005) nll: 1.106924 \n",
      "(GPU: 0, epoch: 6, iters: 28576, time: 0.004) nll: 0.600732 \n",
      "(GPU: 0, epoch: 6, iters: 29376, time: 0.005) nll: 0.754637 \n",
      "(GPU: 0, epoch: 6, iters: 30176, time: 0.004) nll: 0.868684 \n",
      "(GPU: 0, epoch: 6, iters: 30976, time: 0.005) nll: 0.861350 \n",
      "(GPU: 0, epoch: 6, iters: 31776, time: 0.004) nll: 0.561469 \n",
      "(GPU: 0, epoch: 6, iters: 32576, time: 0.005) nll: 0.708332 \n",
      "(GPU: 0, epoch: 6, iters: 33376, time: 0.004) nll: 0.686664 \n",
      "(GPU: 0, epoch: 6, iters: 34176, time: 0.005) nll: 0.841597 \n",
      "(GPU: 0, epoch: 6, iters: 34976, time: 0.004) nll: 0.585451 \n",
      "(GPU: 0, epoch: 6, iters: 35776, time: 0.005) nll: 0.726535 \n",
      "saving the latest model (epoch 6, total_steps 880000)\n",
      "(GPU: 0, epoch: 6, iters: 36576, time: 0.005) nll: 0.614235 \n",
      "(GPU: 0, epoch: 6, iters: 37376, time: 0.005) nll: 0.601662 \n",
      "(GPU: 0, epoch: 6, iters: 38176, time: 0.005) nll: 0.472795 \n",
      "(GPU: 0, epoch: 6, iters: 38976, time: 0.005) nll: 0.793381 \n",
      "(GPU: 0, epoch: 6, iters: 39776, time: 0.004) nll: 0.954389 \n",
      "(GPU: 0, epoch: 6, iters: 40576, time: 0.005) nll: 0.740383 \n",
      "(GPU: 0, epoch: 6, iters: 41376, time: 0.004) nll: 0.984621 \n",
      "(GPU: 0, epoch: 6, iters: 42176, time: 0.005) nll: 0.842448 \n",
      "(GPU: 0, epoch: 6, iters: 42976, time: 0.004) nll: 0.852229 \n",
      "(GPU: 0, epoch: 6, iters: 43776, time: 0.005) nll: 0.706642 \n",
      "(GPU: 0, epoch: 6, iters: 44576, time: 0.005) nll: 0.714938 \n",
      "(GPU: 0, epoch: 6, iters: 45376, time: 0.005) nll: 0.634809 \n",
      "(GPU: 0, epoch: 6, iters: 46176, time: 0.004) nll: 0.789495 \n",
      "(GPU: 0, epoch: 6, iters: 46976, time: 0.005) nll: 0.792784 \n",
      "(GPU: 0, epoch: 6, iters: 47776, time: 0.005) nll: 0.606309 \n",
      "(GPU: 0, epoch: 6, iters: 48576, time: 0.005) nll: 0.826025 \n",
      "(GPU: 0, epoch: 6, iters: 49376, time: 0.005) nll: 0.636867 \n",
      "(GPU: 0, epoch: 6, iters: 50176, time: 0.005) nll: 0.613140 \n",
      "(GPU: 0, epoch: 6, iters: 50976, time: 0.005) nll: 0.747941 \n",
      "(GPU: 0, epoch: 6, iters: 51776, time: 0.005) nll: 0.684171 \n",
      "(GPU: 0, epoch: 6, iters: 52576, time: 0.005) nll: 1.023557 \n",
      "(GPU: 0, epoch: 6, iters: 53376, time: 0.005) nll: 0.719710 \n",
      "(GPU: 0, epoch: 6, iters: 54176, time: 0.005) nll: 0.817537 \n",
      "(GPU: 0, epoch: 6, iters: 54976, time: 0.005) nll: 0.602761 \n",
      "(GPU: 0, epoch: 6, iters: 55776, time: 0.004) nll: 0.736063 \n",
      "saving the latest model (epoch 6, total_steps 900000)\n",
      "(GPU: 0, epoch: 6, iters: 56576, time: 0.005) nll: 0.725186 \n",
      "(GPU: 0, epoch: 6, iters: 57376, time: 0.004) nll: 0.765258 \n",
      "(GPU: 0, epoch: 6, iters: 58176, time: 0.005) nll: 0.661844 \n",
      "(GPU: 0, epoch: 6, iters: 58976, time: 0.004) nll: 0.993993 \n",
      "(GPU: 0, epoch: 6, iters: 59776, time: 0.005) nll: 0.676863 \n",
      "(GPU: 0, epoch: 6, iters: 60576, time: 0.005) nll: 0.689077 \n",
      "(GPU: 0, epoch: 6, iters: 61376, time: 0.005) nll: 0.848343 \n",
      "(GPU: 0, epoch: 6, iters: 62176, time: 0.005) nll: 0.872157 \n",
      "(GPU: 0, epoch: 6, iters: 62976, time: 0.005) nll: 0.689048 \n",
      "(GPU: 0, epoch: 6, iters: 63776, time: 0.005) nll: 0.678688 \n",
      "(GPU: 0, epoch: 6, iters: 64576, time: 0.005) nll: 0.800679 \n",
      "(GPU: 0, epoch: 6, iters: 65376, time: 0.004) nll: 0.955556 \n",
      "(GPU: 0, epoch: 6, iters: 66176, time: 0.005) nll: 0.704500 \n",
      "(GPU: 0, epoch: 6, iters: 66976, time: 0.005) nll: 0.651851 \n",
      "(GPU: 0, epoch: 6, iters: 67776, time: 0.005) nll: 0.808992 \n",
      "(GPU: 0, epoch: 6, iters: 68576, time: 0.004) nll: 0.638970 \n",
      "(GPU: 0, epoch: 6, iters: 69376, time: 0.005) nll: 0.910334 \n",
      "(GPU: 0, epoch: 6, iters: 70176, time: 0.004) nll: 0.570200 \n",
      "(GPU: 0, epoch: 6, iters: 70976, time: 0.005) nll: 0.654236 \n",
      "(GPU: 0, epoch: 6, iters: 71776, time: 0.004) nll: 0.682141 \n",
      "(GPU: 0, epoch: 6, iters: 72576, time: 0.005) nll: 0.789732 \n",
      "(GPU: 0, epoch: 6, iters: 73376, time: 0.004) nll: 0.685481 \n",
      "(GPU: 0, epoch: 6, iters: 74176, time: 0.005) nll: 0.826523 \n",
      "(GPU: 0, epoch: 6, iters: 74976, time: 0.004) nll: 0.597108 \n",
      "(GPU: 0, epoch: 6, iters: 75776, time: 0.005) nll: 0.573599 \n",
      "saving the latest model (epoch 6, total_steps 920000)\n",
      "(GPU: 0, epoch: 6, iters: 76576, time: 0.004) nll: 0.737828 \n",
      "(GPU: 0, epoch: 6, iters: 77376, time: 0.005) nll: 0.778962 \n",
      "(GPU: 0, epoch: 6, iters: 78176, time: 0.004) nll: 0.816244 \n",
      "(GPU: 0, epoch: 6, iters: 78976, time: 0.005) nll: 0.953065 \n",
      "(GPU: 0, epoch: 6, iters: 79776, time: 0.004) nll: 0.693761 \n",
      "(GPU: 0, epoch: 6, iters: 80576, time: 0.005) nll: 0.928888 \n",
      "(GPU: 0, epoch: 6, iters: 81376, time: 0.005) nll: 0.674127 \n",
      "(GPU: 0, epoch: 6, iters: 82176, time: 0.005) nll: 0.810802 \n",
      "(GPU: 0, epoch: 6, iters: 82976, time: 0.004) nll: 0.850925 \n",
      "(GPU: 0, epoch: 6, iters: 83776, time: 0.005) nll: 0.718250 \n",
      "(GPU: 0, epoch: 6, iters: 84576, time: 0.004) nll: 0.913691 \n",
      "(GPU: 0, epoch: 6, iters: 85376, time: 0.005) nll: 0.945684 \n",
      "(GPU: 0, epoch: 6, iters: 86176, time: 0.004) nll: 0.800178 \n",
      "(GPU: 0, epoch: 6, iters: 86976, time: 0.005) nll: 0.855295 \n",
      "(GPU: 0, epoch: 6, iters: 87776, time: 0.005) nll: 0.845340 \n",
      "(GPU: 0, epoch: 6, iters: 88576, time: 0.005) nll: 0.681086 \n",
      "(GPU: 0, epoch: 6, iters: 89376, time: 0.004) nll: 0.842046 \n",
      "(GPU: 0, epoch: 6, iters: 90176, time: 0.005) nll: 0.618548 \n",
      "(GPU: 0, epoch: 6, iters: 90976, time: 0.004) nll: 0.867838 \n",
      "(GPU: 0, epoch: 6, iters: 91776, time: 0.005) nll: 0.719276 \n",
      "(GPU: 0, epoch: 6, iters: 92576, time: 0.004) nll: 0.566287 \n",
      "(GPU: 0, epoch: 6, iters: 93376, time: 0.005) nll: 0.679118 \n",
      "(GPU: 0, epoch: 6, iters: 94176, time: 0.004) nll: 0.677443 \n",
      "(GPU: 0, epoch: 6, iters: 94976, time: 0.005) nll: 1.261160 \n",
      "(GPU: 0, epoch: 6, iters: 95776, time: 0.004) nll: 0.764457 \n",
      "saving the latest model (epoch 6, total_steps 940000)\n",
      "(GPU: 0, epoch: 6, iters: 96576, time: 0.005) nll: 0.771904 \n",
      "(GPU: 0, epoch: 6, iters: 97376, time: 0.005) nll: 0.940218 \n",
      "(GPU: 0, epoch: 6, iters: 98176, time: 0.005) nll: 0.786775 \n",
      "(GPU: 0, epoch: 6, iters: 98976, time: 0.004) nll: 0.689818 \n",
      "(GPU: 0, epoch: 6, iters: 99776, time: 0.005) nll: 0.889288 \n",
      "(GPU: 0, epoch: 6, iters: 100576, time: 0.004) nll: 0.991456 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:47<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 6, iters: 101376, time: 0.005) nll: 0.695578 \n",
      "(GPU: 0, epoch: 6, iters: 102176, time: 0.004) nll: 0.819479 \n",
      "(GPU: 0, epoch: 6, iters: 102976, time: 0.005) nll: 1.027937 \n",
      "(GPU: 0, epoch: 6, iters: 103776, time: 0.005) nll: 0.532656 \n",
      "(GPU: 0, epoch: 6, iters: 104576, time: 0.005) nll: 0.443708 \n",
      "(GPU: 0, epoch: 6, iters: 105376, time: 0.005) nll: 0.672769 \n",
      "(GPU: 0, epoch: 6, iters: 106176, time: 0.005) nll: 0.831129 \n",
      "(GPU: 0, epoch: 6, iters: 106976, time: 0.005) nll: 0.893188 \n",
      "(GPU: 0, epoch: 6, iters: 107776, time: 0.005) nll: 0.656223 \n",
      "(GPU: 0, epoch: 6, iters: 108576, time: 0.004) nll: 0.702530 \n",
      "(GPU: 0, epoch: 6, iters: 109376, time: 0.005) nll: 0.670323 \n",
      "(GPU: 0, epoch: 6, iters: 110176, time: 0.004) nll: 0.755484 \n",
      "(GPU: 0, epoch: 6, iters: 110976, time: 0.005) nll: 0.635288 \n",
      "(GPU: 0, epoch: 6, iters: 111776, time: 0.005) nll: 0.828134 \n",
      "(GPU: 0, epoch: 6, iters: 112576, time: 0.005) nll: 0.658013 \n",
      "(GPU: 0, epoch: 6, iters: 113376, time: 0.004) nll: 0.888228 \n",
      "(GPU: 0, epoch: 6, iters: 114176, time: 0.005) nll: 0.787312 \n",
      "(GPU: 0, epoch: 6, iters: 114976, time: 0.005) nll: 0.603536 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.005) nll: 0.648331 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.008) nll: 0.645384 \n",
      "(GPU: 0, epoch: 6, iters: 115776, time: 0.008) nll: 0.628878 \n",
      "saving the latest model (epoch 6, total_steps 960000)\n",
      "(GPU: 0, epoch: 6, iters: 116576, time: 0.004) nll: 0.887755 \n",
      "(GPU: 0, epoch: 6, iters: 117376, time: 0.005) nll: 0.787786 \n",
      "(GPU: 0, epoch: 6, iters: 118176, time: 0.004) nll: 0.758559 \n",
      "(GPU: 0, epoch: 6, iters: 118976, time: 0.005) nll: 0.664959 \n",
      "(GPU: 0, epoch: 6, iters: 119776, time: 0.005) nll: 0.804814 \n",
      "(GPU: 0, epoch: 6, iters: 120576, time: 0.005) nll: 0.777234 \n",
      "(GPU: 0, epoch: 6, iters: 121376, time: 0.005) nll: 0.842948 \n",
      "(GPU: 0, epoch: 6, iters: 122176, time: 0.005) nll: 0.659970 \n",
      "(GPU: 0, epoch: 6, iters: 122976, time: 0.004) nll: 0.622237 \n",
      "(GPU: 0, epoch: 6, iters: 123776, time: 0.005) nll: 0.812234 \n",
      "(GPU: 0, epoch: 6, iters: 124576, time: 0.005) nll: 0.761442 \n",
      "(GPU: 0, epoch: 6, iters: 125376, time: 0.005) nll: 0.666320 \n",
      "(GPU: 0, epoch: 6, iters: 126176, time: 0.004) nll: 0.706554 \n",
      "(GPU: 0, epoch: 6, iters: 126976, time: 0.005) nll: 0.772003 \n",
      "(GPU: 0, epoch: 6, iters: 127776, time: 0.005) nll: 0.639629 \n",
      "(GPU: 0, epoch: 6, iters: 128576, time: 0.005) nll: 0.781335 \n",
      "(GPU: 0, epoch: 6, iters: 129376, time: 0.004) nll: 0.770143 \n",
      "(GPU: 0, epoch: 6, iters: 130176, time: 0.005) nll: 0.764909 \n",
      "(GPU: 0, epoch: 6, iters: 130976, time: 0.005) nll: 1.041010 \n",
      "(GPU: 0, epoch: 6, iters: 131776, time: 0.005) nll: 0.672342 \n",
      "(GPU: 0, epoch: 6, iters: 132576, time: 0.004) nll: 0.753718 \n",
      "(GPU: 0, epoch: 6, iters: 133376, time: 0.005) nll: 0.565435 \n",
      "(GPU: 0, epoch: 6, iters: 134176, time: 0.004) nll: 0.651503 \n",
      "(GPU: 0, epoch: 6, iters: 134976, time: 0.005) nll: 0.721029 \n",
      "(GPU: 0, epoch: 6, iters: 135776, time: 0.004) nll: 0.737677 \n",
      "saving the latest model (epoch 6, total_steps 980000)\n",
      "(GPU: 0, epoch: 6, iters: 136576, time: 0.005) nll: 1.037897 \n",
      "(GPU: 0, epoch: 6, iters: 137376, time: 0.004) nll: 0.907186 \n",
      "(GPU: 0, epoch: 6, iters: 138176, time: 0.005) nll: 0.544484 \n",
      "(GPU: 0, epoch: 6, iters: 138976, time: 0.005) nll: 0.784892 \n",
      "(GPU: 0, epoch: 6, iters: 139776, time: 0.005) nll: 0.642601 \n",
      "(GPU: 0, epoch: 6, iters: 140576, time: 0.005) nll: 0.738831 \n",
      "saving the model at the end of epoch 6, iters 984928\n",
      "([test] GPU: 0, epoch: 6) \n",
      "OrderedDict()\n",
      "[*] End of epoch 6 / 25 \t Time Taken: 789 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000700\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3170/4397 [09:13<03:16,  6.23it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 32, time: 0.003) nll: 0.557405 \n",
      "(GPU: 0, epoch: 7, iters: 32, time: 0.003) nll: 0.918206 \n",
      "(GPU: 0, epoch: 7, iters: 672, time: 0.005) nll: 0.701959 \n",
      "(GPU: 0, epoch: 7, iters: 1472, time: 0.005) nll: 0.739167 \n",
      "(GPU: 0, epoch: 7, iters: 2272, time: 0.005) nll: 0.730496 \n",
      "(GPU: 0, epoch: 7, iters: 3072, time: 0.005) nll: 0.658950 \n",
      "(GPU: 0, epoch: 7, iters: 3872, time: 0.004) nll: 0.536851 \n",
      "(GPU: 0, epoch: 7, iters: 4672, time: 0.005) nll: 0.758408 \n",
      "(GPU: 0, epoch: 7, iters: 5472, time: 0.004) nll: 0.699319 \n",
      "(GPU: 0, epoch: 7, iters: 6272, time: 0.005) nll: 0.812611 \n",
      "(GPU: 0, epoch: 7, iters: 7072, time: 0.005) nll: 0.694158 \n",
      "(GPU: 0, epoch: 7, iters: 7872, time: 0.005) nll: 0.749408 \n",
      "(GPU: 0, epoch: 7, iters: 8672, time: 0.005) nll: 1.024052 \n",
      "(GPU: 0, epoch: 7, iters: 9472, time: 0.005) nll: 0.790736 \n",
      "(GPU: 0, epoch: 7, iters: 10272, time: 0.005) nll: 0.751766 \n",
      "(GPU: 0, epoch: 7, iters: 11072, time: 0.005) nll: 0.580157 \n",
      "(GPU: 0, epoch: 7, iters: 11872, time: 0.005) nll: 0.671411 \n",
      "(GPU: 0, epoch: 7, iters: 12672, time: 0.005) nll: 0.520495 \n",
      "(GPU: 0, epoch: 7, iters: 13472, time: 0.004) nll: 0.578821 \n",
      "(GPU: 0, epoch: 7, iters: 14272, time: 0.005) nll: 0.781303 \n",
      "(GPU: 0, epoch: 7, iters: 15072, time: 0.004) nll: 0.862161 \n",
      "saving the latest model (epoch 7, total_steps 1000000)\n",
      "(GPU: 0, epoch: 7, iters: 15872, time: 0.005) nll: 0.616869 \n",
      "(GPU: 0, epoch: 7, iters: 16672, time: 0.005) nll: 1.017866 \n",
      "(GPU: 0, epoch: 7, iters: 17472, time: 0.005) nll: 0.517032 \n",
      "(GPU: 0, epoch: 7, iters: 18272, time: 0.004) nll: 0.608678 \n",
      "(GPU: 0, epoch: 7, iters: 19072, time: 0.005) nll: 0.858590 \n",
      "(GPU: 0, epoch: 7, iters: 19872, time: 0.004) nll: 0.831925 \n",
      "(GPU: 0, epoch: 7, iters: 20672, time: 0.005) nll: 0.791979 \n",
      "(GPU: 0, epoch: 7, iters: 21472, time: 0.004) nll: 0.843226 \n",
      "(GPU: 0, epoch: 7, iters: 22272, time: 0.005) nll: 0.678276 \n",
      "(GPU: 0, epoch: 7, iters: 23072, time: 0.004) nll: 0.865997 \n",
      "(GPU: 0, epoch: 7, iters: 23872, time: 0.005) nll: 0.731834 \n",
      "(GPU: 0, epoch: 7, iters: 24672, time: 0.004) nll: 0.952663 \n",
      "(GPU: 0, epoch: 7, iters: 25472, time: 0.005) nll: 0.523205 \n",
      "(GPU: 0, epoch: 7, iters: 26272, time: 0.005) nll: 0.731092 \n",
      "(GPU: 0, epoch: 7, iters: 27072, time: 0.005) nll: 0.518006 \n",
      "(GPU: 0, epoch: 7, iters: 27872, time: 0.005) nll: 0.787763 \n",
      "(GPU: 0, epoch: 7, iters: 28672, time: 0.005) nll: 0.929576 \n",
      "(GPU: 0, epoch: 7, iters: 29472, time: 0.005) nll: 0.852186 \n",
      "(GPU: 0, epoch: 7, iters: 30272, time: 0.005) nll: 0.718300 \n",
      "(GPU: 0, epoch: 7, iters: 31072, time: 0.004) nll: 0.900740 \n",
      "(GPU: 0, epoch: 7, iters: 31872, time: 0.005) nll: 0.722901 \n",
      "(GPU: 0, epoch: 7, iters: 32672, time: 0.004) nll: 0.615586 \n",
      "(GPU: 0, epoch: 7, iters: 33472, time: 0.005) nll: 0.656397 \n",
      "(GPU: 0, epoch: 7, iters: 34272, time: 0.004) nll: 0.877611 \n",
      "(GPU: 0, epoch: 7, iters: 35072, time: 0.005) nll: 0.719144 \n",
      "saving the latest model (epoch 7, total_steps 1020000)\n",
      "(GPU: 0, epoch: 7, iters: 35872, time: 0.004) nll: 0.737677 \n",
      "(GPU: 0, epoch: 7, iters: 36672, time: 0.005) nll: 0.697266 \n",
      "(GPU: 0, epoch: 7, iters: 37472, time: 0.005) nll: 0.717658 \n",
      "(GPU: 0, epoch: 7, iters: 38272, time: 0.005) nll: 0.699611 \n",
      "(GPU: 0, epoch: 7, iters: 39072, time: 0.005) nll: 0.805615 \n",
      "(GPU: 0, epoch: 7, iters: 39872, time: 0.005) nll: 0.816354 \n",
      "(GPU: 0, epoch: 7, iters: 40672, time: 0.004) nll: 0.754147 \n",
      "(GPU: 0, epoch: 7, iters: 41472, time: 0.005) nll: 0.713066 \n",
      "(GPU: 0, epoch: 7, iters: 42272, time: 0.004) nll: 0.767086 \n",
      "(GPU: 0, epoch: 7, iters: 43072, time: 0.005) nll: 0.949635 \n",
      "(GPU: 0, epoch: 7, iters: 43872, time: 0.004) nll: 0.753017 \n",
      "(GPU: 0, epoch: 7, iters: 44672, time: 0.005) nll: 0.785205 \n",
      "(GPU: 0, epoch: 7, iters: 45472, time: 0.004) nll: 0.870732 \n",
      "(GPU: 0, epoch: 7, iters: 46272, time: 0.005) nll: 0.822991 \n",
      "(GPU: 0, epoch: 7, iters: 47072, time: 0.005) nll: 0.556500 \n",
      "(GPU: 0, epoch: 7, iters: 47872, time: 0.005) nll: 0.820234 \n",
      "(GPU: 0, epoch: 7, iters: 48672, time: 0.004) nll: 0.943047 \n",
      "(GPU: 0, epoch: 7, iters: 49472, time: 0.005) nll: 0.504520 \n",
      "(GPU: 0, epoch: 7, iters: 50272, time: 0.005) nll: 0.646229 \n",
      "(GPU: 0, epoch: 7, iters: 51072, time: 0.005) nll: 0.868388 \n",
      "(GPU: 0, epoch: 7, iters: 51872, time: 0.004) nll: 0.854814 \n",
      "(GPU: 0, epoch: 7, iters: 52672, time: 0.005) nll: 0.970389 \n",
      "(GPU: 0, epoch: 7, iters: 53472, time: 0.004) nll: 0.908463 \n",
      "(GPU: 0, epoch: 7, iters: 54272, time: 0.005) nll: 0.762007 \n",
      "(GPU: 0, epoch: 7, iters: 55072, time: 0.005) nll: 0.930035 \n",
      "saving the latest model (epoch 7, total_steps 1040000)\n",
      "(GPU: 0, epoch: 7, iters: 55872, time: 0.005) nll: 0.797502 \n",
      "(GPU: 0, epoch: 7, iters: 56672, time: 0.004) nll: 0.636652 \n",
      "(GPU: 0, epoch: 7, iters: 57472, time: 0.005) nll: 0.498817 \n",
      "(GPU: 0, epoch: 7, iters: 58272, time: 0.004) nll: 0.585608 \n",
      "(GPU: 0, epoch: 7, iters: 59072, time: 0.005) nll: 0.951362 \n",
      "(GPU: 0, epoch: 7, iters: 59872, time: 0.005) nll: 0.661291 \n",
      "(GPU: 0, epoch: 7, iters: 60672, time: 0.005) nll: 0.562963 \n",
      "(GPU: 0, epoch: 7, iters: 61472, time: 0.005) nll: 0.584819 \n",
      "(GPU: 0, epoch: 7, iters: 62272, time: 0.005) nll: 0.836026 \n",
      "(GPU: 0, epoch: 7, iters: 63072, time: 0.004) nll: 0.857424 \n",
      "(GPU: 0, epoch: 7, iters: 63872, time: 0.005) nll: 0.776775 \n",
      "(GPU: 0, epoch: 7, iters: 64672, time: 0.005) nll: 0.725488 \n",
      "(GPU: 0, epoch: 7, iters: 65472, time: 0.005) nll: 0.699596 \n",
      "(GPU: 0, epoch: 7, iters: 66272, time: 0.004) nll: 0.697164 \n",
      "(GPU: 0, epoch: 7, iters: 67072, time: 0.005) nll: 0.705020 \n",
      "(GPU: 0, epoch: 7, iters: 67872, time: 0.004) nll: 0.705064 \n",
      "(GPU: 0, epoch: 7, iters: 68672, time: 0.005) nll: 0.660887 \n",
      "(GPU: 0, epoch: 7, iters: 69472, time: 0.005) nll: 0.858930 \n",
      "(GPU: 0, epoch: 7, iters: 70272, time: 0.005) nll: 0.846687 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.005) nll: 0.522923 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.008) nll: 0.517749 \n",
      "(GPU: 0, epoch: 7, iters: 71072, time: 0.008) nll: 0.973689 \n",
      "(GPU: 0, epoch: 7, iters: 71872, time: 0.005) nll: 0.640532 \n",
      "(GPU: 0, epoch: 7, iters: 72672, time: 0.004) nll: 0.829482 \n",
      "(GPU: 0, epoch: 7, iters: 73472, time: 0.005) nll: 0.694485 \n",
      "(GPU: 0, epoch: 7, iters: 74272, time: 0.004) nll: 0.943741 \n",
      "(GPU: 0, epoch: 7, iters: 75072, time: 0.005) nll: 0.615474 \n",
      "saving the latest model (epoch 7, total_steps 1060000)\n",
      "(GPU: 0, epoch: 7, iters: 75872, time: 0.004) nll: 0.773881 \n",
      "(GPU: 0, epoch: 7, iters: 76672, time: 0.005) nll: 0.708897 \n",
      "(GPU: 0, epoch: 7, iters: 77472, time: 0.004) nll: 0.734882 \n",
      "(GPU: 0, epoch: 7, iters: 78272, time: 0.005) nll: 0.930312 \n",
      "(GPU: 0, epoch: 7, iters: 79072, time: 0.004) nll: 0.843738 \n",
      "(GPU: 0, epoch: 7, iters: 79872, time: 0.005) nll: 0.670071 \n",
      "(GPU: 0, epoch: 7, iters: 80672, time: 0.004) nll: 0.549026 \n",
      "(GPU: 0, epoch: 7, iters: 81472, time: 0.005) nll: 0.835379 \n",
      "(GPU: 0, epoch: 7, iters: 82272, time: 0.004) nll: 0.813570 \n",
      "(GPU: 0, epoch: 7, iters: 83072, time: 0.005) nll: 0.769952 \n",
      "(GPU: 0, epoch: 7, iters: 83872, time: 0.004) nll: 0.593519 \n",
      "(GPU: 0, epoch: 7, iters: 84672, time: 0.005) nll: 0.838729 \n",
      "(GPU: 0, epoch: 7, iters: 85472, time: 0.004) nll: 1.020563 \n",
      "(GPU: 0, epoch: 7, iters: 86272, time: 0.005) nll: 0.714532 \n",
      "(GPU: 0, epoch: 7, iters: 87072, time: 0.004) nll: 1.092942 \n",
      "(GPU: 0, epoch: 7, iters: 87872, time: 0.005) nll: 0.866765 \n",
      "(GPU: 0, epoch: 7, iters: 88672, time: 0.005) nll: 0.449790 \n",
      "(GPU: 0, epoch: 7, iters: 89472, time: 0.005) nll: 0.690781 \n",
      "(GPU: 0, epoch: 7, iters: 90272, time: 0.004) nll: 0.769718 \n",
      "(GPU: 0, epoch: 7, iters: 91072, time: 0.005) nll: 0.637157 \n",
      "(GPU: 0, epoch: 7, iters: 91872, time: 0.005) nll: 0.865026 \n",
      "(GPU: 0, epoch: 7, iters: 92672, time: 0.005) nll: 0.723975 \n",
      "(GPU: 0, epoch: 7, iters: 93472, time: 0.004) nll: 0.782000 \n",
      "(GPU: 0, epoch: 7, iters: 94272, time: 0.005) nll: 0.844552 \n",
      "(GPU: 0, epoch: 7, iters: 95072, time: 0.004) nll: 0.570008 \n",
      "saving the latest model (epoch 7, total_steps 1080000)\n",
      "(GPU: 0, epoch: 7, iters: 95872, time: 0.005) nll: 0.600287 \n",
      "(GPU: 0, epoch: 7, iters: 96672, time: 0.005) nll: 0.750028 \n",
      "(GPU: 0, epoch: 7, iters: 97472, time: 0.005) nll: 0.781625 \n",
      "(GPU: 0, epoch: 7, iters: 98272, time: 0.005) nll: 0.809811 \n",
      "(GPU: 0, epoch: 7, iters: 99072, time: 0.005) nll: 0.630908 \n",
      "(GPU: 0, epoch: 7, iters: 99872, time: 0.004) nll: 0.706371 \n",
      "(GPU: 0, epoch: 7, iters: 100672, time: 0.005) nll: 0.724832 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:50<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 7, iters: 101472, time: 0.005) nll: 0.644733 \n",
      "(GPU: 0, epoch: 7, iters: 102272, time: 0.005) nll: 0.790140 \n",
      "(GPU: 0, epoch: 7, iters: 103072, time: 0.005) nll: 0.632754 \n",
      "(GPU: 0, epoch: 7, iters: 103872, time: 0.005) nll: 0.644314 \n",
      "(GPU: 0, epoch: 7, iters: 104672, time: 0.004) nll: 0.672805 \n",
      "(GPU: 0, epoch: 7, iters: 105472, time: 0.005) nll: 0.672022 \n",
      "(GPU: 0, epoch: 7, iters: 106272, time: 0.005) nll: 0.957585 \n",
      "(GPU: 0, epoch: 7, iters: 107072, time: 0.005) nll: 0.702820 \n",
      "(GPU: 0, epoch: 7, iters: 107872, time: 0.004) nll: 0.905653 \n",
      "(GPU: 0, epoch: 7, iters: 108672, time: 0.005) nll: 0.642282 \n",
      "(GPU: 0, epoch: 7, iters: 109472, time: 0.005) nll: 0.727096 \n",
      "(GPU: 0, epoch: 7, iters: 110272, time: 0.005) nll: 0.848375 \n",
      "(GPU: 0, epoch: 7, iters: 111072, time: 0.005) nll: 0.658547 \n",
      "(GPU: 0, epoch: 7, iters: 111872, time: 0.005) nll: 0.775970 \n",
      "(GPU: 0, epoch: 7, iters: 112672, time: 0.005) nll: 0.566891 \n",
      "(GPU: 0, epoch: 7, iters: 113472, time: 0.005) nll: 0.948258 \n",
      "(GPU: 0, epoch: 7, iters: 114272, time: 0.004) nll: 0.794451 \n",
      "(GPU: 0, epoch: 7, iters: 115072, time: 0.005) nll: 0.957738 \n",
      "saving the latest model (epoch 7, total_steps 1100000)\n",
      "(GPU: 0, epoch: 7, iters: 115872, time: 0.004) nll: 0.509237 \n",
      "(GPU: 0, epoch: 7, iters: 116672, time: 0.005) nll: 0.572632 \n",
      "(GPU: 0, epoch: 7, iters: 117472, time: 0.004) nll: 0.885487 \n",
      "(GPU: 0, epoch: 7, iters: 118272, time: 0.005) nll: 0.744143 \n",
      "(GPU: 0, epoch: 7, iters: 119072, time: 0.005) nll: 0.723346 \n",
      "(GPU: 0, epoch: 7, iters: 119872, time: 0.005) nll: 1.046508 \n",
      "(GPU: 0, epoch: 7, iters: 120672, time: 0.004) nll: 0.847723 \n",
      "(GPU: 0, epoch: 7, iters: 121472, time: 0.005) nll: 0.807483 \n",
      "(GPU: 0, epoch: 7, iters: 122272, time: 0.004) nll: 0.827368 \n",
      "(GPU: 0, epoch: 7, iters: 123072, time: 0.005) nll: 0.669113 \n",
      "(GPU: 0, epoch: 7, iters: 123872, time: 0.004) nll: 0.833889 \n",
      "(GPU: 0, epoch: 7, iters: 124672, time: 0.005) nll: 0.693896 \n",
      "(GPU: 0, epoch: 7, iters: 125472, time: 0.005) nll: 0.826007 \n",
      "(GPU: 0, epoch: 7, iters: 126272, time: 0.005) nll: 0.692338 \n",
      "(GPU: 0, epoch: 7, iters: 127072, time: 0.005) nll: 0.755642 \n",
      "(GPU: 0, epoch: 7, iters: 127872, time: 0.005) nll: 0.612930 \n",
      "(GPU: 0, epoch: 7, iters: 128672, time: 0.005) nll: 0.822459 \n",
      "(GPU: 0, epoch: 7, iters: 129472, time: 0.005) nll: 0.751162 \n",
      "(GPU: 0, epoch: 7, iters: 130272, time: 0.005) nll: 1.218395 \n",
      "(GPU: 0, epoch: 7, iters: 131072, time: 0.005) nll: 0.784499 \n",
      "(GPU: 0, epoch: 7, iters: 131872, time: 0.005) nll: 0.588524 \n",
      "(GPU: 0, epoch: 7, iters: 132672, time: 0.005) nll: 0.825702 \n",
      "(GPU: 0, epoch: 7, iters: 133472, time: 0.004) nll: 0.888070 \n",
      "(GPU: 0, epoch: 7, iters: 134272, time: 0.005) nll: 0.741005 \n",
      "(GPU: 0, epoch: 7, iters: 135072, time: 0.005) nll: 0.786081 \n",
      "saving the latest model (epoch 7, total_steps 1120000)\n",
      "(GPU: 0, epoch: 7, iters: 135872, time: 0.005) nll: 0.835694 \n",
      "(GPU: 0, epoch: 7, iters: 136672, time: 0.005) nll: 1.011946 \n",
      "(GPU: 0, epoch: 7, iters: 137472, time: 0.005) nll: 0.784625 \n",
      "(GPU: 0, epoch: 7, iters: 138272, time: 0.004) nll: 0.795855 \n",
      "(GPU: 0, epoch: 7, iters: 139072, time: 0.005) nll: 0.810197 \n",
      "(GPU: 0, epoch: 7, iters: 139872, time: 0.004) nll: 0.707632 \n",
      "(GPU: 0, epoch: 7, iters: 140672, time: 0.005) nll: 0.911611 \n",
      "[*] End of epoch 7 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000800\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3173/4397 [09:15<03:14,  6.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 32, time: 0.003) nll: 0.738962 \n",
      "(GPU: 0, epoch: 8, iters: 32, time: 0.003) nll: 0.525430 \n",
      "(GPU: 0, epoch: 8, iters: 768, time: 0.005) nll: 0.668416 \n",
      "(GPU: 0, epoch: 8, iters: 1568, time: 0.005) nll: 0.637828 \n",
      "(GPU: 0, epoch: 8, iters: 2368, time: 0.005) nll: 0.517680 \n",
      "(GPU: 0, epoch: 8, iters: 3168, time: 0.005) nll: 0.801337 \n",
      "(GPU: 0, epoch: 8, iters: 3968, time: 0.005) nll: 0.750501 \n",
      "(GPU: 0, epoch: 8, iters: 4768, time: 0.005) nll: 0.754647 \n",
      "(GPU: 0, epoch: 8, iters: 5568, time: 0.005) nll: 0.703427 \n",
      "(GPU: 0, epoch: 8, iters: 6368, time: 0.005) nll: 0.834335 \n",
      "(GPU: 0, epoch: 8, iters: 7168, time: 0.005) nll: 1.055609 \n",
      "(GPU: 0, epoch: 8, iters: 7968, time: 0.004) nll: 0.695537 \n",
      "(GPU: 0, epoch: 8, iters: 8768, time: 0.005) nll: 0.661762 \n",
      "(GPU: 0, epoch: 8, iters: 9568, time: 0.004) nll: 1.022293 \n",
      "(GPU: 0, epoch: 8, iters: 10368, time: 0.005) nll: 0.822621 \n",
      "(GPU: 0, epoch: 8, iters: 11168, time: 0.004) nll: 0.540785 \n",
      "(GPU: 0, epoch: 8, iters: 11968, time: 0.005) nll: 0.806824 \n",
      "(GPU: 0, epoch: 8, iters: 12768, time: 0.004) nll: 0.783002 \n",
      "(GPU: 0, epoch: 8, iters: 13568, time: 0.005) nll: 0.797550 \n",
      "(GPU: 0, epoch: 8, iters: 14368, time: 0.005) nll: 0.758401 \n",
      "saving the latest model (epoch 8, total_steps 1140000)\n",
      "(GPU: 0, epoch: 8, iters: 15168, time: 0.005) nll: 0.638028 \n",
      "(GPU: 0, epoch: 8, iters: 15968, time: 0.005) nll: 0.689919 \n",
      "(GPU: 0, epoch: 8, iters: 16768, time: 0.005) nll: 0.931545 \n",
      "(GPU: 0, epoch: 8, iters: 17568, time: 0.005) nll: 0.827765 \n",
      "(GPU: 0, epoch: 8, iters: 18368, time: 0.005) nll: 0.789488 \n",
      "(GPU: 0, epoch: 8, iters: 19168, time: 0.004) nll: 0.896665 \n",
      "(GPU: 0, epoch: 8, iters: 19968, time: 0.005) nll: 0.716641 \n",
      "(GPU: 0, epoch: 8, iters: 20768, time: 0.004) nll: 0.816776 \n",
      "(GPU: 0, epoch: 8, iters: 21568, time: 0.005) nll: 0.733196 \n",
      "(GPU: 0, epoch: 8, iters: 22368, time: 0.004) nll: 0.820365 \n",
      "(GPU: 0, epoch: 8, iters: 23168, time: 0.005) nll: 0.872834 \n",
      "(GPU: 0, epoch: 8, iters: 23968, time: 0.005) nll: 0.742066 \n",
      "(GPU: 0, epoch: 8, iters: 24768, time: 0.005) nll: 0.807031 \n",
      "(GPU: 0, epoch: 8, iters: 25568, time: 0.005) nll: 0.516938 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.005) nll: 0.721243 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.008) nll: 0.719178 \n",
      "(GPU: 0, epoch: 8, iters: 26368, time: 0.008) nll: 0.864840 \n",
      "(GPU: 0, epoch: 8, iters: 27168, time: 0.004) nll: 0.787566 \n",
      "(GPU: 0, epoch: 8, iters: 27968, time: 0.005) nll: 0.831502 \n",
      "(GPU: 0, epoch: 8, iters: 28768, time: 0.004) nll: 0.609204 \n",
      "(GPU: 0, epoch: 8, iters: 29568, time: 0.005) nll: 0.844943 \n",
      "(GPU: 0, epoch: 8, iters: 30368, time: 0.005) nll: 0.734930 \n",
      "(GPU: 0, epoch: 8, iters: 31168, time: 0.005) nll: 0.827170 \n",
      "(GPU: 0, epoch: 8, iters: 31968, time: 0.005) nll: 0.884663 \n",
      "(GPU: 0, epoch: 8, iters: 32768, time: 0.005) nll: 0.462396 \n",
      "(GPU: 0, epoch: 8, iters: 33568, time: 0.004) nll: 0.513660 \n",
      "(GPU: 0, epoch: 8, iters: 34368, time: 0.005) nll: 0.659344 \n",
      "saving the latest model (epoch 8, total_steps 1160000)\n",
      "(GPU: 0, epoch: 8, iters: 35168, time: 0.004) nll: 0.772710 \n",
      "(GPU: 0, epoch: 8, iters: 35968, time: 0.005) nll: 0.698482 \n",
      "(GPU: 0, epoch: 8, iters: 36768, time: 0.005) nll: 0.672052 \n",
      "(GPU: 0, epoch: 8, iters: 37568, time: 0.005) nll: 0.834528 \n",
      "(GPU: 0, epoch: 8, iters: 38368, time: 0.004) nll: 0.758398 \n",
      "(GPU: 0, epoch: 8, iters: 39168, time: 0.005) nll: 0.897074 \n",
      "(GPU: 0, epoch: 8, iters: 39968, time: 0.005) nll: 0.847843 \n",
      "(GPU: 0, epoch: 8, iters: 40768, time: 0.005) nll: 0.548174 \n",
      "(GPU: 0, epoch: 8, iters: 41568, time: 0.004) nll: 1.216037 \n",
      "(GPU: 0, epoch: 8, iters: 42368, time: 0.005) nll: 0.533759 \n",
      "(GPU: 0, epoch: 8, iters: 43168, time: 0.004) nll: 0.773954 \n",
      "(GPU: 0, epoch: 8, iters: 43968, time: 0.005) nll: 0.927404 \n",
      "(GPU: 0, epoch: 8, iters: 44768, time: 0.004) nll: 0.833506 \n",
      "(GPU: 0, epoch: 8, iters: 45568, time: 0.005) nll: 0.699783 \n",
      "(GPU: 0, epoch: 8, iters: 46368, time: 0.004) nll: 0.788064 \n",
      "(GPU: 0, epoch: 8, iters: 47168, time: 0.005) nll: 0.762370 \n",
      "(GPU: 0, epoch: 8, iters: 47968, time: 0.004) nll: 0.819510 \n",
      "(GPU: 0, epoch: 8, iters: 48768, time: 0.005) nll: 0.888540 \n",
      "(GPU: 0, epoch: 8, iters: 49568, time: 0.005) nll: 0.781373 \n",
      "(GPU: 0, epoch: 8, iters: 50368, time: 0.005) nll: 0.578579 \n",
      "(GPU: 0, epoch: 8, iters: 51168, time: 0.004) nll: 0.594038 \n",
      "(GPU: 0, epoch: 8, iters: 51968, time: 0.005) nll: 0.550994 \n",
      "(GPU: 0, epoch: 8, iters: 52768, time: 0.004) nll: 0.692496 \n",
      "(GPU: 0, epoch: 8, iters: 53568, time: 0.005) nll: 0.668333 \n",
      "(GPU: 0, epoch: 8, iters: 54368, time: 0.004) nll: 0.677057 \n",
      "saving the latest model (epoch 8, total_steps 1180000)\n",
      "(GPU: 0, epoch: 8, iters: 55168, time: 0.005) nll: 1.036702 \n",
      "(GPU: 0, epoch: 8, iters: 55968, time: 0.005) nll: 0.870526 \n",
      "(GPU: 0, epoch: 8, iters: 56768, time: 0.005) nll: 0.581245 \n",
      "(GPU: 0, epoch: 8, iters: 57568, time: 0.005) nll: 0.929800 \n",
      "(GPU: 0, epoch: 8, iters: 58368, time: 0.005) nll: 0.663407 \n",
      "(GPU: 0, epoch: 8, iters: 59168, time: 0.005) nll: 0.875409 \n",
      "(GPU: 0, epoch: 8, iters: 59968, time: 0.005) nll: 0.617410 \n",
      "(GPU: 0, epoch: 8, iters: 60768, time: 0.005) nll: 0.666605 \n",
      "(GPU: 0, epoch: 8, iters: 61568, time: 0.005) nll: 0.864335 \n",
      "(GPU: 0, epoch: 8, iters: 62368, time: 0.005) nll: 0.737191 \n",
      "(GPU: 0, epoch: 8, iters: 63168, time: 0.005) nll: 0.718806 \n",
      "(GPU: 0, epoch: 8, iters: 63968, time: 0.004) nll: 0.853346 \n",
      "(GPU: 0, epoch: 8, iters: 64768, time: 0.005) nll: 0.560130 \n",
      "(GPU: 0, epoch: 8, iters: 65568, time: 0.004) nll: 0.790686 \n",
      "(GPU: 0, epoch: 8, iters: 66368, time: 0.005) nll: 0.785883 \n",
      "(GPU: 0, epoch: 8, iters: 67168, time: 0.005) nll: 1.013340 \n",
      "(GPU: 0, epoch: 8, iters: 67968, time: 0.005) nll: 0.571876 \n",
      "(GPU: 0, epoch: 8, iters: 68768, time: 0.004) nll: 0.779442 \n",
      "(GPU: 0, epoch: 8, iters: 69568, time: 0.005) nll: 0.577830 \n",
      "(GPU: 0, epoch: 8, iters: 70368, time: 0.005) nll: 0.516875 \n",
      "(GPU: 0, epoch: 8, iters: 71168, time: 0.005) nll: 0.560565 \n",
      "(GPU: 0, epoch: 8, iters: 71968, time: 0.004) nll: 0.548979 \n",
      "(GPU: 0, epoch: 8, iters: 72768, time: 0.005) nll: 0.887583 \n",
      "(GPU: 0, epoch: 8, iters: 73568, time: 0.004) nll: 0.875974 \n",
      "(GPU: 0, epoch: 8, iters: 74368, time: 0.005) nll: 0.600146 \n",
      "saving the latest model (epoch 8, total_steps 1200000)\n",
      "(GPU: 0, epoch: 8, iters: 75168, time: 0.005) nll: 0.605689 \n",
      "(GPU: 0, epoch: 8, iters: 75968, time: 0.005) nll: 0.831653 \n",
      "(GPU: 0, epoch: 8, iters: 76768, time: 0.004) nll: 0.615643 \n",
      "(GPU: 0, epoch: 8, iters: 77568, time: 0.005) nll: 0.862429 \n",
      "(GPU: 0, epoch: 8, iters: 78368, time: 0.005) nll: 0.699484 \n",
      "(GPU: 0, epoch: 8, iters: 79168, time: 0.005) nll: 0.507914 \n",
      "(GPU: 0, epoch: 8, iters: 79968, time: 0.004) nll: 0.814198 \n",
      "(GPU: 0, epoch: 8, iters: 80768, time: 0.005) nll: 0.746162 \n",
      "(GPU: 0, epoch: 8, iters: 81568, time: 0.004) nll: 0.602887 \n",
      "(GPU: 0, epoch: 8, iters: 82368, time: 0.005) nll: 0.863662 \n",
      "(GPU: 0, epoch: 8, iters: 83168, time: 0.004) nll: 0.761852 \n",
      "(GPU: 0, epoch: 8, iters: 83968, time: 0.005) nll: 0.448151 \n",
      "(GPU: 0, epoch: 8, iters: 84768, time: 0.004) nll: 1.109979 \n",
      "(GPU: 0, epoch: 8, iters: 85568, time: 0.005) nll: 0.745098 \n",
      "(GPU: 0, epoch: 8, iters: 86368, time: 0.004) nll: 0.792600 \n",
      "(GPU: 0, epoch: 8, iters: 87168, time: 0.005) nll: 0.697375 \n",
      "(GPU: 0, epoch: 8, iters: 87968, time: 0.005) nll: 0.694549 \n",
      "(GPU: 0, epoch: 8, iters: 88768, time: 0.005) nll: 0.792983 \n",
      "(GPU: 0, epoch: 8, iters: 89568, time: 0.004) nll: 0.730449 \n",
      "(GPU: 0, epoch: 8, iters: 90368, time: 0.005) nll: 0.681566 \n",
      "(GPU: 0, epoch: 8, iters: 91168, time: 0.005) nll: 0.735768 \n",
      "(GPU: 0, epoch: 8, iters: 91968, time: 0.005) nll: 0.907447 \n",
      "(GPU: 0, epoch: 8, iters: 92768, time: 0.005) nll: 0.621341 \n",
      "(GPU: 0, epoch: 8, iters: 93568, time: 0.005) nll: 0.788181 \n",
      "(GPU: 0, epoch: 8, iters: 94368, time: 0.004) nll: 0.677973 \n",
      "saving the latest model (epoch 8, total_steps 1220000)\n",
      "(GPU: 0, epoch: 8, iters: 95168, time: 0.005) nll: 0.743388 \n",
      "(GPU: 0, epoch: 8, iters: 95968, time: 0.005) nll: 0.724108 \n",
      "(GPU: 0, epoch: 8, iters: 96768, time: 0.005) nll: 0.827344 \n",
      "(GPU: 0, epoch: 8, iters: 97568, time: 0.004) nll: 0.705348 \n",
      "(GPU: 0, epoch: 8, iters: 98368, time: 0.005) nll: 0.766365 \n",
      "(GPU: 0, epoch: 8, iters: 99168, time: 0.004) nll: 0.681294 \n",
      "(GPU: 0, epoch: 8, iters: 99968, time: 0.005) nll: 0.702229 \n",
      "(GPU: 0, epoch: 8, iters: 100768, time: 0.004) nll: 0.755450 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:49<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 8, iters: 101568, time: 0.005) nll: 0.557862 \n",
      "(GPU: 0, epoch: 8, iters: 102368, time: 0.005) nll: 0.834225 \n",
      "(GPU: 0, epoch: 8, iters: 103168, time: 0.005) nll: 0.638713 \n",
      "(GPU: 0, epoch: 8, iters: 103968, time: 0.005) nll: 0.665616 \n",
      "(GPU: 0, epoch: 8, iters: 104768, time: 0.005) nll: 0.843437 \n",
      "(GPU: 0, epoch: 8, iters: 105568, time: 0.005) nll: 0.895072 \n",
      "(GPU: 0, epoch: 8, iters: 106368, time: 0.005) nll: 0.669378 \n",
      "(GPU: 0, epoch: 8, iters: 107168, time: 0.005) nll: 0.538205 \n",
      "(GPU: 0, epoch: 8, iters: 107968, time: 0.005) nll: 0.722404 \n",
      "(GPU: 0, epoch: 8, iters: 108768, time: 0.004) nll: 0.706174 \n",
      "(GPU: 0, epoch: 8, iters: 109568, time: 0.005) nll: 0.708769 \n",
      "(GPU: 0, epoch: 8, iters: 110368, time: 0.005) nll: 0.707058 \n",
      "(GPU: 0, epoch: 8, iters: 111168, time: 0.005) nll: 0.615042 \n",
      "(GPU: 0, epoch: 8, iters: 111968, time: 0.005) nll: 0.784760 \n",
      "(GPU: 0, epoch: 8, iters: 112768, time: 0.005) nll: 0.819888 \n",
      "(GPU: 0, epoch: 8, iters: 113568, time: 0.005) nll: 0.805176 \n",
      "(GPU: 0, epoch: 8, iters: 114368, time: 0.005) nll: 0.802011 \n",
      "saving the latest model (epoch 8, total_steps 1240000)\n",
      "(GPU: 0, epoch: 8, iters: 115168, time: 0.004) nll: 0.776186 \n",
      "(GPU: 0, epoch: 8, iters: 115968, time: 0.005) nll: 0.903339 \n",
      "(GPU: 0, epoch: 8, iters: 116768, time: 0.005) nll: 0.627741 \n",
      "(GPU: 0, epoch: 8, iters: 117568, time: 0.005) nll: 0.700259 \n",
      "(GPU: 0, epoch: 8, iters: 118368, time: 0.005) nll: 0.789219 \n",
      "(GPU: 0, epoch: 8, iters: 119168, time: 0.005) nll: 0.910662 \n",
      "(GPU: 0, epoch: 8, iters: 119968, time: 0.004) nll: 0.591127 \n",
      "(GPU: 0, epoch: 8, iters: 120768, time: 0.005) nll: 0.695773 \n",
      "(GPU: 0, epoch: 8, iters: 121568, time: 0.004) nll: 0.618141 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.005) nll: 0.706188 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.008) nll: 0.700355 \n",
      "(GPU: 0, epoch: 8, iters: 122368, time: 0.008) nll: 0.802137 \n",
      "(GPU: 0, epoch: 8, iters: 123168, time: 0.004) nll: 1.118606 \n",
      "(GPU: 0, epoch: 8, iters: 123968, time: 0.005) nll: 0.786845 \n",
      "(GPU: 0, epoch: 8, iters: 124768, time: 0.005) nll: 0.836752 \n",
      "(GPU: 0, epoch: 8, iters: 125568, time: 0.005) nll: 0.798619 \n",
      "(GPU: 0, epoch: 8, iters: 126368, time: 0.004) nll: 0.993216 \n",
      "(GPU: 0, epoch: 8, iters: 127168, time: 0.005) nll: 0.932830 \n",
      "(GPU: 0, epoch: 8, iters: 127968, time: 0.004) nll: 0.965297 \n",
      "(GPU: 0, epoch: 8, iters: 128768, time: 0.005) nll: 0.894033 \n",
      "(GPU: 0, epoch: 8, iters: 129568, time: 0.005) nll: 0.690729 \n",
      "(GPU: 0, epoch: 8, iters: 130368, time: 0.005) nll: 0.778360 \n",
      "(GPU: 0, epoch: 8, iters: 131168, time: 0.005) nll: 0.764472 \n",
      "(GPU: 0, epoch: 8, iters: 131968, time: 0.005) nll: 0.969224 \n",
      "(GPU: 0, epoch: 8, iters: 132768, time: 0.005) nll: 0.736436 \n",
      "(GPU: 0, epoch: 8, iters: 133568, time: 0.005) nll: 0.652161 \n",
      "(GPU: 0, epoch: 8, iters: 134368, time: 0.004) nll: 0.773166 \n",
      "saving the latest model (epoch 8, total_steps 1260000)\n",
      "(GPU: 0, epoch: 8, iters: 135168, time: 0.005) nll: 0.538139 \n",
      "(GPU: 0, epoch: 8, iters: 135968, time: 0.005) nll: 0.643357 \n",
      "(GPU: 0, epoch: 8, iters: 136768, time: 0.005) nll: 0.767454 \n",
      "(GPU: 0, epoch: 8, iters: 137568, time: 0.005) nll: 0.625378 \n",
      "(GPU: 0, epoch: 8, iters: 138368, time: 0.005) nll: 0.809034 \n",
      "(GPU: 0, epoch: 8, iters: 139168, time: 0.004) nll: 0.723598 \n",
      "(GPU: 0, epoch: 8, iters: 139968, time: 0.005) nll: 0.942012 \n",
      "[*] End of epoch 8 / 25 \t Time Taken: 770 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000900\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3151/4397 [09:12<03:19,  6.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 32, time: 0.003) nll: 0.929931 \n",
      "(GPU: 0, epoch: 9, iters: 32, time: 0.003) nll: 0.767637 \n",
      "(GPU: 0, epoch: 9, iters: 64, time: 0.002) nll: 0.755208 \n",
      "(GPU: 0, epoch: 9, iters: 864, time: 0.005) nll: 0.598041 \n",
      "(GPU: 0, epoch: 9, iters: 1664, time: 0.005) nll: 0.679494 \n",
      "(GPU: 0, epoch: 9, iters: 2464, time: 0.004) nll: 1.050027 \n",
      "(GPU: 0, epoch: 9, iters: 3264, time: 0.005) nll: 0.783647 \n",
      "(GPU: 0, epoch: 9, iters: 4064, time: 0.004) nll: 0.874597 \n",
      "(GPU: 0, epoch: 9, iters: 4864, time: 0.005) nll: 1.027685 \n",
      "(GPU: 0, epoch: 9, iters: 5664, time: 0.005) nll: 0.846471 \n",
      "(GPU: 0, epoch: 9, iters: 6464, time: 0.005) nll: 0.688878 \n",
      "(GPU: 0, epoch: 9, iters: 7264, time: 0.004) nll: 0.781785 \n",
      "(GPU: 0, epoch: 9, iters: 8064, time: 0.005) nll: 0.786774 \n",
      "(GPU: 0, epoch: 9, iters: 8864, time: 0.004) nll: 0.909054 \n",
      "(GPU: 0, epoch: 9, iters: 9664, time: 0.005) nll: 0.789131 \n",
      "(GPU: 0, epoch: 9, iters: 10464, time: 0.004) nll: 0.836809 \n",
      "(GPU: 0, epoch: 9, iters: 11264, time: 0.005) nll: 0.841564 \n",
      "(GPU: 0, epoch: 9, iters: 12064, time: 0.004) nll: 0.625828 \n",
      "(GPU: 0, epoch: 9, iters: 12864, time: 0.005) nll: 0.700665 \n",
      "(GPU: 0, epoch: 9, iters: 13664, time: 0.004) nll: 0.817200 \n",
      "saving the latest model (epoch 9, total_steps 1280000)\n",
      "(GPU: 0, epoch: 9, iters: 14464, time: 0.005) nll: 0.688478 \n",
      "(GPU: 0, epoch: 9, iters: 15264, time: 0.004) nll: 0.714781 \n",
      "(GPU: 0, epoch: 9, iters: 16064, time: 0.005) nll: 0.702315 \n",
      "(GPU: 0, epoch: 9, iters: 16864, time: 0.005) nll: 0.645592 \n",
      "(GPU: 0, epoch: 9, iters: 17664, time: 0.005) nll: 0.844887 \n",
      "(GPU: 0, epoch: 9, iters: 18464, time: 0.004) nll: 0.676346 \n",
      "(GPU: 0, epoch: 9, iters: 19264, time: 0.005) nll: 0.784109 \n",
      "(GPU: 0, epoch: 9, iters: 20064, time: 0.005) nll: 0.655554 \n",
      "(GPU: 0, epoch: 9, iters: 20864, time: 0.005) nll: 0.747569 \n",
      "(GPU: 0, epoch: 9, iters: 21664, time: 0.004) nll: 0.620018 \n",
      "(GPU: 0, epoch: 9, iters: 22464, time: 0.005) nll: 0.917876 \n",
      "(GPU: 0, epoch: 9, iters: 23264, time: 0.004) nll: 0.689743 \n",
      "(GPU: 0, epoch: 9, iters: 24064, time: 0.005) nll: 0.747272 \n",
      "(GPU: 0, epoch: 9, iters: 24864, time: 0.005) nll: 1.010317 \n",
      "(GPU: 0, epoch: 9, iters: 25664, time: 0.005) nll: 0.963042 \n",
      "(GPU: 0, epoch: 9, iters: 26464, time: 0.004) nll: 0.825340 \n",
      "(GPU: 0, epoch: 9, iters: 27264, time: 0.005) nll: 0.859672 \n",
      "(GPU: 0, epoch: 9, iters: 28064, time: 0.004) nll: 0.468329 \n",
      "(GPU: 0, epoch: 9, iters: 28864, time: 0.005) nll: 0.624411 \n",
      "(GPU: 0, epoch: 9, iters: 29664, time: 0.005) nll: 0.700337 \n",
      "(GPU: 0, epoch: 9, iters: 30464, time: 0.005) nll: 0.594557 \n",
      "(GPU: 0, epoch: 9, iters: 31264, time: 0.004) nll: 0.747347 \n",
      "(GPU: 0, epoch: 9, iters: 32064, time: 0.005) nll: 0.674311 \n",
      "(GPU: 0, epoch: 9, iters: 32864, time: 0.005) nll: 0.658395 \n",
      "(GPU: 0, epoch: 9, iters: 33664, time: 0.005) nll: 0.578108 \n",
      "saving the latest model (epoch 9, total_steps 1300000)\n",
      "(GPU: 0, epoch: 9, iters: 34464, time: 0.005) nll: 0.929203 \n",
      "(GPU: 0, epoch: 9, iters: 35264, time: 0.005) nll: 0.702572 \n",
      "(GPU: 0, epoch: 9, iters: 36064, time: 0.004) nll: 0.708412 \n",
      "(GPU: 0, epoch: 9, iters: 36864, time: 0.005) nll: 0.795790 \n",
      "(GPU: 0, epoch: 9, iters: 37664, time: 0.005) nll: 0.717043 \n",
      "(GPU: 0, epoch: 9, iters: 38464, time: 0.005) nll: 0.714891 \n",
      "(GPU: 0, epoch: 9, iters: 39264, time: 0.005) nll: 0.517877 \n",
      "(GPU: 0, epoch: 9, iters: 40064, time: 0.005) nll: 0.679333 \n",
      "(GPU: 0, epoch: 9, iters: 40864, time: 0.004) nll: 0.826973 \n",
      "(GPU: 0, epoch: 9, iters: 41664, time: 0.005) nll: 0.921311 \n",
      "(GPU: 0, epoch: 9, iters: 42464, time: 0.004) nll: 0.668029 \n",
      "(GPU: 0, epoch: 9, iters: 43264, time: 0.005) nll: 0.885214 \n",
      "(GPU: 0, epoch: 9, iters: 44064, time: 0.004) nll: 0.875150 \n",
      "(GPU: 0, epoch: 9, iters: 44864, time: 0.005) nll: 0.939057 \n",
      "(GPU: 0, epoch: 9, iters: 45664, time: 0.005) nll: 0.703425 \n",
      "(GPU: 0, epoch: 9, iters: 46464, time: 0.005) nll: 0.676923 \n",
      "(GPU: 0, epoch: 9, iters: 47264, time: 0.005) nll: 0.782463 \n",
      "(GPU: 0, epoch: 9, iters: 48064, time: 0.005) nll: 0.684824 \n",
      "(GPU: 0, epoch: 9, iters: 48864, time: 0.004) nll: 0.945593 \n",
      "(GPU: 0, epoch: 9, iters: 49664, time: 0.005) nll: 0.771607 \n",
      "(GPU: 0, epoch: 9, iters: 50464, time: 0.004) nll: 1.079252 \n",
      "(GPU: 0, epoch: 9, iters: 51264, time: 0.005) nll: 0.767306 \n",
      "(GPU: 0, epoch: 9, iters: 52064, time: 0.004) nll: 0.688500 \n",
      "(GPU: 0, epoch: 9, iters: 52864, time: 0.005) nll: 0.751028 \n",
      "(GPU: 0, epoch: 9, iters: 53664, time: 0.004) nll: 0.712342 \n",
      "saving the latest model (epoch 9, total_steps 1320000)\n",
      "(GPU: 0, epoch: 9, iters: 54464, time: 0.005) nll: 0.704862 \n",
      "(GPU: 0, epoch: 9, iters: 55264, time: 0.004) nll: 0.466215 \n",
      "(GPU: 0, epoch: 9, iters: 56064, time: 0.005) nll: 0.920650 \n",
      "(GPU: 0, epoch: 9, iters: 56864, time: 0.005) nll: 0.917231 \n",
      "(GPU: 0, epoch: 9, iters: 57664, time: 0.005) nll: 0.850928 \n",
      "(GPU: 0, epoch: 9, iters: 58464, time: 0.004) nll: 0.947216 \n",
      "(GPU: 0, epoch: 9, iters: 59264, time: 0.005) nll: 0.861715 \n",
      "(GPU: 0, epoch: 9, iters: 60064, time: 0.005) nll: 0.814265 \n",
      "(GPU: 0, epoch: 9, iters: 60864, time: 0.005) nll: 0.810796 \n",
      "(GPU: 0, epoch: 9, iters: 61664, time: 0.004) nll: 0.802001 \n",
      "(GPU: 0, epoch: 9, iters: 62464, time: 0.005) nll: 0.757343 \n",
      "(GPU: 0, epoch: 9, iters: 63264, time: 0.004) nll: 0.476883 \n",
      "(GPU: 0, epoch: 9, iters: 64064, time: 0.005) nll: 0.894365 \n",
      "(GPU: 0, epoch: 9, iters: 64864, time: 0.005) nll: 0.476542 \n",
      "(GPU: 0, epoch: 9, iters: 65664, time: 0.005) nll: 0.917672 \n",
      "(GPU: 0, epoch: 9, iters: 66464, time: 0.004) nll: 0.992560 \n",
      "(GPU: 0, epoch: 9, iters: 67264, time: 0.005) nll: 0.519422 \n",
      "(GPU: 0, epoch: 9, iters: 68064, time: 0.005) nll: 0.679308 \n",
      "(GPU: 0, epoch: 9, iters: 68864, time: 0.005) nll: 0.742567 \n",
      "(GPU: 0, epoch: 9, iters: 69664, time: 0.004) nll: 0.766437 \n",
      "(GPU: 0, epoch: 9, iters: 70464, time: 0.005) nll: 0.729172 \n",
      "(GPU: 0, epoch: 9, iters: 71264, time: 0.005) nll: 0.867579 \n",
      "(GPU: 0, epoch: 9, iters: 72064, time: 0.005) nll: 0.891920 \n",
      "(GPU: 0, epoch: 9, iters: 72864, time: 0.005) nll: 0.928043 \n",
      "(GPU: 0, epoch: 9, iters: 73664, time: 0.005) nll: 0.562130 \n",
      "saving the latest model (epoch 9, total_steps 1340000)\n",
      "(GPU: 0, epoch: 9, iters: 74464, time: 0.004) nll: 1.051467 \n",
      "(GPU: 0, epoch: 9, iters: 75264, time: 0.005) nll: 0.773275 \n",
      "(GPU: 0, epoch: 9, iters: 76064, time: 0.004) nll: 0.833984 \n",
      "(GPU: 0, epoch: 9, iters: 76864, time: 0.005) nll: 0.617008 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.004) nll: 0.569975 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.007) nll: 0.565366 \n",
      "(GPU: 0, epoch: 9, iters: 77664, time: 0.007) nll: 0.636286 \n",
      "(GPU: 0, epoch: 9, iters: 78464, time: 0.005) nll: 0.819362 \n",
      "(GPU: 0, epoch: 9, iters: 79264, time: 0.004) nll: 0.833376 \n",
      "(GPU: 0, epoch: 9, iters: 80064, time: 0.005) nll: 0.579609 \n",
      "(GPU: 0, epoch: 9, iters: 80864, time: 0.005) nll: 0.755742 \n",
      "(GPU: 0, epoch: 9, iters: 81664, time: 0.005) nll: 0.955219 \n",
      "(GPU: 0, epoch: 9, iters: 82464, time: 0.005) nll: 0.725030 \n",
      "(GPU: 0, epoch: 9, iters: 83264, time: 0.005) nll: 0.869573 \n",
      "(GPU: 0, epoch: 9, iters: 84064, time: 0.004) nll: 0.867250 \n",
      "(GPU: 0, epoch: 9, iters: 84864, time: 0.005) nll: 0.743914 \n",
      "(GPU: 0, epoch: 9, iters: 85664, time: 0.004) nll: 0.738866 \n",
      "(GPU: 0, epoch: 9, iters: 86464, time: 0.005) nll: 0.768521 \n",
      "(GPU: 0, epoch: 9, iters: 87264, time: 0.004) nll: 0.531061 \n",
      "(GPU: 0, epoch: 9, iters: 88064, time: 0.005) nll: 0.958223 \n",
      "(GPU: 0, epoch: 9, iters: 88864, time: 0.005) nll: 0.490712 \n",
      "(GPU: 0, epoch: 9, iters: 89664, time: 0.005) nll: 0.713706 \n",
      "(GPU: 0, epoch: 9, iters: 90464, time: 0.005) nll: 0.950613 \n",
      "(GPU: 0, epoch: 9, iters: 91264, time: 0.005) nll: 0.783098 \n",
      "(GPU: 0, epoch: 9, iters: 92064, time: 0.004) nll: 0.665640 \n",
      "(GPU: 0, epoch: 9, iters: 92864, time: 0.005) nll: 0.697819 \n",
      "(GPU: 0, epoch: 9, iters: 93664, time: 0.005) nll: 0.797235 \n",
      "saving the latest model (epoch 9, total_steps 1360000)\n",
      "(GPU: 0, epoch: 9, iters: 94464, time: 0.005) nll: 0.625854 \n",
      "(GPU: 0, epoch: 9, iters: 95264, time: 0.004) nll: 0.685915 \n",
      "(GPU: 0, epoch: 9, iters: 96064, time: 0.005) nll: 0.831172 \n",
      "(GPU: 0, epoch: 9, iters: 96864, time: 0.004) nll: 0.666070 \n",
      "(GPU: 0, epoch: 9, iters: 97664, time: 0.005) nll: 0.954888 \n",
      "(GPU: 0, epoch: 9, iters: 98464, time: 0.005) nll: 0.833386 \n",
      "(GPU: 0, epoch: 9, iters: 99264, time: 0.005) nll: 0.764185 \n",
      "(GPU: 0, epoch: 9, iters: 100064, time: 0.005) nll: 0.590701 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 9, iters: 100864, time: 0.005) nll: 0.892511 \n",
      "(GPU: 0, epoch: 9, iters: 101664, time: 0.005) nll: 0.674247 \n",
      "(GPU: 0, epoch: 9, iters: 102464, time: 0.005) nll: 0.735195 \n",
      "(GPU: 0, epoch: 9, iters: 103264, time: 0.005) nll: 0.781911 \n",
      "(GPU: 0, epoch: 9, iters: 104064, time: 0.005) nll: 0.641104 \n",
      "(GPU: 0, epoch: 9, iters: 104864, time: 0.004) nll: 0.730017 \n",
      "(GPU: 0, epoch: 9, iters: 105664, time: 0.005) nll: 0.944828 \n",
      "(GPU: 0, epoch: 9, iters: 106464, time: 0.004) nll: 0.801591 \n",
      "(GPU: 0, epoch: 9, iters: 107264, time: 0.005) nll: 0.674473 \n",
      "(GPU: 0, epoch: 9, iters: 108064, time: 0.004) nll: 0.719268 \n",
      "(GPU: 0, epoch: 9, iters: 108864, time: 0.005) nll: 0.794563 \n",
      "(GPU: 0, epoch: 9, iters: 109664, time: 0.005) nll: 0.843476 \n",
      "(GPU: 0, epoch: 9, iters: 110464, time: 0.005) nll: 0.824075 \n",
      "(GPU: 0, epoch: 9, iters: 111264, time: 0.004) nll: 0.572296 \n",
      "(GPU: 0, epoch: 9, iters: 112064, time: 0.005) nll: 0.698591 \n",
      "(GPU: 0, epoch: 9, iters: 112864, time: 0.005) nll: 0.571955 \n",
      "(GPU: 0, epoch: 9, iters: 113664, time: 0.005) nll: 0.641459 \n",
      "saving the latest model (epoch 9, total_steps 1380000)\n",
      "(GPU: 0, epoch: 9, iters: 114464, time: 0.004) nll: 0.817246 \n",
      "(GPU: 0, epoch: 9, iters: 115264, time: 0.005) nll: 0.791166 \n",
      "(GPU: 0, epoch: 9, iters: 116064, time: 0.005) nll: 0.750854 \n",
      "(GPU: 0, epoch: 9, iters: 116864, time: 0.005) nll: 0.616825 \n",
      "(GPU: 0, epoch: 9, iters: 117664, time: 0.005) nll: 0.942697 \n",
      "(GPU: 0, epoch: 9, iters: 118464, time: 0.005) nll: 0.699822 \n",
      "(GPU: 0, epoch: 9, iters: 119264, time: 0.004) nll: 0.708624 \n",
      "(GPU: 0, epoch: 9, iters: 120064, time: 0.005) nll: 0.852770 \n",
      "(GPU: 0, epoch: 9, iters: 120864, time: 0.005) nll: 0.976311 \n",
      "(GPU: 0, epoch: 9, iters: 121664, time: 0.005) nll: 0.607748 \n",
      "(GPU: 0, epoch: 9, iters: 122464, time: 0.004) nll: 0.723175 \n",
      "(GPU: 0, epoch: 9, iters: 123264, time: 0.005) nll: 0.593868 \n",
      "(GPU: 0, epoch: 9, iters: 124064, time: 0.004) nll: 0.725753 \n",
      "(GPU: 0, epoch: 9, iters: 124864, time: 0.005) nll: 0.739921 \n",
      "(GPU: 0, epoch: 9, iters: 125664, time: 0.004) nll: 0.728267 \n",
      "(GPU: 0, epoch: 9, iters: 126464, time: 0.005) nll: 0.759809 \n",
      "(GPU: 0, epoch: 9, iters: 127264, time: 0.005) nll: 0.509707 \n",
      "(GPU: 0, epoch: 9, iters: 128064, time: 0.005) nll: 0.828928 \n",
      "(GPU: 0, epoch: 9, iters: 128864, time: 0.005) nll: 1.010161 \n",
      "(GPU: 0, epoch: 9, iters: 129664, time: 0.005) nll: 0.807507 \n",
      "(GPU: 0, epoch: 9, iters: 130464, time: 0.005) nll: 0.674662 \n",
      "(GPU: 0, epoch: 9, iters: 131264, time: 0.005) nll: 0.734108 \n",
      "(GPU: 0, epoch: 9, iters: 132064, time: 0.005) nll: 0.656572 \n",
      "(GPU: 0, epoch: 9, iters: 132864, time: 0.005) nll: 0.715407 \n",
      "(GPU: 0, epoch: 9, iters: 133664, time: 0.005) nll: 0.765447 \n",
      "saving the latest model (epoch 9, total_steps 1400000)\n",
      "(GPU: 0, epoch: 9, iters: 134464, time: 0.005) nll: 0.649775 \n",
      "(GPU: 0, epoch: 9, iters: 135264, time: 0.004) nll: 0.738768 \n",
      "(GPU: 0, epoch: 9, iters: 136064, time: 0.005) nll: 0.772598 \n",
      "(GPU: 0, epoch: 9, iters: 136864, time: 0.004) nll: 0.811617 \n",
      "(GPU: 0, epoch: 9, iters: 137664, time: 0.005) nll: 0.589979 \n",
      "(GPU: 0, epoch: 9, iters: 138464, time: 0.004) nll: 0.882191 \n",
      "(GPU: 0, epoch: 9, iters: 139264, time: 0.005) nll: 0.699564 \n",
      "(GPU: 0, epoch: 9, iters: 140064, time: 0.005) nll: 0.653308 \n",
      "saving the model at the end of epoch 9, iters 1407040\n",
      "([test] GPU: 0, epoch: 9) \n",
      "OrderedDict()\n",
      "[*] End of epoch 9 / 25 \t Time Taken: 792 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0001000\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3079/4397 [09:01<03:27,  6.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 32, time: 0.002) nll: 0.670345 \n",
      "(GPU: 0, epoch: 10, iters: 32, time: 0.002) nll: 0.859412 \n",
      "(GPU: 0, epoch: 10, iters: 160, time: 0.005) nll: 0.819644 \n",
      "(GPU: 0, epoch: 10, iters: 960, time: 0.005) nll: 0.662878 \n",
      "(GPU: 0, epoch: 10, iters: 1760, time: 0.004) nll: 0.827920 \n",
      "(GPU: 0, epoch: 10, iters: 2560, time: 0.005) nll: 0.905260 \n",
      "(GPU: 0, epoch: 10, iters: 3360, time: 0.005) nll: 0.756875 \n",
      "(GPU: 0, epoch: 10, iters: 4160, time: 0.005) nll: 0.675884 \n",
      "(GPU: 0, epoch: 10, iters: 4960, time: 0.004) nll: 0.715760 \n",
      "(GPU: 0, epoch: 10, iters: 5760, time: 0.005) nll: 0.714010 \n",
      "(GPU: 0, epoch: 10, iters: 6560, time: 0.004) nll: 0.788128 \n",
      "(GPU: 0, epoch: 10, iters: 7360, time: 0.005) nll: 0.841528 \n",
      "(GPU: 0, epoch: 10, iters: 8160, time: 0.005) nll: 0.651117 \n",
      "(GPU: 0, epoch: 10, iters: 8960, time: 0.005) nll: 0.669333 \n",
      "(GPU: 0, epoch: 10, iters: 9760, time: 0.004) nll: 0.720768 \n",
      "(GPU: 0, epoch: 10, iters: 10560, time: 0.005) nll: 0.916974 \n",
      "(GPU: 0, epoch: 10, iters: 11360, time: 0.005) nll: 0.855883 \n",
      "(GPU: 0, epoch: 10, iters: 12160, time: 0.005) nll: 0.720945 \n",
      "(GPU: 0, epoch: 10, iters: 12960, time: 0.005) nll: 0.788211 \n",
      "saving the latest model (epoch 10, total_steps 1420000)\n",
      "(GPU: 0, epoch: 10, iters: 13760, time: 0.005) nll: 0.921698 \n",
      "(GPU: 0, epoch: 10, iters: 14560, time: 0.005) nll: 0.848312 \n",
      "(GPU: 0, epoch: 10, iters: 15360, time: 0.005) nll: 0.823662 \n",
      "(GPU: 0, epoch: 10, iters: 16160, time: 0.005) nll: 0.727137 \n",
      "(GPU: 0, epoch: 10, iters: 16960, time: 0.005) nll: 0.699551 \n",
      "(GPU: 0, epoch: 10, iters: 17760, time: 0.005) nll: 0.783759 \n",
      "(GPU: 0, epoch: 10, iters: 18560, time: 0.005) nll: 0.573535 \n",
      "(GPU: 0, epoch: 10, iters: 19360, time: 0.005) nll: 0.591687 \n",
      "(GPU: 0, epoch: 10, iters: 20160, time: 0.005) nll: 0.811257 \n",
      "(GPU: 0, epoch: 10, iters: 20960, time: 0.004) nll: 0.724011 \n",
      "(GPU: 0, epoch: 10, iters: 21760, time: 0.005) nll: 0.965936 \n",
      "(GPU: 0, epoch: 10, iters: 22560, time: 0.005) nll: 0.543063 \n",
      "(GPU: 0, epoch: 10, iters: 23360, time: 0.005) nll: 0.660498 \n",
      "(GPU: 0, epoch: 10, iters: 24160, time: 0.004) nll: 0.722201 \n",
      "(GPU: 0, epoch: 10, iters: 24960, time: 0.005) nll: 0.894979 \n",
      "(GPU: 0, epoch: 10, iters: 25760, time: 0.005) nll: 0.640931 \n",
      "(GPU: 0, epoch: 10, iters: 26560, time: 0.005) nll: 0.819678 \n",
      "(GPU: 0, epoch: 10, iters: 27360, time: 0.004) nll: 0.798138 \n",
      "(GPU: 0, epoch: 10, iters: 28160, time: 0.005) nll: 1.016495 \n",
      "(GPU: 0, epoch: 10, iters: 28960, time: 0.005) nll: 0.824843 \n",
      "(GPU: 0, epoch: 10, iters: 29760, time: 0.005) nll: 0.820724 \n",
      "(GPU: 0, epoch: 10, iters: 30560, time: 0.004) nll: 0.763532 \n",
      "(GPU: 0, epoch: 10, iters: 31360, time: 0.005) nll: 0.635873 \n",
      "(GPU: 0, epoch: 10, iters: 32160, time: 0.004) nll: 0.783886 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.005) nll: 0.832821 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.008) nll: 0.826910 \n",
      "(GPU: 0, epoch: 10, iters: 32960, time: 0.008) nll: 0.479802 \n",
      "saving the latest model (epoch 10, total_steps 1440000)\n",
      "(GPU: 0, epoch: 10, iters: 33760, time: 0.005) nll: 0.759651 \n",
      "(GPU: 0, epoch: 10, iters: 34560, time: 0.005) nll: 0.688058 \n",
      "(GPU: 0, epoch: 10, iters: 35360, time: 0.005) nll: 0.684954 \n",
      "(GPU: 0, epoch: 10, iters: 36160, time: 0.005) nll: 0.736661 \n",
      "(GPU: 0, epoch: 10, iters: 36960, time: 0.005) nll: 0.749006 \n",
      "(GPU: 0, epoch: 10, iters: 37760, time: 0.005) nll: 0.787860 \n",
      "(GPU: 0, epoch: 10, iters: 38560, time: 0.005) nll: 0.856877 \n",
      "(GPU: 0, epoch: 10, iters: 39360, time: 0.005) nll: 0.656044 \n",
      "(GPU: 0, epoch: 10, iters: 40160, time: 0.004) nll: 0.696459 \n",
      "(GPU: 0, epoch: 10, iters: 40960, time: 0.005) nll: 0.755830 \n",
      "(GPU: 0, epoch: 10, iters: 41760, time: 0.005) nll: 0.565778 \n",
      "(GPU: 0, epoch: 10, iters: 42560, time: 0.005) nll: 0.718111 \n",
      "(GPU: 0, epoch: 10, iters: 43360, time: 0.004) nll: 0.658360 \n",
      "(GPU: 0, epoch: 10, iters: 44160, time: 0.005) nll: 0.836996 \n",
      "(GPU: 0, epoch: 10, iters: 44960, time: 0.004) nll: 0.844683 \n",
      "(GPU: 0, epoch: 10, iters: 45760, time: 0.005) nll: 0.729647 \n",
      "(GPU: 0, epoch: 10, iters: 46560, time: 0.005) nll: 0.729948 \n",
      "(GPU: 0, epoch: 10, iters: 47360, time: 0.005) nll: 0.633365 \n",
      "(GPU: 0, epoch: 10, iters: 48160, time: 0.004) nll: 0.823634 \n",
      "(GPU: 0, epoch: 10, iters: 48960, time: 0.005) nll: 0.735982 \n",
      "(GPU: 0, epoch: 10, iters: 49760, time: 0.005) nll: 0.705769 \n",
      "(GPU: 0, epoch: 10, iters: 50560, time: 0.005) nll: 0.599964 \n",
      "(GPU: 0, epoch: 10, iters: 51360, time: 0.005) nll: 0.779336 \n",
      "(GPU: 0, epoch: 10, iters: 52160, time: 0.005) nll: 0.538730 \n",
      "(GPU: 0, epoch: 10, iters: 52960, time: 0.005) nll: 0.669311 \n",
      "saving the latest model (epoch 10, total_steps 1460000)\n",
      "(GPU: 0, epoch: 10, iters: 53760, time: 0.005) nll: 1.020432 \n",
      "(GPU: 0, epoch: 10, iters: 54560, time: 0.004) nll: 0.643163 \n",
      "(GPU: 0, epoch: 10, iters: 55360, time: 0.005) nll: 0.715468 \n",
      "(GPU: 0, epoch: 10, iters: 56160, time: 0.005) nll: 0.582533 \n",
      "(GPU: 0, epoch: 10, iters: 56960, time: 0.005) nll: 0.624517 \n",
      "(GPU: 0, epoch: 10, iters: 57760, time: 0.005) nll: 0.744264 \n",
      "(GPU: 0, epoch: 10, iters: 58560, time: 0.005) nll: 0.803202 \n",
      "(GPU: 0, epoch: 10, iters: 59360, time: 0.005) nll: 0.619942 \n",
      "(GPU: 0, epoch: 10, iters: 60160, time: 0.005) nll: 1.178214 \n",
      "(GPU: 0, epoch: 10, iters: 60960, time: 0.004) nll: 0.738847 \n",
      "(GPU: 0, epoch: 10, iters: 61760, time: 0.005) nll: 0.796793 \n",
      "(GPU: 0, epoch: 10, iters: 62560, time: 0.005) nll: 0.890756 \n",
      "(GPU: 0, epoch: 10, iters: 63360, time: 0.005) nll: 0.748121 \n",
      "(GPU: 0, epoch: 10, iters: 64160, time: 0.005) nll: 0.562436 \n",
      "(GPU: 0, epoch: 10, iters: 64960, time: 0.005) nll: 0.678595 \n",
      "(GPU: 0, epoch: 10, iters: 65760, time: 0.005) nll: 0.706492 \n",
      "(GPU: 0, epoch: 10, iters: 66560, time: 0.005) nll: 0.735792 \n",
      "(GPU: 0, epoch: 10, iters: 67360, time: 0.005) nll: 0.629305 \n",
      "(GPU: 0, epoch: 10, iters: 68160, time: 0.005) nll: 0.986156 \n",
      "(GPU: 0, epoch: 10, iters: 68960, time: 0.004) nll: 0.791971 \n",
      "(GPU: 0, epoch: 10, iters: 69760, time: 0.005) nll: 0.805744 \n",
      "(GPU: 0, epoch: 10, iters: 70560, time: 0.004) nll: 0.656744 \n",
      "(GPU: 0, epoch: 10, iters: 71360, time: 0.005) nll: 0.837511 \n",
      "(GPU: 0, epoch: 10, iters: 72160, time: 0.004) nll: 0.867230 \n",
      "(GPU: 0, epoch: 10, iters: 72960, time: 0.005) nll: 0.787284 \n",
      "saving the latest model (epoch 10, total_steps 1480000)\n",
      "(GPU: 0, epoch: 10, iters: 73760, time: 0.005) nll: 0.759104 \n",
      "(GPU: 0, epoch: 10, iters: 74560, time: 0.005) nll: 0.590030 \n",
      "(GPU: 0, epoch: 10, iters: 75360, time: 0.004) nll: 0.623967 \n",
      "(GPU: 0, epoch: 10, iters: 76160, time: 0.005) nll: 0.737279 \n",
      "(GPU: 0, epoch: 10, iters: 76960, time: 0.005) nll: 0.468459 \n",
      "(GPU: 0, epoch: 10, iters: 77760, time: 0.005) nll: 0.730457 \n",
      "(GPU: 0, epoch: 10, iters: 78560, time: 0.005) nll: 0.649128 \n",
      "(GPU: 0, epoch: 10, iters: 79360, time: 0.005) nll: 0.927978 \n",
      "(GPU: 0, epoch: 10, iters: 80160, time: 0.004) nll: 0.889144 \n",
      "(GPU: 0, epoch: 10, iters: 80960, time: 0.005) nll: 0.656913 \n",
      "(GPU: 0, epoch: 10, iters: 81760, time: 0.004) nll: 0.803750 \n",
      "(GPU: 0, epoch: 10, iters: 82560, time: 0.005) nll: 0.795875 \n",
      "(GPU: 0, epoch: 10, iters: 83360, time: 0.004) nll: 0.855262 \n",
      "(GPU: 0, epoch: 10, iters: 84160, time: 0.005) nll: 0.715845 \n",
      "(GPU: 0, epoch: 10, iters: 84960, time: 0.005) nll: 0.757792 \n",
      "(GPU: 0, epoch: 10, iters: 85760, time: 0.005) nll: 0.877454 \n",
      "(GPU: 0, epoch: 10, iters: 86560, time: 0.004) nll: 0.814206 \n",
      "(GPU: 0, epoch: 10, iters: 87360, time: 0.005) nll: 0.682028 \n",
      "(GPU: 0, epoch: 10, iters: 88160, time: 0.004) nll: 0.750489 \n",
      "(GPU: 0, epoch: 10, iters: 88960, time: 0.005) nll: 0.725159 \n",
      "(GPU: 0, epoch: 10, iters: 89760, time: 0.004) nll: 0.773095 \n",
      "(GPU: 0, epoch: 10, iters: 90560, time: 0.005) nll: 0.877351 \n",
      "(GPU: 0, epoch: 10, iters: 91360, time: 0.004) nll: 0.831404 \n",
      "(GPU: 0, epoch: 10, iters: 92160, time: 0.005) nll: 0.743324 \n",
      "(GPU: 0, epoch: 10, iters: 92960, time: 0.005) nll: 0.758634 \n",
      "saving the latest model (epoch 10, total_steps 1500000)\n",
      "(GPU: 0, epoch: 10, iters: 93760, time: 0.005) nll: 0.733985 \n",
      "(GPU: 0, epoch: 10, iters: 94560, time: 0.005) nll: 0.646838 \n",
      "(GPU: 0, epoch: 10, iters: 95360, time: 0.005) nll: 0.857300 \n",
      "(GPU: 0, epoch: 10, iters: 96160, time: 0.005) nll: 0.827344 \n",
      "(GPU: 0, epoch: 10, iters: 96960, time: 0.005) nll: 0.674665 \n",
      "(GPU: 0, epoch: 10, iters: 97760, time: 0.005) nll: 0.768368 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 10, iters: 98560, time: 0.005) nll: 0.731961 \n",
      "(GPU: 0, epoch: 10, iters: 99360, time: 0.004) nll: 0.630997 \n",
      "(GPU: 0, epoch: 10, iters: 100160, time: 0.005) nll: 0.791366 \n",
      "(GPU: 0, epoch: 10, iters: 100960, time: 0.005) nll: 0.949960 \n",
      "(GPU: 0, epoch: 10, iters: 101760, time: 0.005) nll: 0.757620 \n",
      "(GPU: 0, epoch: 10, iters: 102560, time: 0.004) nll: 0.888786 \n",
      "(GPU: 0, epoch: 10, iters: 103360, time: 0.005) nll: 0.829627 \n",
      "(GPU: 0, epoch: 10, iters: 104160, time: 0.004) nll: 0.796637 \n",
      "(GPU: 0, epoch: 10, iters: 104960, time: 0.005) nll: 0.718489 \n",
      "(GPU: 0, epoch: 10, iters: 105760, time: 0.005) nll: 0.966013 \n",
      "(GPU: 0, epoch: 10, iters: 106560, time: 0.005) nll: 0.642230 \n",
      "(GPU: 0, epoch: 10, iters: 107360, time: 0.004) nll: 0.927118 \n",
      "(GPU: 0, epoch: 10, iters: 108160, time: 0.005) nll: 0.956125 \n",
      "(GPU: 0, epoch: 10, iters: 108960, time: 0.005) nll: 0.850484 \n",
      "(GPU: 0, epoch: 10, iters: 109760, time: 0.005) nll: 0.810327 \n",
      "(GPU: 0, epoch: 10, iters: 110560, time: 0.004) nll: 0.806010 \n",
      "(GPU: 0, epoch: 10, iters: 111360, time: 0.005) nll: 0.717650 \n",
      "(GPU: 0, epoch: 10, iters: 112160, time: 0.005) nll: 0.950466 \n",
      "(GPU: 0, epoch: 10, iters: 112960, time: 0.005) nll: 0.771433 \n",
      "saving the latest model (epoch 10, total_steps 1520000)\n",
      "(GPU: 0, epoch: 10, iters: 113760, time: 0.004) nll: 0.636703 \n",
      "(GPU: 0, epoch: 10, iters: 114560, time: 0.005) nll: 0.660577 \n",
      "(GPU: 0, epoch: 10, iters: 115360, time: 0.004) nll: 0.985910 \n",
      "(GPU: 0, epoch: 10, iters: 116160, time: 0.005) nll: 0.666354 \n",
      "(GPU: 0, epoch: 10, iters: 116960, time: 0.005) nll: 0.642845 \n",
      "(GPU: 0, epoch: 10, iters: 117760, time: 0.005) nll: 0.576095 \n",
      "(GPU: 0, epoch: 10, iters: 118560, time: 0.005) nll: 0.771665 \n",
      "(GPU: 0, epoch: 10, iters: 119360, time: 0.005) nll: 0.850042 \n",
      "(GPU: 0, epoch: 10, iters: 120160, time: 0.005) nll: 0.794618 \n",
      "(GPU: 0, epoch: 10, iters: 120960, time: 0.005) nll: 0.757434 \n",
      "(GPU: 0, epoch: 10, iters: 121760, time: 0.004) nll: 0.643125 \n",
      "(GPU: 0, epoch: 10, iters: 122560, time: 0.005) nll: 0.711558 \n",
      "(GPU: 0, epoch: 10, iters: 123360, time: 0.005) nll: 0.889733 \n",
      "(GPU: 0, epoch: 10, iters: 124160, time: 0.005) nll: 0.834873 \n",
      "(GPU: 0, epoch: 10, iters: 124960, time: 0.004) nll: 0.929132 \n",
      "(GPU: 0, epoch: 10, iters: 125760, time: 0.005) nll: 0.628785 \n",
      "(GPU: 0, epoch: 10, iters: 126560, time: 0.005) nll: 0.870880 \n",
      "(GPU: 0, epoch: 10, iters: 127360, time: 0.005) nll: 0.985630 \n",
      "(GPU: 0, epoch: 10, iters: 128160, time: 0.004) nll: 0.687173 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.005) nll: 0.873598 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.008) nll: 0.863097 \n",
      "(GPU: 0, epoch: 10, iters: 128960, time: 0.008) nll: 0.842089 \n",
      "(GPU: 0, epoch: 10, iters: 129760, time: 0.004) nll: 0.809945 \n",
      "(GPU: 0, epoch: 10, iters: 130560, time: 0.005) nll: 0.828096 \n",
      "(GPU: 0, epoch: 10, iters: 131360, time: 0.005) nll: 0.809308 \n",
      "(GPU: 0, epoch: 10, iters: 132160, time: 0.005) nll: 0.908235 \n",
      "(GPU: 0, epoch: 10, iters: 132960, time: 0.004) nll: 0.769523 \n",
      "saving the latest model (epoch 10, total_steps 1540000)\n",
      "(GPU: 0, epoch: 10, iters: 133760, time: 0.005) nll: 0.902322 \n",
      "(GPU: 0, epoch: 10, iters: 134560, time: 0.005) nll: 0.718767 \n",
      "(GPU: 0, epoch: 10, iters: 135360, time: 0.005) nll: 0.941601 \n",
      "(GPU: 0, epoch: 10, iters: 136160, time: 0.005) nll: 0.740318 \n",
      "(GPU: 0, epoch: 10, iters: 136960, time: 0.005) nll: 1.036320 \n",
      "(GPU: 0, epoch: 10, iters: 137760, time: 0.004) nll: 0.710452 \n",
      "(GPU: 0, epoch: 10, iters: 138560, time: 0.005) nll: 0.966447 \n",
      "(GPU: 0, epoch: 10, iters: 139360, time: 0.005) nll: 0.632875 \n",
      "(GPU: 0, epoch: 10, iters: 140160, time: 0.004) nll: 0.888438 \n",
      "[*] End of epoch 10 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000953\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3082/4397 [09:00<03:30,  6.24it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 32, time: 0.003) nll: 0.778493 \n",
      "(GPU: 0, epoch: 11, iters: 32, time: 0.003) nll: 0.909457 \n",
      "(GPU: 0, epoch: 11, iters: 256, time: 0.005) nll: 0.789980 \n",
      "(GPU: 0, epoch: 11, iters: 1056, time: 0.005) nll: 0.895172 \n",
      "(GPU: 0, epoch: 11, iters: 1856, time: 0.005) nll: 0.770909 \n",
      "(GPU: 0, epoch: 11, iters: 2656, time: 0.005) nll: 1.048330 \n",
      "(GPU: 0, epoch: 11, iters: 3456, time: 0.005) nll: 0.838894 \n",
      "(GPU: 0, epoch: 11, iters: 4256, time: 0.005) nll: 0.738580 \n",
      "(GPU: 0, epoch: 11, iters: 5056, time: 0.005) nll: 0.824291 \n",
      "(GPU: 0, epoch: 11, iters: 5856, time: 0.004) nll: 0.863134 \n",
      "(GPU: 0, epoch: 11, iters: 6656, time: 0.005) nll: 0.656974 \n",
      "(GPU: 0, epoch: 11, iters: 7456, time: 0.005) nll: 0.755453 \n",
      "(GPU: 0, epoch: 11, iters: 8256, time: 0.005) nll: 0.709058 \n",
      "(GPU: 0, epoch: 11, iters: 9056, time: 0.005) nll: 0.733002 \n",
      "(GPU: 0, epoch: 11, iters: 9856, time: 0.005) nll: 0.899255 \n",
      "(GPU: 0, epoch: 11, iters: 10656, time: 0.005) nll: 0.714751 \n",
      "(GPU: 0, epoch: 11, iters: 11456, time: 0.005) nll: 0.684095 \n",
      "(GPU: 0, epoch: 11, iters: 12256, time: 0.004) nll: 0.911129 \n",
      "saving the latest model (epoch 11, total_steps 1560000)\n",
      "(GPU: 0, epoch: 11, iters: 13056, time: 0.005) nll: 0.693969 \n",
      "(GPU: 0, epoch: 11, iters: 13856, time: 0.005) nll: 0.866686 \n",
      "(GPU: 0, epoch: 11, iters: 14656, time: 0.005) nll: 0.732406 \n",
      "(GPU: 0, epoch: 11, iters: 15456, time: 0.005) nll: 0.927366 \n",
      "(GPU: 0, epoch: 11, iters: 16256, time: 0.005) nll: 0.803142 \n",
      "(GPU: 0, epoch: 11, iters: 17056, time: 0.005) nll: 0.630617 \n",
      "(GPU: 0, epoch: 11, iters: 17856, time: 0.005) nll: 0.650348 \n",
      "(GPU: 0, epoch: 11, iters: 18656, time: 0.005) nll: 0.748482 \n",
      "(GPU: 0, epoch: 11, iters: 19456, time: 0.005) nll: 0.750854 \n",
      "(GPU: 0, epoch: 11, iters: 20256, time: 0.004) nll: 0.645672 \n",
      "(GPU: 0, epoch: 11, iters: 21056, time: 0.005) nll: 0.822584 \n",
      "(GPU: 0, epoch: 11, iters: 21856, time: 0.005) nll: 0.716442 \n",
      "(GPU: 0, epoch: 11, iters: 22656, time: 0.005) nll: 0.797386 \n",
      "(GPU: 0, epoch: 11, iters: 23456, time: 0.004) nll: 0.733357 \n",
      "(GPU: 0, epoch: 11, iters: 24256, time: 0.005) nll: 0.847702 \n",
      "(GPU: 0, epoch: 11, iters: 25056, time: 0.005) nll: 0.634099 \n",
      "(GPU: 0, epoch: 11, iters: 25856, time: 0.005) nll: 0.804538 \n",
      "(GPU: 0, epoch: 11, iters: 26656, time: 0.004) nll: 0.821448 \n",
      "(GPU: 0, epoch: 11, iters: 27456, time: 0.005) nll: 0.725797 \n",
      "(GPU: 0, epoch: 11, iters: 28256, time: 0.005) nll: 0.758141 \n",
      "(GPU: 0, epoch: 11, iters: 29056, time: 0.005) nll: 0.857458 \n",
      "(GPU: 0, epoch: 11, iters: 29856, time: 0.004) nll: 0.799239 \n",
      "(GPU: 0, epoch: 11, iters: 30656, time: 0.005) nll: 0.942871 \n",
      "(GPU: 0, epoch: 11, iters: 31456, time: 0.005) nll: 0.858600 \n",
      "(GPU: 0, epoch: 11, iters: 32256, time: 0.005) nll: 0.783252 \n",
      "saving the latest model (epoch 11, total_steps 1580000)\n",
      "(GPU: 0, epoch: 11, iters: 33056, time: 0.005) nll: 0.654859 \n",
      "(GPU: 0, epoch: 11, iters: 33856, time: 0.005) nll: 0.766018 \n",
      "(GPU: 0, epoch: 11, iters: 34656, time: 0.005) nll: 0.715285 \n",
      "(GPU: 0, epoch: 11, iters: 35456, time: 0.005) nll: 0.454673 \n",
      "(GPU: 0, epoch: 11, iters: 36256, time: 0.005) nll: 0.804765 \n",
      "(GPU: 0, epoch: 11, iters: 37056, time: 0.005) nll: 0.857609 \n",
      "(GPU: 0, epoch: 11, iters: 37856, time: 0.004) nll: 0.830860 \n",
      "(GPU: 0, epoch: 11, iters: 38656, time: 0.005) nll: 0.790821 \n",
      "(GPU: 0, epoch: 11, iters: 39456, time: 0.005) nll: 0.858558 \n",
      "(GPU: 0, epoch: 11, iters: 40256, time: 0.005) nll: 0.707044 \n",
      "(GPU: 0, epoch: 11, iters: 41056, time: 0.005) nll: 0.851247 \n",
      "(GPU: 0, epoch: 11, iters: 41856, time: 0.005) nll: 0.791719 \n",
      "(GPU: 0, epoch: 11, iters: 42656, time: 0.005) nll: 0.682848 \n",
      "(GPU: 0, epoch: 11, iters: 43456, time: 0.005) nll: 0.507273 \n",
      "(GPU: 0, epoch: 11, iters: 44256, time: 0.005) nll: 0.791247 \n",
      "(GPU: 0, epoch: 11, iters: 45056, time: 0.005) nll: 0.671104 \n",
      "(GPU: 0, epoch: 11, iters: 45856, time: 0.005) nll: 0.741543 \n",
      "(GPU: 0, epoch: 11, iters: 46656, time: 0.005) nll: 0.693571 \n",
      "(GPU: 0, epoch: 11, iters: 47456, time: 0.005) nll: 0.695510 \n",
      "(GPU: 0, epoch: 11, iters: 48256, time: 0.005) nll: 0.854559 \n",
      "(GPU: 0, epoch: 11, iters: 49056, time: 0.004) nll: 0.717399 \n",
      "(GPU: 0, epoch: 11, iters: 49856, time: 0.005) nll: 0.649613 \n",
      "(GPU: 0, epoch: 11, iters: 50656, time: 0.004) nll: 0.912089 \n",
      "(GPU: 0, epoch: 11, iters: 51456, time: 0.005) nll: 0.662655 \n",
      "(GPU: 0, epoch: 11, iters: 52256, time: 0.004) nll: 0.841103 \n",
      "saving the latest model (epoch 11, total_steps 1600000)\n",
      "(GPU: 0, epoch: 11, iters: 53056, time: 0.005) nll: 0.622861 \n",
      "(GPU: 0, epoch: 11, iters: 53856, time: 0.004) nll: 0.884863 \n",
      "(GPU: 0, epoch: 11, iters: 54656, time: 0.005) nll: 0.671189 \n",
      "(GPU: 0, epoch: 11, iters: 55456, time: 0.005) nll: 0.715534 \n",
      "(GPU: 0, epoch: 11, iters: 56256, time: 0.005) nll: 0.687732 \n",
      "(GPU: 0, epoch: 11, iters: 57056, time: 0.005) nll: 0.674103 \n",
      "(GPU: 0, epoch: 11, iters: 57856, time: 0.005) nll: 0.742532 \n",
      "(GPU: 0, epoch: 11, iters: 58656, time: 0.004) nll: 0.804608 \n",
      "(GPU: 0, epoch: 11, iters: 59456, time: 0.005) nll: 0.613651 \n",
      "(GPU: 0, epoch: 11, iters: 60256, time: 0.004) nll: 0.833661 \n",
      "(GPU: 0, epoch: 11, iters: 61056, time: 0.005) nll: 0.784615 \n",
      "(GPU: 0, epoch: 11, iters: 61856, time: 0.005) nll: 0.793502 \n",
      "(GPU: 0, epoch: 11, iters: 62656, time: 0.005) nll: 0.593102 \n",
      "(GPU: 0, epoch: 11, iters: 63456, time: 0.004) nll: 0.691106 \n",
      "(GPU: 0, epoch: 11, iters: 64256, time: 0.005) nll: 0.893582 \n",
      "(GPU: 0, epoch: 11, iters: 65056, time: 0.005) nll: 0.950770 \n",
      "(GPU: 0, epoch: 11, iters: 65856, time: 0.005) nll: 0.700950 \n",
      "(GPU: 0, epoch: 11, iters: 66656, time: 0.004) nll: 0.668622 \n",
      "(GPU: 0, epoch: 11, iters: 67456, time: 0.005) nll: 0.713033 \n",
      "(GPU: 0, epoch: 11, iters: 68256, time: 0.005) nll: 0.720814 \n",
      "(GPU: 0, epoch: 11, iters: 69056, time: 0.005) nll: 0.705795 \n",
      "(GPU: 0, epoch: 11, iters: 69856, time: 0.005) nll: 0.785723 \n",
      "(GPU: 0, epoch: 11, iters: 70656, time: 0.005) nll: 0.823729 \n",
      "(GPU: 0, epoch: 11, iters: 71456, time: 0.005) nll: 0.729243 \n",
      "(GPU: 0, epoch: 11, iters: 72256, time: 0.005) nll: 0.722129 \n",
      "saving the latest model (epoch 11, total_steps 1620000)\n",
      "(GPU: 0, epoch: 11, iters: 73056, time: 0.004) nll: 0.607520 \n",
      "(GPU: 0, epoch: 11, iters: 73856, time: 0.005) nll: 0.717415 \n",
      "(GPU: 0, epoch: 11, iters: 74656, time: 0.004) nll: 0.753030 \n",
      "(GPU: 0, epoch: 11, iters: 75456, time: 0.005) nll: 0.725343 \n",
      "(GPU: 0, epoch: 11, iters: 76256, time: 0.004) nll: 0.742013 \n",
      "(GPU: 0, epoch: 11, iters: 77056, time: 0.005) nll: 0.628054 \n",
      "(GPU: 0, epoch: 11, iters: 77856, time: 0.005) nll: 0.876645 \n",
      "(GPU: 0, epoch: 11, iters: 78656, time: 0.005) nll: 0.687518 \n",
      "(GPU: 0, epoch: 11, iters: 79456, time: 0.005) nll: 0.794946 \n",
      "(GPU: 0, epoch: 11, iters: 80256, time: 0.005) nll: 0.879211 \n",
      "(GPU: 0, epoch: 11, iters: 81056, time: 0.005) nll: 0.746202 \n",
      "(GPU: 0, epoch: 11, iters: 81856, time: 0.005) nll: 0.922305 \n",
      "(GPU: 0, epoch: 11, iters: 82656, time: 0.004) nll: 0.608156 \n",
      "(GPU: 0, epoch: 11, iters: 83456, time: 0.005) nll: 0.648362 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.004) nll: 0.714611 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.007) nll: 0.709150 \n",
      "(GPU: 0, epoch: 11, iters: 84256, time: 0.007) nll: 0.841979 \n",
      "(GPU: 0, epoch: 11, iters: 85056, time: 0.005) nll: 0.858125 \n",
      "(GPU: 0, epoch: 11, iters: 85856, time: 0.004) nll: 0.636110 \n",
      "(GPU: 0, epoch: 11, iters: 86656, time: 0.005) nll: 0.876217 \n",
      "(GPU: 0, epoch: 11, iters: 87456, time: 0.005) nll: 0.776966 \n",
      "(GPU: 0, epoch: 11, iters: 88256, time: 0.005) nll: 0.836883 \n",
      "(GPU: 0, epoch: 11, iters: 89056, time: 0.004) nll: 0.774259 \n",
      "(GPU: 0, epoch: 11, iters: 89856, time: 0.005) nll: 0.766280 \n",
      "(GPU: 0, epoch: 11, iters: 90656, time: 0.004) nll: 0.913711 \n",
      "(GPU: 0, epoch: 11, iters: 91456, time: 0.005) nll: 0.758637 \n",
      "(GPU: 0, epoch: 11, iters: 92256, time: 0.005) nll: 0.839188 \n",
      "saving the latest model (epoch 11, total_steps 1640000)\n",
      "(GPU: 0, epoch: 11, iters: 93056, time: 0.005) nll: 0.567560 \n",
      "(GPU: 0, epoch: 11, iters: 93856, time: 0.004) nll: 0.900320 \n",
      "(GPU: 0, epoch: 11, iters: 94656, time: 0.005) nll: 0.807969 \n",
      "(GPU: 0, epoch: 11, iters: 95456, time: 0.004) nll: 0.758413 \n",
      "(GPU: 0, epoch: 11, iters: 96256, time: 0.005) nll: 0.947719 \n",
      "(GPU: 0, epoch: 11, iters: 97056, time: 0.005) nll: 0.611623 \n",
      "(GPU: 0, epoch: 11, iters: 97856, time: 0.005) nll: 0.834209 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:49<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 11, iters: 98656, time: 0.005) nll: 0.670930 \n",
      "(GPU: 0, epoch: 11, iters: 99456, time: 0.005) nll: 0.640788 \n",
      "(GPU: 0, epoch: 11, iters: 100256, time: 0.004) nll: 0.809553 \n",
      "(GPU: 0, epoch: 11, iters: 101056, time: 0.005) nll: 0.889479 \n",
      "(GPU: 0, epoch: 11, iters: 101856, time: 0.005) nll: 0.732624 \n",
      "(GPU: 0, epoch: 11, iters: 102656, time: 0.005) nll: 1.045447 \n",
      "(GPU: 0, epoch: 11, iters: 103456, time: 0.004) nll: 0.772670 \n",
      "(GPU: 0, epoch: 11, iters: 104256, time: 0.005) nll: 0.685558 \n",
      "(GPU: 0, epoch: 11, iters: 105056, time: 0.005) nll: 0.564111 \n",
      "(GPU: 0, epoch: 11, iters: 105856, time: 0.005) nll: 0.558975 \n",
      "(GPU: 0, epoch: 11, iters: 106656, time: 0.005) nll: 0.760625 \n",
      "(GPU: 0, epoch: 11, iters: 107456, time: 0.005) nll: 0.918787 \n",
      "(GPU: 0, epoch: 11, iters: 108256, time: 0.004) nll: 0.726319 \n",
      "(GPU: 0, epoch: 11, iters: 109056, time: 0.005) nll: 0.663665 \n",
      "(GPU: 0, epoch: 11, iters: 109856, time: 0.004) nll: 0.867710 \n",
      "(GPU: 0, epoch: 11, iters: 110656, time: 0.005) nll: 0.687632 \n",
      "(GPU: 0, epoch: 11, iters: 111456, time: 0.005) nll: 0.721693 \n",
      "(GPU: 0, epoch: 11, iters: 112256, time: 0.005) nll: 0.904390 \n",
      "saving the latest model (epoch 11, total_steps 1660000)\n",
      "(GPU: 0, epoch: 11, iters: 113056, time: 0.004) nll: 0.789882 \n",
      "(GPU: 0, epoch: 11, iters: 113856, time: 0.005) nll: 0.989095 \n",
      "(GPU: 0, epoch: 11, iters: 114656, time: 0.004) nll: 0.802944 \n",
      "(GPU: 0, epoch: 11, iters: 115456, time: 0.005) nll: 0.879326 \n",
      "(GPU: 0, epoch: 11, iters: 116256, time: 0.004) nll: 0.715899 \n",
      "(GPU: 0, epoch: 11, iters: 117056, time: 0.005) nll: 0.910917 \n",
      "(GPU: 0, epoch: 11, iters: 117856, time: 0.005) nll: 0.752422 \n",
      "(GPU: 0, epoch: 11, iters: 118656, time: 0.005) nll: 0.689277 \n",
      "(GPU: 0, epoch: 11, iters: 119456, time: 0.004) nll: 0.767670 \n",
      "(GPU: 0, epoch: 11, iters: 120256, time: 0.005) nll: 0.679347 \n",
      "(GPU: 0, epoch: 11, iters: 121056, time: 0.005) nll: 0.765241 \n",
      "(GPU: 0, epoch: 11, iters: 121856, time: 0.005) nll: 0.556363 \n",
      "(GPU: 0, epoch: 11, iters: 122656, time: 0.005) nll: 0.889479 \n",
      "(GPU: 0, epoch: 11, iters: 123456, time: 0.005) nll: 0.868352 \n",
      "(GPU: 0, epoch: 11, iters: 124256, time: 0.004) nll: 0.740397 \n",
      "(GPU: 0, epoch: 11, iters: 125056, time: 0.005) nll: 0.713859 \n",
      "(GPU: 0, epoch: 11, iters: 125856, time: 0.005) nll: 0.816399 \n",
      "(GPU: 0, epoch: 11, iters: 126656, time: 0.005) nll: 0.589230 \n",
      "(GPU: 0, epoch: 11, iters: 127456, time: 0.005) nll: 0.862249 \n",
      "(GPU: 0, epoch: 11, iters: 128256, time: 0.005) nll: 0.580213 \n",
      "(GPU: 0, epoch: 11, iters: 129056, time: 0.004) nll: 0.833059 \n",
      "(GPU: 0, epoch: 11, iters: 129856, time: 0.005) nll: 0.814253 \n",
      "(GPU: 0, epoch: 11, iters: 130656, time: 0.004) nll: 0.717168 \n",
      "(GPU: 0, epoch: 11, iters: 131456, time: 0.005) nll: 0.896609 \n",
      "(GPU: 0, epoch: 11, iters: 132256, time: 0.005) nll: 0.780232 \n",
      "saving the latest model (epoch 11, total_steps 1680000)\n",
      "(GPU: 0, epoch: 11, iters: 133056, time: 0.005) nll: 0.971200 \n",
      "(GPU: 0, epoch: 11, iters: 133856, time: 0.004) nll: 0.576088 \n",
      "(GPU: 0, epoch: 11, iters: 134656, time: 0.005) nll: 1.000392 \n",
      "(GPU: 0, epoch: 11, iters: 135456, time: 0.005) nll: 0.850394 \n",
      "(GPU: 0, epoch: 11, iters: 136256, time: 0.005) nll: 0.980803 \n",
      "(GPU: 0, epoch: 11, iters: 137056, time: 0.004) nll: 0.603638 \n",
      "(GPU: 0, epoch: 11, iters: 137856, time: 0.005) nll: 0.892984 \n",
      "(GPU: 0, epoch: 11, iters: 138656, time: 0.004) nll: 0.801901 \n",
      "(GPU: 0, epoch: 11, iters: 139456, time: 0.005) nll: 0.582678 \n",
      "(GPU: 0, epoch: 11, iters: 140256, time: 0.005) nll: 0.793576 \n",
      "[*] End of epoch 11 / 25 \t Time Taken: 770 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000913\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3085/4397 [09:02<03:29,  6.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 32, time: 0.003) nll: 0.589735 \n",
      "(GPU: 0, epoch: 12, iters: 32, time: 0.003) nll: 0.771668 \n",
      "(GPU: 0, epoch: 12, iters: 352, time: 0.005) nll: 0.888153 \n",
      "(GPU: 0, epoch: 12, iters: 1152, time: 0.005) nll: 0.684987 \n",
      "(GPU: 0, epoch: 12, iters: 1952, time: 0.005) nll: 0.555267 \n",
      "(GPU: 0, epoch: 12, iters: 2752, time: 0.005) nll: 0.619310 \n",
      "(GPU: 0, epoch: 12, iters: 3552, time: 0.004) nll: 0.802743 \n",
      "(GPU: 0, epoch: 12, iters: 4352, time: 0.005) nll: 0.627113 \n",
      "(GPU: 0, epoch: 12, iters: 5152, time: 0.004) nll: 0.890093 \n",
      "(GPU: 0, epoch: 12, iters: 5952, time: 0.005) nll: 0.889274 \n",
      "(GPU: 0, epoch: 12, iters: 6752, time: 0.005) nll: 0.654457 \n",
      "(GPU: 0, epoch: 12, iters: 7552, time: 0.005) nll: 0.645485 \n",
      "(GPU: 0, epoch: 12, iters: 8352, time: 0.005) nll: 0.434591 \n",
      "(GPU: 0, epoch: 12, iters: 9152, time: 0.005) nll: 0.881912 \n",
      "(GPU: 0, epoch: 12, iters: 9952, time: 0.004) nll: 0.584891 \n",
      "(GPU: 0, epoch: 12, iters: 10752, time: 0.005) nll: 0.587628 \n",
      "(GPU: 0, epoch: 12, iters: 11552, time: 0.004) nll: 0.761350 \n",
      "saving the latest model (epoch 12, total_steps 1700000)\n",
      "(GPU: 0, epoch: 12, iters: 12352, time: 0.005) nll: 0.795776 \n",
      "(GPU: 0, epoch: 12, iters: 13152, time: 0.005) nll: 0.970328 \n",
      "(GPU: 0, epoch: 12, iters: 13952, time: 0.005) nll: 0.683988 \n",
      "(GPU: 0, epoch: 12, iters: 14752, time: 0.005) nll: 0.521025 \n",
      "(GPU: 0, epoch: 12, iters: 15552, time: 0.005) nll: 0.822010 \n",
      "(GPU: 0, epoch: 12, iters: 16352, time: 0.005) nll: 0.705627 \n",
      "(GPU: 0, epoch: 12, iters: 17152, time: 0.005) nll: 0.560774 \n",
      "(GPU: 0, epoch: 12, iters: 17952, time: 0.005) nll: 0.637775 \n",
      "(GPU: 0, epoch: 12, iters: 18752, time: 0.005) nll: 0.908979 \n",
      "(GPU: 0, epoch: 12, iters: 19552, time: 0.004) nll: 0.792528 \n",
      "(GPU: 0, epoch: 12, iters: 20352, time: 0.005) nll: 0.650645 \n",
      "(GPU: 0, epoch: 12, iters: 21152, time: 0.004) nll: 0.785919 \n",
      "(GPU: 0, epoch: 12, iters: 21952, time: 0.005) nll: 0.703863 \n",
      "(GPU: 0, epoch: 12, iters: 22752, time: 0.004) nll: 0.831114 \n",
      "(GPU: 0, epoch: 12, iters: 23552, time: 0.005) nll: 0.819514 \n",
      "(GPU: 0, epoch: 12, iters: 24352, time: 0.004) nll: 0.927144 \n",
      "(GPU: 0, epoch: 12, iters: 25152, time: 0.005) nll: 0.516716 \n",
      "(GPU: 0, epoch: 12, iters: 25952, time: 0.005) nll: 0.984222 \n",
      "(GPU: 0, epoch: 12, iters: 26752, time: 0.005) nll: 0.760297 \n",
      "(GPU: 0, epoch: 12, iters: 27552, time: 0.005) nll: 0.682857 \n",
      "(GPU: 0, epoch: 12, iters: 28352, time: 0.005) nll: 0.827226 \n",
      "(GPU: 0, epoch: 12, iters: 29152, time: 0.005) nll: 0.521524 \n",
      "(GPU: 0, epoch: 12, iters: 29952, time: 0.005) nll: 0.742233 \n",
      "(GPU: 0, epoch: 12, iters: 30752, time: 0.004) nll: 0.824982 \n",
      "(GPU: 0, epoch: 12, iters: 31552, time: 0.005) nll: 0.769924 \n",
      "saving the latest model (epoch 12, total_steps 1720000)\n",
      "(GPU: 0, epoch: 12, iters: 32352, time: 0.004) nll: 0.668419 \n",
      "(GPU: 0, epoch: 12, iters: 33152, time: 0.005) nll: 0.920363 \n",
      "(GPU: 0, epoch: 12, iters: 33952, time: 0.004) nll: 0.671756 \n",
      "(GPU: 0, epoch: 12, iters: 34752, time: 0.005) nll: 0.608039 \n",
      "(GPU: 0, epoch: 12, iters: 35552, time: 0.005) nll: 0.763238 \n",
      "(GPU: 0, epoch: 12, iters: 36352, time: 0.005) nll: 0.884043 \n",
      "(GPU: 0, epoch: 12, iters: 37152, time: 0.005) nll: 0.662769 \n",
      "(GPU: 0, epoch: 12, iters: 37952, time: 0.005) nll: 0.524453 \n",
      "(GPU: 0, epoch: 12, iters: 38752, time: 0.005) nll: 0.968012 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.005) nll: 0.825174 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.008) nll: 0.812968 \n",
      "(GPU: 0, epoch: 12, iters: 39552, time: 0.008) nll: 0.730819 \n",
      "(GPU: 0, epoch: 12, iters: 40352, time: 0.005) nll: 0.630809 \n",
      "(GPU: 0, epoch: 12, iters: 41152, time: 0.005) nll: 0.753252 \n",
      "(GPU: 0, epoch: 12, iters: 41952, time: 0.004) nll: 0.969149 \n",
      "(GPU: 0, epoch: 12, iters: 42752, time: 0.005) nll: 0.829450 \n",
      "(GPU: 0, epoch: 12, iters: 43552, time: 0.005) nll: 0.774483 \n",
      "(GPU: 0, epoch: 12, iters: 44352, time: 0.005) nll: 0.989012 \n",
      "(GPU: 0, epoch: 12, iters: 45152, time: 0.005) nll: 0.747370 \n",
      "(GPU: 0, epoch: 12, iters: 45952, time: 0.005) nll: 0.779906 \n",
      "(GPU: 0, epoch: 12, iters: 46752, time: 0.004) nll: 0.662931 \n",
      "(GPU: 0, epoch: 12, iters: 47552, time: 0.005) nll: 0.627751 \n",
      "(GPU: 0, epoch: 12, iters: 48352, time: 0.005) nll: 0.754640 \n",
      "(GPU: 0, epoch: 12, iters: 49152, time: 0.005) nll: 0.773522 \n",
      "(GPU: 0, epoch: 12, iters: 49952, time: 0.005) nll: 0.694750 \n",
      "(GPU: 0, epoch: 12, iters: 50752, time: 0.005) nll: 0.564245 \n",
      "(GPU: 0, epoch: 12, iters: 51552, time: 0.004) nll: 0.695510 \n",
      "saving the latest model (epoch 12, total_steps 1740000)\n",
      "(GPU: 0, epoch: 12, iters: 52352, time: 0.005) nll: 0.847855 \n",
      "(GPU: 0, epoch: 12, iters: 53152, time: 0.004) nll: 1.046773 \n",
      "(GPU: 0, epoch: 12, iters: 53952, time: 0.005) nll: 0.918429 \n",
      "(GPU: 0, epoch: 12, iters: 54752, time: 0.005) nll: 0.663423 \n",
      "(GPU: 0, epoch: 12, iters: 55552, time: 0.005) nll: 0.938837 \n",
      "(GPU: 0, epoch: 12, iters: 56352, time: 0.004) nll: 0.827382 \n",
      "(GPU: 0, epoch: 12, iters: 57152, time: 0.005) nll: 0.425594 \n",
      "(GPU: 0, epoch: 12, iters: 57952, time: 0.004) nll: 0.503092 \n",
      "(GPU: 0, epoch: 12, iters: 58752, time: 0.005) nll: 0.679831 \n",
      "(GPU: 0, epoch: 12, iters: 59552, time: 0.005) nll: 0.595456 \n",
      "(GPU: 0, epoch: 12, iters: 60352, time: 0.005) nll: 0.801375 \n",
      "(GPU: 0, epoch: 12, iters: 61152, time: 0.005) nll: 0.746762 \n",
      "(GPU: 0, epoch: 12, iters: 61952, time: 0.005) nll: 0.505552 \n",
      "(GPU: 0, epoch: 12, iters: 62752, time: 0.004) nll: 0.514032 \n",
      "(GPU: 0, epoch: 12, iters: 63552, time: 0.005) nll: 0.804351 \n",
      "(GPU: 0, epoch: 12, iters: 64352, time: 0.005) nll: 0.706942 \n",
      "(GPU: 0, epoch: 12, iters: 65152, time: 0.005) nll: 0.961835 \n",
      "(GPU: 0, epoch: 12, iters: 65952, time: 0.004) nll: 0.700945 \n",
      "(GPU: 0, epoch: 12, iters: 66752, time: 0.005) nll: 0.911058 \n",
      "(GPU: 0, epoch: 12, iters: 67552, time: 0.004) nll: 0.711990 \n",
      "(GPU: 0, epoch: 12, iters: 68352, time: 0.005) nll: 0.703730 \n",
      "(GPU: 0, epoch: 12, iters: 69152, time: 0.004) nll: 0.595748 \n",
      "(GPU: 0, epoch: 12, iters: 69952, time: 0.005) nll: 0.592194 \n",
      "(GPU: 0, epoch: 12, iters: 70752, time: 0.004) nll: 0.842124 \n",
      "(GPU: 0, epoch: 12, iters: 71552, time: 0.005) nll: 0.599015 \n",
      "saving the latest model (epoch 12, total_steps 1760000)\n",
      "(GPU: 0, epoch: 12, iters: 72352, time: 0.004) nll: 0.892518 \n",
      "(GPU: 0, epoch: 12, iters: 73152, time: 0.005) nll: 0.811934 \n",
      "(GPU: 0, epoch: 12, iters: 73952, time: 0.004) nll: 0.801539 \n",
      "(GPU: 0, epoch: 12, iters: 74752, time: 0.005) nll: 0.928152 \n",
      "(GPU: 0, epoch: 12, iters: 75552, time: 0.005) nll: 0.665382 \n",
      "(GPU: 0, epoch: 12, iters: 76352, time: 0.005) nll: 0.672790 \n",
      "(GPU: 0, epoch: 12, iters: 77152, time: 0.004) nll: 0.772562 \n",
      "(GPU: 0, epoch: 12, iters: 77952, time: 0.005) nll: 0.832826 \n",
      "(GPU: 0, epoch: 12, iters: 78752, time: 0.005) nll: 0.772611 \n",
      "(GPU: 0, epoch: 12, iters: 79552, time: 0.005) nll: 0.925684 \n",
      "(GPU: 0, epoch: 12, iters: 80352, time: 0.005) nll: 0.903393 \n",
      "(GPU: 0, epoch: 12, iters: 81152, time: 0.005) nll: 0.853004 \n",
      "(GPU: 0, epoch: 12, iters: 81952, time: 0.004) nll: 0.864818 \n",
      "(GPU: 0, epoch: 12, iters: 82752, time: 0.005) nll: 0.684416 \n",
      "(GPU: 0, epoch: 12, iters: 83552, time: 0.004) nll: 0.835418 \n",
      "(GPU: 0, epoch: 12, iters: 84352, time: 0.005) nll: 0.750539 \n",
      "(GPU: 0, epoch: 12, iters: 85152, time: 0.005) nll: 0.766745 \n",
      "(GPU: 0, epoch: 12, iters: 85952, time: 0.005) nll: 0.742139 \n",
      "(GPU: 0, epoch: 12, iters: 86752, time: 0.005) nll: 0.751403 \n",
      "(GPU: 0, epoch: 12, iters: 87552, time: 0.005) nll: 0.620149 \n",
      "(GPU: 0, epoch: 12, iters: 88352, time: 0.005) nll: 0.731611 \n",
      "(GPU: 0, epoch: 12, iters: 89152, time: 0.005) nll: 0.727233 \n",
      "(GPU: 0, epoch: 12, iters: 89952, time: 0.005) nll: 0.698971 \n",
      "(GPU: 0, epoch: 12, iters: 90752, time: 0.005) nll: 0.643663 \n",
      "(GPU: 0, epoch: 12, iters: 91552, time: 0.005) nll: 0.924334 \n",
      "saving the latest model (epoch 12, total_steps 1780000)\n",
      "(GPU: 0, epoch: 12, iters: 92352, time: 0.005) nll: 0.677719 \n",
      "(GPU: 0, epoch: 12, iters: 93152, time: 0.005) nll: 0.828007 \n",
      "(GPU: 0, epoch: 12, iters: 93952, time: 0.005) nll: 0.535011 \n",
      "(GPU: 0, epoch: 12, iters: 94752, time: 0.004) nll: 0.857257 \n",
      "(GPU: 0, epoch: 12, iters: 95552, time: 0.005) nll: 0.857235 \n",
      "(GPU: 0, epoch: 12, iters: 96352, time: 0.004) nll: 0.836373 \n",
      "(GPU: 0, epoch: 12, iters: 97152, time: 0.005) nll: 0.935727 \n",
      "(GPU: 0, epoch: 12, iters: 97952, time: 0.005) nll: 0.802795 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:52<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 12, iters: 98752, time: 0.005) nll: 0.707193 \n",
      "(GPU: 0, epoch: 12, iters: 99552, time: 0.004) nll: 0.801515 \n",
      "(GPU: 0, epoch: 12, iters: 100352, time: 0.005) nll: 0.779241 \n",
      "(GPU: 0, epoch: 12, iters: 101152, time: 0.004) nll: 0.665008 \n",
      "(GPU: 0, epoch: 12, iters: 101952, time: 0.005) nll: 0.665486 \n",
      "(GPU: 0, epoch: 12, iters: 102752, time: 0.004) nll: 0.869290 \n",
      "(GPU: 0, epoch: 12, iters: 103552, time: 0.005) nll: 0.643018 \n",
      "(GPU: 0, epoch: 12, iters: 104352, time: 0.005) nll: 0.979528 \n",
      "(GPU: 0, epoch: 12, iters: 105152, time: 0.005) nll: 0.665909 \n",
      "(GPU: 0, epoch: 12, iters: 105952, time: 0.004) nll: 0.790342 \n",
      "(GPU: 0, epoch: 12, iters: 106752, time: 0.005) nll: 0.636103 \n",
      "(GPU: 0, epoch: 12, iters: 107552, time: 0.005) nll: 0.879270 \n",
      "(GPU: 0, epoch: 12, iters: 108352, time: 0.005) nll: 0.614315 \n",
      "(GPU: 0, epoch: 12, iters: 109152, time: 0.004) nll: 0.670225 \n",
      "(GPU: 0, epoch: 12, iters: 109952, time: 0.005) nll: 0.856095 \n",
      "(GPU: 0, epoch: 12, iters: 110752, time: 0.004) nll: 0.720560 \n",
      "(GPU: 0, epoch: 12, iters: 111552, time: 0.005) nll: 0.744884 \n",
      "saving the latest model (epoch 12, total_steps 1800000)\n",
      "(GPU: 0, epoch: 12, iters: 112352, time: 0.004) nll: 0.789216 \n",
      "(GPU: 0, epoch: 12, iters: 113152, time: 0.005) nll: 0.630435 \n",
      "(GPU: 0, epoch: 12, iters: 113952, time: 0.004) nll: 0.610607 \n",
      "(GPU: 0, epoch: 12, iters: 114752, time: 0.005) nll: 0.706112 \n",
      "(GPU: 0, epoch: 12, iters: 115552, time: 0.004) nll: 0.913814 \n",
      "(GPU: 0, epoch: 12, iters: 116352, time: 0.005) nll: 0.979201 \n",
      "(GPU: 0, epoch: 12, iters: 117152, time: 0.004) nll: 0.635428 \n",
      "(GPU: 0, epoch: 12, iters: 117952, time: 0.005) nll: 0.706806 \n",
      "(GPU: 0, epoch: 12, iters: 118752, time: 0.005) nll: 0.679066 \n",
      "(GPU: 0, epoch: 12, iters: 119552, time: 0.005) nll: 0.425078 \n",
      "(GPU: 0, epoch: 12, iters: 120352, time: 0.004) nll: 0.895338 \n",
      "(GPU: 0, epoch: 12, iters: 121152, time: 0.005) nll: 0.643302 \n",
      "(GPU: 0, epoch: 12, iters: 121952, time: 0.004) nll: 0.838963 \n",
      "(GPU: 0, epoch: 12, iters: 122752, time: 0.005) nll: 0.811047 \n",
      "(GPU: 0, epoch: 12, iters: 123552, time: 0.005) nll: 0.944181 \n",
      "(GPU: 0, epoch: 12, iters: 124352, time: 0.005) nll: 0.719420 \n",
      "(GPU: 0, epoch: 12, iters: 125152, time: 0.005) nll: 0.654729 \n",
      "(GPU: 0, epoch: 12, iters: 125952, time: 0.005) nll: 0.944044 \n",
      "(GPU: 0, epoch: 12, iters: 126752, time: 0.004) nll: 0.891466 \n",
      "(GPU: 0, epoch: 12, iters: 127552, time: 0.005) nll: 0.790978 \n",
      "(GPU: 0, epoch: 12, iters: 128352, time: 0.005) nll: 0.711328 \n",
      "(GPU: 0, epoch: 12, iters: 129152, time: 0.005) nll: 0.759850 \n",
      "(GPU: 0, epoch: 12, iters: 129952, time: 0.005) nll: 0.856982 \n",
      "(GPU: 0, epoch: 12, iters: 130752, time: 0.005) nll: 0.774895 \n",
      "(GPU: 0, epoch: 12, iters: 131552, time: 0.004) nll: 0.835052 \n",
      "saving the latest model (epoch 12, total_steps 1820000)\n",
      "(GPU: 0, epoch: 12, iters: 132352, time: 0.005) nll: 0.740452 \n",
      "(GPU: 0, epoch: 12, iters: 133152, time: 0.004) nll: 0.748319 \n",
      "(GPU: 0, epoch: 12, iters: 133952, time: 0.005) nll: 0.652491 \n",
      "(GPU: 0, epoch: 12, iters: 134752, time: 0.004) nll: 0.587893 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.005) nll: 0.535504 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.008) nll: 0.529708 \n",
      "(GPU: 0, epoch: 12, iters: 135552, time: 0.008) nll: 0.898712 \n",
      "(GPU: 0, epoch: 12, iters: 136352, time: 0.004) nll: 0.869791 \n",
      "(GPU: 0, epoch: 12, iters: 137152, time: 0.005) nll: 0.554180 \n",
      "(GPU: 0, epoch: 12, iters: 137952, time: 0.005) nll: 0.904655 \n",
      "(GPU: 0, epoch: 12, iters: 138752, time: 0.005) nll: 0.748121 \n",
      "(GPU: 0, epoch: 12, iters: 139552, time: 0.004) nll: 0.719132 \n",
      "(GPU: 0, epoch: 12, iters: 140352, time: 0.005) nll: 0.724848 \n",
      "saving the model at the end of epoch 12, iters 1829152\n",
      "([test] GPU: 0, epoch: 12) \n",
      "OrderedDict()\n",
      "[*] End of epoch 12 / 25 \t Time Taken: 790 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000877\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3088/4397 [09:02<03:26,  6.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 32, time: 0.002) nll: 0.800799 \n",
      "(GPU: 0, epoch: 13, iters: 32, time: 0.002) nll: 0.645923 \n",
      "(GPU: 0, epoch: 13, iters: 448, time: 0.005) nll: 0.585474 \n",
      "(GPU: 0, epoch: 13, iters: 1248, time: 0.005) nll: 0.748042 \n",
      "(GPU: 0, epoch: 13, iters: 2048, time: 0.005) nll: 0.740756 \n",
      "(GPU: 0, epoch: 13, iters: 2848, time: 0.005) nll: 0.546481 \n",
      "(GPU: 0, epoch: 13, iters: 3648, time: 0.005) nll: 0.488396 \n",
      "(GPU: 0, epoch: 13, iters: 4448, time: 0.004) nll: 1.119014 \n",
      "(GPU: 0, epoch: 13, iters: 5248, time: 0.005) nll: 0.771626 \n",
      "(GPU: 0, epoch: 13, iters: 6048, time: 0.005) nll: 0.704279 \n",
      "(GPU: 0, epoch: 13, iters: 6848, time: 0.005) nll: 0.845577 \n",
      "(GPU: 0, epoch: 13, iters: 7648, time: 0.005) nll: 0.540895 \n",
      "(GPU: 0, epoch: 13, iters: 8448, time: 0.005) nll: 0.566685 \n",
      "(GPU: 0, epoch: 13, iters: 9248, time: 0.004) nll: 0.916614 \n",
      "(GPU: 0, epoch: 13, iters: 10048, time: 0.005) nll: 0.711054 \n",
      "(GPU: 0, epoch: 13, iters: 10848, time: 0.004) nll: 0.732239 \n",
      "saving the latest model (epoch 13, total_steps 1840000)\n",
      "(GPU: 0, epoch: 13, iters: 11648, time: 0.005) nll: 0.842455 \n",
      "(GPU: 0, epoch: 13, iters: 12448, time: 0.004) nll: 0.861206 \n",
      "(GPU: 0, epoch: 13, iters: 13248, time: 0.005) nll: 0.710216 \n",
      "(GPU: 0, epoch: 13, iters: 14048, time: 0.004) nll: 0.778210 \n",
      "(GPU: 0, epoch: 13, iters: 14848, time: 0.005) nll: 0.605671 \n",
      "(GPU: 0, epoch: 13, iters: 15648, time: 0.005) nll: 0.930142 \n",
      "(GPU: 0, epoch: 13, iters: 16448, time: 0.005) nll: 0.973829 \n",
      "(GPU: 0, epoch: 13, iters: 17248, time: 0.004) nll: 0.862444 \n",
      "(GPU: 0, epoch: 13, iters: 18048, time: 0.005) nll: 0.865877 \n",
      "(GPU: 0, epoch: 13, iters: 18848, time: 0.005) nll: 0.798991 \n",
      "(GPU: 0, epoch: 13, iters: 19648, time: 0.005) nll: 0.763003 \n",
      "(GPU: 0, epoch: 13, iters: 20448, time: 0.004) nll: 0.723778 \n",
      "(GPU: 0, epoch: 13, iters: 21248, time: 0.005) nll: 0.769302 \n",
      "(GPU: 0, epoch: 13, iters: 22048, time: 0.004) nll: 0.692021 \n",
      "(GPU: 0, epoch: 13, iters: 22848, time: 0.005) nll: 0.726934 \n",
      "(GPU: 0, epoch: 13, iters: 23648, time: 0.004) nll: 0.819503 \n",
      "(GPU: 0, epoch: 13, iters: 24448, time: 0.005) nll: 0.637074 \n",
      "(GPU: 0, epoch: 13, iters: 25248, time: 0.004) nll: 0.754019 \n",
      "(GPU: 0, epoch: 13, iters: 26048, time: 0.005) nll: 0.762408 \n",
      "(GPU: 0, epoch: 13, iters: 26848, time: 0.005) nll: 0.799174 \n",
      "(GPU: 0, epoch: 13, iters: 27648, time: 0.005) nll: 0.843449 \n",
      "(GPU: 0, epoch: 13, iters: 28448, time: 0.004) nll: 0.698650 \n",
      "(GPU: 0, epoch: 13, iters: 29248, time: 0.005) nll: 0.717094 \n",
      "(GPU: 0, epoch: 13, iters: 30048, time: 0.004) nll: 0.808475 \n",
      "(GPU: 0, epoch: 13, iters: 30848, time: 0.005) nll: 0.757775 \n",
      "saving the latest model (epoch 13, total_steps 1860000)\n",
      "(GPU: 0, epoch: 13, iters: 31648, time: 0.004) nll: 0.779302 \n",
      "(GPU: 0, epoch: 13, iters: 32448, time: 0.005) nll: 0.562870 \n",
      "(GPU: 0, epoch: 13, iters: 33248, time: 0.004) nll: 0.609688 \n",
      "(GPU: 0, epoch: 13, iters: 34048, time: 0.005) nll: 0.767547 \n",
      "(GPU: 0, epoch: 13, iters: 34848, time: 0.004) nll: 0.707323 \n",
      "(GPU: 0, epoch: 13, iters: 35648, time: 0.005) nll: 0.848649 \n",
      "(GPU: 0, epoch: 13, iters: 36448, time: 0.004) nll: 0.581460 \n",
      "(GPU: 0, epoch: 13, iters: 37248, time: 0.005) nll: 0.673453 \n",
      "(GPU: 0, epoch: 13, iters: 38048, time: 0.004) nll: 0.727714 \n",
      "(GPU: 0, epoch: 13, iters: 38848, time: 0.005) nll: 0.892458 \n",
      "(GPU: 0, epoch: 13, iters: 39648, time: 0.004) nll: 0.791700 \n",
      "(GPU: 0, epoch: 13, iters: 40448, time: 0.005) nll: 0.696427 \n",
      "(GPU: 0, epoch: 13, iters: 41248, time: 0.004) nll: 0.655327 \n",
      "(GPU: 0, epoch: 13, iters: 42048, time: 0.005) nll: 0.825649 \n",
      "(GPU: 0, epoch: 13, iters: 42848, time: 0.004) nll: 0.866373 \n",
      "(GPU: 0, epoch: 13, iters: 43648, time: 0.005) nll: 0.919698 \n",
      "(GPU: 0, epoch: 13, iters: 44448, time: 0.005) nll: 0.591957 \n",
      "(GPU: 0, epoch: 13, iters: 45248, time: 0.005) nll: 0.701874 \n",
      "(GPU: 0, epoch: 13, iters: 46048, time: 0.004) nll: 0.918622 \n",
      "(GPU: 0, epoch: 13, iters: 46848, time: 0.005) nll: 0.644789 \n",
      "(GPU: 0, epoch: 13, iters: 47648, time: 0.004) nll: 0.744640 \n",
      "(GPU: 0, epoch: 13, iters: 48448, time: 0.005) nll: 0.878168 \n",
      "(GPU: 0, epoch: 13, iters: 49248, time: 0.004) nll: 0.934036 \n",
      "(GPU: 0, epoch: 13, iters: 50048, time: 0.005) nll: 0.676656 \n",
      "(GPU: 0, epoch: 13, iters: 50848, time: 0.005) nll: 0.717809 \n",
      "saving the latest model (epoch 13, total_steps 1880000)\n",
      "(GPU: 0, epoch: 13, iters: 51648, time: 0.005) nll: 0.640373 \n",
      "(GPU: 0, epoch: 13, iters: 52448, time: 0.005) nll: 0.858185 \n",
      "(GPU: 0, epoch: 13, iters: 53248, time: 0.005) nll: 0.899450 \n",
      "(GPU: 0, epoch: 13, iters: 54048, time: 0.004) nll: 0.855491 \n",
      "(GPU: 0, epoch: 13, iters: 54848, time: 0.005) nll: 0.769638 \n",
      "(GPU: 0, epoch: 13, iters: 55648, time: 0.005) nll: 0.579272 \n",
      "(GPU: 0, epoch: 13, iters: 56448, time: 0.005) nll: 0.772951 \n",
      "(GPU: 0, epoch: 13, iters: 57248, time: 0.004) nll: 0.639487 \n",
      "(GPU: 0, epoch: 13, iters: 58048, time: 0.005) nll: 0.917618 \n",
      "(GPU: 0, epoch: 13, iters: 58848, time: 0.004) nll: 0.752059 \n",
      "(GPU: 0, epoch: 13, iters: 59648, time: 0.005) nll: 0.928250 \n",
      "(GPU: 0, epoch: 13, iters: 60448, time: 0.004) nll: 0.924712 \n",
      "(GPU: 0, epoch: 13, iters: 61248, time: 0.005) nll: 0.756229 \n",
      "(GPU: 0, epoch: 13, iters: 62048, time: 0.005) nll: 0.800646 \n",
      "(GPU: 0, epoch: 13, iters: 62848, time: 0.005) nll: 0.717712 \n",
      "(GPU: 0, epoch: 13, iters: 63648, time: 0.005) nll: 0.900296 \n",
      "(GPU: 0, epoch: 13, iters: 64448, time: 0.005) nll: 0.752582 \n",
      "(GPU: 0, epoch: 13, iters: 65248, time: 0.005) nll: 0.700081 \n",
      "(GPU: 0, epoch: 13, iters: 66048, time: 0.005) nll: 0.753445 \n",
      "(GPU: 0, epoch: 13, iters: 66848, time: 0.005) nll: 0.673104 \n",
      "(GPU: 0, epoch: 13, iters: 67648, time: 0.005) nll: 0.610896 \n",
      "(GPU: 0, epoch: 13, iters: 68448, time: 0.004) nll: 0.633760 \n",
      "(GPU: 0, epoch: 13, iters: 69248, time: 0.005) nll: 0.645540 \n",
      "(GPU: 0, epoch: 13, iters: 70048, time: 0.004) nll: 0.668451 \n",
      "(GPU: 0, epoch: 13, iters: 70848, time: 0.005) nll: 0.566934 \n",
      "saving the latest model (epoch 13, total_steps 1900000)\n",
      "(GPU: 0, epoch: 13, iters: 71648, time: 0.004) nll: 0.632467 \n",
      "(GPU: 0, epoch: 13, iters: 72448, time: 0.005) nll: 0.806079 \n",
      "(GPU: 0, epoch: 13, iters: 73248, time: 0.005) nll: 0.587278 \n",
      "(GPU: 0, epoch: 13, iters: 74048, time: 0.005) nll: 0.806442 \n",
      "(GPU: 0, epoch: 13, iters: 74848, time: 0.005) nll: 0.719210 \n",
      "(GPU: 0, epoch: 13, iters: 75648, time: 0.005) nll: 0.568157 \n",
      "(GPU: 0, epoch: 13, iters: 76448, time: 0.005) nll: 0.865032 \n",
      "(GPU: 0, epoch: 13, iters: 77248, time: 0.005) nll: 0.498937 \n",
      "(GPU: 0, epoch: 13, iters: 78048, time: 0.004) nll: 0.651651 \n",
      "(GPU: 0, epoch: 13, iters: 78848, time: 0.005) nll: 0.743264 \n",
      "(GPU: 0, epoch: 13, iters: 79648, time: 0.005) nll: 0.775340 \n",
      "(GPU: 0, epoch: 13, iters: 80448, time: 0.005) nll: 0.845303 \n",
      "(GPU: 0, epoch: 13, iters: 81248, time: 0.004) nll: 0.682896 \n",
      "(GPU: 0, epoch: 13, iters: 82048, time: 0.005) nll: 0.771166 \n",
      "(GPU: 0, epoch: 13, iters: 82848, time: 0.004) nll: 0.671639 \n",
      "(GPU: 0, epoch: 13, iters: 83648, time: 0.005) nll: 0.793296 \n",
      "(GPU: 0, epoch: 13, iters: 84448, time: 0.004) nll: 0.755901 \n",
      "(GPU: 0, epoch: 13, iters: 85248, time: 0.005) nll: 0.962550 \n",
      "(GPU: 0, epoch: 13, iters: 86048, time: 0.005) nll: 0.543902 \n",
      "(GPU: 0, epoch: 13, iters: 86848, time: 0.005) nll: 0.685119 \n",
      "(GPU: 0, epoch: 13, iters: 87648, time: 0.005) nll: 0.805422 \n",
      "(GPU: 0, epoch: 13, iters: 88448, time: 0.005) nll: 0.762410 \n",
      "(GPU: 0, epoch: 13, iters: 89248, time: 0.004) nll: 0.575548 \n",
      "(GPU: 0, epoch: 13, iters: 90048, time: 0.005) nll: 0.718064 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.004) nll: 0.895429 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.007) nll: 0.881042 \n",
      "(GPU: 0, epoch: 13, iters: 90848, time: 0.007) nll: 0.772649 \n",
      "saving the latest model (epoch 13, total_steps 1920000)\n",
      "(GPU: 0, epoch: 13, iters: 91648, time: 0.005) nll: 0.506410 \n",
      "(GPU: 0, epoch: 13, iters: 92448, time: 0.005) nll: 0.833514 \n",
      "(GPU: 0, epoch: 13, iters: 93248, time: 0.005) nll: 0.736646 \n",
      "(GPU: 0, epoch: 13, iters: 94048, time: 0.004) nll: 0.864536 \n",
      "(GPU: 0, epoch: 13, iters: 94848, time: 0.005) nll: 0.803919 \n",
      "(GPU: 0, epoch: 13, iters: 95648, time: 0.004) nll: 0.768108 \n",
      "(GPU: 0, epoch: 13, iters: 96448, time: 0.005) nll: 0.463048 \n",
      "(GPU: 0, epoch: 13, iters: 97248, time: 0.004) nll: 0.745061 \n",
      "(GPU: 0, epoch: 13, iters: 98048, time: 0.005) nll: 0.827910 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 13, iters: 98848, time: 0.005) nll: 0.719624 \n",
      "(GPU: 0, epoch: 13, iters: 99648, time: 0.005) nll: 0.850451 \n",
      "(GPU: 0, epoch: 13, iters: 100448, time: 0.004) nll: 0.742199 \n",
      "(GPU: 0, epoch: 13, iters: 101248, time: 0.005) nll: 0.630733 \n",
      "(GPU: 0, epoch: 13, iters: 102048, time: 0.005) nll: 0.662316 \n",
      "(GPU: 0, epoch: 13, iters: 102848, time: 0.005) nll: 0.659949 \n",
      "(GPU: 0, epoch: 13, iters: 103648, time: 0.004) nll: 0.829252 \n",
      "(GPU: 0, epoch: 13, iters: 104448, time: 0.005) nll: 0.899991 \n",
      "(GPU: 0, epoch: 13, iters: 105248, time: 0.005) nll: 0.891317 \n",
      "(GPU: 0, epoch: 13, iters: 106048, time: 0.005) nll: 0.537875 \n",
      "(GPU: 0, epoch: 13, iters: 106848, time: 0.004) nll: 0.544246 \n",
      "(GPU: 0, epoch: 13, iters: 107648, time: 0.005) nll: 0.591058 \n",
      "(GPU: 0, epoch: 13, iters: 108448, time: 0.004) nll: 0.734298 \n",
      "(GPU: 0, epoch: 13, iters: 109248, time: 0.005) nll: 1.021028 \n",
      "(GPU: 0, epoch: 13, iters: 110048, time: 0.004) nll: 0.982098 \n",
      "(GPU: 0, epoch: 13, iters: 110848, time: 0.005) nll: 0.723391 \n",
      "saving the latest model (epoch 13, total_steps 1940000)\n",
      "(GPU: 0, epoch: 13, iters: 111648, time: 0.004) nll: 0.871252 \n",
      "(GPU: 0, epoch: 13, iters: 112448, time: 0.005) nll: 0.779271 \n",
      "(GPU: 0, epoch: 13, iters: 113248, time: 0.004) nll: 0.711442 \n",
      "(GPU: 0, epoch: 13, iters: 114048, time: 0.005) nll: 0.648019 \n",
      "(GPU: 0, epoch: 13, iters: 114848, time: 0.004) nll: 0.645149 \n",
      "(GPU: 0, epoch: 13, iters: 115648, time: 0.005) nll: 0.577266 \n",
      "(GPU: 0, epoch: 13, iters: 116448, time: 0.004) nll: 0.631924 \n",
      "(GPU: 0, epoch: 13, iters: 117248, time: 0.005) nll: 0.820642 \n",
      "(GPU: 0, epoch: 13, iters: 118048, time: 0.005) nll: 0.652647 \n",
      "(GPU: 0, epoch: 13, iters: 118848, time: 0.005) nll: 0.742367 \n",
      "(GPU: 0, epoch: 13, iters: 119648, time: 0.004) nll: 0.738266 \n",
      "(GPU: 0, epoch: 13, iters: 120448, time: 0.005) nll: 0.942699 \n",
      "(GPU: 0, epoch: 13, iters: 121248, time: 0.005) nll: 0.778350 \n",
      "(GPU: 0, epoch: 13, iters: 122048, time: 0.005) nll: 0.610273 \n",
      "(GPU: 0, epoch: 13, iters: 122848, time: 0.004) nll: 0.675311 \n",
      "(GPU: 0, epoch: 13, iters: 123648, time: 0.005) nll: 0.753533 \n",
      "(GPU: 0, epoch: 13, iters: 124448, time: 0.005) nll: 0.661562 \n",
      "(GPU: 0, epoch: 13, iters: 125248, time: 0.005) nll: 0.536642 \n",
      "(GPU: 0, epoch: 13, iters: 126048, time: 0.004) nll: 0.720290 \n",
      "(GPU: 0, epoch: 13, iters: 126848, time: 0.005) nll: 0.818735 \n",
      "(GPU: 0, epoch: 13, iters: 127648, time: 0.005) nll: 0.925685 \n",
      "(GPU: 0, epoch: 13, iters: 128448, time: 0.005) nll: 0.834255 \n",
      "(GPU: 0, epoch: 13, iters: 129248, time: 0.004) nll: 0.961706 \n",
      "(GPU: 0, epoch: 13, iters: 130048, time: 0.005) nll: 0.711716 \n",
      "(GPU: 0, epoch: 13, iters: 130848, time: 0.005) nll: 0.892565 \n",
      "saving the latest model (epoch 13, total_steps 1960000)\n",
      "(GPU: 0, epoch: 13, iters: 131648, time: 0.005) nll: 0.869362 \n",
      "(GPU: 0, epoch: 13, iters: 132448, time: 0.004) nll: 0.679787 \n",
      "(GPU: 0, epoch: 13, iters: 133248, time: 0.005) nll: 0.938835 \n",
      "(GPU: 0, epoch: 13, iters: 134048, time: 0.004) nll: 0.811583 \n",
      "(GPU: 0, epoch: 13, iters: 134848, time: 0.005) nll: 0.799700 \n",
      "(GPU: 0, epoch: 13, iters: 135648, time: 0.005) nll: 0.608104 \n",
      "(GPU: 0, epoch: 13, iters: 136448, time: 0.005) nll: 0.859252 \n",
      "(GPU: 0, epoch: 13, iters: 137248, time: 0.005) nll: 0.674126 \n",
      "(GPU: 0, epoch: 13, iters: 138048, time: 0.005) nll: 0.767992 \n",
      "(GPU: 0, epoch: 13, iters: 138848, time: 0.005) nll: 0.810506 \n",
      "(GPU: 0, epoch: 13, iters: 139648, time: 0.005) nll: 0.763067 \n",
      "(GPU: 0, epoch: 13, iters: 140448, time: 0.005) nll: 0.671943 \n",
      "[*] End of epoch 13 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000845\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3091/4397 [09:03<03:27,  6.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 32, time: 0.003) nll: 0.716047 \n",
      "(GPU: 0, epoch: 14, iters: 32, time: 0.003) nll: 0.818968 \n",
      "(GPU: 0, epoch: 14, iters: 544, time: 0.005) nll: 0.681491 \n",
      "(GPU: 0, epoch: 14, iters: 1344, time: 0.005) nll: 0.696584 \n",
      "(GPU: 0, epoch: 14, iters: 2144, time: 0.005) nll: 0.458886 \n",
      "(GPU: 0, epoch: 14, iters: 2944, time: 0.005) nll: 0.910891 \n",
      "(GPU: 0, epoch: 14, iters: 3744, time: 0.005) nll: 0.901999 \n",
      "(GPU: 0, epoch: 14, iters: 4544, time: 0.005) nll: 0.741934 \n",
      "(GPU: 0, epoch: 14, iters: 5344, time: 0.004) nll: 0.992240 \n",
      "(GPU: 0, epoch: 14, iters: 6144, time: 0.005) nll: 0.855442 \n",
      "(GPU: 0, epoch: 14, iters: 6944, time: 0.005) nll: 0.693321 \n",
      "(GPU: 0, epoch: 14, iters: 7744, time: 0.005) nll: 0.663639 \n",
      "(GPU: 0, epoch: 14, iters: 8544, time: 0.004) nll: 0.561223 \n",
      "(GPU: 0, epoch: 14, iters: 9344, time: 0.005) nll: 0.768268 \n",
      "(GPU: 0, epoch: 14, iters: 10144, time: 0.005) nll: 0.775573 \n",
      "saving the latest model (epoch 14, total_steps 1980000)\n",
      "(GPU: 0, epoch: 14, iters: 10944, time: 0.005) nll: 0.696810 \n",
      "(GPU: 0, epoch: 14, iters: 11744, time: 0.005) nll: 0.819230 \n",
      "(GPU: 0, epoch: 14, iters: 12544, time: 0.005) nll: 0.608548 \n",
      "(GPU: 0, epoch: 14, iters: 13344, time: 0.005) nll: 0.758456 \n",
      "(GPU: 0, epoch: 14, iters: 14144, time: 0.005) nll: 0.814111 \n",
      "(GPU: 0, epoch: 14, iters: 14944, time: 0.004) nll: 0.975477 \n",
      "(GPU: 0, epoch: 14, iters: 15744, time: 0.005) nll: 1.028055 \n",
      "(GPU: 0, epoch: 14, iters: 16544, time: 0.004) nll: 0.746182 \n",
      "(GPU: 0, epoch: 14, iters: 17344, time: 0.005) nll: 0.753685 \n",
      "(GPU: 0, epoch: 14, iters: 18144, time: 0.004) nll: 0.697976 \n",
      "(GPU: 0, epoch: 14, iters: 18944, time: 0.005) nll: 0.582527 \n",
      "(GPU: 0, epoch: 14, iters: 19744, time: 0.004) nll: 0.597974 \n",
      "(GPU: 0, epoch: 14, iters: 20544, time: 0.005) nll: 0.840049 \n",
      "(GPU: 0, epoch: 14, iters: 21344, time: 0.005) nll: 0.850101 \n",
      "(GPU: 0, epoch: 14, iters: 22144, time: 0.005) nll: 0.628125 \n",
      "(GPU: 0, epoch: 14, iters: 22944, time: 0.004) nll: 1.051432 \n",
      "(GPU: 0, epoch: 14, iters: 23744, time: 0.005) nll: 0.729205 \n",
      "(GPU: 0, epoch: 14, iters: 24544, time: 0.004) nll: 0.592133 \n",
      "(GPU: 0, epoch: 14, iters: 25344, time: 0.005) nll: 0.830847 \n",
      "(GPU: 0, epoch: 14, iters: 26144, time: 0.004) nll: 0.605332 \n",
      "(GPU: 0, epoch: 14, iters: 26944, time: 0.005) nll: 0.888695 \n",
      "(GPU: 0, epoch: 14, iters: 27744, time: 0.005) nll: 0.764433 \n",
      "(GPU: 0, epoch: 14, iters: 28544, time: 0.005) nll: 0.736366 \n",
      "(GPU: 0, epoch: 14, iters: 29344, time: 0.004) nll: 0.760760 \n",
      "(GPU: 0, epoch: 14, iters: 30144, time: 0.005) nll: 0.936342 \n",
      "saving the latest model (epoch 14, total_steps 2000000)\n",
      "(GPU: 0, epoch: 14, iters: 30944, time: 0.004) nll: 0.856758 \n",
      "(GPU: 0, epoch: 14, iters: 31744, time: 0.005) nll: 0.832137 \n",
      "(GPU: 0, epoch: 14, iters: 32544, time: 0.004) nll: 0.692139 \n",
      "(GPU: 0, epoch: 14, iters: 33344, time: 0.005) nll: 0.691885 \n",
      "(GPU: 0, epoch: 14, iters: 34144, time: 0.005) nll: 0.689956 \n",
      "(GPU: 0, epoch: 14, iters: 34944, time: 0.005) nll: 0.731851 \n",
      "(GPU: 0, epoch: 14, iters: 35744, time: 0.004) nll: 0.691929 \n",
      "(GPU: 0, epoch: 14, iters: 36544, time: 0.005) nll: 0.579699 \n",
      "(GPU: 0, epoch: 14, iters: 37344, time: 0.004) nll: 0.896779 \n",
      "(GPU: 0, epoch: 14, iters: 38144, time: 0.005) nll: 0.945634 \n",
      "(GPU: 0, epoch: 14, iters: 38944, time: 0.004) nll: 0.894957 \n",
      "(GPU: 0, epoch: 14, iters: 39744, time: 0.005) nll: 0.613667 \n",
      "(GPU: 0, epoch: 14, iters: 40544, time: 0.005) nll: 0.878799 \n",
      "(GPU: 0, epoch: 14, iters: 41344, time: 0.005) nll: 0.614523 \n",
      "(GPU: 0, epoch: 14, iters: 42144, time: 0.005) nll: 0.750178 \n",
      "(GPU: 0, epoch: 14, iters: 42944, time: 0.005) nll: 0.763369 \n",
      "(GPU: 0, epoch: 14, iters: 43744, time: 0.004) nll: 0.788061 \n",
      "(GPU: 0, epoch: 14, iters: 44544, time: 0.005) nll: 0.691219 \n",
      "(GPU: 0, epoch: 14, iters: 45344, time: 0.004) nll: 0.685123 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.005) nll: 0.543155 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.008) nll: 0.537744 \n",
      "(GPU: 0, epoch: 14, iters: 46144, time: 0.008) nll: 0.673613 \n",
      "(GPU: 0, epoch: 14, iters: 46944, time: 0.004) nll: 0.623767 \n",
      "(GPU: 0, epoch: 14, iters: 47744, time: 0.005) nll: 0.758741 \n",
      "(GPU: 0, epoch: 14, iters: 48544, time: 0.005) nll: 0.531497 \n",
      "(GPU: 0, epoch: 14, iters: 49344, time: 0.005) nll: 0.696220 \n",
      "(GPU: 0, epoch: 14, iters: 50144, time: 0.004) nll: 0.651590 \n",
      "saving the latest model (epoch 14, total_steps 2020000)\n",
      "(GPU: 0, epoch: 14, iters: 50944, time: 0.005) nll: 0.749346 \n",
      "(GPU: 0, epoch: 14, iters: 51744, time: 0.004) nll: 0.979961 \n",
      "(GPU: 0, epoch: 14, iters: 52544, time: 0.005) nll: 0.803189 \n",
      "(GPU: 0, epoch: 14, iters: 53344, time: 0.004) nll: 0.748876 \n",
      "(GPU: 0, epoch: 14, iters: 54144, time: 0.005) nll: 0.748834 \n",
      "(GPU: 0, epoch: 14, iters: 54944, time: 0.004) nll: 0.663216 \n",
      "(GPU: 0, epoch: 14, iters: 55744, time: 0.005) nll: 0.664630 \n",
      "(GPU: 0, epoch: 14, iters: 56544, time: 0.004) nll: 0.824394 \n",
      "(GPU: 0, epoch: 14, iters: 57344, time: 0.005) nll: 0.817744 \n",
      "(GPU: 0, epoch: 14, iters: 58144, time: 0.004) nll: 0.755007 \n",
      "(GPU: 0, epoch: 14, iters: 58944, time: 0.005) nll: 0.819946 \n",
      "(GPU: 0, epoch: 14, iters: 59744, time: 0.004) nll: 0.575067 \n",
      "(GPU: 0, epoch: 14, iters: 60544, time: 0.005) nll: 0.825095 \n",
      "(GPU: 0, epoch: 14, iters: 61344, time: 0.005) nll: 0.541536 \n",
      "(GPU: 0, epoch: 14, iters: 62144, time: 0.005) nll: 0.634226 \n",
      "(GPU: 0, epoch: 14, iters: 62944, time: 0.005) nll: 0.790454 \n",
      "(GPU: 0, epoch: 14, iters: 63744, time: 0.005) nll: 0.820063 \n",
      "(GPU: 0, epoch: 14, iters: 64544, time: 0.005) nll: 0.691979 \n",
      "(GPU: 0, epoch: 14, iters: 65344, time: 0.005) nll: 0.688516 \n",
      "(GPU: 0, epoch: 14, iters: 66144, time: 0.004) nll: 0.867650 \n",
      "(GPU: 0, epoch: 14, iters: 66944, time: 0.005) nll: 0.786620 \n",
      "(GPU: 0, epoch: 14, iters: 67744, time: 0.004) nll: 0.806864 \n",
      "(GPU: 0, epoch: 14, iters: 68544, time: 0.005) nll: 0.570408 \n",
      "(GPU: 0, epoch: 14, iters: 69344, time: 0.004) nll: 0.992925 \n",
      "(GPU: 0, epoch: 14, iters: 70144, time: 0.005) nll: 0.725813 \n",
      "saving the latest model (epoch 14, total_steps 2040000)\n",
      "(GPU: 0, epoch: 14, iters: 70944, time: 0.005) nll: 0.866015 \n",
      "(GPU: 0, epoch: 14, iters: 71744, time: 0.005) nll: 0.798360 \n",
      "(GPU: 0, epoch: 14, iters: 72544, time: 0.005) nll: 0.635995 \n",
      "(GPU: 0, epoch: 14, iters: 73344, time: 0.005) nll: 0.736075 \n",
      "(GPU: 0, epoch: 14, iters: 74144, time: 0.004) nll: 0.748424 \n",
      "(GPU: 0, epoch: 14, iters: 74944, time: 0.005) nll: 0.537339 \n",
      "(GPU: 0, epoch: 14, iters: 75744, time: 0.005) nll: 0.712018 \n",
      "(GPU: 0, epoch: 14, iters: 76544, time: 0.005) nll: 0.770177 \n",
      "(GPU: 0, epoch: 14, iters: 77344, time: 0.004) nll: 0.728224 \n",
      "(GPU: 0, epoch: 14, iters: 78144, time: 0.005) nll: 0.703294 \n",
      "(GPU: 0, epoch: 14, iters: 78944, time: 0.005) nll: 0.910050 \n",
      "(GPU: 0, epoch: 14, iters: 79744, time: 0.005) nll: 0.825419 \n",
      "(GPU: 0, epoch: 14, iters: 80544, time: 0.004) nll: 0.804225 \n",
      "(GPU: 0, epoch: 14, iters: 81344, time: 0.005) nll: 0.802843 \n",
      "(GPU: 0, epoch: 14, iters: 82144, time: 0.005) nll: 0.622272 \n",
      "(GPU: 0, epoch: 14, iters: 82944, time: 0.005) nll: 0.769153 \n",
      "(GPU: 0, epoch: 14, iters: 83744, time: 0.005) nll: 0.745263 \n",
      "(GPU: 0, epoch: 14, iters: 84544, time: 0.005) nll: 0.689495 \n",
      "(GPU: 0, epoch: 14, iters: 85344, time: 0.005) nll: 0.841791 \n",
      "(GPU: 0, epoch: 14, iters: 86144, time: 0.005) nll: 0.944145 \n",
      "(GPU: 0, epoch: 14, iters: 86944, time: 0.004) nll: 0.830582 \n",
      "(GPU: 0, epoch: 14, iters: 87744, time: 0.005) nll: 0.713917 \n",
      "(GPU: 0, epoch: 14, iters: 88544, time: 0.004) nll: 0.666593 \n",
      "(GPU: 0, epoch: 14, iters: 89344, time: 0.005) nll: 0.983396 \n",
      "(GPU: 0, epoch: 14, iters: 90144, time: 0.005) nll: 0.541331 \n",
      "saving the latest model (epoch 14, total_steps 2060000)\n",
      "(GPU: 0, epoch: 14, iters: 90944, time: 0.005) nll: 0.763464 \n",
      "(GPU: 0, epoch: 14, iters: 91744, time: 0.004) nll: 0.943535 \n",
      "(GPU: 0, epoch: 14, iters: 92544, time: 0.005) nll: 0.546903 \n",
      "(GPU: 0, epoch: 14, iters: 93344, time: 0.005) nll: 0.664429 \n",
      "(GPU: 0, epoch: 14, iters: 94144, time: 0.005) nll: 0.819739 \n",
      "(GPU: 0, epoch: 14, iters: 94944, time: 0.004) nll: 0.715597 \n",
      "(GPU: 0, epoch: 14, iters: 95744, time: 0.005) nll: 0.653113 \n",
      "(GPU: 0, epoch: 14, iters: 96544, time: 0.004) nll: 0.721529 \n",
      "(GPU: 0, epoch: 14, iters: 97344, time: 0.005) nll: 0.884145 \n",
      "(GPU: 0, epoch: 14, iters: 98144, time: 0.004) nll: 0.464560 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:53<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 14, iters: 98944, time: 0.005) nll: 0.820188 \n",
      "(GPU: 0, epoch: 14, iters: 99744, time: 0.004) nll: 0.635536 \n",
      "(GPU: 0, epoch: 14, iters: 100544, time: 0.005) nll: 0.807347 \n",
      "(GPU: 0, epoch: 14, iters: 101344, time: 0.004) nll: 0.761818 \n",
      "(GPU: 0, epoch: 14, iters: 102144, time: 0.005) nll: 0.777692 \n",
      "(GPU: 0, epoch: 14, iters: 102944, time: 0.004) nll: 0.694670 \n",
      "(GPU: 0, epoch: 14, iters: 103744, time: 0.005) nll: 0.669071 \n",
      "(GPU: 0, epoch: 14, iters: 104544, time: 0.004) nll: 0.698671 \n",
      "(GPU: 0, epoch: 14, iters: 105344, time: 0.005) nll: 0.635207 \n",
      "(GPU: 0, epoch: 14, iters: 106144, time: 0.005) nll: 0.887891 \n",
      "(GPU: 0, epoch: 14, iters: 106944, time: 0.005) nll: 0.560811 \n",
      "(GPU: 0, epoch: 14, iters: 107744, time: 0.005) nll: 0.585409 \n",
      "(GPU: 0, epoch: 14, iters: 108544, time: 0.005) nll: 0.726531 \n",
      "(GPU: 0, epoch: 14, iters: 109344, time: 0.005) nll: 0.893474 \n",
      "(GPU: 0, epoch: 14, iters: 110144, time: 0.005) nll: 0.855341 \n",
      "saving the latest model (epoch 14, total_steps 2080000)\n",
      "(GPU: 0, epoch: 14, iters: 110944, time: 0.004) nll: 0.927961 \n",
      "(GPU: 0, epoch: 14, iters: 111744, time: 0.005) nll: 0.703483 \n",
      "(GPU: 0, epoch: 14, iters: 112544, time: 0.004) nll: 0.685801 \n",
      "(GPU: 0, epoch: 14, iters: 113344, time: 0.005) nll: 0.547228 \n",
      "(GPU: 0, epoch: 14, iters: 114144, time: 0.004) nll: 0.813922 \n",
      "(GPU: 0, epoch: 14, iters: 114944, time: 0.005) nll: 0.577904 \n",
      "(GPU: 0, epoch: 14, iters: 115744, time: 0.005) nll: 0.852889 \n",
      "(GPU: 0, epoch: 14, iters: 116544, time: 0.005) nll: 0.864947 \n",
      "(GPU: 0, epoch: 14, iters: 117344, time: 0.004) nll: 0.671958 \n",
      "(GPU: 0, epoch: 14, iters: 118144, time: 0.005) nll: 0.654612 \n",
      "(GPU: 0, epoch: 14, iters: 118944, time: 0.005) nll: 0.872220 \n",
      "(GPU: 0, epoch: 14, iters: 119744, time: 0.005) nll: 0.791412 \n",
      "(GPU: 0, epoch: 14, iters: 120544, time: 0.004) nll: 0.774240 \n",
      "(GPU: 0, epoch: 14, iters: 121344, time: 0.005) nll: 0.692014 \n",
      "(GPU: 0, epoch: 14, iters: 122144, time: 0.004) nll: 0.881354 \n",
      "(GPU: 0, epoch: 14, iters: 122944, time: 0.005) nll: 0.712999 \n",
      "(GPU: 0, epoch: 14, iters: 123744, time: 0.004) nll: 0.747014 \n",
      "(GPU: 0, epoch: 14, iters: 124544, time: 0.005) nll: 0.780254 \n",
      "(GPU: 0, epoch: 14, iters: 125344, time: 0.005) nll: 0.744696 \n",
      "(GPU: 0, epoch: 14, iters: 126144, time: 0.005) nll: 0.758280 \n",
      "(GPU: 0, epoch: 14, iters: 126944, time: 0.005) nll: 0.752245 \n",
      "(GPU: 0, epoch: 14, iters: 127744, time: 0.005) nll: 0.697220 \n",
      "(GPU: 0, epoch: 14, iters: 128544, time: 0.004) nll: 0.731726 \n",
      "(GPU: 0, epoch: 14, iters: 129344, time: 0.005) nll: 0.906841 \n",
      "(GPU: 0, epoch: 14, iters: 130144, time: 0.005) nll: 0.588023 \n",
      "saving the latest model (epoch 14, total_steps 2100000)\n",
      "(GPU: 0, epoch: 14, iters: 130944, time: 0.005) nll: 0.638788 \n",
      "(GPU: 0, epoch: 14, iters: 131744, time: 0.004) nll: 0.659416 \n",
      "(GPU: 0, epoch: 14, iters: 132544, time: 0.005) nll: 0.645148 \n",
      "(GPU: 0, epoch: 14, iters: 133344, time: 0.004) nll: 0.679899 \n",
      "(GPU: 0, epoch: 14, iters: 134144, time: 0.005) nll: 0.779046 \n",
      "(GPU: 0, epoch: 14, iters: 134944, time: 0.004) nll: 0.551768 \n",
      "(GPU: 0, epoch: 14, iters: 135744, time: 0.005) nll: 0.853043 \n",
      "(GPU: 0, epoch: 14, iters: 136544, time: 0.004) nll: 0.584989 \n",
      "(GPU: 0, epoch: 14, iters: 137344, time: 0.005) nll: 0.703996 \n",
      "(GPU: 0, epoch: 14, iters: 138144, time: 0.004) nll: 0.712340 \n",
      "(GPU: 0, epoch: 14, iters: 138944, time: 0.005) nll: 0.705957 \n",
      "(GPU: 0, epoch: 14, iters: 139744, time: 0.005) nll: 0.767059 \n",
      "(GPU: 0, epoch: 14, iters: 140544, time: 0.005) nll: 0.690011 \n",
      "[*] End of epoch 14 / 25 \t Time Taken: 773 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000816\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3044/4397 [08:56<03:35,  6.28it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 32, time: 0.002) nll: 0.583851 \n",
      "(GPU: 0, epoch: 15, iters: 32, time: 0.002) nll: 0.614951 \n",
      "(GPU: 0, epoch: 15, iters: 640, time: 0.005) nll: 0.586614 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.004) nll: 0.805723 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.007) nll: 0.800706 \n",
      "(GPU: 0, epoch: 15, iters: 1440, time: 0.007) nll: 0.744529 \n",
      "(GPU: 0, epoch: 15, iters: 2240, time: 0.005) nll: 0.779629 \n",
      "(GPU: 0, epoch: 15, iters: 3040, time: 0.004) nll: 0.951250 \n",
      "(GPU: 0, epoch: 15, iters: 3840, time: 0.005) nll: 0.707470 \n",
      "(GPU: 0, epoch: 15, iters: 4640, time: 0.005) nll: 0.705110 \n",
      "(GPU: 0, epoch: 15, iters: 5440, time: 0.005) nll: 0.758475 \n",
      "(GPU: 0, epoch: 15, iters: 6240, time: 0.004) nll: 0.711080 \n",
      "(GPU: 0, epoch: 15, iters: 7040, time: 0.005) nll: 0.725442 \n",
      "(GPU: 0, epoch: 15, iters: 7840, time: 0.005) nll: 0.862076 \n",
      "(GPU: 0, epoch: 15, iters: 8640, time: 0.005) nll: 0.881044 \n",
      "(GPU: 0, epoch: 15, iters: 9440, time: 0.005) nll: 0.629776 \n",
      "saving the latest model (epoch 15, total_steps 2120000)\n",
      "(GPU: 0, epoch: 15, iters: 10240, time: 0.005) nll: 0.819701 \n",
      "(GPU: 0, epoch: 15, iters: 11040, time: 0.004) nll: 0.676268 \n",
      "(GPU: 0, epoch: 15, iters: 11840, time: 0.005) nll: 0.812108 \n",
      "(GPU: 0, epoch: 15, iters: 12640, time: 0.004) nll: 0.756808 \n",
      "(GPU: 0, epoch: 15, iters: 13440, time: 0.005) nll: 0.772162 \n",
      "(GPU: 0, epoch: 15, iters: 14240, time: 0.004) nll: 0.757328 \n",
      "(GPU: 0, epoch: 15, iters: 15040, time: 0.005) nll: 0.672342 \n",
      "(GPU: 0, epoch: 15, iters: 15840, time: 0.005) nll: 0.675162 \n",
      "(GPU: 0, epoch: 15, iters: 16640, time: 0.005) nll: 0.866764 \n",
      "(GPU: 0, epoch: 15, iters: 17440, time: 0.004) nll: 0.788360 \n",
      "(GPU: 0, epoch: 15, iters: 18240, time: 0.005) nll: 0.859697 \n",
      "(GPU: 0, epoch: 15, iters: 19040, time: 0.005) nll: 0.770622 \n",
      "(GPU: 0, epoch: 15, iters: 19840, time: 0.005) nll: 0.773718 \n",
      "(GPU: 0, epoch: 15, iters: 20640, time: 0.005) nll: 0.577303 \n",
      "(GPU: 0, epoch: 15, iters: 21440, time: 0.005) nll: 0.756065 \n",
      "(GPU: 0, epoch: 15, iters: 22240, time: 0.005) nll: 0.870622 \n",
      "(GPU: 0, epoch: 15, iters: 23040, time: 0.005) nll: 0.716220 \n",
      "(GPU: 0, epoch: 15, iters: 23840, time: 0.004) nll: 0.732934 \n",
      "(GPU: 0, epoch: 15, iters: 24640, time: 0.005) nll: 0.782722 \n",
      "(GPU: 0, epoch: 15, iters: 25440, time: 0.005) nll: 0.742859 \n",
      "(GPU: 0, epoch: 15, iters: 26240, time: 0.005) nll: 0.632607 \n",
      "(GPU: 0, epoch: 15, iters: 27040, time: 0.004) nll: 0.806895 \n",
      "(GPU: 0, epoch: 15, iters: 27840, time: 0.005) nll: 0.650355 \n",
      "(GPU: 0, epoch: 15, iters: 28640, time: 0.005) nll: 0.761929 \n",
      "(GPU: 0, epoch: 15, iters: 29440, time: 0.005) nll: 0.804961 \n",
      "saving the latest model (epoch 15, total_steps 2140000)\n",
      "(GPU: 0, epoch: 15, iters: 30240, time: 0.005) nll: 0.840811 \n",
      "(GPU: 0, epoch: 15, iters: 31040, time: 0.005) nll: 0.758752 \n",
      "(GPU: 0, epoch: 15, iters: 31840, time: 0.004) nll: 0.783912 \n",
      "(GPU: 0, epoch: 15, iters: 32640, time: 0.005) nll: 0.815303 \n",
      "(GPU: 0, epoch: 15, iters: 33440, time: 0.005) nll: 0.744874 \n",
      "(GPU: 0, epoch: 15, iters: 34240, time: 0.005) nll: 0.694269 \n",
      "(GPU: 0, epoch: 15, iters: 35040, time: 0.005) nll: 0.730989 \n",
      "(GPU: 0, epoch: 15, iters: 35840, time: 0.005) nll: 0.870103 \n",
      "(GPU: 0, epoch: 15, iters: 36640, time: 0.005) nll: 0.749673 \n",
      "(GPU: 0, epoch: 15, iters: 37440, time: 0.005) nll: 0.637714 \n",
      "(GPU: 0, epoch: 15, iters: 38240, time: 0.005) nll: 0.676486 \n",
      "(GPU: 0, epoch: 15, iters: 39040, time: 0.005) nll: 0.761297 \n",
      "(GPU: 0, epoch: 15, iters: 39840, time: 0.004) nll: 0.655824 \n",
      "(GPU: 0, epoch: 15, iters: 40640, time: 0.005) nll: 0.589887 \n",
      "(GPU: 0, epoch: 15, iters: 41440, time: 0.005) nll: 0.595359 \n",
      "(GPU: 0, epoch: 15, iters: 42240, time: 0.005) nll: 0.883222 \n",
      "(GPU: 0, epoch: 15, iters: 43040, time: 0.005) nll: 0.546958 \n",
      "(GPU: 0, epoch: 15, iters: 43840, time: 0.005) nll: 0.995669 \n",
      "(GPU: 0, epoch: 15, iters: 44640, time: 0.004) nll: 0.766927 \n",
      "(GPU: 0, epoch: 15, iters: 45440, time: 0.005) nll: 0.560282 \n",
      "(GPU: 0, epoch: 15, iters: 46240, time: 0.005) nll: 0.735927 \n",
      "(GPU: 0, epoch: 15, iters: 47040, time: 0.005) nll: 0.756119 \n",
      "(GPU: 0, epoch: 15, iters: 47840, time: 0.004) nll: 0.587937 \n",
      "(GPU: 0, epoch: 15, iters: 48640, time: 0.005) nll: 0.700538 \n",
      "(GPU: 0, epoch: 15, iters: 49440, time: 0.004) nll: 0.650708 \n",
      "saving the latest model (epoch 15, total_steps 2160000)\n",
      "(GPU: 0, epoch: 15, iters: 50240, time: 0.005) nll: 0.908328 \n",
      "(GPU: 0, epoch: 15, iters: 51040, time: 0.005) nll: 0.880598 \n",
      "(GPU: 0, epoch: 15, iters: 51840, time: 0.005) nll: 0.726777 \n",
      "(GPU: 0, epoch: 15, iters: 52640, time: 0.004) nll: 0.735558 \n",
      "(GPU: 0, epoch: 15, iters: 53440, time: 0.005) nll: 0.484865 \n",
      "(GPU: 0, epoch: 15, iters: 54240, time: 0.005) nll: 0.752258 \n",
      "(GPU: 0, epoch: 15, iters: 55040, time: 0.005) nll: 0.747797 \n",
      "(GPU: 0, epoch: 15, iters: 55840, time: 0.004) nll: 0.746159 \n",
      "(GPU: 0, epoch: 15, iters: 56640, time: 0.005) nll: 0.911636 \n",
      "(GPU: 0, epoch: 15, iters: 57440, time: 0.005) nll: 0.581579 \n",
      "(GPU: 0, epoch: 15, iters: 58240, time: 0.005) nll: 0.883554 \n",
      "(GPU: 0, epoch: 15, iters: 59040, time: 0.004) nll: 0.904186 \n",
      "(GPU: 0, epoch: 15, iters: 59840, time: 0.005) nll: 0.886100 \n",
      "(GPU: 0, epoch: 15, iters: 60640, time: 0.005) nll: 0.590742 \n",
      "(GPU: 0, epoch: 15, iters: 61440, time: 0.005) nll: 0.837406 \n",
      "(GPU: 0, epoch: 15, iters: 62240, time: 0.005) nll: 0.631976 \n",
      "(GPU: 0, epoch: 15, iters: 63040, time: 0.005) nll: 0.704530 \n",
      "(GPU: 0, epoch: 15, iters: 63840, time: 0.005) nll: 0.961326 \n",
      "(GPU: 0, epoch: 15, iters: 64640, time: 0.005) nll: 0.709038 \n",
      "(GPU: 0, epoch: 15, iters: 65440, time: 0.005) nll: 0.911121 \n",
      "(GPU: 0, epoch: 15, iters: 66240, time: 0.005) nll: 0.714397 \n",
      "(GPU: 0, epoch: 15, iters: 67040, time: 0.004) nll: 0.644573 \n",
      "(GPU: 0, epoch: 15, iters: 67840, time: 0.005) nll: 0.718782 \n",
      "(GPU: 0, epoch: 15, iters: 68640, time: 0.004) nll: 1.041956 \n",
      "(GPU: 0, epoch: 15, iters: 69440, time: 0.005) nll: 0.710343 \n",
      "saving the latest model (epoch 15, total_steps 2180000)\n",
      "(GPU: 0, epoch: 15, iters: 70240, time: 0.004) nll: 0.721868 \n",
      "(GPU: 0, epoch: 15, iters: 71040, time: 0.005) nll: 0.739059 \n",
      "(GPU: 0, epoch: 15, iters: 71840, time: 0.004) nll: 0.744571 \n",
      "(GPU: 0, epoch: 15, iters: 72640, time: 0.005) nll: 0.757393 \n",
      "(GPU: 0, epoch: 15, iters: 73440, time: 0.004) nll: 0.665790 \n",
      "(GPU: 0, epoch: 15, iters: 74240, time: 0.005) nll: 0.789856 \n",
      "(GPU: 0, epoch: 15, iters: 75040, time: 0.004) nll: 0.625654 \n",
      "(GPU: 0, epoch: 15, iters: 75840, time: 0.005) nll: 0.977118 \n",
      "(GPU: 0, epoch: 15, iters: 76640, time: 0.004) nll: 0.642516 \n",
      "(GPU: 0, epoch: 15, iters: 77440, time: 0.005) nll: 0.841172 \n",
      "(GPU: 0, epoch: 15, iters: 78240, time: 0.005) nll: 0.777717 \n",
      "(GPU: 0, epoch: 15, iters: 79040, time: 0.005) nll: 0.774093 \n",
      "(GPU: 0, epoch: 15, iters: 79840, time: 0.005) nll: 0.684827 \n",
      "(GPU: 0, epoch: 15, iters: 80640, time: 0.005) nll: 0.872189 \n",
      "(GPU: 0, epoch: 15, iters: 81440, time: 0.004) nll: 0.831390 \n",
      "(GPU: 0, epoch: 15, iters: 82240, time: 0.005) nll: 0.730593 \n",
      "(GPU: 0, epoch: 15, iters: 83040, time: 0.005) nll: 0.879985 \n",
      "(GPU: 0, epoch: 15, iters: 83840, time: 0.005) nll: 0.804293 \n",
      "(GPU: 0, epoch: 15, iters: 84640, time: 0.004) nll: 0.760405 \n",
      "(GPU: 0, epoch: 15, iters: 85440, time: 0.005) nll: 0.854825 \n",
      "(GPU: 0, epoch: 15, iters: 86240, time: 0.004) nll: 0.636808 \n",
      "(GPU: 0, epoch: 15, iters: 87040, time: 0.005) nll: 0.687742 \n",
      "(GPU: 0, epoch: 15, iters: 87840, time: 0.004) nll: 0.650355 \n",
      "(GPU: 0, epoch: 15, iters: 88640, time: 0.005) nll: 0.808803 \n",
      "(GPU: 0, epoch: 15, iters: 89440, time: 0.004) nll: 0.722374 \n",
      "saving the latest model (epoch 15, total_steps 2200000)\n",
      "(GPU: 0, epoch: 15, iters: 90240, time: 0.005) nll: 0.890189 \n",
      "(GPU: 0, epoch: 15, iters: 91040, time: 0.005) nll: 0.706684 \n",
      "(GPU: 0, epoch: 15, iters: 91840, time: 0.005) nll: 0.719679 \n",
      "(GPU: 0, epoch: 15, iters: 92640, time: 0.005) nll: 0.809049 \n",
      "(GPU: 0, epoch: 15, iters: 93440, time: 0.005) nll: 0.551715 \n",
      "(GPU: 0, epoch: 15, iters: 94240, time: 0.005) nll: 0.667506 \n",
      "(GPU: 0, epoch: 15, iters: 95040, time: 0.005) nll: 0.603923 \n",
      "(GPU: 0, epoch: 15, iters: 95840, time: 0.005) nll: 0.596468 \n",
      "(GPU: 0, epoch: 15, iters: 96640, time: 0.005) nll: 0.575523 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.004) nll: 0.714987 \n",
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.007) nll: 0.709017 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:50<00:00,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 15, iters: 97440, time: 0.007) nll: 0.683238 \n",
      "(GPU: 0, epoch: 15, iters: 98240, time: 0.005) nll: 0.773261 \n",
      "(GPU: 0, epoch: 15, iters: 99040, time: 0.005) nll: 0.840622 \n",
      "(GPU: 0, epoch: 15, iters: 99840, time: 0.005) nll: 0.795686 \n",
      "(GPU: 0, epoch: 15, iters: 100640, time: 0.005) nll: 0.979044 \n",
      "(GPU: 0, epoch: 15, iters: 101440, time: 0.005) nll: 0.645685 \n",
      "(GPU: 0, epoch: 15, iters: 102240, time: 0.004) nll: 0.849453 \n",
      "(GPU: 0, epoch: 15, iters: 103040, time: 0.005) nll: 0.621258 \n",
      "(GPU: 0, epoch: 15, iters: 103840, time: 0.005) nll: 0.522203 \n",
      "(GPU: 0, epoch: 15, iters: 104640, time: 0.005) nll: 0.790222 \n",
      "(GPU: 0, epoch: 15, iters: 105440, time: 0.004) nll: 0.652227 \n",
      "(GPU: 0, epoch: 15, iters: 106240, time: 0.005) nll: 0.842460 \n",
      "(GPU: 0, epoch: 15, iters: 107040, time: 0.005) nll: 0.809797 \n",
      "(GPU: 0, epoch: 15, iters: 107840, time: 0.005) nll: 0.916692 \n",
      "(GPU: 0, epoch: 15, iters: 108640, time: 0.004) nll: 0.846178 \n",
      "(GPU: 0, epoch: 15, iters: 109440, time: 0.005) nll: 0.761892 \n",
      "saving the latest model (epoch 15, total_steps 2220000)\n",
      "(GPU: 0, epoch: 15, iters: 110240, time: 0.005) nll: 0.583694 \n",
      "(GPU: 0, epoch: 15, iters: 111040, time: 0.005) nll: 0.649304 \n",
      "(GPU: 0, epoch: 15, iters: 111840, time: 0.005) nll: 0.876339 \n",
      "(GPU: 0, epoch: 15, iters: 112640, time: 0.005) nll: 0.843930 \n",
      "(GPU: 0, epoch: 15, iters: 113440, time: 0.004) nll: 0.686090 \n",
      "(GPU: 0, epoch: 15, iters: 114240, time: 0.005) nll: 0.821220 \n",
      "(GPU: 0, epoch: 15, iters: 115040, time: 0.005) nll: 0.602451 \n",
      "(GPU: 0, epoch: 15, iters: 115840, time: 0.005) nll: 0.620202 \n",
      "(GPU: 0, epoch: 15, iters: 116640, time: 0.005) nll: 0.571771 \n",
      "(GPU: 0, epoch: 15, iters: 117440, time: 0.005) nll: 0.813984 \n",
      "(GPU: 0, epoch: 15, iters: 118240, time: 0.004) nll: 0.815995 \n",
      "(GPU: 0, epoch: 15, iters: 119040, time: 0.005) nll: 0.832350 \n",
      "(GPU: 0, epoch: 15, iters: 119840, time: 0.004) nll: 0.690230 \n",
      "(GPU: 0, epoch: 15, iters: 120640, time: 0.005) nll: 0.786392 \n",
      "(GPU: 0, epoch: 15, iters: 121440, time: 0.004) nll: 0.669086 \n",
      "(GPU: 0, epoch: 15, iters: 122240, time: 0.005) nll: 0.756163 \n",
      "(GPU: 0, epoch: 15, iters: 123040, time: 0.004) nll: 0.881824 \n",
      "(GPU: 0, epoch: 15, iters: 123840, time: 0.005) nll: 0.716935 \n",
      "(GPU: 0, epoch: 15, iters: 124640, time: 0.004) nll: 0.813088 \n",
      "(GPU: 0, epoch: 15, iters: 125440, time: 0.005) nll: 0.696323 \n",
      "(GPU: 0, epoch: 15, iters: 126240, time: 0.004) nll: 0.684543 \n",
      "(GPU: 0, epoch: 15, iters: 127040, time: 0.005) nll: 0.767212 \n",
      "(GPU: 0, epoch: 15, iters: 127840, time: 0.004) nll: 0.780839 \n",
      "(GPU: 0, epoch: 15, iters: 128640, time: 0.005) nll: 0.786092 \n",
      "(GPU: 0, epoch: 15, iters: 129440, time: 0.004) nll: 0.664776 \n",
      "saving the latest model (epoch 15, total_steps 2240000)\n",
      "(GPU: 0, epoch: 15, iters: 130240, time: 0.005) nll: 0.732694 \n",
      "(GPU: 0, epoch: 15, iters: 131040, time: 0.004) nll: 0.655725 \n",
      "(GPU: 0, epoch: 15, iters: 131840, time: 0.005) nll: 0.569153 \n",
      "(GPU: 0, epoch: 15, iters: 132640, time: 0.005) nll: 0.786916 \n",
      "(GPU: 0, epoch: 15, iters: 133440, time: 0.005) nll: 0.785978 \n",
      "(GPU: 0, epoch: 15, iters: 134240, time: 0.004) nll: 0.523132 \n",
      "(GPU: 0, epoch: 15, iters: 135040, time: 0.005) nll: 0.593511 \n",
      "(GPU: 0, epoch: 15, iters: 135840, time: 0.005) nll: 0.793357 \n",
      "(GPU: 0, epoch: 15, iters: 136640, time: 0.005) nll: 0.866037 \n",
      "(GPU: 0, epoch: 15, iters: 137440, time: 0.004) nll: 0.747288 \n",
      "(GPU: 0, epoch: 15, iters: 138240, time: 0.005) nll: 0.943308 \n",
      "(GPU: 0, epoch: 15, iters: 139040, time: 0.005) nll: 0.428216 \n",
      "(GPU: 0, epoch: 15, iters: 139840, time: 0.005) nll: 0.830536 \n",
      "(GPU: 0, epoch: 15, iters: 140640, time: 0.005) nll: 0.749351 \n",
      "saving the model at the end of epoch 15, iters 2251264\n",
      "([test] GPU: 0, epoch: 15) \n",
      "OrderedDict()\n",
      "[*] End of epoch 15 / 25 \t Time Taken: 790 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000791\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3097/4397 [09:03<03:27,  6.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 32, time: 0.003) nll: 0.658148 \n",
      "(GPU: 0, epoch: 16, iters: 32, time: 0.003) nll: 0.684787 \n",
      "(GPU: 0, epoch: 16, iters: 736, time: 0.005) nll: 0.605133 \n",
      "(GPU: 0, epoch: 16, iters: 1536, time: 0.005) nll: 0.699249 \n",
      "(GPU: 0, epoch: 16, iters: 2336, time: 0.004) nll: 0.622536 \n",
      "(GPU: 0, epoch: 16, iters: 3136, time: 0.005) nll: 0.767678 \n",
      "(GPU: 0, epoch: 16, iters: 3936, time: 0.004) nll: 0.641696 \n",
      "(GPU: 0, epoch: 16, iters: 4736, time: 0.005) nll: 0.507978 \n",
      "(GPU: 0, epoch: 16, iters: 5536, time: 0.005) nll: 0.529425 \n",
      "(GPU: 0, epoch: 16, iters: 6336, time: 0.005) nll: 0.539939 \n",
      "(GPU: 0, epoch: 16, iters: 7136, time: 0.005) nll: 0.607875 \n",
      "(GPU: 0, epoch: 16, iters: 7936, time: 0.005) nll: 0.651382 \n",
      "(GPU: 0, epoch: 16, iters: 8736, time: 0.005) nll: 0.948441 \n",
      "saving the latest model (epoch 16, total_steps 2260000)\n",
      "(GPU: 0, epoch: 16, iters: 9536, time: 0.005) nll: 0.774094 \n",
      "(GPU: 0, epoch: 16, iters: 10336, time: 0.005) nll: 0.736325 \n",
      "(GPU: 0, epoch: 16, iters: 11136, time: 0.005) nll: 0.722662 \n",
      "(GPU: 0, epoch: 16, iters: 11936, time: 0.004) nll: 0.511287 \n",
      "(GPU: 0, epoch: 16, iters: 12736, time: 0.005) nll: 0.737816 \n",
      "(GPU: 0, epoch: 16, iters: 13536, time: 0.005) nll: 0.653737 \n",
      "(GPU: 0, epoch: 16, iters: 14336, time: 0.005) nll: 0.878172 \n",
      "(GPU: 0, epoch: 16, iters: 15136, time: 0.005) nll: 0.645744 \n",
      "(GPU: 0, epoch: 16, iters: 15936, time: 0.005) nll: 0.566009 \n",
      "(GPU: 0, epoch: 16, iters: 16736, time: 0.005) nll: 0.623153 \n",
      "(GPU: 0, epoch: 16, iters: 17536, time: 0.005) nll: 0.811655 \n",
      "(GPU: 0, epoch: 16, iters: 18336, time: 0.005) nll: 0.794298 \n",
      "(GPU: 0, epoch: 16, iters: 19136, time: 0.005) nll: 0.771741 \n",
      "(GPU: 0, epoch: 16, iters: 19936, time: 0.004) nll: 0.734662 \n",
      "(GPU: 0, epoch: 16, iters: 20736, time: 0.005) nll: 0.672263 \n",
      "(GPU: 0, epoch: 16, iters: 21536, time: 0.005) nll: 0.841976 \n",
      "(GPU: 0, epoch: 16, iters: 22336, time: 0.005) nll: 0.474705 \n",
      "(GPU: 0, epoch: 16, iters: 23136, time: 0.004) nll: 0.694002 \n",
      "(GPU: 0, epoch: 16, iters: 23936, time: 0.005) nll: 0.733784 \n",
      "(GPU: 0, epoch: 16, iters: 24736, time: 0.004) nll: 0.600326 \n",
      "(GPU: 0, epoch: 16, iters: 25536, time: 0.005) nll: 0.568813 \n",
      "(GPU: 0, epoch: 16, iters: 26336, time: 0.005) nll: 0.614935 \n",
      "(GPU: 0, epoch: 16, iters: 27136, time: 0.005) nll: 0.683919 \n",
      "(GPU: 0, epoch: 16, iters: 27936, time: 0.005) nll: 0.850339 \n",
      "(GPU: 0, epoch: 16, iters: 28736, time: 0.005) nll: 0.650657 \n",
      "saving the latest model (epoch 16, total_steps 2280000)\n",
      "(GPU: 0, epoch: 16, iters: 29536, time: 0.004) nll: 0.729804 \n",
      "(GPU: 0, epoch: 16, iters: 30336, time: 0.005) nll: 0.878163 \n",
      "(GPU: 0, epoch: 16, iters: 31136, time: 0.004) nll: 0.864711 \n",
      "(GPU: 0, epoch: 16, iters: 31936, time: 0.005) nll: 0.815657 \n",
      "(GPU: 0, epoch: 16, iters: 32736, time: 0.005) nll: 1.061687 \n",
      "(GPU: 0, epoch: 16, iters: 33536, time: 0.005) nll: 0.724599 \n",
      "(GPU: 0, epoch: 16, iters: 34336, time: 0.005) nll: 0.722014 \n",
      "(GPU: 0, epoch: 16, iters: 35136, time: 0.005) nll: 0.630181 \n",
      "(GPU: 0, epoch: 16, iters: 35936, time: 0.005) nll: 0.772390 \n",
      "(GPU: 0, epoch: 16, iters: 36736, time: 0.005) nll: 0.838177 \n",
      "(GPU: 0, epoch: 16, iters: 37536, time: 0.004) nll: 0.669906 \n",
      "(GPU: 0, epoch: 16, iters: 38336, time: 0.005) nll: 0.526770 \n",
      "(GPU: 0, epoch: 16, iters: 39136, time: 0.005) nll: 0.864079 \n",
      "(GPU: 0, epoch: 16, iters: 39936, time: 0.005) nll: 0.739902 \n",
      "(GPU: 0, epoch: 16, iters: 40736, time: 0.004) nll: 0.801169 \n",
      "(GPU: 0, epoch: 16, iters: 41536, time: 0.005) nll: 0.909407 \n",
      "(GPU: 0, epoch: 16, iters: 42336, time: 0.004) nll: 0.930510 \n",
      "(GPU: 0, epoch: 16, iters: 43136, time: 0.005) nll: 1.033679 \n",
      "(GPU: 0, epoch: 16, iters: 43936, time: 0.005) nll: 0.635463 \n",
      "(GPU: 0, epoch: 16, iters: 44736, time: 0.005) nll: 0.533961 \n",
      "(GPU: 0, epoch: 16, iters: 45536, time: 0.004) nll: 0.723384 \n",
      "(GPU: 0, epoch: 16, iters: 46336, time: 0.005) nll: 0.687817 \n",
      "(GPU: 0, epoch: 16, iters: 47136, time: 0.004) nll: 0.830399 \n",
      "(GPU: 0, epoch: 16, iters: 47936, time: 0.005) nll: 0.728033 \n",
      "(GPU: 0, epoch: 16, iters: 48736, time: 0.005) nll: 0.842247 \n",
      "saving the latest model (epoch 16, total_steps 2300000)\n",
      "(GPU: 0, epoch: 16, iters: 49536, time: 0.005) nll: 0.857633 \n",
      "(GPU: 0, epoch: 16, iters: 50336, time: 0.004) nll: 0.703703 \n",
      "(GPU: 0, epoch: 16, iters: 51136, time: 0.005) nll: 0.709452 \n",
      "(GPU: 0, epoch: 16, iters: 51936, time: 0.005) nll: 0.779598 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.005) nll: 0.861371 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.008) nll: 0.854492 \n",
      "(GPU: 0, epoch: 16, iters: 52736, time: 0.008) nll: 0.692207 \n",
      "(GPU: 0, epoch: 16, iters: 53536, time: 0.004) nll: 0.611001 \n",
      "(GPU: 0, epoch: 16, iters: 54336, time: 0.005) nll: 0.832368 \n",
      "(GPU: 0, epoch: 16, iters: 55136, time: 0.004) nll: 0.745466 \n",
      "(GPU: 0, epoch: 16, iters: 55936, time: 0.005) nll: 0.954261 \n",
      "(GPU: 0, epoch: 16, iters: 56736, time: 0.004) nll: 0.895076 \n",
      "(GPU: 0, epoch: 16, iters: 57536, time: 0.005) nll: 0.810874 \n",
      "(GPU: 0, epoch: 16, iters: 58336, time: 0.004) nll: 0.823184 \n",
      "(GPU: 0, epoch: 16, iters: 59136, time: 0.005) nll: 0.736039 \n",
      "(GPU: 0, epoch: 16, iters: 59936, time: 0.005) nll: 0.644632 \n",
      "(GPU: 0, epoch: 16, iters: 60736, time: 0.005) nll: 0.588533 \n",
      "(GPU: 0, epoch: 16, iters: 61536, time: 0.004) nll: 0.802067 \n",
      "(GPU: 0, epoch: 16, iters: 62336, time: 0.005) nll: 0.616411 \n",
      "(GPU: 0, epoch: 16, iters: 63136, time: 0.005) nll: 0.719052 \n",
      "(GPU: 0, epoch: 16, iters: 63936, time: 0.005) nll: 0.794151 \n",
      "(GPU: 0, epoch: 16, iters: 64736, time: 0.004) nll: 0.595625 \n",
      "(GPU: 0, epoch: 16, iters: 65536, time: 0.005) nll: 0.848957 \n",
      "(GPU: 0, epoch: 16, iters: 66336, time: 0.004) nll: 0.510938 \n",
      "(GPU: 0, epoch: 16, iters: 67136, time: 0.005) nll: 0.583792 \n",
      "(GPU: 0, epoch: 16, iters: 67936, time: 0.005) nll: 0.651321 \n",
      "(GPU: 0, epoch: 16, iters: 68736, time: 0.005) nll: 0.776480 \n",
      "saving the latest model (epoch 16, total_steps 2320000)\n",
      "(GPU: 0, epoch: 16, iters: 69536, time: 0.004) nll: 0.880936 \n",
      "(GPU: 0, epoch: 16, iters: 70336, time: 0.005) nll: 0.733501 \n",
      "(GPU: 0, epoch: 16, iters: 71136, time: 0.005) nll: 0.630804 \n",
      "(GPU: 0, epoch: 16, iters: 71936, time: 0.005) nll: 0.582994 \n",
      "(GPU: 0, epoch: 16, iters: 72736, time: 0.005) nll: 0.923223 \n",
      "(GPU: 0, epoch: 16, iters: 73536, time: 0.005) nll: 0.829792 \n",
      "(GPU: 0, epoch: 16, iters: 74336, time: 0.004) nll: 0.761932 \n",
      "(GPU: 0, epoch: 16, iters: 75136, time: 0.005) nll: 0.962595 \n",
      "(GPU: 0, epoch: 16, iters: 75936, time: 0.004) nll: 0.669315 \n",
      "(GPU: 0, epoch: 16, iters: 76736, time: 0.005) nll: 0.858100 \n",
      "(GPU: 0, epoch: 16, iters: 77536, time: 0.004) nll: 0.614084 \n",
      "(GPU: 0, epoch: 16, iters: 78336, time: 0.005) nll: 0.732627 \n",
      "(GPU: 0, epoch: 16, iters: 79136, time: 0.004) nll: 0.720217 \n",
      "(GPU: 0, epoch: 16, iters: 79936, time: 0.005) nll: 0.924288 \n",
      "(GPU: 0, epoch: 16, iters: 80736, time: 0.005) nll: 0.867428 \n",
      "(GPU: 0, epoch: 16, iters: 81536, time: 0.005) nll: 0.881494 \n",
      "(GPU: 0, epoch: 16, iters: 82336, time: 0.004) nll: 0.649165 \n",
      "(GPU: 0, epoch: 16, iters: 83136, time: 0.005) nll: 0.845032 \n",
      "(GPU: 0, epoch: 16, iters: 83936, time: 0.004) nll: 0.876517 \n",
      "(GPU: 0, epoch: 16, iters: 84736, time: 0.005) nll: 0.694810 \n",
      "(GPU: 0, epoch: 16, iters: 85536, time: 0.005) nll: 0.798110 \n",
      "(GPU: 0, epoch: 16, iters: 86336, time: 0.005) nll: 0.501762 \n",
      "(GPU: 0, epoch: 16, iters: 87136, time: 0.004) nll: 0.693846 \n",
      "(GPU: 0, epoch: 16, iters: 87936, time: 0.005) nll: 0.628230 \n",
      "(GPU: 0, epoch: 16, iters: 88736, time: 0.004) nll: 0.797886 \n",
      "saving the latest model (epoch 16, total_steps 2340000)\n",
      "(GPU: 0, epoch: 16, iters: 89536, time: 0.005) nll: 0.678277 \n",
      "(GPU: 0, epoch: 16, iters: 90336, time: 0.005) nll: 0.801968 \n",
      "(GPU: 0, epoch: 16, iters: 91136, time: 0.005) nll: 0.523266 \n",
      "(GPU: 0, epoch: 16, iters: 91936, time: 0.005) nll: 0.711446 \n",
      "(GPU: 0, epoch: 16, iters: 92736, time: 0.005) nll: 0.892807 \n",
      "(GPU: 0, epoch: 16, iters: 93536, time: 0.004) nll: 0.657589 \n",
      "(GPU: 0, epoch: 16, iters: 94336, time: 0.005) nll: 0.545672 \n",
      "(GPU: 0, epoch: 16, iters: 95136, time: 0.005) nll: 0.552577 \n",
      "(GPU: 0, epoch: 16, iters: 95936, time: 0.005) nll: 0.839480 \n",
      "(GPU: 0, epoch: 16, iters: 96736, time: 0.004) nll: 0.895443 \n",
      "(GPU: 0, epoch: 16, iters: 97536, time: 0.005) nll: 0.944199 \n",
      "(GPU: 0, epoch: 16, iters: 98336, time: 0.004) nll: 0.741540 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:53<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 16, iters: 99136, time: 0.005) nll: 0.777999 \n",
      "(GPU: 0, epoch: 16, iters: 99936, time: 0.005) nll: 0.866332 \n",
      "(GPU: 0, epoch: 16, iters: 100736, time: 0.005) nll: 0.700121 \n",
      "(GPU: 0, epoch: 16, iters: 101536, time: 0.004) nll: 0.840583 \n",
      "(GPU: 0, epoch: 16, iters: 102336, time: 0.005) nll: 0.634906 \n",
      "(GPU: 0, epoch: 16, iters: 103136, time: 0.004) nll: 0.665761 \n",
      "(GPU: 0, epoch: 16, iters: 103936, time: 0.005) nll: 0.616155 \n",
      "(GPU: 0, epoch: 16, iters: 104736, time: 0.005) nll: 0.921065 \n",
      "(GPU: 0, epoch: 16, iters: 105536, time: 0.005) nll: 0.777770 \n",
      "(GPU: 0, epoch: 16, iters: 106336, time: 0.004) nll: 0.859307 \n",
      "(GPU: 0, epoch: 16, iters: 107136, time: 0.005) nll: 0.794967 \n",
      "(GPU: 0, epoch: 16, iters: 107936, time: 0.004) nll: 0.704129 \n",
      "(GPU: 0, epoch: 16, iters: 108736, time: 0.005) nll: 0.859898 \n",
      "saving the latest model (epoch 16, total_steps 2360000)\n",
      "(GPU: 0, epoch: 16, iters: 109536, time: 0.005) nll: 0.976176 \n",
      "(GPU: 0, epoch: 16, iters: 110336, time: 0.005) nll: 0.835414 \n",
      "(GPU: 0, epoch: 16, iters: 111136, time: 0.004) nll: 0.963004 \n",
      "(GPU: 0, epoch: 16, iters: 111936, time: 0.005) nll: 0.721255 \n",
      "(GPU: 0, epoch: 16, iters: 112736, time: 0.004) nll: 0.783435 \n",
      "(GPU: 0, epoch: 16, iters: 113536, time: 0.005) nll: 0.768097 \n",
      "(GPU: 0, epoch: 16, iters: 114336, time: 0.004) nll: 0.573569 \n",
      "(GPU: 0, epoch: 16, iters: 115136, time: 0.005) nll: 0.570433 \n",
      "(GPU: 0, epoch: 16, iters: 115936, time: 0.004) nll: 0.614326 \n",
      "(GPU: 0, epoch: 16, iters: 116736, time: 0.005) nll: 0.784929 \n",
      "(GPU: 0, epoch: 16, iters: 117536, time: 0.004) nll: 0.629420 \n",
      "(GPU: 0, epoch: 16, iters: 118336, time: 0.005) nll: 0.709338 \n",
      "(GPU: 0, epoch: 16, iters: 119136, time: 0.004) nll: 0.749352 \n",
      "(GPU: 0, epoch: 16, iters: 119936, time: 0.005) nll: 0.664407 \n",
      "(GPU: 0, epoch: 16, iters: 120736, time: 0.005) nll: 0.710063 \n",
      "(GPU: 0, epoch: 16, iters: 121536, time: 0.005) nll: 0.592200 \n",
      "(GPU: 0, epoch: 16, iters: 122336, time: 0.005) nll: 0.676194 \n",
      "(GPU: 0, epoch: 16, iters: 123136, time: 0.005) nll: 0.935333 \n",
      "(GPU: 0, epoch: 16, iters: 123936, time: 0.005) nll: 0.667574 \n",
      "(GPU: 0, epoch: 16, iters: 124736, time: 0.005) nll: 0.725553 \n",
      "(GPU: 0, epoch: 16, iters: 125536, time: 0.005) nll: 0.635505 \n",
      "(GPU: 0, epoch: 16, iters: 126336, time: 0.005) nll: 0.691240 \n",
      "(GPU: 0, epoch: 16, iters: 127136, time: 0.005) nll: 0.678379 \n",
      "(GPU: 0, epoch: 16, iters: 127936, time: 0.005) nll: 0.617067 \n",
      "(GPU: 0, epoch: 16, iters: 128736, time: 0.005) nll: 0.758278 \n",
      "saving the latest model (epoch 16, total_steps 2380000)\n",
      "(GPU: 0, epoch: 16, iters: 129536, time: 0.005) nll: 0.910218 \n",
      "(GPU: 0, epoch: 16, iters: 130336, time: 0.004) nll: 0.766209 \n",
      "(GPU: 0, epoch: 16, iters: 131136, time: 0.005) nll: 0.791130 \n",
      "(GPU: 0, epoch: 16, iters: 131936, time: 0.004) nll: 0.652146 \n",
      "(GPU: 0, epoch: 16, iters: 132736, time: 0.005) nll: 0.846852 \n",
      "(GPU: 0, epoch: 16, iters: 133536, time: 0.004) nll: 0.668221 \n",
      "(GPU: 0, epoch: 16, iters: 134336, time: 0.005) nll: 0.780660 \n",
      "(GPU: 0, epoch: 16, iters: 135136, time: 0.004) nll: 0.935957 \n",
      "(GPU: 0, epoch: 16, iters: 135936, time: 0.005) nll: 0.718937 \n",
      "(GPU: 0, epoch: 16, iters: 136736, time: 0.004) nll: 0.631576 \n",
      "(GPU: 0, epoch: 16, iters: 137536, time: 0.005) nll: 0.822427 \n",
      "(GPU: 0, epoch: 16, iters: 138336, time: 0.004) nll: 0.564830 \n",
      "(GPU: 0, epoch: 16, iters: 139136, time: 0.005) nll: 0.859308 \n",
      "(GPU: 0, epoch: 16, iters: 139936, time: 0.005) nll: 0.720687 \n",
      "[*] End of epoch 16 / 25 \t Time Taken: 773 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000767\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3075/4397 [09:01<03:30,  6.29it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 32, time: 0.002) nll: 0.795956 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.005) nll: 0.790129 \n",
      "(GPU: 0, epoch: 17, iters: 32, time: 0.005) nll: 0.907287 \n",
      "(GPU: 0, epoch: 17, iters: 832, time: 0.005) nll: 0.852410 \n",
      "(GPU: 0, epoch: 17, iters: 1632, time: 0.005) nll: 0.701784 \n",
      "(GPU: 0, epoch: 17, iters: 2432, time: 0.005) nll: 0.764585 \n",
      "(GPU: 0, epoch: 17, iters: 3232, time: 0.005) nll: 0.663104 \n",
      "(GPU: 0, epoch: 17, iters: 4032, time: 0.005) nll: 0.704269 \n",
      "(GPU: 0, epoch: 17, iters: 4832, time: 0.005) nll: 0.593218 \n",
      "(GPU: 0, epoch: 17, iters: 5632, time: 0.005) nll: 0.590879 \n",
      "(GPU: 0, epoch: 17, iters: 6432, time: 0.004) nll: 0.752710 \n",
      "(GPU: 0, epoch: 17, iters: 7232, time: 0.005) nll: 0.729936 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.005) nll: 0.923332 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.008) nll: 0.914768 \n",
      "(GPU: 0, epoch: 17, iters: 8032, time: 0.008) nll: 0.914034 \n",
      "saving the latest model (epoch 17, total_steps 2400000)\n",
      "(GPU: 0, epoch: 17, iters: 8832, time: 0.005) nll: 0.946049 \n",
      "(GPU: 0, epoch: 17, iters: 9632, time: 0.005) nll: 0.755877 \n",
      "(GPU: 0, epoch: 17, iters: 10432, time: 0.005) nll: 0.772433 \n",
      "(GPU: 0, epoch: 17, iters: 11232, time: 0.005) nll: 0.699626 \n",
      "(GPU: 0, epoch: 17, iters: 12032, time: 0.005) nll: 0.700451 \n",
      "(GPU: 0, epoch: 17, iters: 12832, time: 0.005) nll: 0.669254 \n",
      "(GPU: 0, epoch: 17, iters: 13632, time: 0.005) nll: 0.782808 \n",
      "(GPU: 0, epoch: 17, iters: 14432, time: 0.004) nll: 0.650389 \n",
      "(GPU: 0, epoch: 17, iters: 15232, time: 0.005) nll: 0.469850 \n",
      "(GPU: 0, epoch: 17, iters: 16032, time: 0.005) nll: 0.571102 \n",
      "(GPU: 0, epoch: 17, iters: 16832, time: 0.005) nll: 0.735223 \n",
      "(GPU: 0, epoch: 17, iters: 17632, time: 0.004) nll: 0.602112 \n",
      "(GPU: 0, epoch: 17, iters: 18432, time: 0.005) nll: 0.652079 \n",
      "(GPU: 0, epoch: 17, iters: 19232, time: 0.004) nll: 0.602647 \n",
      "(GPU: 0, epoch: 17, iters: 20032, time: 0.005) nll: 0.720250 \n",
      "(GPU: 0, epoch: 17, iters: 20832, time: 0.004) nll: 0.837165 \n",
      "(GPU: 0, epoch: 17, iters: 21632, time: 0.005) nll: 0.538478 \n",
      "(GPU: 0, epoch: 17, iters: 22432, time: 0.005) nll: 0.604598 \n",
      "(GPU: 0, epoch: 17, iters: 23232, time: 0.005) nll: 0.649932 \n",
      "(GPU: 0, epoch: 17, iters: 24032, time: 0.005) nll: 0.790948 \n",
      "(GPU: 0, epoch: 17, iters: 24832, time: 0.005) nll: 0.714210 \n",
      "(GPU: 0, epoch: 17, iters: 25632, time: 0.004) nll: 0.652239 \n",
      "(GPU: 0, epoch: 17, iters: 26432, time: 0.005) nll: 0.768223 \n",
      "(GPU: 0, epoch: 17, iters: 27232, time: 0.005) nll: 0.767184 \n",
      "(GPU: 0, epoch: 17, iters: 28032, time: 0.005) nll: 0.712216 \n",
      "saving the latest model (epoch 17, total_steps 2420000)\n",
      "(GPU: 0, epoch: 17, iters: 28832, time: 0.004) nll: 0.765088 \n",
      "(GPU: 0, epoch: 17, iters: 29632, time: 0.005) nll: 0.805926 \n",
      "(GPU: 0, epoch: 17, iters: 30432, time: 0.004) nll: 0.611453 \n",
      "(GPU: 0, epoch: 17, iters: 31232, time: 0.005) nll: 0.777951 \n",
      "(GPU: 0, epoch: 17, iters: 32032, time: 0.005) nll: 0.761440 \n",
      "(GPU: 0, epoch: 17, iters: 32832, time: 0.005) nll: 0.874188 \n",
      "(GPU: 0, epoch: 17, iters: 33632, time: 0.005) nll: 0.624110 \n",
      "(GPU: 0, epoch: 17, iters: 34432, time: 0.005) nll: 0.816702 \n",
      "(GPU: 0, epoch: 17, iters: 35232, time: 0.004) nll: 0.844737 \n",
      "(GPU: 0, epoch: 17, iters: 36032, time: 0.005) nll: 0.903695 \n",
      "(GPU: 0, epoch: 17, iters: 36832, time: 0.004) nll: 0.719130 \n",
      "(GPU: 0, epoch: 17, iters: 37632, time: 0.005) nll: 0.637296 \n",
      "(GPU: 0, epoch: 17, iters: 38432, time: 0.004) nll: 0.835058 \n",
      "(GPU: 0, epoch: 17, iters: 39232, time: 0.005) nll: 0.811188 \n",
      "(GPU: 0, epoch: 17, iters: 40032, time: 0.005) nll: 0.535851 \n",
      "(GPU: 0, epoch: 17, iters: 40832, time: 0.005) nll: 0.578078 \n",
      "(GPU: 0, epoch: 17, iters: 41632, time: 0.004) nll: 0.780824 \n",
      "(GPU: 0, epoch: 17, iters: 42432, time: 0.005) nll: 0.736006 \n",
      "(GPU: 0, epoch: 17, iters: 43232, time: 0.005) nll: 0.676998 \n",
      "(GPU: 0, epoch: 17, iters: 44032, time: 0.005) nll: 0.683466 \n",
      "(GPU: 0, epoch: 17, iters: 44832, time: 0.005) nll: 0.717817 \n",
      "(GPU: 0, epoch: 17, iters: 45632, time: 0.005) nll: 0.716318 \n",
      "(GPU: 0, epoch: 17, iters: 46432, time: 0.004) nll: 0.743438 \n",
      "(GPU: 0, epoch: 17, iters: 47232, time: 0.005) nll: 0.666621 \n",
      "(GPU: 0, epoch: 17, iters: 48032, time: 0.005) nll: 0.669511 \n",
      "saving the latest model (epoch 17, total_steps 2440000)\n",
      "(GPU: 0, epoch: 17, iters: 48832, time: 0.005) nll: 0.671974 \n",
      "(GPU: 0, epoch: 17, iters: 49632, time: 0.004) nll: 0.881363 \n",
      "(GPU: 0, epoch: 17, iters: 50432, time: 0.005) nll: 0.615346 \n",
      "(GPU: 0, epoch: 17, iters: 51232, time: 0.004) nll: 0.711207 \n",
      "(GPU: 0, epoch: 17, iters: 52032, time: 0.005) nll: 0.573174 \n",
      "(GPU: 0, epoch: 17, iters: 52832, time: 0.005) nll: 0.798449 \n",
      "(GPU: 0, epoch: 17, iters: 53632, time: 0.005) nll: 0.580957 \n",
      "(GPU: 0, epoch: 17, iters: 54432, time: 0.005) nll: 0.721000 \n",
      "(GPU: 0, epoch: 17, iters: 55232, time: 0.005) nll: 0.601369 \n",
      "(GPU: 0, epoch: 17, iters: 56032, time: 0.004) nll: 0.641134 \n",
      "(GPU: 0, epoch: 17, iters: 56832, time: 0.005) nll: 0.651923 \n",
      "(GPU: 0, epoch: 17, iters: 57632, time: 0.005) nll: 0.700205 \n",
      "(GPU: 0, epoch: 17, iters: 58432, time: 0.005) nll: 0.760505 \n",
      "(GPU: 0, epoch: 17, iters: 59232, time: 0.004) nll: 0.726161 \n",
      "(GPU: 0, epoch: 17, iters: 60032, time: 0.005) nll: 1.002093 \n",
      "(GPU: 0, epoch: 17, iters: 60832, time: 0.005) nll: 0.876837 \n",
      "(GPU: 0, epoch: 17, iters: 61632, time: 0.005) nll: 0.594450 \n",
      "(GPU: 0, epoch: 17, iters: 62432, time: 0.005) nll: 0.928202 \n",
      "(GPU: 0, epoch: 17, iters: 63232, time: 0.005) nll: 0.828952 \n",
      "(GPU: 0, epoch: 17, iters: 64032, time: 0.004) nll: 0.770577 \n",
      "(GPU: 0, epoch: 17, iters: 64832, time: 0.005) nll: 0.729026 \n",
      "(GPU: 0, epoch: 17, iters: 65632, time: 0.005) nll: 1.058847 \n",
      "(GPU: 0, epoch: 17, iters: 66432, time: 0.005) nll: 0.790763 \n",
      "(GPU: 0, epoch: 17, iters: 67232, time: 0.004) nll: 0.906645 \n",
      "(GPU: 0, epoch: 17, iters: 68032, time: 0.005) nll: 0.674118 \n",
      "saving the latest model (epoch 17, total_steps 2460000)\n",
      "(GPU: 0, epoch: 17, iters: 68832, time: 0.004) nll: 0.604580 \n",
      "(GPU: 0, epoch: 17, iters: 69632, time: 0.005) nll: 0.884363 \n",
      "(GPU: 0, epoch: 17, iters: 70432, time: 0.004) nll: 0.696353 \n",
      "(GPU: 0, epoch: 17, iters: 71232, time: 0.005) nll: 0.600043 \n",
      "(GPU: 0, epoch: 17, iters: 72032, time: 0.005) nll: 0.627514 \n",
      "(GPU: 0, epoch: 17, iters: 72832, time: 0.005) nll: 0.793200 \n",
      "(GPU: 0, epoch: 17, iters: 73632, time: 0.004) nll: 0.773338 \n",
      "(GPU: 0, epoch: 17, iters: 74432, time: 0.005) nll: 0.847815 \n",
      "(GPU: 0, epoch: 17, iters: 75232, time: 0.004) nll: 0.772951 \n",
      "(GPU: 0, epoch: 17, iters: 76032, time: 0.005) nll: 0.718444 \n",
      "(GPU: 0, epoch: 17, iters: 76832, time: 0.005) nll: 0.744145 \n",
      "(GPU: 0, epoch: 17, iters: 77632, time: 0.005) nll: 0.485495 \n",
      "(GPU: 0, epoch: 17, iters: 78432, time: 0.004) nll: 0.703226 \n",
      "(GPU: 0, epoch: 17, iters: 79232, time: 0.005) nll: 0.624093 \n",
      "(GPU: 0, epoch: 17, iters: 80032, time: 0.004) nll: 0.657146 \n",
      "(GPU: 0, epoch: 17, iters: 80832, time: 0.005) nll: 0.819964 \n",
      "(GPU: 0, epoch: 17, iters: 81632, time: 0.004) nll: 0.666123 \n",
      "(GPU: 0, epoch: 17, iters: 82432, time: 0.005) nll: 0.736836 \n",
      "(GPU: 0, epoch: 17, iters: 83232, time: 0.005) nll: 0.696489 \n",
      "(GPU: 0, epoch: 17, iters: 84032, time: 0.005) nll: 0.859364 \n",
      "(GPU: 0, epoch: 17, iters: 84832, time: 0.004) nll: 0.802218 \n",
      "(GPU: 0, epoch: 17, iters: 85632, time: 0.005) nll: 0.732669 \n",
      "(GPU: 0, epoch: 17, iters: 86432, time: 0.004) nll: 0.826926 \n",
      "(GPU: 0, epoch: 17, iters: 87232, time: 0.005) nll: 0.675271 \n",
      "(GPU: 0, epoch: 17, iters: 88032, time: 0.004) nll: 0.793127 \n",
      "saving the latest model (epoch 17, total_steps 2480000)\n",
      "(GPU: 0, epoch: 17, iters: 88832, time: 0.005) nll: 0.674226 \n",
      "(GPU: 0, epoch: 17, iters: 89632, time: 0.005) nll: 0.674642 \n",
      "(GPU: 0, epoch: 17, iters: 90432, time: 0.005) nll: 0.997631 \n",
      "(GPU: 0, epoch: 17, iters: 91232, time: 0.005) nll: 0.591925 \n",
      "(GPU: 0, epoch: 17, iters: 92032, time: 0.005) nll: 0.725827 \n",
      "(GPU: 0, epoch: 17, iters: 92832, time: 0.005) nll: 0.659636 \n",
      "(GPU: 0, epoch: 17, iters: 93632, time: 0.005) nll: 0.653148 \n",
      "(GPU: 0, epoch: 17, iters: 94432, time: 0.005) nll: 0.842976 \n",
      "(GPU: 0, epoch: 17, iters: 95232, time: 0.005) nll: 0.740994 \n",
      "(GPU: 0, epoch: 17, iters: 96032, time: 0.005) nll: 0.798813 \n",
      "(GPU: 0, epoch: 17, iters: 96832, time: 0.005) nll: 0.686671 \n",
      "(GPU: 0, epoch: 17, iters: 97632, time: 0.004) nll: 0.796565 \n",
      "(GPU: 0, epoch: 17, iters: 98432, time: 0.005) nll: 0.646969 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:50<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 17, iters: 99232, time: 0.004) nll: 0.705141 \n",
      "(GPU: 0, epoch: 17, iters: 100032, time: 0.005) nll: 0.614347 \n",
      "(GPU: 0, epoch: 17, iters: 100832, time: 0.004) nll: 0.905577 \n",
      "(GPU: 0, epoch: 17, iters: 101632, time: 0.005) nll: 0.533867 \n",
      "(GPU: 0, epoch: 17, iters: 102432, time: 0.005) nll: 0.763865 \n",
      "(GPU: 0, epoch: 17, iters: 103232, time: 0.005) nll: 0.784013 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.004) nll: 0.591914 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.007) nll: 0.587332 \n",
      "(GPU: 0, epoch: 17, iters: 104032, time: 0.007) nll: 0.769969 \n",
      "(GPU: 0, epoch: 17, iters: 104832, time: 0.005) nll: 0.577230 \n",
      "(GPU: 0, epoch: 17, iters: 105632, time: 0.005) nll: 0.637570 \n",
      "(GPU: 0, epoch: 17, iters: 106432, time: 0.005) nll: 0.702606 \n",
      "(GPU: 0, epoch: 17, iters: 107232, time: 0.004) nll: 0.787926 \n",
      "(GPU: 0, epoch: 17, iters: 108032, time: 0.005) nll: 0.796121 \n",
      "saving the latest model (epoch 17, total_steps 2500000)\n",
      "(GPU: 0, epoch: 17, iters: 108832, time: 0.005) nll: 0.722211 \n",
      "(GPU: 0, epoch: 17, iters: 109632, time: 0.005) nll: 0.647839 \n",
      "(GPU: 0, epoch: 17, iters: 110432, time: 0.005) nll: 0.441589 \n",
      "(GPU: 0, epoch: 17, iters: 111232, time: 0.005) nll: 0.901956 \n",
      "(GPU: 0, epoch: 17, iters: 112032, time: 0.005) nll: 0.736221 \n",
      "(GPU: 0, epoch: 17, iters: 112832, time: 0.005) nll: 0.884582 \n",
      "(GPU: 0, epoch: 17, iters: 113632, time: 0.005) nll: 0.882637 \n",
      "(GPU: 0, epoch: 17, iters: 114432, time: 0.005) nll: 0.570508 \n",
      "(GPU: 0, epoch: 17, iters: 115232, time: 0.005) nll: 0.646242 \n",
      "(GPU: 0, epoch: 17, iters: 116032, time: 0.005) nll: 0.710550 \n",
      "(GPU: 0, epoch: 17, iters: 116832, time: 0.004) nll: 0.688037 \n",
      "(GPU: 0, epoch: 17, iters: 117632, time: 0.005) nll: 0.777592 \n",
      "(GPU: 0, epoch: 17, iters: 118432, time: 0.005) nll: 0.496097 \n",
      "(GPU: 0, epoch: 17, iters: 119232, time: 0.005) nll: 0.730998 \n",
      "(GPU: 0, epoch: 17, iters: 120032, time: 0.004) nll: 0.671988 \n",
      "(GPU: 0, epoch: 17, iters: 120832, time: 0.005) nll: 0.705312 \n",
      "(GPU: 0, epoch: 17, iters: 121632, time: 0.004) nll: 0.816151 \n",
      "(GPU: 0, epoch: 17, iters: 122432, time: 0.005) nll: 0.673687 \n",
      "(GPU: 0, epoch: 17, iters: 123232, time: 0.004) nll: 0.828081 \n",
      "(GPU: 0, epoch: 17, iters: 124032, time: 0.005) nll: 0.734971 \n",
      "(GPU: 0, epoch: 17, iters: 124832, time: 0.004) nll: 0.667328 \n",
      "(GPU: 0, epoch: 17, iters: 125632, time: 0.005) nll: 0.823712 \n",
      "(GPU: 0, epoch: 17, iters: 126432, time: 0.004) nll: 0.602360 \n",
      "(GPU: 0, epoch: 17, iters: 127232, time: 0.005) nll: 0.806028 \n",
      "(GPU: 0, epoch: 17, iters: 128032, time: 0.005) nll: 0.706447 \n",
      "saving the latest model (epoch 17, total_steps 2520000)\n",
      "(GPU: 0, epoch: 17, iters: 128832, time: 0.005) nll: 0.735079 \n",
      "(GPU: 0, epoch: 17, iters: 129632, time: 0.005) nll: 0.829151 \n",
      "(GPU: 0, epoch: 17, iters: 130432, time: 0.005) nll: 0.700583 \n",
      "(GPU: 0, epoch: 17, iters: 131232, time: 0.005) nll: 0.691845 \n",
      "(GPU: 0, epoch: 17, iters: 132032, time: 0.005) nll: 0.731175 \n",
      "(GPU: 0, epoch: 17, iters: 132832, time: 0.004) nll: 0.657665 \n",
      "(GPU: 0, epoch: 17, iters: 133632, time: 0.005) nll: 0.743030 \n",
      "(GPU: 0, epoch: 17, iters: 134432, time: 0.005) nll: 0.645206 \n",
      "(GPU: 0, epoch: 17, iters: 135232, time: 0.005) nll: 0.710180 \n",
      "(GPU: 0, epoch: 17, iters: 136032, time: 0.004) nll: 0.826146 \n",
      "(GPU: 0, epoch: 17, iters: 136832, time: 0.005) nll: 0.698156 \n",
      "(GPU: 0, epoch: 17, iters: 137632, time: 0.005) nll: 0.618196 \n",
      "(GPU: 0, epoch: 17, iters: 138432, time: 0.005) nll: 0.737587 \n",
      "(GPU: 0, epoch: 17, iters: 139232, time: 0.004) nll: 0.620273 \n",
      "(GPU: 0, epoch: 17, iters: 140032, time: 0.005) nll: 0.807608 \n",
      "[*] End of epoch 17 / 25 \t Time Taken: 771 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000745\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3078/4397 [09:00<03:32,  6.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 32, time: 0.002) nll: 0.597070 \n",
      "(GPU: 0, epoch: 18, iters: 32, time: 0.002) nll: 0.776110 \n",
      "(GPU: 0, epoch: 18, iters: 128, time: 0.005) nll: 0.855552 \n",
      "(GPU: 0, epoch: 18, iters: 928, time: 0.005) nll: 0.705381 \n",
      "(GPU: 0, epoch: 18, iters: 1728, time: 0.005) nll: 0.583230 \n",
      "(GPU: 0, epoch: 18, iters: 2528, time: 0.005) nll: 0.761929 \n",
      "(GPU: 0, epoch: 18, iters: 3328, time: 0.005) nll: 0.859084 \n",
      "(GPU: 0, epoch: 18, iters: 4128, time: 0.004) nll: 0.570029 \n",
      "(GPU: 0, epoch: 18, iters: 4928, time: 0.005) nll: 0.769253 \n",
      "(GPU: 0, epoch: 18, iters: 5728, time: 0.005) nll: 0.850945 \n",
      "(GPU: 0, epoch: 18, iters: 6528, time: 0.005) nll: 0.816702 \n",
      "(GPU: 0, epoch: 18, iters: 7328, time: 0.005) nll: 0.932244 \n",
      "saving the latest model (epoch 18, total_steps 2540000)\n",
      "(GPU: 0, epoch: 18, iters: 8128, time: 0.005) nll: 0.476573 \n",
      "(GPU: 0, epoch: 18, iters: 8928, time: 0.004) nll: 0.640406 \n",
      "(GPU: 0, epoch: 18, iters: 9728, time: 0.005) nll: 0.847738 \n",
      "(GPU: 0, epoch: 18, iters: 10528, time: 0.004) nll: 0.592337 \n",
      "(GPU: 0, epoch: 18, iters: 11328, time: 0.005) nll: 0.694371 \n",
      "(GPU: 0, epoch: 18, iters: 12128, time: 0.004) nll: 0.830277 \n",
      "(GPU: 0, epoch: 18, iters: 12928, time: 0.005) nll: 0.638892 \n",
      "(GPU: 0, epoch: 18, iters: 13728, time: 0.005) nll: 0.948170 \n",
      "(GPU: 0, epoch: 18, iters: 14528, time: 0.005) nll: 0.642231 \n",
      "(GPU: 0, epoch: 18, iters: 15328, time: 0.005) nll: 0.887724 \n",
      "(GPU: 0, epoch: 18, iters: 16128, time: 0.005) nll: 0.712435 \n",
      "(GPU: 0, epoch: 18, iters: 16928, time: 0.005) nll: 0.812029 \n",
      "(GPU: 0, epoch: 18, iters: 17728, time: 0.005) nll: 0.472032 \n",
      "(GPU: 0, epoch: 18, iters: 18528, time: 0.004) nll: 0.633948 \n",
      "(GPU: 0, epoch: 18, iters: 19328, time: 0.005) nll: 0.869511 \n",
      "(GPU: 0, epoch: 18, iters: 20128, time: 0.005) nll: 0.642976 \n",
      "(GPU: 0, epoch: 18, iters: 20928, time: 0.005) nll: 0.863107 \n",
      "(GPU: 0, epoch: 18, iters: 21728, time: 0.004) nll: 0.653102 \n",
      "(GPU: 0, epoch: 18, iters: 22528, time: 0.005) nll: 0.848368 \n",
      "(GPU: 0, epoch: 18, iters: 23328, time: 0.004) nll: 0.598051 \n",
      "(GPU: 0, epoch: 18, iters: 24128, time: 0.005) nll: 0.797220 \n",
      "(GPU: 0, epoch: 18, iters: 24928, time: 0.005) nll: 0.541494 \n",
      "(GPU: 0, epoch: 18, iters: 25728, time: 0.005) nll: 0.861473 \n",
      "(GPU: 0, epoch: 18, iters: 26528, time: 0.005) nll: 0.591236 \n",
      "(GPU: 0, epoch: 18, iters: 27328, time: 0.005) nll: 0.867511 \n",
      "saving the latest model (epoch 18, total_steps 2560000)\n",
      "(GPU: 0, epoch: 18, iters: 28128, time: 0.005) nll: 0.862275 \n",
      "(GPU: 0, epoch: 18, iters: 28928, time: 0.005) nll: 0.683537 \n",
      "(GPU: 0, epoch: 18, iters: 29728, time: 0.004) nll: 0.665073 \n",
      "(GPU: 0, epoch: 18, iters: 30528, time: 0.005) nll: 0.642144 \n",
      "(GPU: 0, epoch: 18, iters: 31328, time: 0.004) nll: 0.762417 \n",
      "(GPU: 0, epoch: 18, iters: 32128, time: 0.005) nll: 0.688757 \n",
      "(GPU: 0, epoch: 18, iters: 32928, time: 0.004) nll: 0.795310 \n",
      "(GPU: 0, epoch: 18, iters: 33728, time: 0.005) nll: 0.664346 \n",
      "(GPU: 0, epoch: 18, iters: 34528, time: 0.004) nll: 0.713307 \n",
      "(GPU: 0, epoch: 18, iters: 35328, time: 0.005) nll: 0.731010 \n",
      "(GPU: 0, epoch: 18, iters: 36128, time: 0.004) nll: 0.634198 \n",
      "(GPU: 0, epoch: 18, iters: 36928, time: 0.005) nll: 0.631299 \n",
      "(GPU: 0, epoch: 18, iters: 37728, time: 0.005) nll: 0.789140 \n",
      "(GPU: 0, epoch: 18, iters: 38528, time: 0.005) nll: 0.848271 \n",
      "(GPU: 0, epoch: 18, iters: 39328, time: 0.004) nll: 0.722950 \n",
      "(GPU: 0, epoch: 18, iters: 40128, time: 0.005) nll: 0.695104 \n",
      "(GPU: 0, epoch: 18, iters: 40928, time: 0.004) nll: 0.706134 \n",
      "(GPU: 0, epoch: 18, iters: 41728, time: 0.005) nll: 0.574478 \n",
      "(GPU: 0, epoch: 18, iters: 42528, time: 0.004) nll: 0.539443 \n",
      "(GPU: 0, epoch: 18, iters: 43328, time: 0.005) nll: 0.649225 \n",
      "(GPU: 0, epoch: 18, iters: 44128, time: 0.004) nll: 0.679285 \n",
      "(GPU: 0, epoch: 18, iters: 44928, time: 0.005) nll: 0.678927 \n",
      "(GPU: 0, epoch: 18, iters: 45728, time: 0.004) nll: 0.585865 \n",
      "(GPU: 0, epoch: 18, iters: 46528, time: 0.005) nll: 0.826375 \n",
      "(GPU: 0, epoch: 18, iters: 47328, time: 0.004) nll: 0.873849 \n",
      "saving the latest model (epoch 18, total_steps 2580000)\n",
      "(GPU: 0, epoch: 18, iters: 48128, time: 0.005) nll: 0.777803 \n",
      "(GPU: 0, epoch: 18, iters: 48928, time: 0.004) nll: 0.755416 \n",
      "(GPU: 0, epoch: 18, iters: 49728, time: 0.005) nll: 0.715038 \n",
      "(GPU: 0, epoch: 18, iters: 50528, time: 0.004) nll: 0.636989 \n",
      "(GPU: 0, epoch: 18, iters: 51328, time: 0.005) nll: 0.828809 \n",
      "(GPU: 0, epoch: 18, iters: 52128, time: 0.005) nll: 0.895987 \n",
      "(GPU: 0, epoch: 18, iters: 52928, time: 0.005) nll: 0.706111 \n",
      "(GPU: 0, epoch: 18, iters: 53728, time: 0.004) nll: 0.897248 \n",
      "(GPU: 0, epoch: 18, iters: 54528, time: 0.005) nll: 0.684316 \n",
      "(GPU: 0, epoch: 18, iters: 55328, time: 0.004) nll: 0.724689 \n",
      "(GPU: 0, epoch: 18, iters: 56128, time: 0.005) nll: 0.776238 \n",
      "(GPU: 0, epoch: 18, iters: 56928, time: 0.005) nll: 0.886516 \n",
      "(GPU: 0, epoch: 18, iters: 57728, time: 0.005) nll: 0.912053 \n",
      "(GPU: 0, epoch: 18, iters: 58528, time: 0.005) nll: 0.683405 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.005) nll: 0.753954 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.008) nll: 0.744898 \n",
      "(GPU: 0, epoch: 18, iters: 59328, time: 0.008) nll: 0.694124 \n",
      "(GPU: 0, epoch: 18, iters: 60128, time: 0.004) nll: 0.749886 \n",
      "(GPU: 0, epoch: 18, iters: 60928, time: 0.005) nll: 0.755183 \n",
      "(GPU: 0, epoch: 18, iters: 61728, time: 0.005) nll: 0.829661 \n",
      "(GPU: 0, epoch: 18, iters: 62528, time: 0.005) nll: 0.718396 \n",
      "(GPU: 0, epoch: 18, iters: 63328, time: 0.005) nll: 0.768024 \n",
      "(GPU: 0, epoch: 18, iters: 64128, time: 0.005) nll: 0.859267 \n",
      "(GPU: 0, epoch: 18, iters: 64928, time: 0.004) nll: 0.700075 \n",
      "(GPU: 0, epoch: 18, iters: 65728, time: 0.005) nll: 0.591992 \n",
      "(GPU: 0, epoch: 18, iters: 66528, time: 0.004) nll: 0.744435 \n",
      "(GPU: 0, epoch: 18, iters: 67328, time: 0.005) nll: 0.678960 \n",
      "saving the latest model (epoch 18, total_steps 2600000)\n",
      "(GPU: 0, epoch: 18, iters: 68128, time: 0.005) nll: 0.851587 \n",
      "(GPU: 0, epoch: 18, iters: 68928, time: 0.005) nll: 0.609451 \n",
      "(GPU: 0, epoch: 18, iters: 69728, time: 0.004) nll: 0.727216 \n",
      "(GPU: 0, epoch: 18, iters: 70528, time: 0.005) nll: 0.574990 \n",
      "(GPU: 0, epoch: 18, iters: 71328, time: 0.005) nll: 0.725927 \n",
      "(GPU: 0, epoch: 18, iters: 72128, time: 0.005) nll: 0.582397 \n",
      "(GPU: 0, epoch: 18, iters: 72928, time: 0.005) nll: 0.710563 \n",
      "(GPU: 0, epoch: 18, iters: 73728, time: 0.005) nll: 0.633722 \n",
      "(GPU: 0, epoch: 18, iters: 74528, time: 0.004) nll: 0.756697 \n",
      "(GPU: 0, epoch: 18, iters: 75328, time: 0.005) nll: 0.710429 \n",
      "(GPU: 0, epoch: 18, iters: 76128, time: 0.004) nll: 0.592678 \n",
      "(GPU: 0, epoch: 18, iters: 76928, time: 0.005) nll: 0.621196 \n",
      "(GPU: 0, epoch: 18, iters: 77728, time: 0.004) nll: 0.717609 \n",
      "(GPU: 0, epoch: 18, iters: 78528, time: 0.005) nll: 0.732620 \n",
      "(GPU: 0, epoch: 18, iters: 79328, time: 0.004) nll: 0.629725 \n",
      "(GPU: 0, epoch: 18, iters: 80128, time: 0.005) nll: 0.638172 \n",
      "(GPU: 0, epoch: 18, iters: 80928, time: 0.005) nll: 0.629554 \n",
      "(GPU: 0, epoch: 18, iters: 81728, time: 0.005) nll: 0.578248 \n",
      "(GPU: 0, epoch: 18, iters: 82528, time: 0.004) nll: 0.837678 \n",
      "(GPU: 0, epoch: 18, iters: 83328, time: 0.005) nll: 0.722719 \n",
      "(GPU: 0, epoch: 18, iters: 84128, time: 0.004) nll: 0.529362 \n",
      "(GPU: 0, epoch: 18, iters: 84928, time: 0.005) nll: 0.843608 \n",
      "(GPU: 0, epoch: 18, iters: 85728, time: 0.004) nll: 0.828691 \n",
      "(GPU: 0, epoch: 18, iters: 86528, time: 0.005) nll: 0.779821 \n",
      "(GPU: 0, epoch: 18, iters: 87328, time: 0.004) nll: 0.786787 \n",
      "saving the latest model (epoch 18, total_steps 2620000)\n",
      "(GPU: 0, epoch: 18, iters: 88128, time: 0.005) nll: 0.904195 \n",
      "(GPU: 0, epoch: 18, iters: 88928, time: 0.004) nll: 0.611014 \n",
      "(GPU: 0, epoch: 18, iters: 89728, time: 0.005) nll: 0.807433 \n",
      "(GPU: 0, epoch: 18, iters: 90528, time: 0.005) nll: 0.682773 \n",
      "(GPU: 0, epoch: 18, iters: 91328, time: 0.005) nll: 0.733844 \n",
      "(GPU: 0, epoch: 18, iters: 92128, time: 0.004) nll: 0.664268 \n",
      "(GPU: 0, epoch: 18, iters: 92928, time: 0.005) nll: 0.651099 \n",
      "(GPU: 0, epoch: 18, iters: 93728, time: 0.004) nll: 0.692410 \n",
      "(GPU: 0, epoch: 18, iters: 94528, time: 0.005) nll: 0.791192 \n",
      "(GPU: 0, epoch: 18, iters: 95328, time: 0.004) nll: 0.739898 \n",
      "(GPU: 0, epoch: 18, iters: 96128, time: 0.005) nll: 0.692871 \n",
      "(GPU: 0, epoch: 18, iters: 96928, time: 0.004) nll: 0.704501 \n",
      "(GPU: 0, epoch: 18, iters: 97728, time: 0.005) nll: 0.474732 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4397/4397 [12:51<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 18, iters: 98528, time: 0.005) nll: 0.962926 \n",
      "(GPU: 0, epoch: 18, iters: 99328, time: 0.005) nll: 0.651516 \n",
      "(GPU: 0, epoch: 18, iters: 100128, time: 0.004) nll: 0.971023 \n",
      "(GPU: 0, epoch: 18, iters: 100928, time: 0.005) nll: 0.798320 \n",
      "(GPU: 0, epoch: 18, iters: 101728, time: 0.004) nll: 0.585799 \n",
      "(GPU: 0, epoch: 18, iters: 102528, time: 0.005) nll: 0.781652 \n",
      "(GPU: 0, epoch: 18, iters: 103328, time: 0.005) nll: 0.661487 \n",
      "(GPU: 0, epoch: 18, iters: 104128, time: 0.005) nll: 0.752263 \n",
      "(GPU: 0, epoch: 18, iters: 104928, time: 0.004) nll: 0.674165 \n",
      "(GPU: 0, epoch: 18, iters: 105728, time: 0.005) nll: 0.803248 \n",
      "(GPU: 0, epoch: 18, iters: 106528, time: 0.004) nll: 1.005908 \n",
      "(GPU: 0, epoch: 18, iters: 107328, time: 0.005) nll: 0.759646 \n",
      "saving the latest model (epoch 18, total_steps 2640000)\n",
      "(GPU: 0, epoch: 18, iters: 108128, time: 0.005) nll: 0.743237 \n",
      "(GPU: 0, epoch: 18, iters: 108928, time: 0.005) nll: 0.605244 \n",
      "(GPU: 0, epoch: 18, iters: 109728, time: 0.005) nll: 0.690460 \n",
      "(GPU: 0, epoch: 18, iters: 110528, time: 0.005) nll: 0.868538 \n",
      "(GPU: 0, epoch: 18, iters: 111328, time: 0.004) nll: 0.589107 \n",
      "(GPU: 0, epoch: 18, iters: 112128, time: 0.005) nll: 0.885272 \n",
      "(GPU: 0, epoch: 18, iters: 112928, time: 0.004) nll: 0.577126 \n",
      "(GPU: 0, epoch: 18, iters: 113728, time: 0.005) nll: 0.947489 \n",
      "(GPU: 0, epoch: 18, iters: 114528, time: 0.005) nll: 0.769892 \n",
      "(GPU: 0, epoch: 18, iters: 115328, time: 0.005) nll: 0.780640 \n",
      "(GPU: 0, epoch: 18, iters: 116128, time: 0.004) nll: 0.584299 \n",
      "(GPU: 0, epoch: 18, iters: 116928, time: 0.005) nll: 0.718924 \n",
      "(GPU: 0, epoch: 18, iters: 117728, time: 0.005) nll: 0.672967 \n",
      "(GPU: 0, epoch: 18, iters: 118528, time: 0.005) nll: 1.027854 \n",
      "(GPU: 0, epoch: 18, iters: 119328, time: 0.005) nll: 0.706037 \n",
      "(GPU: 0, epoch: 18, iters: 120128, time: 0.005) nll: 0.588344 \n",
      "(GPU: 0, epoch: 18, iters: 120928, time: 0.004) nll: 0.696229 \n",
      "(GPU: 0, epoch: 18, iters: 121728, time: 0.005) nll: 0.933584 \n",
      "(GPU: 0, epoch: 18, iters: 122528, time: 0.004) nll: 0.703808 \n",
      "(GPU: 0, epoch: 18, iters: 123328, time: 0.005) nll: 0.859557 \n",
      "(GPU: 0, epoch: 18, iters: 124128, time: 0.004) nll: 0.779603 \n",
      "(GPU: 0, epoch: 18, iters: 124928, time: 0.005) nll: 0.623607 \n",
      "(GPU: 0, epoch: 18, iters: 125728, time: 0.005) nll: 0.923772 \n",
      "(GPU: 0, epoch: 18, iters: 126528, time: 0.005) nll: 0.804662 \n",
      "(GPU: 0, epoch: 18, iters: 127328, time: 0.005) nll: 0.657331 \n",
      "saving the latest model (epoch 18, total_steps 2660000)\n",
      "(GPU: 0, epoch: 18, iters: 128128, time: 0.005) nll: 0.613836 \n",
      "(GPU: 0, epoch: 18, iters: 128928, time: 0.004) nll: 0.522504 \n",
      "(GPU: 0, epoch: 18, iters: 129728, time: 0.005) nll: 0.656817 \n",
      "(GPU: 0, epoch: 18, iters: 130528, time: 0.004) nll: 0.760530 \n",
      "(GPU: 0, epoch: 18, iters: 131328, time: 0.005) nll: 0.903798 \n",
      "(GPU: 0, epoch: 18, iters: 132128, time: 0.004) nll: 0.736843 \n",
      "(GPU: 0, epoch: 18, iters: 132928, time: 0.005) nll: 0.734664 \n",
      "(GPU: 0, epoch: 18, iters: 133728, time: 0.004) nll: 0.623763 \n",
      "(GPU: 0, epoch: 18, iters: 134528, time: 0.005) nll: 0.573524 \n",
      "(GPU: 0, epoch: 18, iters: 135328, time: 0.004) nll: 0.857494 \n",
      "(GPU: 0, epoch: 18, iters: 136128, time: 0.005) nll: 0.735227 \n",
      "(GPU: 0, epoch: 18, iters: 136928, time: 0.004) nll: 0.685490 \n",
      "(GPU: 0, epoch: 18, iters: 137728, time: 0.005) nll: 0.678618 \n",
      "(GPU: 0, epoch: 18, iters: 138528, time: 0.005) nll: 0.984989 \n",
      "(GPU: 0, epoch: 18, iters: 139328, time: 0.005) nll: 0.864389 \n",
      "(GPU: 0, epoch: 18, iters: 140128, time: 0.004) nll: 0.722145 \n",
      "saving the model at the end of epoch 18, iters 2673376\n",
      "([test] GPU: 0, epoch: 18) \n",
      "OrderedDict()\n",
      "[*] End of epoch 18 / 25 \t Time Taken: 791 sec \n",
      "/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/logs/bert2vqsc_v4-text2shape-seq-LR1e-4-july-9-network-normalized-input-to-bert-concat-cross-entropy-FINAL-FINAL\n",
      "[*] learning rate = 0.0000725\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 347/4397 [01:05<12:47,  5.28it/s]  \n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 159, in <module>\n",
      "    train_one_epoch()\n",
      "  File \"train.py\", line 96, in train_one_epoch\n",
      "    model.set_input(data)\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/bert2vq_scmodel_v4.py\", line 88, in set_input\n",
      "    self.tocuda(var_names=vars_list)\n",
      "  File \"/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/base_model.py\", line 220, in tocuda\n",
      "    setattr(self, name, var.cuda(self.gpu_ids[0], non_blocking=True))\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(GPU: 0, epoch: 19, iters: 32, time: 0.002) nll: 0.689385 \n",
      "(GPU: 0, epoch: 19, iters: 32, time: 0.002) nll: 0.874042 \n",
      "(GPU: 0, epoch: 19, iters: 224, time: 0.004) nll: 0.553480 \n",
      "(GPU: 0, epoch: 19, iters: 1024, time: 0.005) nll: 0.637776 \n",
      "(GPU: 0, epoch: 19, iters: 1824, time: 0.004) nll: 0.649804 \n",
      "(GPU: 0, epoch: 19, iters: 2624, time: 0.005) nll: 0.836769 \n",
      "(GPU: 0, epoch: 19, iters: 3424, time: 0.005) nll: 0.680421 \n",
      "(GPU: 0, epoch: 19, iters: 4224, time: 0.005) nll: 0.864751 \n",
      "(GPU: 0, epoch: 19, iters: 5024, time: 0.004) nll: 0.687586 \n",
      "(GPU: 0, epoch: 19, iters: 5824, time: 0.005) nll: 0.643590 \n",
      "(GPU: 0, epoch: 19, iters: 6624, time: 0.004) nll: 0.539385 \n",
      "saving the latest model (epoch 19, total_steps 2680000)\n",
      "(GPU: 0, epoch: 19, iters: 7424, time: 0.005) nll: 0.859586 \n",
      "(GPU: 0, epoch: 19, iters: 8224, time: 0.005) nll: 0.806350 \n",
      "(GPU: 0, epoch: 19, iters: 9024, time: 0.005) nll: 0.853433 \n",
      "(GPU: 0, epoch: 19, iters: 9824, time: 0.005) nll: 0.864762 \n",
      "(GPU: 0, epoch: 19, iters: 10624, time: 0.005) nll: 0.632094 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4173657/1349841514.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./launchers/train_rand_tf_snet_code.sh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1804\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1805\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1806\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1807\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1762\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_rand_tf_snet_code.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf46647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
