{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image as ipy_image\n",
    "from IPython.display import display\n",
    "\n",
    "#from utils.demo_util import get_shape_comp_model, get_shape_comp_opt, make_dummy_batch\n",
    "#from utils.qual_util import load_bert2vqsc_model, get_lang_prob, save_mesh_as_gif\n",
    "from utils.qual_util import get_lang_prob, save_mesh_as_gif\n",
    "from utils.util import seed_everything\n",
    "from utils.util_3d import init_mesh_renderer, sdf_to_mesh\n",
    "import os\n",
    "from termcolor import colored, cprint\n",
    "import torch\n",
    "import utils.util as util\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datasets.ys_shapeset import  ShapeNetZSets\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(111)\n",
    "\n",
    "description = \"Loading new bert mode no probs passed\"\n",
    "res_dir = 'logs/comparison/v14'\n",
    "if not os.path.exists(res_dir): os.makedirs(res_dir)\n",
    "\n",
    "with open(f\"{res_dir}/description.txt\",\"w\") as f:\n",
    "    f.write(description)\n",
    "\n",
    "gpu_id = 0\n",
    "nimgs=6\n",
    "\n",
    "class Opt:\n",
    "    def __init__(self):\n",
    "        self.name = 'opt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bert2vqsc_model(opt):\n",
    "    from models.networks.bert2vq_sc import BERT2VQ\n",
    "    \n",
    "    net = BERT2VQ(opt)\n",
    "    # bert2vq_ckpt = '/home/paritosh/Desktop/Capstone/clean-code/generative_transformers/logs/bert2vq-shapenet_lang-all-LR1e-4-cleanCode-langMode-/ckpt/bert2vq_epoch-145.pth'\n",
    "    bert2vq_ckpt = '../raw_dataset/checkpoints_new/bert2vq_epoch-latest.pth'\n",
    "    state_dict = torch.load(bert2vq_ckpt)\n",
    "    net.load_state_dict(state_dict['bert2vq'])\n",
    "    net.eval()\n",
    "    net.to(opt.device)\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeset = ShapeNetZSets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 8, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y  = shapeset[4][\"z_set\"]\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(opt):\n",
    "    model = None\n",
    "\n",
    "    if opt.model == 'pvqvae':\n",
    "        # vqvae\n",
    "        from models.pvqvae_model import PVQVAEModel\n",
    "        model = PVQVAEModel()\n",
    "    elif opt.model == 'rand_tf':\n",
    "        # transformer\n",
    "        from models.rand_tf_model import RandTransformerModel\n",
    "        model = RandTransformerModel()\n",
    "    elif opt.model == 'rand_tf_old':\n",
    "        from models.rand_tf_model_old import RandTransformerModelOld\n",
    "        model = RandTransformerModelOld()\n",
    "    elif opt.model == 'seq_tf':\n",
    "        # seq-transformer\n",
    "        from models.seq_tf_model import SeqTransformerModel\n",
    "        model = SeqTransformerModel()\n",
    "    elif opt.model == 'bert2vq':\n",
    "        from models.bert2vq_model import BERT2VQModel\n",
    "        model = BERT2VQModel()\n",
    "    elif opt.model == \"bert2vqsc\":\n",
    "        from models.bert2vq_scmodel import BERT2VQSCModel\n",
    "        model = BERT2VQSCModel()\n",
    "    elif opt.model == 'resnet2vq':\n",
    "        from models.resnet2vq_model import ResNet2VQModel\n",
    "        model = ResNet2VQModel()\n",
    "    elif opt.model == 'resnet2vox':\n",
    "        from models.resnet2vox_model import ResNet2VoxModel\n",
    "        model = ResNet2VoxModel()\n",
    "    elif opt.model == 'resnet2sdf':\n",
    "        from models.resnet2sdf_model import ResNet2SDFModel\n",
    "        model = ResNet2SDFModel()\n",
    "    elif opt.model == 'baseline_je':\n",
    "        from models.baseline_je_model import LangJEModel\n",
    "        model = LangJEModel()\n",
    "    elif opt.model == 'img_je':\n",
    "        from models.img_je_model import ImgJEModel\n",
    "        model = ImgJEModel()\n",
    "    else:\n",
    "        raise ValueError(\"Model [%s] not recognized.\" % opt.model)\n",
    "\n",
    "    model.initialize(opt)\n",
    "    cprint(\"[*] Model has been created: %s\" % model.name(), 'blue')\n",
    "    if(opt.ckpt is not None):\n",
    "        model.load_ckpt(opt.ckpt)\n",
    "        print(\"MODEL LOADED\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape_comp_opt(gpu_id=0):\n",
    "    opt = Opt()\n",
    "\n",
    "    # args\n",
    "    gpuid=[gpu_id]\n",
    "    batch_size=1\n",
    "    max_dataset_size=10000000\n",
    "\n",
    "    name='test_transformer'\n",
    "\n",
    "    # default args\n",
    "    opt.serial_batches = False\n",
    "    opt.nThreads = 4\n",
    "\n",
    "    # important args\n",
    "    opt.dataset_mode = 'shapenet_code'\n",
    "    opt.seed = 111\n",
    "    opt.isTrain = False\n",
    "    opt.gpu_ids = gpuid\n",
    "    opt.device = 'cuda:%s' % gpuid[0]\n",
    "    opt.batch_size = batch_size\n",
    "    opt.max_dataset_size = max_dataset_size\n",
    "\n",
    "    opt.name = name\n",
    "\n",
    "    #utils.util.seed_everything(opt.seed)\n",
    "    opt.phase = 'test'\n",
    "    return opt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_shape_comp_model(opt, model, ckpt):\n",
    "    \n",
    "    # load tf stuff\n",
    "    opt.model=model\n",
    "    opt.tf_cfg='configs/rand_tf_snet_code.yaml'\n",
    "    opt.ckpt = ckpt\n",
    "    \n",
    "    # load vq stuff\n",
    "    opt.vq_model='pvqvae'\n",
    "    opt.vq_cfg='configs/pvqvae_snet.yaml'\n",
    "    opt.vq_ckpt='../raw_dataset/checkpoints/vqvae.pth'\n",
    "    \n",
    "    ### opt.vq_dset='sdf_code' # original\n",
    "    opt.vq_dset='snet'\n",
    "\n",
    "    model = create_model(opt)\n",
    "    print(f'[*] \"{opt.model}\" initialized.')\n",
    "    model.load_ckpt(opt.ckpt)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Working with z of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "[*] VQVAE: weight successfully load from: ../raw_dataset/checkpoints/vqvae.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Model has been created: Rand-Transformer-Model\n",
      "[*] weight successfully load from: ../raw_dataset/checkpoints/rand_tf_singles_best.pth\n",
      "MODEL LOADED\n",
      "[*] \"rand_tf_old\" initialized.\n",
      "[*] weight successfully load from: ../raw_dataset/checkpoints/rand_tf_singles_best.pth\n",
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Working with z of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "[*] VQVAE: weight successfully load from: ../raw_dataset/checkpoints/vqvae.pth\n",
      "[*] Model has been created: Rand-Transformer-Model\n",
      "[*] weight successfully load from: ../raw_dataset/checkpoints_new/rand_tf_epoch_latest_fusion_transfer_v1.pth\n",
      "MODEL LOADED\n",
      "[*] \"rand_tf\" initialized.\n",
      "[*] weight successfully load from: ../raw_dataset/checkpoints_new/rand_tf_epoch_latest_fusion_transfer_v1.pth\n"
     ]
    }
   ],
   "source": [
    "opt = get_shape_comp_opt(gpu_id=gpu_id)\n",
    "opt.dataset_mode = \"text2shape\"\n",
    "modelOld = get_shape_comp_model(opt,\"rand_tf_old\",\"../raw_dataset/checkpoints/rand_tf_singles_best.pth\")    \n",
    "modelOld.eval()\n",
    "\n",
    "#new_checkpoint_path = \"logs/valid-valid-with-fusion-rand_tf-owndataset-chair-LR1e-4-clean-with-ckpt/ckpt/rand_tf_epoch-latest.pth\"\n",
    "new_checkpoint_path = \"../raw_dataset/checkpoints_new/rand_tf_epoch_latest_fusion_transfer_v1.pth\"\n",
    "modelNew = get_shape_comp_model(opt,\"rand_tf\",new_checkpoint_path) \n",
    "modelNew.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\"\"\" setup renderer \"\"\"\n",
    "dist, elev, azim = 1.7, 20, 20\n",
    "mesh_renderer = init_mesh_renderer(image_size=256, dist=dist, elev=elev, azim=azim, device=opt.device)\n",
    "\n",
    "opt.mlp_layers = 3\n",
    "opt.mlp_hidden = 1024\n",
    "bert2vq = load_bert2vqsc_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test_samples_paper.txt\") as file:\n",
    "    sequences = [line.rstrip() for line in file]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_clean = [0] * len(sequences)\n",
    "for i in range(len(sequences)):\n",
    "    seq = sequences[i]\n",
    "    sequence = seq.split(\",\")\n",
    "    sequences_clean[i] = sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a high bar seat',\n",
       " 'has a molded curved seat',\n",
       " 'has a metal footrest and circular base']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...:  63%|█████████████████████████████████████████████████▉                             | 324/512 [00:02<00:01, 125.69it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3496695/2805065814.py\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mlang_conditional_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang_conditional_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtopk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgen_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"code\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/rand_tf_model_old.py\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, data, seq_len, gen_order, topk, prob, alpha, should_render, verbose)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mtgt_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;31m# inp_mask = self.generate_square_subsequent_mask(transformer_inp.shape[0], self.opt.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0moutp_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0;31m# outp_t = F.softmax(outp_t, dim=-1) # compute prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/networks/transformer_networks/rand_transformer_old.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp, inp_posn, tgt_posn)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/networks/transformer_networks/rand_transformer_old.py\u001b[0m in \u001b[0;36mforward_transformer\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;31m# output = self.decoder(tgt, memory, tgt_mask=tgt_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    350\u001b[0m     def _sa_block(self, x: Tensor,\n\u001b[1;32m    351\u001b[0m                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) -> Tensor:\n\u001b[0;32m--> 352\u001b[0;31m         x = self.self_attn(x, x, x,\n\u001b[0m\u001b[1;32m    353\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = modelOld\n",
    "model_name = \"model_old\"\n",
    "\n",
    "import torch\n",
    "from utils.qual_util import get_lang_prob_recursive, save_mesh_as_pics\n",
    "from einops import rearrange\n",
    "\n",
    "z1 = torch.full((1,8,8,8,512), 1/512).cuda()\n",
    "\n",
    "test_data = { }\n",
    "sampler = torch.distributions.categorical.Categorical(z1)\n",
    "codeix = sampler.sample()\n",
    "test_data[\"code\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "test_data[\"idx\"] = sampler.sample().repeat_interleave(nimgs, axis=0).cpu()\n",
    "test_data[\"z_q\"] = z1\n",
    "\n",
    "\n",
    "for sequence in sequences_clean:\n",
    "    last_text = \"\"\n",
    "    for text in sequence:\n",
    "        all_text = last_text + text\n",
    "        text_conditional = text\n",
    "        lang_conditional_prob = get_lang_prob_recursive(bert2vq, text_conditional, z1)\n",
    "        z1_old = rearrange(z1, 'bs d h w c -> (d h w bs) c')\n",
    "        z1 = rearrange(lang_conditional_prob, '(d h w) bs c -> bs d h w c', d=8, h=8, w=8)\n",
    "        gen_order = torch.argsort((torch.abs(lang_conditional_prob[:, 0, :]-z1_old)).sum(-1), dim=-1, descending=True)\n",
    "        lang_conditional_prob = lang_conditional_prob.repeat(1, nimgs, 1)\n",
    "        topk = 50\n",
    "        model.inference(test_data, topk=topk, prob=None,gen_order=None)\n",
    "        test_data[\"code\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "        sampler = torch.distributions.categorical.Categorical(z1)\n",
    "        test_data[\"idx\"] = torch.cat( [sampler.sample().cpu() for i in range(6)], dim=0)\n",
    "        print(test_data[\"idx\"].shape)\n",
    "        gen_mesh = sdf_to_mesh(model.x_recon_tf)\n",
    "    \n",
    "        gen_gif_name = f'{res_dir}/{model_name}-{all_text}.gif'\n",
    "        #import pdb;pdb.set_trace()\n",
    "        try:\n",
    "            save_mesh_as_pics(mesh_renderer, gen_mesh, nrow=3, out_name=gen_gif_name)\n",
    "        except:\n",
    "            import pdb;pdb.set_trace()\n",
    "        last_text = text_conditional + \" \"\n",
    "        \n",
    "        print(text_conditional)\n",
    "        for name in [gen_gif_name]:\n",
    "            display(ipy_image(name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randperm(512, device='cuda').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afabf11a909a49d295a5e93673cd26c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "number of dims don't match in permute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_956481/824692355.py\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mall_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_text\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtext_conditional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mlang_conditional_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_lang_prob_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert2vq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mz1_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bs d h w c -> (d h w bs) c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_conditional_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(d h w) bs c -> bs d h w c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/utils/qual_util.py\u001b[0m in \u001b[0;36mget_lang_prob_recursive\u001b[0;34m(bert_model, test_data, z1, opt)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_lang_prob_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mlang_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mlang_logprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_logits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute the prob. of next ele\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;31m# img_logprob = torch.sum(img_logprob, dim=1) # multiply the image priors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/plz-autosdf/models/networks/bert2vq_sc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, z1)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbertmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Map to 3D space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: number of dims don't match in permute"
     ]
    }
   ],
   "source": [
    "model = modelNew\n",
    "model_name = \"model_new\"\n",
    "\n",
    "import torch\n",
    "from utils.qual_util import get_lang_prob_recursive, save_mesh_as_pics\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for j in tqdm(range(len(sequences_clean))):\n",
    "    #text = sequence[j]\n",
    "    sequence = sequences_clean[j]\n",
    "    last_text = \"\"\n",
    "    z1 = torch.full((1,8,8,8,512), 1/512).cuda()\n",
    "    test_data = { }\n",
    "    sampler = torch.distributions.categorical.Categorical(z1)\n",
    "    codeix = sampler.sample()\n",
    "    \n",
    "    \n",
    "    #test_data[\"z_set\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "    test_data[\"z_set\"] = shapeset[4][\"z_set\"].unsqueeze(0).repeat_interleave(nimgs, dim=0)\n",
    "   \n",
    "    test_data[\"idx\"] = sampler.sample().repeat_interleave(nimgs, axis=0).cpu()\n",
    "    test_data[\"z_q\"] = z1\n",
    "    print(\"======================================================================================================\")\n",
    "    for i in range(len(sequence)):\n",
    "        text = sequence[i]\n",
    "        all_text = last_text + text\n",
    "        text_conditional = text\n",
    "        lang_conditional_prob = get_lang_prob_recursive(bert2vq, all_text, z1)\n",
    "        z1_old = rearrange(z1, 'bs d h w c -> (d h w bs) c')\n",
    "        z1 = rearrange(lang_conditional_prob, '(d h w) bs c -> bs d h w c', d=8, h=8, w=8)\n",
    "        gen_order = torch.argsort((torch.abs(lang_conditional_prob[:, 0, :]-z1_old)).sum(-1), dim=-1, descending=True)\n",
    "        lang_conditional_prob = lang_conditional_prob.repeat(1, nimgs, 1)\n",
    "        topk = 50\n",
    "        # This should be replaced by bert output\n",
    "        #test_data[\"z_set\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "        model.inference(test_data, topk=topk, prob=None,gen_order=None)\n",
    "        #test_data[\"z_set\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "        sampler = torch.distributions.categorical.Categorical(z1)\n",
    "        test_data[\"idx\"] = torch.cat( [sampler.sample().cpu() for i in range(6)], dim=0)\n",
    "        print(test_data[\"idx\"].shape)\n",
    "        gen_mesh = sdf_to_mesh(model.x_recon_tf)\n",
    "    \n",
    "        gen_gif_name = f'{res_dir}/{j}-{i}-{model_name}-{all_text}.gif'\n",
    "        #import pdb;pdb.set_trace()\n",
    "        try:\n",
    "            save_mesh_as_pics(mesh_renderer, gen_mesh, nrow=3, out_name=gen_gif_name)\n",
    "        except:\n",
    "            import pdb;pdb.set_trace()\n",
    "        last_text = text_conditional + \" \"\n",
    "        \n",
    "        print(\"TEXT:\", text_conditional)\n",
    "        print(\"Full Text:\", all_text)\n",
    "        print(\"Saved:\", gen_gif_name)\n",
    "        for name in [gen_gif_name]:\n",
    "            display(ipy_image(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5838d28a96dbe8fdf9e2c297fc8cad3e28297307de97d2852e60d93cca6675fa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
