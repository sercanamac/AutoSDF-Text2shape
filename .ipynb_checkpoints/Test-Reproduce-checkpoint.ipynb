{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08abafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.sc_snet_code_dataset import ScSnetCodeDataset\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from options.train_options import TrainOptions\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets.ys_shapeset import ShapeNetZSets\n",
    "import subprocess\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0da3edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TrainOptions()\n",
    "opt.phase = 'train'\n",
    "opt.max_dataset_size=10000000\n",
    "\n",
    "dataset = ScSnetCodeDataset()\n",
    "dataset.initialize(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b0885a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ShapeNetZSets(isTrain = True)\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(\n",
    "            ds,\n",
    "            batch_size=24,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9f6a7cf9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7837463b3f74e4492584caea383ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2246875/2253977124.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, data in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
    "        x = 1\n",
    "\n",
    "len(ds)\n",
    "\n",
    "\n",
    "# for i in tqdm(range(len(ds))):\n",
    "#     ds[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d626ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "alpha: 0.75\n",
      "batch_size: 24\n",
      "bert_cfg: configs/bert2vq_shapeglot.yaml\n",
      "cat: chair\n",
      "checkpoints_dir: ./checkpoints\n",
      "ckpt: None\n",
      "continue_train: False\n",
      "dataset_mode: owndataset\n",
      "debug: 0\n",
      "device: cuda\n",
      "display_freq: 3000\n",
      "gpu_ids: [0]\n",
      "gpu_ids_str: 0\n",
      "input_nc: 3\n",
      "iou_thres: 0.0\n",
      "isTrain: True\n",
      "lambda_L1: 10.0\n",
      "logs_dir: logs\n",
      "lr: 0.0001\n",
      "lr_decay_iters: 50\n",
      "lr_policy: lambda\n",
      "max_dataset_size: 10000000\n",
      "model: rand_tf\n",
      "nThreads: 9\n",
      "n_less: 0\n",
      "name: own-dataset-z-sets-to-sampled-set-rand_tf-owndataset-chair-LR1e-4-clean\n",
      "ndf: 64\n",
      "nepochs: 200\n",
      "nepochs_decay: 50\n",
      "ngf: 64\n",
      "output_nc: 3\n",
      "pix3d_mode: noBG\n",
      "print_freq: 25\n",
      "profiler: 0\n",
      "ratio: 1.0\n",
      "resnet2vq_ckpt: None\n",
      "resnet_arch: resnet18\n",
      "resnet_cfg: configs/resnet2vq_pix3d.yaml\n",
      "resnet_ckpt: None\n",
      "resnet_dset: None\n",
      "resnet_model: None\n",
      "resnet_norm: gn\n",
      "save_epoch_freq: 3\n",
      "save_latest_freq: 5000\n",
      "seed: 111\n",
      "serial_batches: False\n",
      "snet_mode: noBG\n",
      "tf_cfg: configs/rand_tf_snet_code.yaml\n",
      "topk: 30\n",
      "trunc_thres: 0.2\n",
      "use_bin_sdf: 0\n",
      "use_marginal: 0\n",
      "vq_cat: chair\n",
      "vq_cfg: configs/pvqvae_snet.yaml\n",
      "vq_ckpt: ../raw_dataset/checkpoints/vqvae.pth\n",
      "vq_dset: snet\n",
      "vq_model: pvqvae\n",
      "vq_note: default\n",
      "which_epoch: latest\n",
      "-------------- End ----------------\n",
      "[*] Dataset has been created: OwnDataset\n",
      "[*] # training images = 45000\n",
      "[*] # testing images = 3173\n",
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Working with z of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "[*] VQVAE: weight successfully load from: ../raw_dataset/checkpoints/vqvae.pth\n",
      "---------- Networks initialized -------------\n",
      "-----------------------------------------------\n",
      "[*] Model has been created: Rand-Transformer-Model\n",
      "[*] \"rand_tf\" initialized.\n",
      "[*] create image directory:\n",
      "/cluster/54/streakfull/ADL4CV/Project/src/AutoSDF-Text2shape/logs/own-dataset-z-sets-to-sampled-set-rand_tf-owndataset-chair-LR1e-4-clean/images...\n",
      "[*] saving model and dataset files: /cluster/54/streakfull/ADL4CV/Project/src/AutoSDF-Text2shape/models/rand_tf_model.py, /cluster/54/streakfull/ADL4CV/Project/src/AutoSDF-Text2shape/datasets/ys_shapeset.py\n",
      "1875 LN\n",
      "[*] Start training. name: own-dataset-z-sets-to-sampled-set-rand_tf-owndataset-chair-LR1e-4-clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "[*] autoregressively inferencing...:   0%|          | 0/512 [00:00<?, ?it/s]\n",
      "Warning! Will not return all meshes\n",
      "Warning! Will not return all meshes\n",
      "Warning! Will not return all meshes\n",
      "[*] autoregressively inferencing...:   0%|          | 0/512 [00:00<?, ?it/s]\n",
      "Warning! Will not return all meshes\n",
      "Warning! Will not return all meshes\n",
      "Warning! Will not return all meshes\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n",
      "torch.Size([12288]) torch.Size([512, 24, 512]) SHAPEEEE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 137, in <module>\n",
      "    train_one_epoch()\n",
      "  File \"train.py\", line 82, in train_one_epoch\n",
      "    for i, data in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/tqdm/notebook.py\", line 254, in __iter__\n",
      "    for obj in it:\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 530, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1224, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1250, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/_utils.py\", line 457, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 157, in default_collate\n",
      "    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 157, in <dictcomp>\n",
      "    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n",
      "  File \"/rhome/streakfull/.cache/pypoetry/virtualenvs/adl4cv-I-Koul65-py3.8/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 138, in default_collate\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "RuntimeError: result type Float can't be cast to the desired output type Long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rc = subprocess.call(\"./launchers/train_rand_tf_snet_code.sh\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d356e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Dataset has been created: OwnDataset\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TrainOptions' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2254307/21785327.py\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'owndataset'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/54/streakfull/ADL4CV/Project/src/AutoSDF-Text2shape/datasets/dataloader.py\u001b[0m in \u001b[0;36mCreateDataLoader\u001b[0;34m(opt, drop_last)\u001b[0m\n\u001b[1;32m     43\u001b[0m     train_dl = torch.utils.data.DataLoader(\n\u001b[1;32m     44\u001b[0m             \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_last\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainOptions' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import inspect\n",
    "\n",
    "from termcolor import colored, cprint\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# profiler\n",
    "from torch import profiler\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "\n",
    "from options.train_options import TrainOptions\n",
    "from datasets.dataloader import CreateDataLoader, get_data_generator\n",
    "from models.base_model import create_model\n",
    "\n",
    "from utils.visualizer import Visualizer\n",
    "from utils import util\n",
    "\n",
    "opt = TrainOptions()\n",
    "opt.phase = 'train'\n",
    "\n",
    "seed =111\n",
    "util.seed_everything(seed)\n",
    "\n",
    "opt.dataset_mode='owndataset'\n",
    "train_dl, test_dl = CreateDataLoader(opt)\n",
    "train_ds, test_ds = train_dl.dataset, test_dl.dataset\n",
    "\n",
    "test_dg = get_data_generator(test_dl)\n",
    "\n",
    "dataset_size = len(train_ds)\n",
    "if opt.dataset_mode == 'shapenet_lang':\n",
    "    cprint('[*] # training text snippets = %d' % len(train_ds), 'yellow')\n",
    "    cprint('[*] # testing text snippets = %d' % len(test_ds), 'yellow')\n",
    "else:\n",
    "    cprint('[*] # training images = %d' % len(train_ds), 'yellow')\n",
    "    cprint('[*] # testing images = %d' % len(test_ds), 'yellow')\n",
    "\n",
    "# main loop\n",
    "model = create_model(opt)\n",
    "cprint(f'[*] \"{opt.model}\" initialized.', 'cyan')\n",
    "\n",
    "visualizer = Visualizer(opt)\n",
    "\n",
    "# save model and dataset files\n",
    "expr_dir = '%s/%s' % (opt.logs_dir, opt.name)\n",
    "model_f = inspect.getfile(model.__class__)\n",
    "dset_f = inspect.getfile(train_ds.__class__)\n",
    "cprint(f'[*] saving model and dataset files: {model_f}, {dset_f}', 'blue')\n",
    "modelf_out = os.path.join(expr_dir, os.path.basename(model_f))\n",
    "dsetf_out = os.path.join(expr_dir, os.path.basename(dset_f))\n",
    "os.system(f'cp {model_f} {modelf_out}')\n",
    "os.system(f'cp {dset_f} {dsetf_out}')\n",
    "\n",
    "if opt.vq_cfg is not None:\n",
    "    vq_cfg = opt.vq_cfg\n",
    "    cfg_out = os.path.join(expr_dir, os.path.basename(vq_cfg))\n",
    "    os.system(f'cp {vq_cfg} {cfg_out}')\n",
    "    \n",
    "if opt.tf_cfg is not None:\n",
    "    tf_cfg = opt.tf_cfg\n",
    "    cfg_out = os.path.join(expr_dir, os.path.basename(tf_cfg))\n",
    "    os.system(f'cp {tf_cfg} {cfg_out}')\n",
    "\n",
    "\n",
    "# use profiler or not\n",
    "if opt.profiler == '1':\n",
    "    cprint(\"[*] Using pytorch's profiler...\", 'blue')\n",
    "    tensorboard_trace_handler = profiler.tensorboard_trace_handler(opt.tb_dir)\n",
    "    schedule_args = {'wait': 2, 'warmup': 2, 'active': 6, 'repeat': 1}\n",
    "    schedule = profiler.schedule(**schedule_args)\n",
    "    activities = [profiler.ProfilerActivity.CPU, profiler.ProfilerActivity.CUDA]\n",
    "\n",
    "    \n",
    "\n",
    "################## main training loops #####################\n",
    "def train_one_epoch(pt_profiler=None):\n",
    "    global total_steps\n",
    "    \n",
    "    epoch_iter = 0\n",
    "    for i, data in tqdm(enumerate(train_dl), total=len(train_dl)):\n",
    "        iter_start_time = time.time()\n",
    "        visualizer.reset()\n",
    "        total_steps += opt.batch_size\n",
    "        epoch_iter += opt.batch_size\n",
    "\n",
    "        model.set_input(data)\n",
    "\n",
    "        model.optimize_parameters(total_steps)\n",
    "\n",
    "        nBatches_has_trained = total_steps // opt.batch_size\n",
    "\n",
    "        # if total_steps % opt.print_freq == 0:\n",
    "        if nBatches_has_trained % opt.print_freq == 0:\n",
    "            errors = model.get_current_errors()\n",
    "\n",
    "            t = (time.time() - iter_start_time) / opt.batch_size\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, total_steps, errors, t)\n",
    "\n",
    "        if (nBatches_has_trained % opt.display_freq == 0) or i == 0:\n",
    "            # eval\n",
    "            model.inference(data)\n",
    "            visualizer.display_current_results(model.get_current_visuals(), total_steps, phase='train')\n",
    "\n",
    "            # model.set_input(next(test_dg))\n",
    "            test_data = next(test_dg)\n",
    "            model.inference(test_data)\n",
    "            visualizer.display_current_results(model.get_current_visuals(), total_steps, phase='test')\n",
    "\n",
    "        if total_steps % opt.save_latest_freq == 0:\n",
    "            cprint('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps), 'blue')\n",
    "            latest_name = f'epoch-latest'\n",
    "            model.save(latest_name)\n",
    "        \n",
    "        if pt_profiler is not None:\n",
    "            pt_profiler.step()\n",
    "\n",
    "\n",
    "cprint('[*] Start training. name: %s' % opt.name, 'blue')\n",
    "total_steps = 0\n",
    "for epoch in range(opt.nepochs + opt.nepochs_decay):\n",
    "    epoch_start_time = time.time()\n",
    "    # epoch_iter = 0\n",
    "\n",
    "    # profile\n",
    "    if opt.profiler == '1':\n",
    "         with profiler.profile(\n",
    "            schedule=schedule,\n",
    "            activities=activities,\n",
    "            on_trace_ready=tensorboard_trace_handler,\n",
    "            record_shapes=True,\n",
    "            with_stack=True,\n",
    "        ) as pt_profiler:\n",
    "            train_one_epoch(pt_profiler)\n",
    "    else:\n",
    "        train_one_epoch()\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        cprint('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps), 'blue')\n",
    "        latest_name = f'epoch-latest'\n",
    "        model.save(latest_name)\n",
    "        cur_name = f'epoch-{epoch}'\n",
    "        model.save(cur_name)\n",
    "\n",
    "    # eval every 3 epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        metrics = model.eval_metrics(test_dl)\n",
    "        visualizer.print_current_metrics(epoch, metrics, phase='test')\n",
    "        print(metrics)\n",
    "\n",
    "    cprint(f'[*] End of epoch %d / %d \\t Time Taken: %d sec \\n%s' %\n",
    "        (\n",
    "            epoch, opt.nepochs + opt.nepochs_decay,\n",
    "            time.time() - epoch_start_time,\n",
    "            os.path.abspath( os.path.join(opt.logs_dir, opt.name) )\n",
    "        ), 'blue', attrs=['bold']\n",
    "        )\n",
    "    model.update_learning_rate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd3131d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
