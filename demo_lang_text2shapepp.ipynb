{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image as ipy_image\n",
    "from IPython.display import display\n",
    "\n",
    "from utils.demo_util import get_shape_comp_model, get_shape_comp_opt, make_dummy_batch\n",
    "from utils.qual_util import load_bert2vqsc_model, get_lang_prob, save_mesh_as_gif\n",
    "from utils.util import seed_everything\n",
    "from utils.util_3d import init_mesh_renderer, sdf_to_mesh\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(111)\n",
    "\n",
    "res_dir = 'results'\n",
    "if not os.path.exists(res_dir): os.makedirs(res_dir)\n",
    "\n",
    "gpu_id = 0\n",
    "nimgs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Working with z of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "[*] VQVAE: weight successfully load from: /home/fslsegment/sercan/AutoSDF-Text2shape/pretrained_ckpts_text2shapepp/vqvae.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fslsegment/miniconda3/envs/ddf/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Model has been created: Rand-Transformer-Model\n",
      "[*] \"rand_tf\" initialized.\n",
      "[*] weight successfully load from: /home/fslsegment/sercan/AutoSDF-Text2shape/pretrained_ckpts_text2shapepp/rand_tf_singles_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "opt = get_shape_comp_opt(gpu_id=gpu_id)\n",
    "opt.dataset_mode = \"text2shape\"\n",
    "model = get_shape_comp_model(opt)    \n",
    "model.eval()\n",
    "\n",
    "\"\"\" setup renderer \"\"\"\n",
    "dist, elev, azim = 1.7, 20, 20\n",
    "mesh_renderer = init_mesh_renderer(image_size=256, dist=dist, elev=elev, azim=azim, device=opt.device)\n",
    "\n",
    "opt.mlp_layers = 3\n",
    "opt.mlp_hidden = 1024\n",
    "bert2vq = load_bert2vqsc_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 512])\n",
      "torch.Size([512, 1, 512]) torch.Size([512, 1, 512])\n",
      "torch.Size([513, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:03<00:00, 134.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 512])\n",
      "torch.Size([512, 1, 512]) torch.Size([512, 1, 512])\n",
      "torch.Size([513, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:03<00:00, 137.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 1, 512])\n",
      "torch.Size([512, 1, 512]) torch.Size([512, 1, 512])\n",
      "torch.Size([513, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 512/512 [00:03<00:00, 138.13it/s]\n"
     ]
    },
    {
     "data": {
      "image/gif": "R0lGODlhAAEAAYIAAP///39/f5OTk4yMjKamprW1tcXFxQAAACH5BAEAAAAALAAAAAAAAQABQAj/AAEIHEiwoMGDCBMqXMiwocOHECNKnEixosWLGDNq3Mixo8ePIEOKHEmypMmTKFOqXMmypcuXMGPKnEmzps2bOHPq3Mmzp8+fQIMKHUoUaICjSJMqXcq0qdOnRaPufEq1qtWqA6RqtXm1q1erW8PG/Eq27NKsYtOKNMu2LVi1cCW6nUvXKdq4eAnW3cvXbt68AgILFjxgQN/DVgsrXnz0L+DBhBUjnqy0MOTLjh9fFiCZ8mTLmwdn1hy6tOnTqFOHHqBawOi/lxfLnk27tu3buG+nfq0Zd2vIuVn/Hr6ZN+zgiokrR+4bs3HAyQUTKExgowEDBbIXIMC9O/fSzGcL/35OXmho7uXTq1/Pvr379/Djy59Pv779+/jz69/Pv7///wAGKOCABBZo4IEIJqjgggw26KBAns314FARunXXhD5V6BaGU3VlmIZVcQgTiCQiJWJJiBVWIlUXnniRZLOtKGOLLlq0WWcy1gVaaTVqBJ6KWFGXI1M78thjRspxFh6OERZZ3JE+JinllFSOB2WUgy2p5Zbh7Xalj7JVuVpuYp725UZc6jZlmmqe6VF23em0nXfdmenmnXjmqeeefPbp55+ABirooIQWauihiCaq6KKMNuroo5BGKumklFZq6aWYZqrpppx26imDQ7716UKhYjUqqaWyeKpCqVK1akKtuv/6qkGxqjorhE8xGeqqtW6Iaa97VQpsX5LupWurNCI6rGfJDrqshs0C+uOzxiY6JrUeCheatTcCiW2u2m6L6Jje2iUAAQX06uST4177bVPrOtcuueW+G69oipYpJZtqmsaovgAHLC+3sfFLpsCtNVqwwQxziZrCWSK3sMGq2eblooHVVubBCLP7b5gdT3xvxrQR92jDi1GJcpGQineuktEFRufMdCa5snCREgBcYSzB6Z2Yt9ZUp8dBzzRYdwUUrfTSTDft9NNQRy311FRXbfXVWGet9dZcd+3112CHLfbYZJdt9tlop6322my37fbbcMct99x012333XjnrffefPf/7fffgAcu+J9lzU3t0986nXjT2EbL6+JLf+v4qd+6xjTkSn94+OWYF/0u55Ir/e5Rk2uaWL1Dvjq6rJuuflWmrnd1aexeWUp77ZPe/lXuOi5buqHGHlvq74LqbhbxhBt/vKLKW5ho884fehv0ic1bMPUhHjot9SUHFgDBO3Nvp/YTNz9yYOBHrLnu51tOfvlVCeD7w9arvz68gWVXa/vuv78w++ESV/0iZjz+5Ytet2sfxk6DHGApUFE609fNUMeiABLNUCGT4JIulr4MevA3//qgCEG4wG6BLDIjDFgIdzZBfgEMYvZroQxTNr4DxnCGMuRgB3HIJpj1y18r9GH3qyqmJZvRsIY2/CFxgpPC/h3QZRpszgcfRTL+qUyJAqOixprIwg0iMV8UAxjKINMyHC7xZlZy1Ba3GLIWou9kNOROAQyAFp3JMTsIuQ52fEaz75hmjE4sYbgsQxLtzOlnP9LYEQPJKEQibyR8RCQJ8YYdPwpQb5YkY98ugzTA3RGPgwulKEdJylKa8pSoTKUqV8nKVrrylbCMpSxnScta2vKWuMylLnfJS+MEBAA7\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.dataloader import CreateDataLoader\n",
    "import torch\n",
    "from utils.qual_util import get_lang_prob_recursive, save_mesh_as_pics\n",
    "from einops import rearrange\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "from utils.demo_util import make_dummy_batch\n",
    "with open(f'./info-shapenet.json') as f:\n",
    "    info = json.load(f)\n",
    "\n",
    "# model_list = []\n",
    "# cat_to_id = info['cats']\n",
    "# all_files = glob.glob(f\"/home/fslsegment/sercan/shap/*/*\")\n",
    "# with open(f'./filelists/{cat_to_id[\"chair\"]}_train.lst') as f:\n",
    "#     lang_list_s = []\n",
    "#     model_list_s = []\n",
    "#     for l in f.readlines():\n",
    "#         model_id = l.rstrip('\\n')\n",
    "#         model_list.append(model_id)\n",
    "# with open(f'./filelists/{cat_to_id[\"chair\"]}_test.lst') as f:\n",
    "\n",
    "#     for l in f.readlines():\n",
    "#         model_id = l.rstrip('\\n')\n",
    "#         model_list.append(model_id)\n",
    "# set_zs = [p for p in all_files if \"z_set\" in p and p.split(\"/\")[-2] in model_list]\n",
    "# shape_zs = [p for p in all_files if \"z\" in p and \"set\" not in p and p.split(\"/\")[-2] in model_list]\n",
    "# set2path = {p.split(\"/\")[-1].split(\"_\")[-1].replace(\".pt\", \"\"): p for p in set_zs}\n",
    "# print(list(set2path.keys())[:10])\n",
    "# mod2code_path = {p.split(\"/\")[-2]: p for p in shape_zs}\n",
    "# text2shapepp = pd.read_csv('./similar_phrase_2.csv')\n",
    "# with open(\"file.json\", 'r') as f:\n",
    "#     all_id_list = json.load(f)\n",
    "# sequences = all_id_list\n",
    "# model_list = []\n",
    "\n",
    "# seq = sequences[155]\n",
    "# print(seq)\n",
    "# t_2_row_ind = seq[1]\n",
    "\n",
    "# t_2_row = text2shapepp.iloc[t_2_row_ind]\n",
    "# t_2_text = t_2_row[\"phrase_texts\"]\n",
    "# t_2_row = text2shapepp.iloc[t_2_row_ind]\n",
    "# t_2_code = torch.load(set2path[str(t_2_row_ind)], map_location=\"cpu\")\n",
    "# print(t_2_text)\n",
    "z1 = torch.full((1,8,8,8,512), 1/512).cuda()\n",
    "# last_text = \"\"\n",
    "\n",
    "prompts = [\"The chair has short legs\", \"A wodden chair polished yellow colour with a reclining back\", \"and a square horizontal armrest on both the sides\"]\n",
    "test_data = make_dummy_batch(nimgs)\n",
    "last_text = \"\"\n",
    "for i,text in enumerate(prompts):\n",
    "    \n",
    "\n",
    "    text_conditional = text\n",
    "    lang_conditional_prob = get_lang_prob_recursive(bert2vq, nimgs*[text_conditional], z1)\n",
    "    print(lang_conditional_prob.shape)\n",
    "    z1_old = rearrange(z1, 'bs d h w c -> (d h w) bs c')\n",
    "    print(lang_conditional_prob.shape, z1_old.shape)\n",
    "    gen_order = torch.argsort((torch.abs(lang_conditional_prob-z1_old)).sum(-1).squeeze(1), dim=0, descending=True)\n",
    "    \n",
    "    # lang_conditional_prob = lang_conditional_prob.repeat(1, nimgs, 1)\n",
    "    topk = 3\n",
    "    alpha = 0.5 + 0.1*i\n",
    "\n",
    "    model.inference(test_data,topk=topk, prob=lang_conditional_prob, alpha=alpha, gen_order=gen_order)\n",
    "    \n",
    "    gen_mesh = sdf_to_mesh(model.x_recon_tf)\n",
    "    pred_probs = model.x_probs\n",
    "    z1 = rearrange(pred_probs, '(d h w) bs c -> bs d h w c', d=8, h=8, w=8)\n",
    "    test_data[\"idx\"] = rearrange(model.pred, '(d1 d2 d3) bs-> bs d1 d2 d3', d1=8, d2=8, d3=8).cpu()\n",
    "    gen_gif_name = f'{res_dir}/lang-guided-gen{text_conditional}.gif'\n",
    "    save_mesh_as_pics(mesh_renderer, gen_mesh, nrow=1, out_name=gen_gif_name)\n",
    "    last_text = text + \" \"\n",
    "\n",
    "for name in [gen_gif_name]:\n",
    "    display(ipy_image(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(512, device='cuda').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  5 00:14:18 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.182.03   Driver Version: 470.182.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 22%   38C    P8    28W / 250W |      0MiB / 12211MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN V      Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 28%   39C    P8    26W / 250W |      0MiB / 12066MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 53%   42C    P8    42W / 350W |  20851MiB / 24268MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A     30186      C   ...onda3/envs/ddf/bin/python    20849MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 30186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 15035), started 0:01:25 ago. (Use '!kill 15035' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cfc98abd9dfe8107\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cfc98abd9dfe8107\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "                     USER        PID ACCESS COMMAND\n",
      "6006/tcp:            fslsegment  15035 F.... tensorboard\n"
     ]
    }
   ],
   "source": [
    "!fuser -v -n tcp 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!kill -9 15035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5d5b7059ba695b6f22126def3ee4bd4e191bfd0bb6fdbdd231b6709d761b01f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
