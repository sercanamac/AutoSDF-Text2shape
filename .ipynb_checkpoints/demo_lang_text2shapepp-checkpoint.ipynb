{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image as ipy_image\n",
    "from IPython.display import display\n",
    "\n",
    "from utils.demo_util import get_shape_comp_model, get_shape_comp_opt, make_dummy_batch\n",
    "from utils.qual_util import load_bert2vqsc_model, get_lang_prob, save_mesh_as_gif\n",
    "from utils.util import seed_everything\n",
    "from utils.util_3d import init_mesh_renderer, sdf_to_mesh\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(111)\n",
    "\n",
    "res_dir = 'results'\n",
    "if not os.path.exists(res_dir): os.makedirs(res_dir)\n",
    "\n",
    "gpu_id = 0\n",
    "nimgs=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Working with z of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "[*] VQVAE: weight successfully load from: /home/amac/data/vqvae.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amac/miniconda3/envs/ddf/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3190.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Model has been created: Rand-Transformer-Model\n",
      "[*] \"rand_tf\" initialized.\n",
      "[*] weight successfully load from: /home/amac/data/rand_tf_singles_best.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "opt = get_shape_comp_opt(gpu_id=gpu_id)\n",
    "opt.dataset_mode = \"text2shape\"\n",
    "model = get_shape_comp_model(opt)    \n",
    "model.eval()\n",
    "\n",
    "\"\"\" setup renderer \"\"\"\n",
    "dist, elev, azim = 1.7, 20, 20\n",
    "mesh_renderer = init_mesh_renderer(image_size=256, dist=dist, elev=elev, azim=azim, device=opt.device)\n",
    "\n",
    "opt.mlp_layers = 3\n",
    "opt.mlp_hidden = 1024\n",
    "bert2vq = load_bert2vqsc_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████| 512/512 [00:07<00:00, 65.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 8, 8, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████| 512/512 [00:07<00:00, 66.18it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 8, 8, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*] autoregressively inferencing...: 100%|██████████| 512/512 [00:07<00:00, 65.83it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 8, 8, 8])\n"
     ]
    },
    {
     "data": {
      "image/gif": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets.dataloader import CreateDataLoader\n",
    "import torch\n",
    "from utils.qual_util import get_lang_prob_recursive, save_mesh_as_pics\n",
    "from einops import rearrange\n",
    "\n",
    "z1 = torch.full((1,8,8,8,512), 1/512).cuda()\n",
    "last_text = \"\"\n",
    "z_init = torch.load(\"/home/amac/data/chairs/bf3c02f71de0260a8dfc31d0ab372d9c/z_shape.pt\", map_location=\"cpu\")\n",
    "\n",
    "prompts = [\"an office chair\", \"with long back\", \"without arms\", ]\n",
    "test_data = make_dummy_batch(nimgs)\n",
    "sampler = torch.distributions.categorical.Categorical(z1)\n",
    "codeix = sampler.sample()\n",
    "test_data[\"code\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "test_data[\"idx\"] = sampler.sample().repeat_interleave(nimgs, axis=0).cpu()\n",
    "\n",
    "for text in prompts:\n",
    "    \n",
    "\n",
    "    text_conditional = last_text + text\n",
    "    lang_conditional_prob = get_lang_prob_recursive(bert2vq, text_conditional, z1)\n",
    "    z1_old = rearrange(z1, 'bs d h w c -> (d h w bs) c')\n",
    "    z1 = rearrange(lang_conditional_prob, '(d h w) bs c -> bs d h w c', d=8, h=8, w=8)\n",
    "\n",
    "    gen_order = torch.argsort((torch.abs(lang_conditional_prob[:, 0, :]-z1_old)).sum(-1), dim=-1, descending=True)\n",
    "\n",
    "    lang_conditional_prob = lang_conditional_prob.repeat(1, nimgs, 1)\n",
    "    topk = 50\n",
    "    alpha = .5\n",
    "\n",
    "    model.inference(test_data, topk=topk, prob=None, alpha=alpha, gen_order=None)\n",
    "    test_data[\"code\"] = z1.repeat_interleave(nimgs, dim=0)\n",
    "    sampler = torch.distributions.categorical.Categorical(z1)\n",
    "    test_data[\"idx\"] = torch.cat( [sampler.sample().cpu() for i in range(6)], dim=0)\n",
    "    print(test_data[\"idx\"].shape)\n",
    "    gen_mesh = sdf_to_mesh(model.x_recon_tf)\n",
    "    \n",
    "    gen_gif_name = f'{res_dir}/lang-guided-gen{text_conditional}.gif'\n",
    "    save_mesh_as_pics(mesh_renderer, gen_mesh, nrow=3, out_name=gen_gif_name)\n",
    "    last_text = text_conditional + \" \"\n",
    "\n",
    "for name in [gen_gif_name]:\n",
    "    display(ipy_image(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(512, device='cuda').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5838d28a96dbe8fdf9e2c297fc8cad3e28297307de97d2852e60d93cca6675fa"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
